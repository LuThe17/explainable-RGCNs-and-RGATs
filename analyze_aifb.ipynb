{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch.tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minline\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensor\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtensor\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch.tensor'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.tensor as tensor\n",
    "import pickle\n",
    "import os\n",
    "from rdflib import Graph\n",
    "import rdflib as rdf\n",
    "import os\n",
    "from scipy import sparse\n",
    "import re\n",
    "from collections import defaultdict\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_pickle_without_ending(path):\n",
    "    \"\"\"\n",
    "    Read all pickle files in a directory and return a list of the dataframes.\n",
    "    \"\"\"\n",
    "    files = os.listdir(path)\n",
    "    files = [file for file in files if file.endswith(\".pkl\")]\n",
    "    files.sort()\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        dfs.append(pd.read_pickle(path + file))\n",
    "    return dfs\n",
    "\n",
    "def readallcsvinpath(path):\n",
    "    \"\"\"\n",
    "    Read all csv files in a directory and return a list of the dataframes.\n",
    "    \"\"\"\n",
    "    fil = os.listdir(path)\n",
    "    fil = [file for file in fil if file.endswith(\".csv\")]\n",
    "    fil.sort()\n",
    "    dfs = []\n",
    "    for file in fil:\n",
    "        dfs.append(pd.read_csv(path + file))\n",
    "    return dfs\n",
    "def get_nameincolfor_index(df,id_list):\n",
    "    \"\"\"\n",
    "    # df: dataframe\n",
    "    # id_list: list of ids\n",
    "    # return: list of names of ids\n",
    "    \"\"\"\n",
    "    name_list=[]\n",
    "    for i in id_list:\n",
    "        name_list.append(df[df.index==i][0].values[0])\n",
    "    return name_list\n",
    "def cut_string(list):\n",
    "    for i in range(len(list)):\n",
    "        list[i] = list[i].split('mov')[1]\n",
    "    return list\n",
    "def parse_tensor_string(tensor_str):\n",
    "    values_str = re.search(r'\\[(.*?)\\]', tensor_str).group(1)\n",
    "    values = [float(val) for val in values_str.split(', ')]\n",
    "    return torch.tensor(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = read_all_pickle_without_ending('out/AIFB/RGAT_no_emb/')\n",
    "csv = readallcsvinpath('out/AIFB/RGAT_no_emb/')\n",
    "data = torch.load('out/AIFB/RGAT_no_emb/pred_before.pt')\n",
    "test_file = pd.read_csv('data/AIFB/testSet.tsv', sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(indices=tensor([[   5,   27,   31,   35,   43,   55,   58,   63,   67,\n",
      "                         106,  111,  120,  122,  154,  166,  238,  254,  284,\n",
      "                         310,  315,  330,  334,  347,  355,  357,  372,  378,\n",
      "                         386,  392,  411,  431,  446,  455,  457,  488,  495,\n",
      "                         501,  505,  509,  510,  517,  519,  525,  542,  544,\n",
      "                         566,  568,  613,  628,  646,  654,  659,  666,  668,\n",
      "                         675,  676,  687,  703,  708,  721,  752,  778,  797,\n",
      "                         822,  841,  842,  860,  865,  867,  871,  878,  885,\n",
      "                         888,  898,  914,  915,  930,  934,  950,  955,  961,\n",
      "                         997, 1001, 1014, 1019, 1021, 1022, 1025, 1084, 1095,\n",
      "                        1098, 1107, 1133, 1139, 1163, 1173, 1205, 1210, 1218,\n",
      "                        1285, 1291, 1316, 1318, 1323, 1347, 1365, 1378, 1384,\n",
      "                        1428, 1473, 1475, 1476, 1523, 1534, 1543, 1553, 1571,\n",
      "                        1579, 1593, 1607, 1610, 1633, 1648, 1662, 1678, 1681,\n",
      "                        1693, 1697, 1736, 1737, 1756, 1763, 1764, 1773, 1796,\n",
      "                        1800, 1815, 1820, 1827, 1851, 1852, 1870, 1873, 1916,\n",
      "                        1921, 1930, 1934, 1967, 1993, 2015, 2047, 2063, 2065,\n",
      "                        2067, 2071, 2079, 2086, 2092, 2100, 2125, 2132, 2166,\n",
      "                        2169, 2191, 2222, 2223, 2257, 2266, 2270, 2278, 2293,\n",
      "                        2295, 2359, 2360, 2400, 2410, 2415, 2434, 2448, 2449,\n",
      "                        2494, 2498, 2500, 2552, 2585, 2634, 2645, 2647, 2668,\n",
      "                        2673, 2674, 2688, 2693, 2696, 2702, 2713, 2721, 2740,\n",
      "                        2754, 2758, 2777]]),\n",
      "       values=tensor([-1.2026e-06,  1.2056e-07,  4.6418e-07, -3.5247e-09,\n",
      "                      -6.4417e-06, -6.7219e-09,  5.5414e-08,  5.8645e-01,\n",
      "                      -4.3485e-07,  2.3141e-06,  9.4506e-06, -1.7667e-07,\n",
      "                       1.2069e-06,  6.5684e-08, -8.0829e-08,  3.6947e-08,\n",
      "                       1.9371e-07, -4.1093e-06,  3.8812e-07,  2.8057e-07,\n",
      "                      -8.0189e-06, -1.3698e-07,  1.3310e-08, -2.6416e-07,\n",
      "                      -3.5484e-05,  7.2307e-08, -1.6115e-05,  5.0478e-07,\n",
      "                       2.3874e-07, -1.7204e-07, -4.8716e-08, -1.4230e-07,\n",
      "                      -5.6159e-08,  1.6473e-07, -1.4185e-07,  8.7655e-08,\n",
      "                      -2.8369e-07, -3.2233e-07, -6.5602e-07,  7.7701e-07,\n",
      "                       4.6430e-07,  2.9321e-07,  4.5333e-07, -4.4206e-07,\n",
      "                       3.9063e-07, -3.2059e-07,  5.1823e-08,  3.4678e-01,\n",
      "                       5.0022e-07,  1.7453e-07,  7.5646e-07,  5.0181e-08,\n",
      "                       4.7007e-07,  3.5883e-07, -4.9142e-08,  1.6347e-07,\n",
      "                      -1.6020e-07,  3.8899e-06, -4.6224e-07,  8.4634e-07,\n",
      "                      -7.5685e-07,  1.0434e-07, -1.4852e-07,  2.3620e-07,\n",
      "                      -3.2664e-08, -6.6154e-07, -4.9346e-07, -1.9170e-07,\n",
      "                      -4.6357e-08, -4.9288e-05,  3.6397e-07,  1.4565e-07,\n",
      "                       5.2686e-08,  2.6322e-07,  4.4723e-08,  4.6550e-07,\n",
      "                       5.5752e-08,  4.4033e-07,  4.6952e-07, -1.7511e-08,\n",
      "                      -1.6553e-07, -4.1996e-07, -2.5387e-08,  1.4104e-01,\n",
      "                      -8.4923e-01,  5.8379e-01,  7.1075e-05, -2.4818e+00,\n",
      "                       5.6528e-01, -4.9343e-08, -3.8432e-07, -3.1156e-07,\n",
      "                       1.6713e-07, -3.9118e-07,  6.9399e-06, -2.3166e-07,\n",
      "                      -4.0396e-08,  5.7044e-07, -3.0228e-07,  7.0972e-01,\n",
      "                      -5.2254e-07, -1.7618e-07, -4.7445e-07, -6.8696e-07,\n",
      "                       1.3648e-08,  5.3954e-07, -7.4827e-08,  4.0069e-07,\n",
      "                      -4.8871e-07,  2.7360e-07,  2.0119e-07, -6.7943e-07,\n",
      "                      -3.0411e-08,  2.7254e-07, -1.1619e-07,  2.6892e-08,\n",
      "                      -6.5766e-07,  5.1407e-06, -3.4362e-07,  1.3040e-07,\n",
      "                      -4.5559e-07,  4.1256e-07, -9.3782e-10,  3.1499e-07,\n",
      "                      -4.4089e-07,  7.0478e-01, -8.8466e-08, -2.5959e-07,\n",
      "                      -1.7688e-07,  2.3885e-07,  2.2339e-07, -4.4645e-07,\n",
      "                      -1.0589e-07, -2.8809e-07,  2.1014e-07, -4.1161e-07,\n",
      "                       6.5927e-08,  2.5766e-07, -5.3358e-07, -3.2543e-07,\n",
      "                      -3.8425e-07,  1.0249e-07,  7.5481e-08,  1.9755e-07,\n",
      "                       1.8442e-07,  4.3784e-05,  1.8681e-07,  5.4492e-08,\n",
      "                      -9.7288e-08,  2.0445e-07, -2.5113e-07, -3.4758e-08,\n",
      "                      -2.0676e-08, -5.8979e-07, -1.7134e-07, -4.5111e-07,\n",
      "                      -1.3009e-07, -1.8273e-07, -3.5259e-07, -5.1623e-06,\n",
      "                       3.7383e-01,  2.1439e-07,  3.8080e-07, -3.5446e-08,\n",
      "                      -1.2622e-06, -4.6855e-07,  2.0099e-07, -8.5925e-06,\n",
      "                      -3.6112e-07,  1.8413e-07,  8.0351e-08,  3.3192e-07,\n",
      "                       6.3512e-06,  2.3034e-08, -6.8024e-08,  3.0572e-07,\n",
      "                      -2.8700e-08, -7.9076e-09, -2.3028e-07,  9.4484e-08,\n",
      "                      -2.2407e-07,  1.1102e-04,  5.3959e-07, -1.8498e-07,\n",
      "                      -5.0634e-07, -2.8982e-07, -3.1890e-07,  5.2781e-08,\n",
      "                      -3.8360e-07,  3.7467e-07, -1.4179e-07,  4.4832e-07,\n",
      "                       3.1931e-01,  3.1952e-07, -2.0423e-06,  8.2456e-07,\n",
      "                      -9.4745e-09, -2.5407e-07, -2.8479e-07,  1.6313e-07,\n",
      "                      -2.9002e-07]),\n",
      "       size=(2835,), nnz=201, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([[   4,    6,   13,   15,   18,   20,   21,   22,   23,\n",
      "                          24,   25,   28,   30,   34,   37,   40,   42,   45,\n",
      "                          47,   51,   54,   56,   59,   63,   64,   65,   66,\n",
      "                          68,   70,   75,   80,   81,   88,   91,   93,   97,\n",
      "                          98,  103,  104,  111,  112,  113,  116,  123,  126,\n",
      "                         128,  129,  130,  132,  134,  136,  137,  139,  140,\n",
      "                         147,  148,  150,  152,  153,  158,  160,  161,  169,\n",
      "                         173,  174,  178,  181,  184,  186,  194,  195,  198,\n",
      "                         202,  203,  205,  209,  210,  212,  215,  218,  222,\n",
      "                         225,  229,  232,  236,  237,  239,  241,  245,  248,\n",
      "                         249,  257,  261,  263,  267,  268,  269,  272,  275,\n",
      "                         277,  278,  280,  281,  282,  287,  288,  290,  296,\n",
      "                         299,  301,  302,  303,  311,  313,  317,  322,  324,\n",
      "                         325,  327,  329,  331,  332,  333,  335,  339,  341,\n",
      "                         343,  344,  346,  349,  350,  362,  366,  369,  370,\n",
      "                         371,  372,  373,  374,  376,  377,  379,  380,  381,\n",
      "                         393,  395,  396,  399,  403,  404,  406,  409,  413,\n",
      "                         419,  420,  422,  423,  425,  430,  432,  434,  435,\n",
      "                         436,  442,  444,  447,  448,  449,  453,  454,  457,\n",
      "                         458,  460,  472,  473,  476,  478,  482,  486,  487,\n",
      "                         489,  490,  493,  496,  500,  504,  513,  518,  524,\n",
      "                         526,  528,  530,  532,  537,  540,  545,  549,  550,\n",
      "                         554,  556,  557,  560,  562,  563,  570,  571,  573,\n",
      "                         575,  576,  577,  579,  580,  581,  584,  586,  588,\n",
      "                         593,  600,  604,  606,  608,  610,  612,  613,  614,\n",
      "                         615,  618,  619,  620,  621,  626,  631,  632,  635,\n",
      "                         636,  639,  641,  647,  650,  651,  652,  655,  657,\n",
      "                         667,  669,  674,  678,  683,  686,  689,  691,  692,\n",
      "                         694,  695,  701,  704,  710,  711,  712,  714,  717,\n",
      "                         718,  719,  720,  722,  723,  725,  726,  727,  730,\n",
      "                         731,  735,  736,  739,  741,  743,  746,  749,  750,\n",
      "                         757,  760,  762,  764,  769,  773,  776,  777,  779,\n",
      "                         784,  786,  789,  791,  793,  796,  800,  801,  806,\n",
      "                         807,  808,  809,  810,  811,  818,  820,  828,  829,\n",
      "                         831,  834,  838,  839,  840,  850,  852,  856,  858,\n",
      "                         859,  873,  875,  876,  877,  880,  904,  905,  906,\n",
      "                         907,  909,  910,  917,  921,  922,  926,  927,  928,\n",
      "                         929,  935,  936,  939,  940,  941,  942,  943,  946,\n",
      "                         949,  951,  954,  963,  971,  972,  975,  979,  981,\n",
      "                         982,  983,  984,  988,  989, 1003, 1007, 1010, 1015,\n",
      "                        1017, 1018, 1019, 1021, 1023, 1025, 1027, 1029, 1030,\n",
      "                        1032, 1036, 1037, 1044, 1050, 1051, 1053, 1056, 1065,\n",
      "                        1068, 1069, 1071, 1072, 1075, 1076, 1077, 1079, 1080,\n",
      "                        1082, 1083, 1084, 1090, 1091, 1094, 1100, 1104, 1105,\n",
      "                        1106, 1109, 1114, 1116, 1118, 1129, 1135, 1138, 1141,\n",
      "                        1142, 1144, 1147, 1157, 1161, 1164, 1166, 1168, 1171,\n",
      "                        1176, 1177, 1178, 1180, 1181, 1182, 1183, 1191, 1195,\n",
      "                        1196, 1203, 1204, 1207, 1211, 1219, 1220, 1224, 1225,\n",
      "                        1229, 1232, 1233, 1237, 1238, 1239, 1245, 1247, 1250,\n",
      "                        1251, 1253, 1254, 1257, 1258, 1261, 1263, 1264, 1267,\n",
      "                        1269, 1270, 1272, 1274, 1280, 1284, 1285, 1286, 1287,\n",
      "                        1292, 1295, 1308, 1311, 1315, 1319, 1324, 1329, 1330,\n",
      "                        1331, 1336, 1337, 1338, 1342, 1343, 1345, 1346, 1349,\n",
      "                        1350, 1352, 1355, 1358, 1368, 1369, 1372, 1373, 1376,\n",
      "                        1381, 1383, 1385, 1389, 1392, 1395, 1396, 1402, 1403,\n",
      "                        1405, 1407, 1414, 1415, 1417, 1418, 1419, 1423, 1424,\n",
      "                        1425, 1426, 1431, 1438, 1439, 1442, 1444, 1445, 1446,\n",
      "                        1447, 1449, 1451, 1454, 1458, 1459, 1460, 1464, 1468,\n",
      "                        1469, 1470, 1471, 1482, 1490, 1491, 1492, 1493, 1503,\n",
      "                        1510, 1515, 1517, 1518, 1521, 1524, 1525, 1528, 1531,\n",
      "                        1535, 1536, 1538, 1545, 1546, 1548, 1549, 1556, 1560,\n",
      "                        1561, 1563, 1564, 1565, 1566, 1567, 1568, 1570, 1573,\n",
      "                        1574, 1576, 1578, 1584, 1585, 1586, 1590, 1592, 1595,\n",
      "                        1599, 1601, 1603, 1614, 1615, 1616, 1617, 1619, 1620,\n",
      "                        1623, 1630, 1631, 1634, 1636, 1638, 1639, 1641, 1645,\n",
      "                        1647, 1649, 1653, 1657, 1659, 1664, 1665, 1666, 1671,\n",
      "                        1674, 1677, 1679, 1683, 1685, 1687, 1696, 1698, 1701,\n",
      "                        1702, 1703, 1704, 1706, 1707, 1711, 1716, 1717, 1721,\n",
      "                        1722, 1724, 1729, 1731, 1734, 1735, 1738, 1741, 1744,\n",
      "                        1746, 1747, 1748, 1758, 1760, 1766, 1771, 1772, 1776,\n",
      "                        1777, 1778, 1783, 1784, 1789, 1790, 1791, 1793, 1794,\n",
      "                        1803, 1805, 1808, 1809, 1814, 1818, 1822, 1830, 1831,\n",
      "                        1833, 1834, 1835, 1838, 1839, 1841, 1842, 1843, 1846,\n",
      "                        1847, 1854, 1856, 1863, 1866, 1868, 1872, 1874, 1875,\n",
      "                        1878, 1883, 1884, 1885, 1886, 1894, 1896, 1900, 1901,\n",
      "                        1909, 1914, 1917, 1919, 1920, 1924, 1925, 1928, 1929,\n",
      "                        1932, 1936, 1938, 1939, 1942, 1943, 1944, 1945, 1946,\n",
      "                        1948, 1952, 1954, 1957, 1958, 1960, 1961, 1963, 1965,\n",
      "                        1974, 1975, 1981, 1994, 1995, 1997, 2001, 2004, 2011,\n",
      "                        2012, 2014, 2016, 2017, 2019, 2027, 2029, 2030, 2031,\n",
      "                        2035, 2037, 2038, 2040, 2041, 2044, 2045, 2048, 2056,\n",
      "                        2058, 2060, 2062, 2072, 2073, 2075, 2080, 2082, 2083,\n",
      "                        2089, 2094, 2095, 2097, 2099, 2101, 2108, 2112, 2114,\n",
      "                        2116, 2117, 2126, 2128, 2132, 2133, 2134, 2136, 2138,\n",
      "                        2145, 2148, 2153, 2155, 2158, 2160, 2162, 2170, 2172,\n",
      "                        2173, 2174, 2175, 2176, 2178, 2179, 2182, 2186, 2187,\n",
      "                        2192, 2193, 2194, 2196, 2201, 2203, 2207, 2209, 2210,\n",
      "                        2212, 2215, 2216, 2221, 2225, 2230, 2231, 2232, 2239,\n",
      "                        2240, 2242, 2248, 2250, 2251, 2258, 2259, 2265, 2269,\n",
      "                        2273, 2276, 2292, 2297, 2301, 2306, 2307, 2308, 2312,\n",
      "                        2313, 2322, 2324, 2325, 2327, 2345, 2346, 2351, 2352,\n",
      "                        2353, 2362, 2365, 2367, 2371, 2373, 2380, 2383, 2386,\n",
      "                        2390, 2396, 2397, 2398, 2401, 2403, 2409, 2416, 2418,\n",
      "                        2420, 2422, 2423, 2426, 2427, 2428, 2429, 2431, 2436,\n",
      "                        2437, 2439, 2443, 2444, 2446, 2456, 2459, 2463, 2464,\n",
      "                        2466, 2467, 2468, 2470, 2472, 2473, 2477, 2480, 2484,\n",
      "                        2488, 2496, 2497, 2503, 2509, 2512, 2514, 2516, 2517,\n",
      "                        2521, 2525, 2526, 2527, 2528, 2533, 2534, 2536, 2537,\n",
      "                        2538, 2542, 2545, 2546, 2547, 2550, 2554, 2558, 2561,\n",
      "                        2564, 2566, 2567, 2568, 2573, 2576, 2577, 2580, 2582,\n",
      "                        2583, 2585, 2589, 2590, 2601, 2605, 2606, 2607, 2609,\n",
      "                        2610, 2613, 2614, 2616, 2617, 2621, 2629, 2631, 2632,\n",
      "                        2634, 2638, 2640, 2643, 2652, 2653, 2667, 2670, 2676,\n",
      "                        2680, 2685, 2686, 2689, 2693, 2699, 2700, 2701, 2706,\n",
      "                        2709, 2710, 2715, 2716, 2718, 2719, 2728, 2733, 2736,\n",
      "                        2739, 2741, 2742, 2743, 2744, 2745, 2747, 2750, 2753,\n",
      "                        2755, 2762, 2764, 2766, 2773, 2776, 2778, 2780, 2781,\n",
      "                        2782, 2783, 2784, 2786, 2789, 2790, 2791, 2800, 2802,\n",
      "                        2804, 2805, 2809, 2817, 2818, 2819, 2827, 2830, 2833]]),\n",
      "       values=tensor([-1.2866e-07, -3.6175e-07, -1.0994e-06,  4.3574e-07,\n",
      "                       7.5500e-08, -8.2422e-08, -7.3660e-07,  1.6655e-04,\n",
      "                       5.3406e-07,  8.0067e-08,  4.3014e-07,  8.2770e-07,\n",
      "                      -3.2271e-07, -6.1165e-07, -6.0992e-07,  3.5972e-07,\n",
      "                      -8.5203e-07, -6.0513e-07,  4.8385e-07, -1.4359e-07,\n",
      "                       5.6319e-07, -7.6395e-07,  1.4808e-06,  1.9557e-01,\n",
      "                      -1.3109e-04, -1.0437e-07, -8.0298e-07, -7.6841e-07,\n",
      "                       5.1124e-07,  3.8004e-07,  1.4553e-07, -3.0069e-08,\n",
      "                       3.5941e-07, -2.5924e-07,  2.0503e-07,  1.4162e-06,\n",
      "                      -5.7939e-07,  6.3107e-06,  2.5071e-07,  4.5520e-03,\n",
      "                      -3.4734e-07, -2.7601e-07, -2.7713e-07,  1.0098e-06,\n",
      "                      -4.5815e-07, -5.1775e-07, -3.5518e-07,  2.1519e-04,\n",
      "                      -8.6248e-07,  4.6436e-06,  3.2006e-07,  1.2494e-09,\n",
      "                       2.0370e-03,  7.1024e-08, -8.8146e-07,  1.1099e-07,\n",
      "                       3.9368e-02,  6.5750e-08, -6.1261e-08,  8.0017e-08,\n",
      "                       4.4029e-07, -1.3115e-06,  4.4437e-07,  8.1695e-07,\n",
      "                      -2.6254e-04, -4.1893e-08, -4.0665e-09, -1.8982e-06,\n",
      "                      -5.5156e-07,  2.0328e-07,  7.4313e-06, -2.8486e-07,\n",
      "                       2.4549e-02,  3.8519e-03,  2.0037e-07,  6.5560e-06,\n",
      "                       1.2758e-07, -9.8389e-08, -4.0453e-07, -1.5902e-07,\n",
      "                       1.1309e-07, -3.7338e-07, -1.5291e-07,  4.5868e-03,\n",
      "                      -1.1575e-06,  4.8604e-03,  9.2477e-07, -6.4452e-07,\n",
      "                      -9.7253e-07, -4.6974e-07,  1.5125e-05,  4.9202e-07,\n",
      "                      -3.5544e-08,  2.7221e-08,  4.8957e-08,  7.2845e-02,\n",
      "                      -4.8340e-07,  6.4465e-03,  5.4668e-07, -2.2756e-06,\n",
      "                       1.1632e-07, -3.1164e-07, -5.1859e-07,  4.6059e-07,\n",
      "                       5.1449e-02,  3.0983e-08,  3.0511e-08,  1.1291e-09,\n",
      "                      -1.1556e-06,  1.5902e-06, -3.9053e-07, -8.8203e-06,\n",
      "                      -1.8787e-07,  2.7969e-07,  6.2137e-07, -2.1105e-05,\n",
      "                       3.1496e-06,  1.2758e-08,  2.0350e-07,  4.5624e-08,\n",
      "                       7.3984e-08, -7.6492e-07,  5.3120e-04,  9.9515e-08,\n",
      "                      -1.0793e-07,  2.9291e-05,  1.0092e-08, -1.2555e-07,\n",
      "                      -9.8040e-07,  3.2428e-07, -3.2075e-07,  2.7328e-02,\n",
      "                       6.1218e-07, -6.6388e-07, -2.9948e-07,  6.7148e-08,\n",
      "                       4.8758e-07, -1.7961e-08, -2.7176e-08, -8.2593e-07,\n",
      "                      -1.9765e-07, -7.2998e-07,  4.0888e-07,  4.7187e-07,\n",
      "                       6.4899e-07,  8.3412e-07,  6.1869e-08,  1.2264e-07,\n",
      "                       7.6481e-07, -4.6793e-08,  1.6957e-07, -8.3288e-07,\n",
      "                       1.2477e-06,  2.1664e-07,  6.3153e-07,  1.1185e-07,\n",
      "                      -4.6187e-07, -9.0118e-07,  2.8289e-07,  1.5626e-06,\n",
      "                      -5.1183e-08, -7.1854e-07,  8.1707e-07,  1.1701e-06,\n",
      "                       6.5914e-07, -7.4423e-08, -3.5473e-07, -2.8609e-07,\n",
      "                      -8.4522e-08,  8.9746e-07, -4.3635e-08, -1.0805e-06,\n",
      "                       1.1918e-07, -1.5419e-07,  2.8499e-07, -7.3887e-07,\n",
      "                       4.0164e-08,  1.1750e-07,  8.6565e-04,  2.5508e-07,\n",
      "                      -3.2383e-07,  4.1333e-07,  9.3761e-07, -6.2658e-07,\n",
      "                      -1.9122e-07,  4.1650e-07, -1.7783e-06,  1.0029e-06,\n",
      "                       6.7903e-07,  1.1007e-06, -1.3168e-06,  7.6622e-07,\n",
      "                       4.8624e-07,  1.3557e-06, -4.5838e-07, -5.5929e-08,\n",
      "                       7.2602e-07,  8.3806e-07,  1.0107e-06, -2.3262e-08,\n",
      "                       5.5853e-02,  1.7337e-06, -4.0113e-07, -3.6886e-07,\n",
      "                      -2.1652e-07,  1.0252e-06,  4.8504e-07, -1.1649e-06,\n",
      "                      -2.5153e-06,  1.0931e-07, -2.2383e-07, -5.4310e-07,\n",
      "                       6.4362e-07, -9.7066e-07, -3.0977e-07, -2.0302e-07,\n",
      "                      -2.9888e-07, -4.3742e-07,  4.0035e-08,  1.6969e-07,\n",
      "                       1.8545e-02, -4.7429e-07,  1.1254e-06,  1.1602e-01,\n",
      "                       6.9300e-07, -9.5109e-07, -4.9127e-07, -4.6036e-07,\n",
      "                      -2.5373e-03,  2.8592e-08,  3.0026e-07,  6.2397e-07,\n",
      "                       6.8056e-07, -1.3391e-06,  8.0884e-08,  1.3355e-05,\n",
      "                       1.5641e-06,  5.7575e-08,  4.5556e-07,  3.1263e-08,\n",
      "                       8.7127e-08,  6.3152e-07, -1.0186e-07, -3.5142e-07,\n",
      "                      -1.1590e-07, -1.3333e-07,  2.0270e-03, -3.5525e-08,\n",
      "                       3.4868e-07, -3.2952e-07, -2.1517e-06, -2.4825e-07,\n",
      "                      -2.8001e-07,  6.9895e-07, -1.3064e-06,  6.3312e-08,\n",
      "                       3.4083e-07,  1.4576e-06,  8.8705e-07,  1.2898e-06,\n",
      "                       2.4331e-04, -1.0965e-05, -5.4399e-07, -5.8516e-07,\n",
      "                      -6.1319e-07,  6.8865e-07, -3.2184e-07,  9.7957e-04,\n",
      "                      -5.6456e-07, -6.1953e-07, -7.3700e-07, -4.0806e-07,\n",
      "                      -1.1274e-06, -3.9353e-07, -4.8250e-10,  6.2189e-07,\n",
      "                      -1.7396e-07, -2.2488e-07,  7.3331e-07,  4.1564e-07,\n",
      "                      -5.0346e-07, -4.3427e-08,  1.1939e-05,  1.2503e-07,\n",
      "                       9.6090e-07, -1.4200e-07, -9.6644e-07,  2.4259e-07,\n",
      "                      -3.6334e-08,  1.8204e-02, -2.9676e-07, -7.4467e-07,\n",
      "                       1.7309e-07, -1.2003e-06,  2.4224e-07,  6.0241e-07,\n",
      "                       8.5907e-07, -8.5006e-07,  2.2239e-08,  5.0277e-07,\n",
      "                      -1.0426e-06,  1.8725e-07,  4.0612e-05, -5.5494e-07,\n",
      "                      -8.0559e-07,  4.4831e-02, -1.7327e-06, -1.0239e-06,\n",
      "                       6.0951e-02, -4.2410e-07,  1.6532e-07,  2.4845e-05,\n",
      "                      -8.2563e-07, -1.0055e-08, -1.0766e-06, -3.6917e-07,\n",
      "                       8.6549e-07, -4.4004e-07, -6.0964e-07, -5.1420e-07,\n",
      "                      -7.5110e-07,  1.5439e-08, -1.0851e-06,  6.3147e-07,\n",
      "                      -4.3954e-07,  2.1303e-06,  9.5304e-08, -1.8565e-08,\n",
      "                       3.0360e-02,  6.1069e-07,  2.4256e-07, -3.1440e-07,\n",
      "                       1.1432e-06, -2.1885e-07,  4.2376e-07,  1.3356e-06,\n",
      "                       7.2930e-07,  1.2858e-06,  1.4286e-07,  2.5470e-07,\n",
      "                      -1.3886e-06, -1.5711e-07,  6.2188e-08,  3.8369e-07,\n",
      "                       3.0804e-02,  1.6712e-06,  3.9800e-08, -2.9913e-07,\n",
      "                      -3.2623e-07,  1.6044e-07,  4.5318e-07,  3.2322e-07,\n",
      "                       6.6467e-07,  5.0498e-07, -4.2485e-07, -2.4612e-06,\n",
      "                       7.3997e-08,  9.8071e-07, -2.9999e-07,  2.7924e-07,\n",
      "                      -3.0125e-07,  4.6701e-02, -3.0194e-01,  1.9487e-01,\n",
      "                       2.0495e-02, -1.0074e+00,  8.7097e-09,  2.0966e-07,\n",
      "                       1.6268e-03, -6.6173e-06, -6.5604e-07, -2.5144e-06,\n",
      "                      -6.3852e-07, -5.8587e-07, -1.0443e-06, -9.1113e-03,\n",
      "                      -1.7487e-07, -3.5287e-07, -6.4293e-07,  2.1969e-07,\n",
      "                       3.0405e-07, -7.5544e-09,  1.6685e-07,  1.7328e-07,\n",
      "                      -3.7207e-07,  2.7065e-04, -1.1699e-06,  1.1321e-06,\n",
      "                       7.5410e-06,  1.8630e-01,  9.5753e-07,  3.7261e-07,\n",
      "                      -1.1591e-06,  4.6733e-07, -7.7925e-07,  6.9017e-07,\n",
      "                       1.2688e-07, -3.3807e-07,  9.1345e-07,  7.8986e-08,\n",
      "                       1.0291e-07, -3.0347e-07, -3.2930e-07, -3.9536e-07,\n",
      "                       2.0684e-07, -7.2653e-07,  1.1958e-06,  4.3813e-02,\n",
      "                      -1.4702e-07, -3.5089e-07, -8.8869e-07, -3.9828e-07,\n",
      "                      -3.0238e-07, -4.4647e-08, -4.5917e-07,  3.6271e-07,\n",
      "                      -3.2483e-07,  4.9715e-06,  4.1267e-07,  1.0982e-06,\n",
      "                       4.6873e-07, -1.3169e-06,  4.2781e-02, -3.0091e-07,\n",
      "                       5.2666e-07, -1.6137e-07, -6.6512e-07, -9.8370e-07,\n",
      "                      -5.0578e-07,  2.1596e-07,  3.1761e-07, -9.0182e-07,\n",
      "                      -5.9791e-07,  1.9752e-07, -6.3019e-07, -9.7969e-08,\n",
      "                       9.3732e-07, -2.5234e-07,  4.2439e-07,  1.2474e-06,\n",
      "                       1.4948e-07,  1.2934e-07, -5.8952e-07,  5.7106e-07,\n",
      "                       5.2878e-07, -4.2307e-07,  6.6513e-07,  3.2230e-03,\n",
      "                      -9.8174e-07,  7.0468e-03,  1.1692e-06,  2.3718e-07,\n",
      "                      -1.9813e-05,  1.5779e-07,  1.8823e-07, -2.7525e-07,\n",
      "                       2.3577e-01, -3.7138e-08,  1.5764e-05, -5.6319e-07,\n",
      "                      -6.0349e-07,  4.6934e-09,  1.1148e-07,  3.9900e-03,\n",
      "                       1.2288e-07,  6.8431e-07,  5.9958e-07, -3.4118e-06,\n",
      "                      -1.5627e-07,  1.1428e-05, -3.1920e-07,  1.2109e-07,\n",
      "                       2.5447e-07,  2.3077e-07,  2.0222e-07, -1.1449e-08,\n",
      "                       1.3771e-06,  4.6959e-02,  4.0473e-10,  5.9347e-07,\n",
      "                      -1.8572e-08,  1.5418e-07,  9.8981e-04,  8.8764e-08,\n",
      "                      -4.7243e-05, -1.2130e-07, -1.1409e-07, -6.0433e-07,\n",
      "                      -2.4001e-07, -1.4121e-06,  5.1866e-07, -1.1696e-06,\n",
      "                       4.4833e-07,  6.4692e-07, -4.7028e-06,  1.2965e-06,\n",
      "                      -4.2573e-08, -1.6802e-07,  2.0684e-07,  1.3225e-05,\n",
      "                       9.4889e-08, -2.9879e-08,  3.1956e-07, -1.2990e-08,\n",
      "                       1.0491e-05,  8.3216e-07,  1.0882e-06, -9.2729e-07,\n",
      "                       2.4302e-07, -4.2303e-07, -5.5386e-07, -6.0761e-07,\n",
      "                      -4.1106e-07,  2.9087e-02,  7.0816e-07, -7.2931e-07,\n",
      "                       5.3458e-07,  8.5255e-08, -1.6421e-07, -1.1266e-07,\n",
      "                       7.0961e-07, -7.0657e-07, -1.8897e-01, -4.3938e-07,\n",
      "                       4.4051e-07, -2.1608e-07, -2.4204e-05, -1.2500e-06,\n",
      "                      -2.1919e-07,  1.6632e-06, -7.2746e-07,  6.7193e-07,\n",
      "                       1.3809e-06,  9.1724e-07,  6.3170e-08, -8.1318e-07,\n",
      "                      -2.3037e-07,  1.8010e-07, -7.3964e-08,  1.0451e-06,\n",
      "                       4.8125e-07, -5.2822e-07, -1.3126e-07,  3.6508e-08,\n",
      "                       5.5368e-07,  5.3001e-07,  3.7476e-02,  2.8411e-07,\n",
      "                       3.2053e-07, -7.3298e-07, -1.0028e-06, -1.0703e-06,\n",
      "                      -6.3255e-07, -2.5606e-07, -4.0954e-07,  1.6947e-07,\n",
      "                       3.8125e-07,  1.0710e-06,  1.8848e-07,  2.9845e-07,\n",
      "                      -3.4313e-07,  3.0356e-07, -2.5606e-08, -3.0234e-07,\n",
      "                       1.6083e-06, -2.1714e-07,  2.5177e-07,  2.0841e-07,\n",
      "                       5.5355e-07, -2.3010e-07, -8.8428e-08, -5.9604e-07,\n",
      "                       2.4797e-07,  6.9689e-06,  2.6320e-07,  1.1264e-06,\n",
      "                       8.3112e-03,  1.5725e-03,  8.2392e-07, -3.3756e-04,\n",
      "                       4.0154e-03, -5.8501e-07,  2.6103e-08,  1.0873e-06,\n",
      "                       5.3810e-07,  7.7171e-08, -7.9848e-07,  4.6648e-08,\n",
      "                       1.1085e-02,  2.4909e-07, -1.8379e-07,  6.5019e-07,\n",
      "                       4.0927e-07,  1.4981e-07, -3.4482e-07,  6.1906e-07,\n",
      "                      -4.8055e-07, -2.9441e-08,  1.7596e-03, -1.6222e-07,\n",
      "                      -6.4098e-07,  1.4187e-06, -6.9123e-07,  7.0188e-07,\n",
      "                       6.4029e-07, -5.2615e-08,  2.3394e-08, -1.6448e-06,\n",
      "                       5.1607e-07, -8.9962e-08, -1.6476e-07,  4.0708e-08,\n",
      "                       1.5751e-02,  8.5366e-07,  3.5865e-08, -2.8284e-07,\n",
      "                       6.7093e-02, -1.5145e-07,  7.4514e-07, -1.1693e-06,\n",
      "                       7.5957e-07, -8.2540e-08, -2.2854e-07,  5.2062e-07,\n",
      "                       2.7870e-06, -1.3018e-07,  2.7693e-07,  2.6408e-07,\n",
      "                      -3.5659e-07,  6.8905e-07,  1.6847e-06, -1.5633e-06,\n",
      "                      -6.5932e-10,  5.6704e-07, -4.8946e-07, -3.7581e-07,\n",
      "                       1.1805e-07, -4.9375e-07, -1.2275e-06,  1.4347e-07,\n",
      "                      -4.0213e-07,  4.7599e-08,  4.2683e-07, -3.5865e-07,\n",
      "                       3.6962e-07, -4.3258e-07,  3.3955e-07,  7.7154e-07,\n",
      "                      -1.4493e-07, -2.5012e-08, -1.4169e-07, -2.8246e-07,\n",
      "                       2.4273e-07, -4.9318e-07,  2.0704e-07,  7.2534e-07,\n",
      "                       2.7777e-07, -3.0344e-07,  5.6686e-07,  8.3706e-07,\n",
      "                       8.7809e-08, -2.0780e-06,  3.0411e-07, -7.5067e-07,\n",
      "                       6.3733e-07,  2.7718e-07,  7.2239e-07, -3.3036e-07,\n",
      "                      -2.0374e-07,  2.1216e-06,  9.2168e-05,  1.3070e-08,\n",
      "                      -9.6684e-08, -1.4320e-06, -7.3791e-07,  2.4186e-07,\n",
      "                       4.0362e-07, -8.6723e-07,  6.5624e-07, -1.6251e-07,\n",
      "                       1.1192e-06, -2.3568e-07, -3.3761e-07, -3.4121e-07,\n",
      "                       8.0029e-07, -4.5269e-07, -4.0967e-07,  9.5193e-07,\n",
      "                      -1.8877e-07,  5.0112e-03, -4.3303e-05,  1.2372e-05,\n",
      "                      -6.7183e-07, -8.5264e-07,  1.0349e-07,  3.5370e-07,\n",
      "                       4.8283e-07,  7.9830e-08, -4.9964e-08,  1.2757e-07,\n",
      "                       3.8461e-07, -2.5096e-03,  2.4075e-08,  1.1752e-06,\n",
      "                      -2.4979e-07,  1.1168e-06,  5.5173e-06,  7.9082e-07,\n",
      "                       5.7962e-07, -3.7606e-07, -1.1059e-06,  8.7816e-04,\n",
      "                       1.2291e-06,  6.1078e-07,  3.6521e-02, -2.2742e-07,\n",
      "                      -3.1873e-07,  8.6214e-07,  4.7780e-03,  7.0613e-07,\n",
      "                       3.4735e-07,  1.2640e-06, -2.1336e-07, -4.4438e-08,\n",
      "                      -4.1437e-07, -1.2775e-06,  2.4627e-07,  6.1183e-07,\n",
      "                      -9.9809e-07,  6.8062e-08,  2.7041e-07, -5.9526e-07,\n",
      "                      -1.5591e-08,  2.9016e-07,  1.2518e-06,  1.4317e-06,\n",
      "                       1.1293e-06, -7.8916e-06,  3.5996e-07,  4.6175e-07,\n",
      "                       1.3420e-06,  5.7254e-07,  2.5435e-07, -3.4465e-07,\n",
      "                      -5.5950e-08,  4.0612e-07, -1.2517e-06,  1.0049e-08,\n",
      "                      -4.8476e-07,  6.9239e-07, -5.6636e-04,  1.2478e-01,\n",
      "                       4.2733e-07, -2.1168e-07, -2.4254e-08,  8.3562e-07,\n",
      "                      -2.5325e-08,  5.2848e-02,  5.8861e-07, -1.2991e-07,\n",
      "                       2.1873e-07, -6.5317e-07,  1.1599e-07, -2.4912e-07,\n",
      "                      -1.2986e-07, -8.1410e-07,  1.1227e-07,  3.4451e-07,\n",
      "                       9.4870e-08, -6.5722e-07,  5.9548e-07, -1.5109e-06,\n",
      "                      -1.7161e-07, -1.3263e-07, -2.4894e-05, -9.8262e-07,\n",
      "                      -1.1065e-07, -1.1561e-06, -7.2557e-07, -5.9987e-07,\n",
      "                       1.8385e-07,  2.7761e-07, -5.6025e-07, -6.5012e-07,\n",
      "                       6.6867e-06, -1.6355e-06, -3.8008e-07,  2.4569e-02,\n",
      "                       2.4227e-07, -3.0638e-07, -6.5520e-07,  8.9679e-06,\n",
      "                       6.4219e-07,  5.8530e-05, -4.3738e-07, -2.8417e-07,\n",
      "                      -3.7211e-07,  4.6094e-07,  5.1659e-02,  3.1144e-07,\n",
      "                       1.0204e-07,  1.1253e-07, -1.4923e-07, -2.2159e-07,\n",
      "                      -2.7299e-07,  6.0376e-07,  3.9540e-07,  3.0877e-02,\n",
      "                      -2.0977e-07,  8.8972e-07, -3.8072e-07,  9.9629e-07,\n",
      "                      -6.2680e-07, -1.4264e-07,  1.1163e-04, -3.7728e-07,\n",
      "                      -1.3800e-06, -1.5848e-08,  9.3344e-07,  1.5102e-07,\n",
      "                       5.1051e-08, -2.9109e-07, -2.4416e-07,  8.6858e-07,\n",
      "                      -2.4277e-07,  1.8870e-07, -1.8185e-07, -5.3198e-08,\n",
      "                      -2.0408e-07, -2.0729e-07,  1.5056e-06, -5.0996e-07,\n",
      "                      -8.2694e-07,  3.2624e-06, -1.7675e-07,  4.4412e-07,\n",
      "                       4.7869e-07, -2.8068e-07,  2.8962e-07,  4.3367e-07,\n",
      "                      -7.1114e-07, -1.0460e-06, -8.7281e-07,  1.2598e-06,\n",
      "                      -8.8402e-05,  1.7208e-04, -5.8056e-07,  6.5648e-07,\n",
      "                      -1.3083e-06, -3.2469e-07,  3.9648e-02, -5.7385e-09,\n",
      "                       1.0330e-02,  2.7590e-07, -3.2241e-07,  4.3442e-07,\n",
      "                      -1.1809e-06, -9.6198e-04,  1.3434e-02, -3.0216e-07,\n",
      "                       9.7144e-07, -8.2760e-07,  2.7483e-05,  2.1964e-07,\n",
      "                      -5.3115e-07, -8.2038e-07,  4.8672e-02,  1.1295e-05,\n",
      "                       1.2551e-06, -4.2289e-08,  1.6832e-07,  1.7345e-07,\n",
      "                      -4.4205e-07,  4.4579e-03,  5.7537e-07, -1.6605e-08,\n",
      "                      -5.0265e-07, -4.2886e-07, -1.7389e-07, -1.6054e-06,\n",
      "                      -2.3072e-08, -1.0583e-06, -5.5879e-07,  7.5129e-07,\n",
      "                       8.1058e-07, -3.6737e-03,  1.3089e-07, -5.3236e-07,\n",
      "                      -1.2467e-07, -9.6704e-07, -8.0750e-07,  1.9484e-06,\n",
      "                       2.4885e-07, -3.0606e-07,  5.5353e-08,  6.0619e-07,\n",
      "                       1.7337e-07, -1.6565e-06,  5.9499e-07,  9.5392e-07,\n",
      "                      -2.4047e-04,  5.1080e-07,  5.3255e-07,  2.4659e-07,\n",
      "                      -8.3381e-08, -8.0499e-07,  8.8540e-08,  3.3285e-07,\n",
      "                       2.9414e-07, -5.9134e-06, -3.7366e-07,  3.0761e-02,\n",
      "                      -6.0560e-08, -4.0217e-07, -1.9862e-07,  6.1368e-07,\n",
      "                       6.9132e-04,  2.1960e-07, -1.7549e-07,  6.0683e-07,\n",
      "                       4.5944e-08,  5.4645e-07, -2.3303e-07,  1.0530e-01,\n",
      "                       3.8378e-07, -2.1561e-07, -1.6070e-08, -4.3631e-07,\n",
      "                      -2.4067e-07,  2.3211e-08,  1.5339e-07,  1.0328e-01,\n",
      "                       7.2812e-07, -5.8916e-07, -2.1298e-07, -6.4256e-07,\n",
      "                       6.6888e-07,  8.2661e-07, -1.0176e-06,  5.0090e-07,\n",
      "                      -2.2385e-07, -6.7231e-08,  1.0073e-06, -4.1932e-07,\n",
      "                       1.0345e-06, -1.1975e-06, -2.1421e-07, -1.5225e-06,\n",
      "                       9.5158e-07, -6.2285e-07, -3.0885e-08,  3.0295e-07,\n",
      "                       1.3535e-06, -3.6010e-07,  5.1350e-09, -5.6290e-07,\n",
      "                      -7.9038e-07, -2.5806e-07, -3.1250e-07, -1.8312e-07,\n",
      "                      -3.9408e-08, -4.2463e-07,  2.1094e-07,  1.0061e-06,\n",
      "                      -1.7247e-07,  1.0090e-06,  5.8878e-09,  1.5230e-04,\n",
      "                       3.1714e-07, -1.0559e-06, -4.2379e-07,  3.7291e-07,\n",
      "                      -7.4091e-07, -2.8563e-07,  2.0318e-07,  9.2169e-08,\n",
      "                      -1.3078e-07, -1.3091e-06,  5.5425e-04,  3.6465e-07,\n",
      "                       2.0320e-07]),\n",
      "       size=(2835,), nnz=981, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([[   2,    5,   14,   58,   63,   71,   74,   82,  102,\n",
      "                         111,  126,  129,  138,  157,  165,  185,  199,  200,\n",
      "                         211,  217,  252,  258,  262,  272,  284,  286,  354,\n",
      "                         360,  368,  433,  441,  450,  465,  469,  474,  475,\n",
      "                         516,  533,  534,  535,  541,  552,  553,  559,  613,\n",
      "                         670,  679,  680,  716,  751,  812,  838,  882,  886,\n",
      "                         899,  913,  957,  962,  973,  985,  992,  993, 1004,\n",
      "                        1006, 1011, 1019, 1021, 1025, 1033, 1061, 1069, 1078,\n",
      "                        1084, 1092, 1102, 1123, 1143, 1184, 1212, 1227, 1228,\n",
      "                        1256, 1271, 1276, 1285, 1299, 1303, 1326, 1382, 1402,\n",
      "                        1403, 1409, 1423, 1462, 1500, 1501, 1504, 1506, 1532,\n",
      "                        1539, 1541, 1555, 1580, 1588, 1589, 1602, 1611, 1612,\n",
      "                        1670, 1689, 1692, 1695, 1719, 1722, 1723, 1730, 1753,\n",
      "                        1762, 1764, 1770, 1825, 1848, 1882, 1885, 1962, 1971,\n",
      "                        1979, 1980, 1984, 1986, 1999, 2020, 2026, 2049, 2113,\n",
      "                        2123, 2132, 2143, 2151, 2183, 2218, 2237, 2268, 2287,\n",
      "                        2304, 2314, 2318, 2329, 2344, 2376, 2381, 2382, 2404,\n",
      "                        2419, 2470, 2486, 2489, 2490, 2492, 2505, 2540, 2570,\n",
      "                        2591, 2592, 2595, 2598, 2600, 2604, 2612, 2628, 2636,\n",
      "                        2657, 2658, 2660, 2663, 2678, 2691, 2693, 2698, 2711,\n",
      "                        2712, 2713, 2714, 2722, 2748, 2779, 2788, 2826, 2831]]),\n",
      "       values=tensor([-4.2063e-08,  3.2315e-07,  1.0941e-07,  1.3070e-02,\n",
      "                      -8.8351e-02,  4.6602e-08, -1.4942e-07,  6.0580e-03,\n",
      "                       2.4101e-04,  2.4340e-05, -1.9568e-04, -7.9295e-05,\n",
      "                       5.7492e-06,  4.1043e-08,  1.6803e-03, -1.1024e-07,\n",
      "                      -7.4441e-07, -2.7723e-07,  4.3750e-07, -7.4438e-04,\n",
      "                      -4.7976e-08,  2.6742e-08,  6.0366e-04, -2.3659e-02,\n",
      "                       4.8928e-07, -1.6977e-07, -2.9526e-08, -1.8242e-07,\n",
      "                      -4.0895e-07, -5.6690e-09,  4.8306e-09,  2.6347e-04,\n",
      "                       1.9384e-07, -1.3189e-07,  1.6907e-01,  3.6471e-08,\n",
      "                      -3.3631e-08,  6.9323e-08, -5.3688e-07, -1.5829e-07,\n",
      "                       9.8902e-03, -1.0483e-09, -3.0701e-07,  3.9815e-03,\n",
      "                      -5.3539e-02, -1.3001e-07,  9.6396e-08,  9.8662e-03,\n",
      "                       1.4456e-08,  4.3073e-08, -1.4538e-08, -1.2613e-01,\n",
      "                      -8.0328e-07, -8.0251e-08, -5.7791e-08, -1.1303e-08,\n",
      "                      -1.8240e-04, -1.2675e-07, -1.1671e-07,  7.5683e-08,\n",
      "                       3.4434e-07,  4.0970e-08,  8.5929e-03, -3.5094e-07,\n",
      "                      -4.4141e-08,  1.3580e-01, -8.6697e-02,  4.1134e-01,\n",
      "                       1.7393e-08,  1.8194e-07,  1.7983e-03, -1.5157e-08,\n",
      "                      -8.5310e-02,  2.8924e-03,  9.0367e-03, -1.6076e-07,\n",
      "                      -3.9115e-08,  1.2082e-06, -4.1532e-08,  1.2734e-08,\n",
      "                       7.2836e-08, -4.7502e-08, -1.5674e-07, -9.2153e-08,\n",
      "                      -1.0423e-01,  1.6184e-08,  1.0608e-07, -2.2646e-08,\n",
      "                      -7.5507e-08,  2.8468e-04,  4.3599e-07,  7.8368e-09,\n",
      "                       5.0551e-04,  2.3169e-01, -3.7691e-08,  1.0792e-07,\n",
      "                      -6.0980e-08,  1.0399e-03,  1.1624e-02,  2.8381e-08,\n",
      "                       5.2563e-08, -1.1644e-07, -7.1307e-08,  7.8926e-08,\n",
      "                      -2.7050e-07, -2.7879e-08,  9.1941e-08,  1.8826e-02,\n",
      "                       9.0496e-08,  1.4343e-02, -7.0497e-09, -1.8790e-07,\n",
      "                      -1.7046e-07, -2.1394e-02, -8.4151e-07,  6.0969e-08,\n",
      "                       4.6604e-03,  1.0023e-06,  7.2105e-03,  1.1278e-06,\n",
      "                       2.1793e-07, -6.0147e-10,  1.3611e-07,  6.2911e-03,\n",
      "                      -1.6455e-07,  1.7840e-06,  1.2833e-07,  2.4891e-03,\n",
      "                       1.3432e-02,  1.5853e-07,  4.1508e-08,  1.1636e-07,\n",
      "                       1.8286e-08, -8.9553e-08,  5.7537e-02,  6.0099e-02,\n",
      "                      -5.5409e-02,  4.4343e-09, -1.6792e-08, -1.8244e-08,\n",
      "                       2.9489e-03, -2.2269e-08,  5.4059e-08, -2.5353e-08,\n",
      "                       8.1719e-08,  1.1193e-07,  1.3560e-07,  1.0971e-07,\n",
      "                      -4.2202e-09,  8.1832e-05,  1.1376e-02,  3.8922e-09,\n",
      "                      -2.6479e-08,  8.0709e-09, -2.1240e-02,  2.2335e-06,\n",
      "                      -3.1104e-08,  3.3593e-01, -9.7891e-08,  1.1928e-07,\n",
      "                      -7.5558e-09, -7.5754e-10,  1.2356e-07,  5.9010e-04,\n",
      "                       1.3319e-07,  3.6475e-02, -4.0876e-08,  9.7987e-02,\n",
      "                      -4.2913e-08,  1.1429e-02, -2.4135e-08, -1.1854e-06,\n",
      "                      -2.5320e-07, -1.3412e-07, -5.2062e-08,  1.6194e-07,\n",
      "                      -1.8854e-03, -4.6534e-02, -9.5371e-08, -6.4862e-08,\n",
      "                      -1.8423e-06, -2.7138e-08, -1.1817e-07,  4.4944e-03,\n",
      "                       1.2753e-08, -1.2412e-07,  1.9597e-07,  3.0975e-09,\n",
      "                      -1.1899e-07]),\n",
      "       size=(2835,), nnz=189, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([[   4,    6,   13,   15,   18,   20,   21,   23,   24,\n",
      "                          25,   28,   30,   34,   37,   40,   42,   45,   47,\n",
      "                          51,   52,   54,   56,   59,   63,   64,   65,   66,\n",
      "                          68,   70,   75,   80,   81,   88,   91,   93,   97,\n",
      "                          98,  103,  104,  111,  112,  113,  116,  123,  124,\n",
      "                         126,  128,  129,  130,  132,  136,  137,  140,  147,\n",
      "                         148,  150,  152,  153,  158,  160,  161,  169,  173,\n",
      "                         178,  181,  184,  186,  194,  195,  198,  202,  203,\n",
      "                         205,  209,  210,  212,  215,  218,  222,  225,  229,\n",
      "                         236,  239,  241,  245,  248,  249,  257,  261,  263,\n",
      "                         267,  268,  269,  272,  275,  277,  278,  280,  281,\n",
      "                         282,  287,  288,  290,  296,  299,  301,  302,  303,\n",
      "                         306,  311,  313,  317,  318,  322,  324,  325,  327,\n",
      "                         329,  331,  332,  335,  339,  341,  343,  344,  346,\n",
      "                         349,  350,  362,  366,  369,  370,  371,  372,  373,\n",
      "                         374,  376,  377,  379,  380,  381,  393,  395,  396,\n",
      "                         399,  403,  404,  406,  409,  413,  419,  420,  422,\n",
      "                         423,  425,  426,  430,  432,  434,  435,  436,  440,\n",
      "                         442,  444,  447,  448,  449,  453,  454,  457,  458,\n",
      "                         460,  462,  472,  473,  476,  478,  482,  486,  487,\n",
      "                         489,  490,  493,  496,  500,  503,  504,  513,  518,\n",
      "                         524,  526,  528,  530,  532,  537,  540,  541,  545,\n",
      "                         549,  550,  554,  556,  557,  560,  562,  563,  570,\n",
      "                         571,  573,  575,  576,  577,  579,  580,  581,  584,\n",
      "                         586,  588,  593,  600,  604,  606,  608,  610,  612,\n",
      "                         613,  614,  615,  618,  619,  621,  626,  631,  632,\n",
      "                         635,  636,  639,  641,  647,  650,  651,  652,  653,\n",
      "                         655,  657,  667,  669,  674,  678,  683,  686,  689,\n",
      "                         691,  692,  694,  695,  701,  704,  710,  711,  712,\n",
      "                         714,  717,  718,  719,  720,  722,  723,  725,  727,\n",
      "                         730,  731,  735,  736,  739,  741,  743,  746,  749,\n",
      "                         750,  757,  759,  760,  762,  764,  769,  773,  776,\n",
      "                         777,  779,  784,  786,  789,  791,  793,  796,  800,\n",
      "                         801,  806,  807,  808,  809,  810,  811,  818,  819,\n",
      "                         820,  828,  829,  831,  834,  838,  839,  840,  850,\n",
      "                         852,  856,  858,  859,  873,  875,  876,  877,  880,\n",
      "                         896,  903,  904,  905,  906,  907,  909,  910,  917,\n",
      "                         921,  922,  926,  927,  928,  929,  935,  936,  939,\n",
      "                         940,  941,  942,  943,  946,  949,  951,  954,  963,\n",
      "                         970,  971,  972,  975,  979,  981,  982,  983,  984,\n",
      "                         988,  989, 1003, 1007, 1010, 1015, 1017, 1018, 1019,\n",
      "                        1021, 1023, 1025, 1027, 1029, 1030, 1032, 1036, 1037,\n",
      "                        1043, 1044, 1050, 1051, 1056, 1065, 1068, 1069, 1071,\n",
      "                        1072, 1075, 1076, 1077, 1079, 1080, 1082, 1083, 1084,\n",
      "                        1090, 1091, 1094, 1100, 1104, 1105, 1106, 1109, 1114,\n",
      "                        1116, 1118, 1129, 1135, 1138, 1141, 1142, 1144, 1147,\n",
      "                        1157, 1161, 1164, 1166, 1168, 1171, 1176, 1177, 1178,\n",
      "                        1180, 1181, 1182, 1183, 1191, 1195, 1196, 1203, 1204,\n",
      "                        1207, 1211, 1219, 1220, 1223, 1224, 1225, 1229, 1232,\n",
      "                        1233, 1237, 1238, 1239, 1245, 1247, 1250, 1251, 1253,\n",
      "                        1254, 1257, 1258, 1261, 1264, 1269, 1270, 1272, 1274,\n",
      "                        1280, 1284, 1285, 1286, 1287, 1292, 1295, 1308, 1311,\n",
      "                        1319, 1324, 1329, 1330, 1331, 1337, 1338, 1342, 1343,\n",
      "                        1345, 1346, 1349, 1350, 1351, 1352, 1355, 1358, 1363,\n",
      "                        1368, 1372, 1376, 1381, 1383, 1385, 1389, 1391, 1392,\n",
      "                        1395, 1396, 1402, 1403, 1405, 1407, 1414, 1415, 1417,\n",
      "                        1418, 1419, 1423, 1424, 1425, 1426, 1431, 1436, 1438,\n",
      "                        1439, 1440, 1442, 1444, 1445, 1446, 1447, 1449, 1451,\n",
      "                        1454, 1458, 1459, 1460, 1464, 1468, 1470, 1471, 1472,\n",
      "                        1482, 1485, 1490, 1491, 1492, 1493, 1503, 1510, 1512,\n",
      "                        1514, 1515, 1517, 1518, 1521, 1524, 1525, 1528, 1531,\n",
      "                        1535, 1536, 1538, 1545, 1546, 1548, 1549, 1556, 1560,\n",
      "                        1561, 1563, 1564, 1565, 1566, 1567, 1568, 1570, 1573,\n",
      "                        1574, 1576, 1578, 1584, 1585, 1586, 1590, 1592, 1595,\n",
      "                        1599, 1601, 1603, 1614, 1615, 1616, 1617, 1619, 1620,\n",
      "                        1623, 1631, 1634, 1638, 1639, 1641, 1643, 1645, 1647,\n",
      "                        1649, 1653, 1659, 1664, 1665, 1666, 1671, 1674, 1677,\n",
      "                        1679, 1680, 1683, 1687, 1696, 1698, 1701, 1702, 1703,\n",
      "                        1704, 1706, 1707, 1711, 1716, 1717, 1721, 1722, 1724,\n",
      "                        1729, 1731, 1734, 1735, 1738, 1741, 1744, 1746, 1747,\n",
      "                        1748, 1758, 1760, 1766, 1771, 1772, 1775, 1776, 1777,\n",
      "                        1778, 1783, 1784, 1789, 1790, 1791, 1793, 1794, 1803,\n",
      "                        1805, 1808, 1809, 1814, 1818, 1822, 1830, 1831, 1832,\n",
      "                        1833, 1834, 1835, 1838, 1839, 1841, 1842, 1843, 1846,\n",
      "                        1847, 1854, 1856, 1863, 1866, 1868, 1872, 1874, 1875,\n",
      "                        1878, 1883, 1884, 1885, 1894, 1896, 1897, 1900, 1901,\n",
      "                        1909, 1914, 1917, 1919, 1920, 1924, 1925, 1928, 1929,\n",
      "                        1932, 1933, 1936, 1938, 1939, 1940, 1942, 1944, 1945,\n",
      "                        1946, 1948, 1952, 1954, 1957, 1958, 1960, 1961, 1963,\n",
      "                        1974, 1975, 1981, 1994, 1995, 1997, 2001, 2003, 2004,\n",
      "                        2008, 2011, 2014, 2016, 2017, 2019, 2027, 2029, 2031,\n",
      "                        2035, 2037, 2038, 2040, 2041, 2044, 2045, 2048, 2056,\n",
      "                        2058, 2060, 2062, 2072, 2073, 2075, 2080, 2082, 2083,\n",
      "                        2089, 2094, 2095, 2097, 2099, 2101, 2108, 2112, 2113,\n",
      "                        2114, 2116, 2117, 2124, 2126, 2132, 2133, 2134, 2136,\n",
      "                        2138, 2145, 2148, 2153, 2155, 2158, 2160, 2162, 2170,\n",
      "                        2172, 2173, 2174, 2175, 2176, 2178, 2179, 2182, 2186,\n",
      "                        2187, 2192, 2193, 2194, 2196, 2201, 2203, 2207, 2209,\n",
      "                        2210, 2212, 2213, 2215, 2216, 2221, 2225, 2230, 2231,\n",
      "                        2232, 2239, 2240, 2242, 2248, 2250, 2251, 2258, 2259,\n",
      "                        2263, 2265, 2269, 2273, 2276, 2292, 2297, 2301, 2306,\n",
      "                        2307, 2308, 2312, 2313, 2322, 2324, 2325, 2327, 2345,\n",
      "                        2346, 2351, 2352, 2353, 2357, 2362, 2365, 2367, 2371,\n",
      "                        2373, 2380, 2383, 2386, 2390, 2396, 2397, 2398, 2401,\n",
      "                        2403, 2405, 2409, 2416, 2418, 2420, 2422, 2423, 2426,\n",
      "                        2427, 2428, 2429, 2437, 2439, 2443, 2444, 2446, 2456,\n",
      "                        2459, 2463, 2464, 2466, 2467, 2468, 2470, 2472, 2473,\n",
      "                        2477, 2480, 2484, 2488, 2496, 2497, 2503, 2509, 2512,\n",
      "                        2514, 2516, 2517, 2525, 2526, 2527, 2528, 2533, 2534,\n",
      "                        2536, 2537, 2538, 2542, 2545, 2547, 2550, 2554, 2558,\n",
      "                        2561, 2564, 2565, 2566, 2567, 2568, 2573, 2574, 2576,\n",
      "                        2577, 2580, 2582, 2583, 2585, 2589, 2590, 2601, 2605,\n",
      "                        2606, 2607, 2609, 2610, 2613, 2614, 2616, 2617, 2621,\n",
      "                        2629, 2632, 2634, 2638, 2640, 2643, 2652, 2653, 2667,\n",
      "                        2670, 2676, 2680, 2681, 2685, 2686, 2689, 2693, 2699,\n",
      "                        2700, 2701, 2706, 2709, 2710, 2715, 2716, 2718, 2719,\n",
      "                        2724, 2728, 2733, 2736, 2739, 2741, 2742, 2743, 2744,\n",
      "                        2745, 2747, 2750, 2753, 2755, 2762, 2764, 2766, 2773,\n",
      "                        2776, 2778, 2780, 2781, 2782, 2783, 2784, 2786, 2790,\n",
      "                        2791, 2800, 2802, 2804, 2805, 2809, 2817, 2818, 2819,\n",
      "                        2827, 2830, 2833]]),\n",
      "       values=tensor([-2.7073e-07, -3.6294e-07, -1.0660e-06,  3.5661e-07,\n",
      "                       1.4547e-07, -1.0662e-07, -5.2899e-07,  5.1090e-07,\n",
      "                       1.7971e-07,  3.7808e-07,  9.4352e-07, -3.9466e-07,\n",
      "                      -7.9076e-07, -6.0847e-07,  3.5937e-07, -8.0105e-07,\n",
      "                      -3.9237e-07,  3.9825e-07, -1.3918e-07, -1.4894e-03,\n",
      "                       5.5158e-07, -8.4321e-07,  1.2433e-06,  1.0160e-01,\n",
      "                      -1.1732e-04, -1.5207e-07, -5.6754e-07, -5.5352e-07,\n",
      "                       4.5742e-07,  2.9075e-07,  5.9685e-08, -8.1305e-08,\n",
      "                       2.5478e-07, -3.1346e-07, -2.2355e-04,  1.4058e-06,\n",
      "                      -3.7748e-07,  3.3631e-01,  3.7645e-07,  4.7932e-03,\n",
      "                      -4.1133e-07, -2.5128e-07, -2.0589e-07,  9.8843e-07,\n",
      "                      -5.5917e-03, -3.1545e-07, -2.9917e-07, -3.8214e-07,\n",
      "                      -1.5458e-05, -6.6385e-07,  2.2020e-07, -2.3756e-08,\n",
      "                       1.6285e-07, -6.7054e-07,  1.0806e-07, -8.1793e-08,\n",
      "                      -9.9709e-08, -8.2963e-09,  6.8629e-08,  4.8401e-07,\n",
      "                      -1.2111e-06,  4.0000e-07,  6.9422e-07, -2.6565e-07,\n",
      "                      -7.2500e-08, -1.4728e-06, -5.0800e-07,  2.1127e-07,\n",
      "                       6.1138e-06, -1.6510e-07,  1.0907e-02,  2.6308e-03,\n",
      "                       2.6584e-07,  5.9029e-06,  1.2825e-07, -2.2574e-08,\n",
      "                      -4.7520e-07, -6.0916e-08,  8.0029e-08, -3.8888e-07,\n",
      "                      -1.1391e-07, -9.5395e-07,  1.0329e-06, -6.7933e-07,\n",
      "                      -7.9229e-07, -5.4001e-07,  1.5693e-05,  3.7700e-07,\n",
      "                       2.0771e-08, -1.6331e-07, -2.7334e-08,  4.3094e-07,\n",
      "                      -4.3207e-07,  1.2792e-03,  4.4053e-07, -2.3056e-06,\n",
      "                       2.4146e-07, -3.8631e-07, -2.0232e-02,  4.6402e-07,\n",
      "                       1.2877e-06, -1.3413e-07,  8.8092e-08,  8.7854e-08,\n",
      "                       6.9571e-02,  1.1983e-06, -5.3685e-07, -9.6280e-06,\n",
      "                       1.9527e-03, -3.4774e-07,  2.9082e-07,  3.2976e-07,\n",
      "                       4.1358e-05, -1.9101e-05,  4.4246e-06,  3.5184e-08,\n",
      "                       1.4342e-07,  2.1677e-07,  1.6599e-08, -8.0292e-07,\n",
      "                       1.8724e-07,  1.4834e-07,  2.7854e-05, -6.9967e-08,\n",
      "                      -1.5932e-07, -1.0144e-06,  2.7924e-07, -2.2897e-07,\n",
      "                      -2.3921e-07,  5.6195e-07, -4.4965e-07, -2.4950e-07,\n",
      "                       1.5680e-07,  5.4927e-07, -4.2286e-08,  2.1146e-07,\n",
      "                      -8.3391e-07, -1.4437e-07, -5.8934e-07,  4.5600e-07,\n",
      "                       4.4074e-07,  4.7277e-07,  7.3331e-07, -5.6972e-09,\n",
      "                      -1.7424e-08,  1.7863e-02,  2.5037e-08,  9.4243e-08,\n",
      "                      -8.1366e-07,  1.1463e-06,  2.9194e-07,  5.8537e-07,\n",
      "                       1.0344e-07, -1.7725e-07, -6.8780e-07,  8.1228e-03,\n",
      "                       2.2020e-07,  1.3638e-06,  1.4962e-07, -6.6763e-07,\n",
      "                       6.9049e-07,  4.3342e-05,  9.4171e-07,  6.9307e-03,\n",
      "                      -2.3868e-07, -2.7956e-07,  2.6865e-03, -7.3921e-08,\n",
      "                       7.9194e-07, -3.0907e-08, -9.0427e-07,  3.1934e-07,\n",
      "                      -7.9564e-05, -1.2380e-07,  1.9744e-07, -7.1702e-07,\n",
      "                       3.6389e-08,  1.0337e-07, -7.4242e-03, -4.0890e-08,\n",
      "                      -2.9888e-07,  2.5359e-07,  8.0584e-07, -5.1606e-07,\n",
      "                      -3.1546e-07, -1.0440e-01,  5.3372e-07,  9.0571e-02,\n",
      "                       7.8772e-07,  7.2187e-07,  8.9952e-07, -1.2294e-06,\n",
      "                       9.1313e-07,  4.4514e-07, -2.0167e-02, -4.3030e-07,\n",
      "                       1.7444e-01, -1.3058e-07,  5.1709e-07,  9.8275e-07,\n",
      "                       9.2213e-07,  9.3323e-08,  1.4029e-07,  1.4609e-06,\n",
      "                      -3.0265e-07, -1.5270e-07, -2.2888e-07,  5.4843e-04,\n",
      "                       3.3389e-07, -1.0310e-06, -2.1064e-06, -4.4448e-08,\n",
      "                      -2.5229e-08, -5.3455e-07,  6.1458e-07, -9.8621e-07,\n",
      "                      -2.5041e-07, -1.9291e-07, -1.9842e-07, -2.8945e-07,\n",
      "                      -7.6881e-08,  6.3741e-09, -6.8363e-07, -4.5377e-07,\n",
      "                       1.1603e-06,  6.0383e-02,  6.0331e-07, -8.8364e-07,\n",
      "                      -2.4583e-06, -3.3045e-07, -5.8375e-09,  1.9918e-07,\n",
      "                       3.8593e-07,  6.6612e-07, -1.2333e-06,  5.7906e-09,\n",
      "                       1.1088e-05,  1.6147e-06,  1.6727e-07,  3.3155e-07,\n",
      "                       2.1904e-07,  1.2942e-07,  6.7161e-03,  3.2376e-07,\n",
      "                      -1.6364e-07, -5.4092e-07, -1.3289e-07, -2.5348e-08,\n",
      "                       2.5323e-06, -1.9421e-08,  3.1200e-07, -4.1233e-07,\n",
      "                      -1.8484e-06, -2.0112e-07, -3.9470e-07,  6.6869e-07,\n",
      "                      -1.4713e-06,  1.4147e-07,  3.9287e-07,  1.2213e-06,\n",
      "                       1.1302e-06,  1.2090e-06,  1.0974e-05, -1.0796e-05,\n",
      "                      -6.6991e-07, -5.0060e-07, -4.2953e-07,  6.7971e-07,\n",
      "                      -3.1128e-07, -7.9111e-07, -6.6003e-07, -7.0609e-07,\n",
      "                      -1.7892e-07, -1.0716e-06, -3.7827e-07,  3.5332e-09,\n",
      "                       6.1438e-07,  8.7334e-02,  9.5989e-02,  5.8554e-07,\n",
      "                       5.5970e-07, -9.7840e-04, -3.4391e-07, -3.8364e-08,\n",
      "                       1.2636e-05,  1.3989e-07,  8.4621e-07, -1.2132e-07,\n",
      "                      -1.0653e-02,  1.8366e-07, -1.3521e-07, -2.1178e-07,\n",
      "                      -2.5744e-07, -5.8063e-07,  1.1734e-07, -9.1784e-07,\n",
      "                       3.6466e-07,  6.7941e-07,  7.5559e-07, -7.6818e-07,\n",
      "                       2.0293e-08,  5.0607e-07, -1.2106e-06,  5.5387e-08,\n",
      "                       3.3648e-06,  8.4748e-04, -5.5460e-07, -8.1819e-07,\n",
      "                       9.8606e-07,  5.9701e-01, -8.9600e-07,  6.6752e-02,\n",
      "                      -4.6735e-07,  1.4724e-07, -1.8484e-04, -1.0071e-06,\n",
      "                      -7.7878e-08, -9.1235e-07, -3.1992e-07,  8.8821e-07,\n",
      "                      -5.3529e-07, -4.7456e-07, -2.8444e-07, -6.4608e-07,\n",
      "                      -2.7988e-03,  1.3588e-03,  2.5049e-08,  1.3438e-03,\n",
      "                       9.3961e-07, -3.2382e-07,  1.9690e-06,  1.7655e-07,\n",
      "                       9.6912e-08,  4.4070e-07,  7.5168e-07,  2.1982e-07,\n",
      "                      -1.9033e-07,  1.0696e-06, -2.1509e-07,  4.0329e-07,\n",
      "                       1.1715e-06,  6.3195e-07,  1.1884e-06,  2.0081e-08,\n",
      "                       2.4813e-07, -1.4798e-06, -8.1349e-08,  1.1386e-07,\n",
      "                       2.7961e-07, -5.6179e-07,  1.4564e-06,  8.3747e-03,\n",
      "                       1.9268e-07, -3.0583e-07, -2.9051e-07,  2.0006e-07,\n",
      "                       3.6587e-07,  2.3695e-07,  6.5157e-07,  4.7183e-07,\n",
      "                      -5.0487e-07, -2.4436e-06,  2.2561e-07,  3.8557e-02,\n",
      "                      -3.1420e-07, -4.2450e-04, -2.1785e-07, -5.9678e-07,\n",
      "                      -1.2116e-01,  1.0129e-01,  4.8202e-07, -3.4948e-01,\n",
      "                       1.5696e-08,  9.3819e-04,  7.4884e-04, -7.1480e-06,\n",
      "                      -5.9039e-07, -2.1197e-06,  1.4865e-04, -4.8410e-07,\n",
      "                      -5.5284e-07, -7.9126e-07, -1.4888e-07,  2.8871e-02,\n",
      "                      -8.8636e-07,  2.5880e-07,  2.9051e-07, -7.2796e-08,\n",
      "                       1.0646e-07,  2.6297e-07, -3.9281e-07,  4.4121e-04,\n",
      "                      -1.1484e-06,  1.1791e-06,  7.0160e-06,  9.7861e-02,\n",
      "                       7.6255e-07,  3.1980e-07, -9.7656e-07,  4.8905e-07,\n",
      "                      -7.9671e-07,  5.6736e-07,  9.4317e-08, -5.3997e-07,\n",
      "                       8.8193e-07,  1.1078e-08,  1.3486e-07, -3.6800e-07,\n",
      "                      -3.9799e-07, -9.4504e-03,  2.1282e-07,  5.1759e-02,\n",
      "                       1.1500e-06,  2.1258e-07, -2.8982e-07, -3.5907e-07,\n",
      "                      -5.9117e-07, -2.6005e-07, -1.9293e-07, -9.4967e-08,\n",
      "                      -3.3011e-07,  3.3077e-07, -2.9673e-07,  9.5322e-06,\n",
      "                       3.6576e-07,  8.6441e-07,  4.8286e-07, -1.1627e-06,\n",
      "                      -4.4406e-08, -1.9574e-07,  3.8130e-07, -2.6553e-07,\n",
      "                      -1.2347e-03, -7.3660e-07, -5.6040e-07,  2.5484e-07,\n",
      "                       9.1060e-03,  1.9413e-07, -1.1363e-06, -4.8814e-07,\n",
      "                       2.2508e-07, -3.0415e-07, -3.9298e-08,  8.7602e-07,\n",
      "                      -1.9438e-07,  4.2243e-07,  1.0598e-06,  1.2780e-07,\n",
      "                       1.1561e-08, -7.5736e-07,  4.0825e-07,  5.1897e-07,\n",
      "                      -3.8056e-07,  1.0598e-01, -7.5969e-07,  8.9505e-07,\n",
      "                       1.4084e-07, -1.8849e-05,  1.4478e-07,  1.5311e-07,\n",
      "                      -1.5058e-07,  1.2296e-01, -1.7965e-08,  1.3274e-05,\n",
      "                      -3.1758e-07, -6.8081e-07,  3.0771e-08,  8.0352e-08,\n",
      "                       9.1564e-08,  5.2330e-07,  3.5583e-07, -1.9570e-06,\n",
      "                      -2.1134e-07, -2.3009e-07,  5.2217e-08,  3.5168e-03,\n",
      "                       1.8581e-07,  1.2654e-07,  1.1190e-07,  1.4248e-06,\n",
      "                      -1.2443e-07,  6.0383e-03, -9.1209e-08,  3.5227e-07,\n",
      "                      -1.4345e-08, -8.4125e-03,  2.1294e-07,  4.5297e-08,\n",
      "                      -1.0482e-02,  9.1325e-08,  1.7178e-03, -3.1997e-07,\n",
      "                      -1.3407e-06, -1.2804e-03,  5.7894e-07, -1.0983e-06,\n",
      "                       3.9343e-07,  6.2478e-07,  1.0109e-03,  1.1144e-06,\n",
      "                      -7.8592e-08,  1.2038e-07,  1.8483e-07,  1.0458e-05,\n",
      "                       5.4206e-08, -3.4312e-08,  3.4587e-07,  1.7824e-07,\n",
      "                      -3.7993e-01,  8.4273e-07,  1.0117e-06,  1.0632e-02,\n",
      "                      -6.2529e-07,  2.3519e-07, -3.2984e-03, -4.9955e-07,\n",
      "                      -5.9639e-07, -5.2861e-07, -2.8370e-07, -1.9432e-07,\n",
      "                       7.0121e-07, -7.2049e-07,  4.4341e-07,  1.1706e-07,\n",
      "                      -1.5211e-07, -1.7415e-07,  5.3410e-07, -6.5668e-07,\n",
      "                      -3.9928e-07,  4.8875e-07,  2.0406e-03, -2.2251e-07,\n",
      "                       2.3954e+01, -2.2622e-05, -3.5048e-03, -2.1950e-07,\n",
      "                       1.7402e-06,  3.0271e-06,  5.6895e-07, -2.3136e-01,\n",
      "                       1.7906e-02,  1.3240e-06,  7.9857e-07, -5.6052e-08,\n",
      "                      -6.6227e-07, -2.8814e-07,  1.2085e-07, -1.1524e-07,\n",
      "                       9.8860e-07,  4.5299e-07, -3.3345e-07, -5.9112e-08,\n",
      "                       9.6162e-08,  4.2657e-07,  4.8396e-07, -6.7402e-08,\n",
      "                       2.2855e-07,  3.0025e-07, -6.6539e-07, -1.0647e-06,\n",
      "                      -9.1577e-07, -5.4797e-07, -9.3615e-08, -2.8558e-07,\n",
      "                       1.7947e-07,  2.7106e-07,  7.2983e-07,  8.1560e-08,\n",
      "                       3.1836e-07, -2.0993e-07,  1.9340e-07, -5.3250e-08,\n",
      "                      -3.1220e-07,  1.5276e-06, -1.3392e-07,  1.3328e-07,\n",
      "                       1.5430e-07,  5.3979e-07, -1.8610e-07,  1.5312e-07,\n",
      "                      -4.9764e-07,  3.9578e-07,  9.0379e-06,  2.3983e-07,\n",
      "                       1.0170e-06,  3.4583e-03,  7.5806e-07,  2.0797e-04,\n",
      "                      -4.7770e-07, -2.0689e-07,  1.0788e-06, -7.7996e-03,\n",
      "                       4.8248e-07,  1.8497e-08, -7.1704e-07,  8.9310e-08,\n",
      "                       5.4784e-09, -9.2481e-08,  4.8015e-07,  4.1971e-07,\n",
      "                       5.9654e-08, -2.5686e-07,  4.8835e-07, -2.9295e-07,\n",
      "                      -9.8666e-03,  7.5907e-09, -1.5007e-07, -7.5615e-07,\n",
      "                       1.2874e-06, -6.1357e-07,  8.3222e-07,  5.3087e-07,\n",
      "                      -4.1022e-08,  6.4268e-08, -1.3590e-06,  7.5622e-07,\n",
      "                      -1.8341e-07, -1.5356e-07,  9.8862e-08,  3.3113e-02,\n",
      "                       8.1569e-07,  2.0117e-07, -4.1259e-07, -5.6007e-08,\n",
      "                      -2.4871e-07,  6.9693e-07, -9.7717e-07,  6.1942e-07,\n",
      "                      -2.4702e-07, -1.5951e-07,  4.9985e-07,  2.6347e-06,\n",
      "                      -1.3776e-07,  1.3659e-07,  3.4355e-07, -2.3931e-07,\n",
      "                       1.2762e-02,  6.6155e-07,  1.4040e-06, -1.5599e-06,\n",
      "                      -1.3323e-07,  4.3040e-07, -4.0690e-07, -3.3142e-07,\n",
      "                       2.4353e-07, -3.7942e-07, -9.9587e-07,  5.8580e-08,\n",
      "                      -2.8240e-07, -2.3496e-08,  3.7492e-07, -3.5990e-07,\n",
      "                       1.6019e-07, -3.0249e-07,  3.8875e-07,  6.4990e-07,\n",
      "                      -2.0349e-05, -1.2878e-07,  7.6512e-08, -1.2323e-08,\n",
      "                       4.8673e-08,  3.5114e-07, -4.6127e-07,  1.9381e-07,\n",
      "                       4.3129e-07,  6.7197e-02, -1.7508e-07,  4.7217e-07,\n",
      "                       7.2465e-07, -1.2543e-07, -1.8765e-06,  3.4228e-07,\n",
      "                      -7.1953e-07,  5.8379e-07,  2.3785e-07,  6.4320e-07,\n",
      "                      -4.0863e-07, -1.4698e-07,  1.7260e-06,  1.5787e-07,\n",
      "                      -1.0195e-07, -6.9974e-02, -1.3713e-06, -6.1942e-07,\n",
      "                       2.3841e-07,  6.1349e-07, -7.8272e-07,  4.3285e-07,\n",
      "                      -4.0957e-08,  8.1365e-07, -2.9461e-07, -2.7898e-07,\n",
      "                      -3.4428e-07,  8.0086e-07,  1.5537e-04, -5.2227e-07,\n",
      "                      -4.7753e-07,  7.6615e-07, -3.5619e-03, -1.9228e-07,\n",
      "                      -3.8328e-05,  9.9038e-06,  2.5597e-02, -1.0380e-06,\n",
      "                       8.6401e-09,  3.0713e-07,  2.7120e-07,  9.1854e-08,\n",
      "                      -8.8971e-08,  1.9606e-07,  5.5108e-07,  8.7426e-08,\n",
      "                       9.9919e-07, -1.4644e-07,  9.6108e-07,  4.6657e-05,\n",
      "                       5.0869e-07,  5.6514e-07,  4.5607e-04, -2.5721e-07,\n",
      "                       1.2348e-02, -1.0519e-06,  1.3959e-06,  5.0044e-07,\n",
      "                      -5.4276e-03, -1.7085e-07, -8.9807e-04,  8.3760e-07,\n",
      "                       5.2479e-07,  2.2105e-07,  1.1242e-06, -1.7122e-07,\n",
      "                      -1.3313e-07, -3.7046e-07, -1.1683e-06,  2.8800e-07,\n",
      "                       2.8133e-07, -8.0336e-07,  6.1446e-08, -5.4445e-08,\n",
      "                      -6.9506e-07, -3.2988e-08,  2.0295e-07,  1.3155e-06,\n",
      "                       1.3784e-06,  1.0598e-06, -8.2697e-06,  2.7341e-07,\n",
      "                       4.2347e-07,  1.2637e-06,  6.7198e-07,  2.1028e-07,\n",
      "                      -3.5326e-07, -1.0348e-07,  1.3967e-07, -4.7751e-01,\n",
      "                      -1.2604e-06,  3.3612e-08, -6.4191e-07, -2.4062e-03,\n",
      "                       7.1440e-04,  6.4722e-02,  4.3189e-07, -2.6522e-07,\n",
      "                      -8.9454e-08,  7.1555e-07,  1.5876e-07,  7.9718e-07,\n",
      "                       5.8766e-07, -1.5095e-07,  1.6283e-07, -5.8293e-07,\n",
      "                       1.1204e-07, -4.2020e-07, -9.0391e-08, -6.8000e-07,\n",
      "                       6.3680e-08,  2.5741e-07,  1.4049e-07, -1.0139e-06,\n",
      "                       6.7723e-07, -1.5602e-06, -1.8013e-07, -1.0386e-07,\n",
      "                      -4.4610e-03, -9.2174e-07, -2.7647e-07, -9.6179e-07,\n",
      "                      -6.9088e-07, -5.7128e-07,  2.1237e-07,  3.6028e-07,\n",
      "                      -4.9281e-07, -4.8245e-07, -1.8093e-03,  5.3358e-06,\n",
      "                      -1.3056e-06, -3.1067e-07,  4.9027e-07,  1.9790e-07,\n",
      "                      -2.9773e-07, -7.8616e-07,  6.7547e-06,  4.8710e-07,\n",
      "                       1.3937e-02, -2.5117e-06, -3.2630e-07, -3.6504e-07,\n",
      "                       2.7552e-07, -5.8368e-07,  2.8236e-04,  2.7629e-07,\n",
      "                       2.2621e-07,  1.0522e-07, -5.1480e-08, -2.8303e-07,\n",
      "                      -2.6225e-07,  4.7482e-07,  5.9569e-07,  7.4521e-07,\n",
      "                      -1.8300e-07,  7.6040e-07, -3.8458e-07,  7.1203e-07,\n",
      "                      -5.3252e-07, -2.2881e-07,  8.1884e-05,  3.1500e-03,\n",
      "                      -1.4604e-06,  8.7093e-08,  9.2726e-07, -4.0365e-08,\n",
      "                      -2.3248e-05, -4.7502e-08, -2.2206e-07, -1.1254e-07,\n",
      "                       7.2932e-07, -2.5655e-07, -1.0909e-07, -1.9045e-07,\n",
      "                       1.2206e-07, -1.7726e-07, -2.6728e-07,  1.3731e-06,\n",
      "                      -3.5310e-07, -7.5421e-07,  3.3642e-06,  1.9261e-03,\n",
      "                      -7.1318e-08,  5.2625e-07,  3.9732e-07,  2.8173e-02,\n",
      "                       3.2981e-07,  4.5525e-07, -6.1013e-07, -9.4237e-07,\n",
      "                      -7.9445e-07,  1.0262e-06, -5.4256e-07,  7.3638e-07,\n",
      "                      -1.1728e-06, -1.8279e-07,  1.2194e-07,  5.7613e-09,\n",
      "                       3.8732e-03,  1.7323e-07, -3.1223e-07,  1.9651e-07,\n",
      "                      -9.8937e-07,  1.0675e-05,  2.6684e-03, -3.1162e-07,\n",
      "                       6.2319e-03, -5.8248e-07,  2.0953e-05,  1.6189e-07,\n",
      "                      -4.5920e-07, -6.1628e-07, -2.6355e-07,  7.2718e-06,\n",
      "                       1.0422e-06, -8.0076e-08,  9.8403e-04,  1.7297e-07,\n",
      "                      -1.3693e-03,  4.0971e-07, -9.5489e-08, -4.9605e-07,\n",
      "                      -4.0257e-07,  3.0938e-04, -1.2945e-06, -3.2599e-08,\n",
      "                      -9.9706e-07, -4.1802e-07,  7.1018e-07,  6.0113e-07,\n",
      "                       1.1379e-07, -5.4550e-07, -2.8082e-07, -8.6981e-07,\n",
      "                      -9.0216e-07,  1.0822e-02,  5.9370e-05,  1.4685e-07,\n",
      "                      -3.7692e-07,  1.1958e-08,  5.6174e-07, -2.8610e-03,\n",
      "                       1.8738e-07, -1.3347e-06,  4.8043e-07,  8.9408e-07,\n",
      "                      -2.4611e+01, -1.8045e-04,  4.0688e-07,  2.5152e-07,\n",
      "                      -2.4730e-08, -5.2830e-07, -1.3032e-07,  3.9965e-07,\n",
      "                       4.0443e-07, -6.4092e-06, -3.3919e-07,  8.3050e-07,\n",
      "                      -6.9595e-08, -3.7424e-07, -1.7311e-07,  5.2745e-07,\n",
      "                       1.5983e-07, -3.0397e-08,  7.2843e-07, -1.9238e-08,\n",
      "                       3.4345e-07, -2.3304e-07,  8.0657e-01,  2.1668e-07,\n",
      "                      -1.5608e-07,  6.9772e-08, -5.7140e-07,  1.6653e-04,\n",
      "                      -3.3977e-07, -2.2969e-09,  1.7026e-07,  5.4525e-02,\n",
      "                       5.3488e-07, -8.2535e-07, -2.2446e-07, -6.3522e-07,\n",
      "                       7.1657e-07,  7.4850e-07, -7.0804e-07,  2.4625e-07,\n",
      "                      -1.6733e-07, -1.3374e-07, -3.8484e-03,  1.0227e-06,\n",
      "                      -5.0893e-07,  1.0588e-06, -9.2560e-07,  2.6978e-08,\n",
      "                      -1.5296e-06,  7.4651e-07, -5.7592e-07, -1.6732e-07,\n",
      "                       4.0944e-07,  1.3753e-06, -3.8095e-07, -8.0112e-08,\n",
      "                      -5.9109e-07, -5.5508e-07, -1.9677e-07, -2.3072e-07,\n",
      "                      -1.5487e-07, -5.0279e-08, -1.1158e-02,  2.5339e-07,\n",
      "                       1.0275e-06, -2.5522e-07,  9.2240e-07, -1.5663e-08,\n",
      "                       3.3843e-07, -8.8258e-07, -3.5441e-07,  2.3710e-07,\n",
      "                      -7.0711e-07, -2.9606e-07,  2.8801e-07, -6.5607e-08,\n",
      "                      -1.9916e-07, -1.3169e-06,  3.5684e-03,  3.8243e-02,\n",
      "                       4.4323e-07]),\n",
      "       size=(2835,), nnz=993, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([[   5,   27,   31,   35,   43,   55,   58,   63,   67,\n",
      "                         106,  111,  120,  122,  154,  166,  238,  254,  284,\n",
      "                         310,  315,  330,  334,  347,  355,  357,  372,  378,\n",
      "                         386,  392,  411,  431,  446,  455,  457,  488,  495,\n",
      "                         501,  505,  509,  510,  517,  519,  525,  542,  544,\n",
      "                         566,  568,  613,  628,  646,  654,  659,  666,  668,\n",
      "                         675,  676,  687,  703,  708,  721,  752,  778,  797,\n",
      "                         817,  822,  841,  842,  860,  865,  867,  871,  878,\n",
      "                         885,  888,  898,  914,  915,  930,  934,  950,  955,\n",
      "                         961,  997, 1001, 1014, 1019, 1021, 1022, 1025, 1084,\n",
      "                        1095, 1098, 1107, 1133, 1139, 1163, 1173, 1205, 1210,\n",
      "                        1218, 1285, 1291, 1316, 1318, 1323, 1347, 1365, 1378,\n",
      "                        1384, 1428, 1473, 1475, 1476, 1523, 1534, 1543, 1553,\n",
      "                        1571, 1579, 1593, 1607, 1610, 1633, 1648, 1662, 1678,\n",
      "                        1693, 1697, 1736, 1737, 1756, 1763, 1764, 1773, 1796,\n",
      "                        1800, 1815, 1820, 1827, 1851, 1852, 1870, 1873, 1916,\n",
      "                        1921, 1930, 1934, 1967, 1993, 2015, 2047, 2063, 2065,\n",
      "                        2067, 2071, 2079, 2086, 2092, 2100, 2125, 2132, 2166,\n",
      "                        2169, 2191, 2222, 2223, 2257, 2266, 2270, 2278, 2293,\n",
      "                        2295, 2359, 2360, 2400, 2410, 2415, 2434, 2448, 2449,\n",
      "                        2494, 2498, 2500, 2552, 2585, 2634, 2645, 2647, 2668,\n",
      "                        2673, 2674, 2688, 2693, 2696, 2702, 2713, 2721, 2740,\n",
      "                        2754, 2758, 2777]]),\n",
      "       values=tensor([-1.2026e-06,  1.2056e-07,  4.6418e-07, -3.5247e-09,\n",
      "                      -6.4417e-06, -6.7219e-09,  5.5414e-08,  5.8645e-01,\n",
      "                      -4.3485e-07,  2.3141e-06,  9.4506e-06, -1.7667e-07,\n",
      "                       1.2069e-06,  6.5684e-08, -8.0829e-08,  3.6947e-08,\n",
      "                       1.9371e-07, -4.1093e-06,  3.8812e-07,  2.8057e-07,\n",
      "                      -8.0189e-06, -1.3698e-07,  1.3310e-08, -2.6416e-07,\n",
      "                      -3.5484e-05,  7.2307e-08, -1.6115e-05,  5.0478e-07,\n",
      "                       2.3874e-07, -1.7204e-07, -4.8716e-08, -1.4230e-07,\n",
      "                      -5.6159e-08,  1.6473e-07, -1.4185e-07,  8.7655e-08,\n",
      "                      -2.8369e-07, -3.2233e-07, -6.5602e-07,  7.7701e-07,\n",
      "                       4.6430e-07,  2.9321e-07,  4.5333e-07, -4.4206e-07,\n",
      "                       3.9063e-07, -3.2059e-07,  5.1823e-08,  3.4678e-01,\n",
      "                       5.0022e-07,  1.7453e-07,  7.5646e-07,  5.0181e-08,\n",
      "                       4.7007e-07,  3.5883e-07, -4.9142e-08,  1.6347e-07,\n",
      "                      -1.6020e-07,  3.8899e-06, -4.6224e-07,  8.4634e-07,\n",
      "                      -7.5685e-07,  1.0434e-07, -1.4852e-07,  7.0485e-01,\n",
      "                       2.3620e-07, -3.2664e-08, -6.6154e-07, -4.9346e-07,\n",
      "                      -1.9170e-07, -4.6357e-08, -4.9288e-05,  3.6397e-07,\n",
      "                       1.4565e-07,  5.2686e-08,  2.6322e-07,  4.4723e-08,\n",
      "                       4.6550e-07,  5.5752e-08,  4.4033e-07,  4.6952e-07,\n",
      "                      -1.7511e-08, -1.6553e-07, -4.1996e-07, -2.5387e-08,\n",
      "                       1.4104e-01, -8.4923e-01,  5.8379e-01,  7.1075e-05,\n",
      "                      -2.4818e+00,  5.6528e-01, -4.9343e-08, -3.8432e-07,\n",
      "                      -3.1156e-07,  1.6713e-07, -3.9118e-07,  6.9399e-06,\n",
      "                      -2.3166e-07, -4.0396e-08,  5.7044e-07, -3.0228e-07,\n",
      "                       7.0972e-01, -5.2254e-07, -1.7618e-07, -4.7445e-07,\n",
      "                      -6.8696e-07,  1.3648e-08,  5.3954e-07, -7.4827e-08,\n",
      "                       4.0069e-07, -4.8871e-07,  2.7360e-07,  2.0119e-07,\n",
      "                      -6.7943e-07, -3.0411e-08,  2.7254e-07, -1.1619e-07,\n",
      "                       2.6892e-08, -6.5766e-07,  5.1407e-06, -3.4362e-07,\n",
      "                       1.3040e-07, -4.5559e-07,  4.1256e-07, -9.3782e-10,\n",
      "                       3.1499e-07, -4.4089e-07, -8.8466e-08, -2.5959e-07,\n",
      "                      -1.7688e-07,  2.3885e-07,  2.2339e-07, -4.4645e-07,\n",
      "                      -1.0589e-07, -2.8809e-07,  2.1014e-07, -4.1161e-07,\n",
      "                       6.5927e-08,  2.5766e-07, -5.3358e-07, -3.2543e-07,\n",
      "                      -3.8425e-07,  1.0249e-07,  7.5481e-08,  1.9755e-07,\n",
      "                       1.8442e-07,  4.3784e-05,  1.8681e-07,  5.4492e-08,\n",
      "                      -9.7288e-08,  2.0445e-07, -2.5113e-07, -3.4758e-08,\n",
      "                      -2.0676e-08, -5.8979e-07, -1.7134e-07, -4.5111e-07,\n",
      "                      -1.3009e-07, -1.8273e-07, -3.5259e-07, -5.1623e-06,\n",
      "                       3.7383e-01,  2.1439e-07,  3.8080e-07, -3.5446e-08,\n",
      "                      -1.2622e-06, -4.6855e-07,  2.0099e-07, -8.5925e-06,\n",
      "                      -3.6112e-07,  1.8413e-07,  8.0351e-08,  3.3192e-07,\n",
      "                       6.3512e-06,  2.3034e-08, -6.8024e-08,  3.0572e-07,\n",
      "                      -2.8700e-08, -7.9076e-09, -2.3028e-07,  9.4484e-08,\n",
      "                      -2.2407e-07,  1.1102e-04,  5.3959e-07, -1.8498e-07,\n",
      "                      -5.0634e-07, -2.8982e-07, -3.1890e-07,  5.2781e-08,\n",
      "                      -3.8360e-07,  3.7467e-07, -1.4179e-07,  4.4832e-07,\n",
      "                       3.1931e-01,  3.1952e-07, -2.0423e-06,  8.2456e-07,\n",
      "                      -9.4745e-09, -2.5407e-07, -2.8479e-07,  1.6313e-07,\n",
      "                      -2.9002e-07]),\n",
      "       size=(2835,), nnz=201, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([[   4,    6,   13,  ..., 2829, 2830, 2833]]),\n",
      "       values=tensor([-2.4182e-07,  1.8262e-02, -9.9521e-07,  ...,\n",
      "                       1.3009e-03,  3.3530e-07,  3.9467e-07]),\n",
      "       size=(2835,), nnz=1017, layout=torch.sparse_coo)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Could not infer dtype of ellipsis",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[135], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mindex:\n\u001b[0;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mtensor_nodes[i])\n\u001b[1;32m----> 5\u001b[0m     test \u001b[39m=\u001b[39m \u001b[39meval\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mtorch.tensor\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m([[\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49mdf\u001b[39m.\u001b[39;49mtensor_nodes[i]\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m([[\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m]])\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m0\u001b[39;49m] \u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m]])\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m     val \u001b[39m=\u001b[39m \u001b[39meval\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtorch.tensor\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m([\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mdf\u001b[39m.\u001b[39mtensor_nodes[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m([\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m])\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m])\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m     \u001b[39m#t_{i} = torch.sparse_coo_tensor(test,val, size=(2835,) )\u001b[39;00m\n",
      "File \u001b[1;32m<string>:1\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Could not infer dtype of ellipsis"
     ]
    }
   ],
   "source": [
    "csv_file_path = 'out/AIFB/RGAT_no_emb/LRP_nodes_table.csv'\n",
    "list = []\n",
    "for i in df.index:\n",
    "    print(df.tensor_nodes[i])\n",
    "    test = eval('torch.tensor'+ '([['+df.tensor_nodes[i].split('([[')[1].split(']])')[0] +']])')\n",
    "    val = eval('torch.tensor'+ '(['+df.tensor_nodes[0].split('([')[2].split('])')[0] +'])')\n",
    "    #t_{i} = torch.sparse_coo_tensor(test,val, size=(2835,) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>rel_nodes_new</th>\n",
       "      <th>rel_edges_new</th>\n",
       "      <th>max_nodes_new</th>\n",
       "      <th>pos_max_nodes_new</th>\n",
       "      <th>min_nodes_new</th>\n",
       "      <th>pos_min_nodes_new</th>\n",
       "      <th>max_edges_new</th>\n",
       "      <th>pos_max_edges_new</th>\n",
       "      <th>min_edges_new</th>\n",
       "      <th>pos_min_edges_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>tensor(2583, device='cuda:7')</td>\n",
       "      <td>tensor([0.0000e+00, 0.0000e+00, 0.0000e+00,  ....</td>\n",
       "      <td>tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00...</td>\n",
       "      <td>23.954380</td>\n",
       "      <td>1485</td>\n",
       "      <td>-24.611176</td>\n",
       "      <td>2583</td>\n",
       "      <td>61.515854</td>\n",
       "      <td>tensor([[   1, 1485]])</td>\n",
       "      <td>-97.712036</td>\n",
       "      <td>tensor([[   1, 2583]])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>tensor(2657, device='cuda:7')</td>\n",
       "      <td>tensor([ 0.0000e+00,  0.0000e+00, -4.4495e-08,...</td>\n",
       "      <td>tensor([[ 0.0000e+00,  0.0000e+00, -1.2724e-06...</td>\n",
       "      <td>21.767021</td>\n",
       "      <td>1276</td>\n",
       "      <td>-21.986816</td>\n",
       "      <td>1151</td>\n",
       "      <td>142.385300</td>\n",
       "      <td>tensor([[   1, 1276]])</td>\n",
       "      <td>-116.734055</td>\n",
       "      <td>tensor([[  16, 1276]])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>tensor(2030, device='cuda:7')</td>\n",
       "      <td>tensor([0.0000e+00, 0.0000e+00, 0.0000e+00,  ....</td>\n",
       "      <td>tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00...</td>\n",
       "      <td>12.116058</td>\n",
       "      <td>2113</td>\n",
       "      <td>-13.741415</td>\n",
       "      <td>2653</td>\n",
       "      <td>283.724609</td>\n",
       "      <td>tensor([[   3, 2113]])</td>\n",
       "      <td>-305.332916</td>\n",
       "      <td>tensor([[  12, 2113]])</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                     Unnamed: 1  \\\n",
       "0           3  tensor(2583, device='cuda:7')   \n",
       "1          34  tensor(2657, device='cuda:7')   \n",
       "2          22  tensor(2030, device='cuda:7')   \n",
       "\n",
       "                                       rel_nodes_new  \\\n",
       "0  tensor([0.0000e+00, 0.0000e+00, 0.0000e+00,  ....   \n",
       "1  tensor([ 0.0000e+00,  0.0000e+00, -4.4495e-08,...   \n",
       "2  tensor([0.0000e+00, 0.0000e+00, 0.0000e+00,  ....   \n",
       "\n",
       "                                       rel_edges_new  max_nodes_new  \\\n",
       "0  tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00...      23.954380   \n",
       "1  tensor([[ 0.0000e+00,  0.0000e+00, -1.2724e-06...      21.767021   \n",
       "2  tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00...      12.116058   \n",
       "\n",
       "   pos_max_nodes_new  min_nodes_new  pos_min_nodes_new  max_edges_new  \\\n",
       "0               1485     -24.611176               2583      61.515854   \n",
       "1               1276     -21.986816               1151     142.385300   \n",
       "2               2113     -13.741415               2653     283.724609   \n",
       "\n",
       "        pos_max_edges_new  min_edges_new       pos_min_edges_new  \n",
       "0  tensor([[   1, 1485]])     -97.712036  tensor([[   1, 2583]])  \n",
       "1  tensor([[   1, 1276]])    -116.734055  tensor([[  16, 1276]])  \n",
       "2  tensor([[   3, 2113]])    -305.332916  tensor([[  12, 2113]])  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = files[0]\n",
    "i2n = files[1]\n",
    "i2r = files[2]\n",
    "triples_plus = files[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_after_nodes = csv[0]\n",
    "large_after_edges = csv[1]\n",
    "edges = csv[2]\n",
    "nodes = csv[3]\n",
    "small_after_nodes = csv[4]\n",
    "small_after_edges = csv[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_before = torch.load('out/AIFB/RGAT_no_emb/pred_before.pt')\n",
    "filename = [file for file in os.listdir('out/AIFB/RGAT_no_emb/') if file.endswith(\".pt\")]\n",
    "name_list = []\n",
    "for i in range((len(filename)-1)):\n",
    "    first = filename[i].split('(')[2].split(',')[0]\n",
    "    try:\n",
    "        second = filename[i].split('adapt_tensor([ ')[1].split(']')[0].replace(' ','').replace(',','__')\n",
    "    except:\n",
    "        second = filename[i].split('adapt_')[1].split('.')[0]\n",
    "    name_list.append('pred_after'+first+'_'+second)\n",
    "\n",
    "pred_after2486_19__1025 = torch.load('out/AIFB/RGAT_no_emb/pred_after(17, tensor(2486, device=\\'cuda7\\'))adapt_tensor([  19, 1025])_5.pt')\n",
    "pred_after2486_19__2486 = torch.load('out/AIFB/RGAT_no_emb/pred_after(17, tensor(2486, device=\\'cuda7\\'))adapt_tensor([  19, 2486])_4.pt')\n",
    "pred_after2498_1__1485 = torch.load('out/AIFB/RGAT_no_emb/pred_after(21, tensor(2498, device=\\'cuda7\\'))adapt_tensor([   1, 1485])_2.pt')\n",
    "pred_after2498_7__1485 = torch.load('out/AIFB/RGAT_no_emb/pred_after(21, tensor(2498, device=\\'cuda7\\'))adapt_tensor([   7, 1485])_21.pt')\n",
    "pred_after2030_2113_22 = torch.load('out/AIFB/RGAT_no_emb/pred_after(22, tensor(2030, device=\\'cuda7\\'))adapt_2113_22.pt')\n",
    "pred_after2030_2653_5 = torch.load('out/AIFB/RGAT_no_emb/pred_after(22, tensor(2030, device=\\'cuda7\\'))adapt_2653_5.pt')\n",
    "pred_after2030_3__2113 = torch.load('out/AIFB/RGAT_no_emb/pred_after(22, tensor(2030, device=\\'cuda7\\'))adapt_tensor([   3, 2113])_22.pt')\n",
    "pred_after2030_12__2113= torch.load('out/AIFB/RGAT_no_emb/pred_after(22, tensor(2030, device=\\'cuda7\\'))adapt_tensor([  12, 2113])_3.pt')\n",
    "pred_after2583_1485_3 = torch.load('out/AIFB/RGAT_no_emb/pred_after(3, tensor(2583, device=\\'cuda7\\'))adapt_1485_3.pt')\n",
    "pred_after2583_2583_22 = torch.load('out/AIFB/RGAT_no_emb/pred_after(3, tensor(2583, device=\\'cuda7\\'))adapt_2583_22.pt')\n",
    "pred_after2657_1151_12 = torch.load('out/AIFB/RGAT_no_emb/pred_after(34, tensor(2657, device=\\'cuda7\\'))adapt_1151_12.pt')\n",
    "pred_after2657_1276_19 = torch.load('out/AIFB/RGAT_no_emb/pred_after(34, tensor(2657, device=\\'cuda7\\'))adapt_1276_19.pt')\n",
    "\n",
    "pred_after_list = [pred_after2486_19__1025,pred_after2486_19__2486,pred_after2498_1__1485,pred_after2498_7__1485,pred_after2030_2113_22,pred_after2030_2653_5,pred_after2030_3__2113,pred_after2030_12__2113,pred_after2583_1485_3,pred_after2583_2583_22,pred_after2657_1151_12,pred_after2657_1276_19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>rel_nodes_new</th>\n",
       "      <th>rel_edges_new</th>\n",
       "      <th>max_nodes_new</th>\n",
       "      <th>pos_max_nodes_new</th>\n",
       "      <th>min_nodes_new</th>\n",
       "      <th>pos_min_nodes_new</th>\n",
       "      <th>max_edges_new</th>\n",
       "      <th>pos_max_edges_new</th>\n",
       "      <th>min_edges_new</th>\n",
       "      <th>pos_min_edges_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>tensor(2030, device='cuda:7')</td>\n",
       "      <td>tensor([0.0000e+00, 0.0000e+00, 0.0000e+00,  ....</td>\n",
       "      <td>tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00...</td>\n",
       "      <td>12.116058</td>\n",
       "      <td>2113</td>\n",
       "      <td>-13.741415</td>\n",
       "      <td>2653</td>\n",
       "      <td>283.724609</td>\n",
       "      <td>tensor([[   3, 2113]])</td>\n",
       "      <td>-305.332916</td>\n",
       "      <td>tensor([[  12, 2113]])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>tensor(2486, device='cuda:7')</td>\n",
       "      <td>tensor([0.0000e+00, 0.0000e+00, 3.8014e-06,  ....</td>\n",
       "      <td>tensor([[ 0.0000e+00,  0.0000e+00,  1.5323e-05...</td>\n",
       "      <td>16.862610</td>\n",
       "      <td>2486</td>\n",
       "      <td>-15.271867</td>\n",
       "      <td>1485</td>\n",
       "      <td>310.629364</td>\n",
       "      <td>tensor([[   3, 2486]])</td>\n",
       "      <td>-336.856628</td>\n",
       "      <td>tensor([[   0, 2486]])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>tensor(2498, device='cuda:7')</td>\n",
       "      <td>tensor([0., 0., 0.,  ..., 0., 0., 0.])</td>\n",
       "      <td>tensor([[0., 0., 0.,  ..., 0., 0., 0.],\\r\\n   ...</td>\n",
       "      <td>225.307114</td>\n",
       "      <td>2498</td>\n",
       "      <td>-214.648071</td>\n",
       "      <td>1485</td>\n",
       "      <td>912.593323</td>\n",
       "      <td>tensor([[   0, 2498]])</td>\n",
       "      <td>-399.981750</td>\n",
       "      <td>tensor([[   1, 1485]])</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                     Unnamed: 1  \\\n",
       "0          22  tensor(2030, device='cuda:7')   \n",
       "1          17  tensor(2486, device='cuda:7')   \n",
       "2          21  tensor(2498, device='cuda:7')   \n",
       "\n",
       "                                       rel_nodes_new  \\\n",
       "0  tensor([0.0000e+00, 0.0000e+00, 0.0000e+00,  ....   \n",
       "1  tensor([0.0000e+00, 0.0000e+00, 3.8014e-06,  ....   \n",
       "2             tensor([0., 0., 0.,  ..., 0., 0., 0.])   \n",
       "\n",
       "                                       rel_edges_new  max_nodes_new  \\\n",
       "0  tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00...      12.116058   \n",
       "1  tensor([[ 0.0000e+00,  0.0000e+00,  1.5323e-05...      16.862610   \n",
       "2  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\\r\\n   ...     225.307114   \n",
       "\n",
       "   pos_max_nodes_new  min_nodes_new  pos_min_nodes_new  max_edges_new  \\\n",
       "0               2113     -13.741415               2653     283.724609   \n",
       "1               2486     -15.271867               1485     310.629364   \n",
       "2               2498    -214.648071               1485     912.593323   \n",
       "\n",
       "        pos_max_edges_new  min_edges_new       pos_min_edges_new  \n",
       "0  tensor([[   3, 2113]])    -305.332916  tensor([[  12, 2113]])  \n",
       "1  tensor([[   3, 2486]])    -336.856628  tensor([[   0, 2486]])  \n",
       "2  tensor([[   0, 2498]])    -399.981750  tensor([[   1, 1485]])  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pred nderung RGCN before/after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineplot_pred_before(tensor):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(tensor.detach().cpu().numpy())\n",
    "    plt.title('Prediction before Adaptation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(indices=tensor([], size=(2, 0)),\n",
      "       values=tensor([], size=(0,)),\n",
      "       size=(2835, 4), nnz=0, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([], size=(2, 0)),\n",
      "       values=tensor([], size=(0,)),\n",
      "       size=(2835, 4), nnz=0, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([], size=(2, 0)),\n",
      "       values=tensor([], size=(0,)),\n",
      "       size=(2835, 4), nnz=0, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([], size=(2, 0)),\n",
      "       values=tensor([], size=(0,)),\n",
      "       size=(2835, 4), nnz=0, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([], size=(2, 0)),\n",
      "       values=tensor([], size=(0,)),\n",
      "       size=(2835, 4), nnz=0, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([], size=(2, 0)),\n",
      "       values=tensor([], size=(0,)),\n",
      "       size=(2835, 4), nnz=0, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([], size=(2, 0)),\n",
      "       values=tensor([], size=(0,)),\n",
      "       size=(2835, 4), nnz=0, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([], size=(2, 0)),\n",
      "       values=tensor([], size=(0,)),\n",
      "       size=(2835, 4), nnz=0, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([], size=(2, 0)),\n",
      "       values=tensor([], size=(0,)),\n",
      "       size=(2835, 4), nnz=0, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([], size=(2, 0)),\n",
      "       values=tensor([], size=(0,)),\n",
      "       size=(2835, 4), nnz=0, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([], size=(2, 0)),\n",
      "       values=tensor([], size=(0,)),\n",
      "       size=(2835, 4), nnz=0, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([], size=(2, 0)),\n",
      "       values=tensor([], size=(0,)),\n",
      "       size=(2835, 4), nnz=0, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "for i in enumerate(name_list):\n",
    "    print((pred_before - pred_after_list[i[0]]).to_sparse_coo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevanzverteilung vor/nach Tausch Kante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>rel_nodes_new</th>\n",
       "      <th>rel_edges_new</th>\n",
       "      <th>max_nodes_new</th>\n",
       "      <th>pos_max_nodes_new</th>\n",
       "      <th>min_nodes_new</th>\n",
       "      <th>pos_min_nodes_new</th>\n",
       "      <th>max_edges_new</th>\n",
       "      <th>pos_max_edges_new</th>\n",
       "      <th>min_edges_new</th>\n",
       "      <th>pos_min_edges_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>tensor(2030, device='cuda:7')</td>\n",
       "      <td>tensor([0.0000e+00, 0.0000e+00, 0.0000e+00,  ....</td>\n",
       "      <td>tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00...</td>\n",
       "      <td>12.116058</td>\n",
       "      <td>2113</td>\n",
       "      <td>-13.741415</td>\n",
       "      <td>2653</td>\n",
       "      <td>283.724609</td>\n",
       "      <td>tensor([[   3, 2113]])</td>\n",
       "      <td>-305.332916</td>\n",
       "      <td>tensor([[  12, 2113]])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>tensor(2486, device='cuda:7')</td>\n",
       "      <td>tensor([0.0000e+00, 0.0000e+00, 3.8014e-06,  ....</td>\n",
       "      <td>tensor([[ 0.0000e+00,  0.0000e+00,  1.5323e-05...</td>\n",
       "      <td>16.862610</td>\n",
       "      <td>2486</td>\n",
       "      <td>-15.271867</td>\n",
       "      <td>1485</td>\n",
       "      <td>310.629364</td>\n",
       "      <td>tensor([[   3, 2486]])</td>\n",
       "      <td>-336.856628</td>\n",
       "      <td>tensor([[   0, 2486]])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>tensor(2498, device='cuda:7')</td>\n",
       "      <td>tensor([0., 0., 0.,  ..., 0., 0., 0.])</td>\n",
       "      <td>tensor([[0., 0., 0.,  ..., 0., 0., 0.],\\r\\n   ...</td>\n",
       "      <td>225.307114</td>\n",
       "      <td>2498</td>\n",
       "      <td>-214.648071</td>\n",
       "      <td>1485</td>\n",
       "      <td>912.593323</td>\n",
       "      <td>tensor([[   0, 2498]])</td>\n",
       "      <td>-399.981750</td>\n",
       "      <td>tensor([[   1, 1485]])</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                     Unnamed: 1  \\\n",
       "0          22  tensor(2030, device='cuda:7')   \n",
       "1          17  tensor(2486, device='cuda:7')   \n",
       "2          21  tensor(2498, device='cuda:7')   \n",
       "\n",
       "                                       rel_nodes_new  \\\n",
       "0  tensor([0.0000e+00, 0.0000e+00, 0.0000e+00,  ....   \n",
       "1  tensor([0.0000e+00, 0.0000e+00, 3.8014e-06,  ....   \n",
       "2             tensor([0., 0., 0.,  ..., 0., 0., 0.])   \n",
       "\n",
       "                                       rel_edges_new  max_nodes_new  \\\n",
       "0  tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00...      12.116058   \n",
       "1  tensor([[ 0.0000e+00,  0.0000e+00,  1.5323e-05...      16.862610   \n",
       "2  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\\r\\n   ...     225.307114   \n",
       "\n",
       "   pos_max_nodes_new  min_nodes_new  pos_min_nodes_new  max_edges_new  \\\n",
       "0               2113     -13.741415               2653     283.724609   \n",
       "1               2486     -15.271867               1485     310.629364   \n",
       "2               2498    -214.648071               1485     912.593323   \n",
       "\n",
       "        pos_max_edges_new  min_edges_new       pos_min_edges_new  \n",
       "0  tensor([[   3, 2113]])    -305.332916  tensor([[  12, 2113]])  \n",
       "1  tensor([[   3, 2486]])    -336.856628  tensor([[   0, 2486]])  \n",
       "2  tensor([[   0, 2498]])    -399.981750  tensor([[   1, 1485]])  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensor([0.0000e+00, 0.0000e+00, 3.8014e-06,  ..., 0.0000e+00, 0.0000e+00,\\r\\n        0.0000e+00])'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes.rel_nodes_new[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ' ...'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m stri\u001b[39m=\u001b[39m(nodes\u001b[39m.\u001b[39mrel_nodes_new[i]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m[\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[39m#values_str = re.search(r'\\[(.*?)\\]', nodes.rel_nodes_new[i]).group(1)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m values \u001b[39m=\u001b[39m [\u001b[39mfloat\u001b[39m(val) \u001b[39mfor\u001b[39;00m val \u001b[39min\u001b[39;00m stri\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m      6\u001b[0m \u001b[39m# Convert the list of values to a PyTorch tensor\u001b[39;00m\n\u001b[0;32m      7\u001b[0m reconstructed_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(values)\n",
      "Cell \u001b[1;32mIn[110], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m stri\u001b[39m=\u001b[39m(nodes\u001b[39m.\u001b[39mrel_nodes_new[i]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m[\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[39m#values_str = re.search(r'\\[(.*?)\\]', nodes.rel_nodes_new[i]).group(1)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m values \u001b[39m=\u001b[39m [\u001b[39mfloat\u001b[39;49m(val) \u001b[39mfor\u001b[39;00m val \u001b[39min\u001b[39;00m stri\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m      6\u001b[0m \u001b[39m# Convert the list of values to a PyTorch tensor\u001b[39;00m\n\u001b[0;32m      7\u001b[0m reconstructed_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(values)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ' ...'"
     ]
    }
   ],
   "source": [
    "for i in nodes.index:\n",
    "    stri=(nodes.rel_nodes_new[i].split('[')[1].split(']')[0])\n",
    "    #values_str = re.search(r'\\[(.*?)\\]', nodes.rel_nodes_new[i]).group(1)\n",
    "    values = [float(val) for val in stri.split(', ')]\n",
    "\n",
    "    # Convert the list of values to a PyTorch tensor\n",
    "    reconstructed_tensor = torch.tensor(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aifb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
