dataset:  MUTAG
model:  RGCN_no_emb
Labels loaded.
RDF loaded.
Graph loaded.
cuda:  True
shape edges:  torch.Size([63382, 3])
test_idx:  tensor([12917, 21950,  3144, 20225,  7271, 10768, 11934,  4336, 10172, 13510,
        19233, 19260,  7860,  9637,  7315, 21185,  9704, 15542,  1543,  9956,
        19946,  2144, 17777, 13745,  5234, 20943,  3410,  5643,   211,  3969,
        11213, 10620, 11150, 10248, 19890, 18276,  1166, 10336,  4256,   963,
         4369,  6785,  2579, 17531,   541, 13333, 19769, 16980, 14021,  9082,
        15956, 19216, 18218,   101,  5170,  6744, 10582,  7417, 15108, 22241,
        21863,  2846,  6607, 22189,  8783,  9376, 12544, 20261],
       device='cuda:7')
num_classes:  2
num_nodes:  22540
num_relations:  9
tensor([[0.5408, 0.4592],
        [0.5569, 0.4431],
        [0.5274, 0.4726],
        [0.5179, 0.4821],
        [0.5742, 0.4258],
        [0.4733, 0.5267],
        [0.4806, 0.5194],
        [0.5465, 0.4535],
        [0.5110, 0.4890],
        [0.5052, 0.4948],
        [0.5614, 0.4386],
        [0.5258, 0.4742],
        [0.5071, 0.4929],
        [0.5064, 0.4936],
        [0.5216, 0.4784],
        [0.5467, 0.4533],
        [0.5457, 0.4543],
        [0.5256, 0.4744],
        [0.5015, 0.4985],
        [0.5259, 0.4741],
        [0.5146, 0.4854],
        [0.5370, 0.4630],
        [0.5350, 0.4650],
        [0.5548, 0.4452],
        [0.5082, 0.4918],
        [0.5063, 0.4937],
        [0.5360, 0.4640],
        [0.5135, 0.4865],
        [0.5707, 0.4293],
        [0.5560, 0.4440],
        [0.5220, 0.4780],
        [0.5420, 0.4580],
        [0.5314, 0.4686],
        [0.5138, 0.4862],
        [0.5385, 0.4615],
        [0.5383, 0.4617],
        [0.5775, 0.4225],
        [0.5287, 0.4713],
        [0.5167, 0.4833],
        [0.4720, 0.5280],
        [0.5395, 0.4605],
        [0.5453, 0.4547],
        [0.4826, 0.5174],
        [0.5251, 0.4749],
        [0.4750, 0.5250],
        [0.4715, 0.5285],
        [0.5446, 0.4554],
        [0.5877, 0.4123],
        [0.5085, 0.4915],
        [0.5752, 0.4248],
        [0.5344, 0.4656],
        [0.5483, 0.4517],
        [0.5046, 0.4954],
        [0.5138, 0.4862],
        [0.4978, 0.5022],
        [0.6067, 0.3933],
        [0.5250, 0.4750],
        [0.5672, 0.4328],
        [0.5280, 0.4720],
        [0.5461, 0.4539],
        [0.5281, 0.4719],
        [0.5062, 0.4938],
        [0.5186, 0.4814],
        [0.5026, 0.4974],
        [0.5068, 0.4932],
        [0.5068, 0.4932],
        [0.4842, 0.5158],
        [0.5036, 0.4964],
        [0.5194, 0.4806],
        [0.5125, 0.4875],
        [0.4923, 0.5077],
        [0.4883, 0.5117],
        [0.4731, 0.5269],
        [0.4670, 0.5330],
        [0.4874, 0.5126],
        [0.4745, 0.5255],
        [0.5774, 0.4226],
        [0.4990, 0.5010],
        [0.4687, 0.5313],
        [0.4866, 0.5134],
        [0.5264, 0.4736],
        [0.5589, 0.4411],
        [0.5143, 0.4857],
        [0.5278, 0.4722],
        [0.4928, 0.5072],
        [0.5266, 0.4734],
        [0.5124, 0.4876],
        [0.5333, 0.4667],
        [0.5114, 0.4886],
        [0.5383, 0.4617],
        [0.5129, 0.4871],
        [0.4908, 0.5092],
        [0.5272, 0.4728],
        [0.5041, 0.4959],
        [0.4900, 0.5100],
        [0.5288, 0.4712],
        [0.5185, 0.4815],
        [0.5495, 0.4505],
        [0.5318, 0.4682],
        [0.5865, 0.4135],
        [0.5194, 0.4806],
        [0.5370, 0.4630],
        [0.5161, 0.4839],
        [0.5242, 0.4758],
        [0.5305, 0.4695],
        [0.5006, 0.4994],
        [0.5230, 0.4770],
        [0.4899, 0.5101],
        [0.5619, 0.4381],
        [0.5665, 0.4335],
        [0.4797, 0.5203],
        [0.5177, 0.4823],
        [0.5171, 0.4829],
        [0.5264, 0.4736],
        [0.5411, 0.4589],
        [0.4701, 0.5299],
        [0.4943, 0.5057],
        [0.5251, 0.4749],
        [0.5192, 0.4808],
        [0.4727, 0.5273],
        [0.5183, 0.4817],
        [0.5378, 0.4622],
        [0.5245, 0.4755],
        [0.5229, 0.4771],
        [0.5003, 0.4997],
        [0.5662, 0.4338],
        [0.5398, 0.4602],
        [0.5203, 0.4797],
        [0.5094, 0.4906],
        [0.5180, 0.4820],
        [0.5252, 0.4748],
        [0.5413, 0.4587],
        [0.5319, 0.4681],
        [0.4664, 0.5336],
        [0.5083, 0.4917],
        [0.5223, 0.4777],
        [0.5341, 0.4659],
        [0.5319, 0.4681],
        [0.5055, 0.4945],
        [0.4812, 0.5188],
        [0.5174, 0.4826],
        [0.5340, 0.4660],
        [0.5371, 0.4629],
        [0.5409, 0.4591],
        [0.5462, 0.4538],
        [0.5194, 0.4806],
        [0.5552, 0.4448],
        [0.5449, 0.4551],
        [0.5584, 0.4416],
        [0.5555, 0.4445],
        [0.5469, 0.4531],
        [0.5158, 0.4842],
        [0.5240, 0.4760],
        [0.4922, 0.5078],
        [0.5780, 0.4220],
        [0.4893, 0.5107],
        [0.4989, 0.5011],
        [0.5296, 0.4704],
        [0.5303, 0.4697],
        [0.4927, 0.5073],
        [0.5194, 0.4806],
        [0.4979, 0.5021],
        [0.5173, 0.4827],
        [0.5167, 0.4833],
        [0.4787, 0.5213],
        [0.5020, 0.4980],
        [0.5539, 0.4461],
        [0.4917, 0.5083],
        [0.4937, 0.5063],
        [0.5458, 0.4542],
        [0.4736, 0.5264],
        [0.5131, 0.4869],
        [0.5263, 0.4737],
        [0.5121, 0.4879],
        [0.4889, 0.5111],
        [0.4672, 0.5328],
        [0.5382, 0.4618],
        [0.5293, 0.4707],
        [0.4941, 0.5059],
        [0.4734, 0.5266],
        [0.5492, 0.4508],
        [0.5161, 0.4839],
        [0.5007, 0.4993],
        [0.5074, 0.4926],
        [0.5487, 0.4513],
        [0.5123, 0.4877],
        [0.5693, 0.4307],
        [0.5031, 0.4969],
        [0.4946, 0.5054],
        [0.5208, 0.4792],
        [0.5328, 0.4672],
        [0.5138, 0.4862],
        [0.5078, 0.4922],
        [0.4903, 0.5097],
        [0.4966, 0.5034],
        [0.5236, 0.4764],
        [0.5576, 0.4424],
        [0.5253, 0.4747],
        [0.5274, 0.4726],
        [0.5562, 0.4438],
        [0.4972, 0.5028],
        [0.5530, 0.4470],
        [0.4899, 0.5101],
        [0.4788, 0.5212],
        [0.5394, 0.4606],
        [0.4766, 0.5234],
        [0.5349, 0.4651],
        [0.5339, 0.4661],
        [0.5536, 0.4464],
        [0.4643, 0.5357],
        [0.5226, 0.4774],
        [0.4968, 0.5032],
        [0.5237, 0.4763],
        [0.5300, 0.4700],
        [0.4929, 0.5071],
        [0.5034, 0.4966],
        [0.4763, 0.5237],
        [0.5064, 0.4936],
        [0.5420, 0.4580],
        [0.5048, 0.4952],
        [0.5493, 0.4507],
        [0.5315, 0.4685],
        [0.5081, 0.4919],
        [0.4977, 0.5023],
        [0.5162, 0.4838],
        [0.5337, 0.4663],
        [0.5393, 0.4607],
        [0.5008, 0.4992],
        [0.5206, 0.4794],
        [0.5457, 0.4543],
        [0.5153, 0.4847],
        [0.5362, 0.4638],
        [0.5356, 0.4644],
        [0.5254, 0.4746],
        [0.5092, 0.4908],
        [0.4701, 0.5299],
        [0.5558, 0.4442],
        [0.4979, 0.5021],
        [0.5466, 0.4534],
        [0.5524, 0.4476],
        [0.4975, 0.5025],
        [0.5039, 0.4961],
        [0.5109, 0.4891],
        [0.5463, 0.4537],
        [0.5134, 0.4866],
        [0.5224, 0.4776],
        [0.4911, 0.5089],
        [0.5171, 0.4829],
        [0.5117, 0.4883],
        [0.5107, 0.4893],
        [0.5267, 0.4733],
        [0.5113, 0.4887],
        [0.4966, 0.5034],
        [0.5385, 0.4615],
        [0.5193, 0.4807],
        [0.5049, 0.4951],
        [0.5870, 0.4130],
        [0.5758, 0.4242],
        [0.5106, 0.4894],
        [0.5518, 0.4482],
        [0.5470, 0.4530],
        [0.5441, 0.4559],
        [0.5155, 0.4845],
        [0.5154, 0.4846],
        [0.4748, 0.5252],
        [0.4892, 0.5108],
        [0.4755, 0.5245],
        [0.4810, 0.5190],
        [0.4917, 0.5083],
        [0.5337, 0.4663],
        [0.5090, 0.4910],
        [0.5153, 0.4847]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0002 loss: 0.6904 acc_train: 0.5368 time: 0.1587s
tensor([[0.7111, 0.2889],
        [0.7461, 0.2539],
        [0.7361, 0.2639],
        [0.6990, 0.3010],
        [0.7652, 0.2348],
        [0.7031, 0.2969],
        [0.6862, 0.3138],
        [0.7421, 0.2579],
        [0.7012, 0.2988],
        [0.7276, 0.2724],
        [0.7386, 0.2614],
        [0.6956, 0.3044],
        [0.6952, 0.3048],
        [0.6951, 0.3049],
        [0.7261, 0.2739],
        [0.7317, 0.2683],
        [0.7479, 0.2521],
        [0.7231, 0.2769],
        [0.6865, 0.3135],
        [0.7120, 0.2880],
        [0.7241, 0.2759],
        [0.7091, 0.2909],
        [0.7535, 0.2465],
        [0.7448, 0.2552],
        [0.7119, 0.2881],
        [0.6980, 0.3020],
        [0.7191, 0.2809],
        [0.7237, 0.2763],
        [0.7482, 0.2518],
        [0.7475, 0.2525],
        [0.7294, 0.2706],
        [0.6959, 0.3041],
        [0.7159, 0.2841],
        [0.7354, 0.2646],
        [0.7217, 0.2783],
        [0.7210, 0.2790],
        [0.7388, 0.2612],
        [0.7099, 0.2901],
        [0.7310, 0.2690],
        [0.6714, 0.3286],
        [0.7341, 0.2659],
        [0.7558, 0.2442],
        [0.6785, 0.3215],
        [0.7228, 0.2772],
        [0.6982, 0.3018],
        [0.7013, 0.2987],
        [0.7445, 0.2555],
        [0.7571, 0.2429],
        [0.7091, 0.2909],
        [0.7438, 0.2562],
        [0.7205, 0.2795],
        [0.7281, 0.2719],
        [0.7041, 0.2959],
        [0.7187, 0.2813],
        [0.7371, 0.2629],
        [0.7647, 0.2353],
        [0.7354, 0.2646],
        [0.7427, 0.2573],
        [0.7172, 0.2828],
        [0.7147, 0.2853],
        [0.7118, 0.2882],
        [0.7117, 0.2883],
        [0.7183, 0.2817],
        [0.7456, 0.2544],
        [0.7192, 0.2808],
        [0.7068, 0.2932],
        [0.6833, 0.3167],
        [0.7006, 0.2994],
        [0.7361, 0.2639],
        [0.7347, 0.2653],
        [0.6967, 0.3033],
        [0.7077, 0.2923],
        [0.7279, 0.2721],
        [0.7150, 0.2850],
        [0.6973, 0.3027],
        [0.6974, 0.3026],
        [0.7631, 0.2369],
        [0.7164, 0.2836],
        [0.7187, 0.2813],
        [0.6941, 0.3059],
        [0.7054, 0.2946],
        [0.7429, 0.2571],
        [0.7068, 0.2932],
        [0.7201, 0.2799],
        [0.7086, 0.2914],
        [0.7149, 0.2851],
        [0.7258, 0.2742],
        [0.7163, 0.2837],
        [0.7021, 0.2979],
        [0.7370, 0.2630],
        [0.7001, 0.2999],
        [0.7183, 0.2817],
        [0.7248, 0.2752],
        [0.6874, 0.3126],
        [0.7116, 0.2884],
        [0.7379, 0.2621],
        [0.7327, 0.2673],
        [0.7018, 0.2982],
        [0.7258, 0.2742],
        [0.7439, 0.2561],
        [0.7348, 0.2652],
        [0.7144, 0.2856],
        [0.7115, 0.2885],
        [0.7159, 0.2841],
        [0.7288, 0.2712],
        [0.7273, 0.2727],
        [0.7316, 0.2684],
        [0.7094, 0.2906],
        [0.7166, 0.2834],
        [0.7342, 0.2658],
        [0.6792, 0.3208],
        [0.7096, 0.2904],
        [0.7318, 0.2682],
        [0.7284, 0.2716],
        [0.7170, 0.2830],
        [0.6961, 0.3039],
        [0.7172, 0.2828],
        [0.7391, 0.2609],
        [0.7283, 0.2717],
        [0.6902, 0.3098],
        [0.7130, 0.2870],
        [0.7259, 0.2741],
        [0.7209, 0.2791],
        [0.7291, 0.2709],
        [0.7196, 0.2804],
        [0.7358, 0.2642],
        [0.7044, 0.2956],
        [0.7182, 0.2818],
        [0.7046, 0.2954],
        [0.6995, 0.3005],
        [0.7277, 0.2723],
        [0.7370, 0.2630],
        [0.7353, 0.2647],
        [0.6860, 0.3140],
        [0.7046, 0.2954],
        [0.7102, 0.2898],
        [0.6984, 0.3016],
        [0.7371, 0.2629],
        [0.7014, 0.2986],
        [0.7013, 0.2987],
        [0.7002, 0.2998],
        [0.7307, 0.2693],
        [0.7167, 0.2833],
        [0.7242, 0.2758],
        [0.7227, 0.2773],
        [0.7234, 0.2766],
        [0.7314, 0.2686],
        [0.7349, 0.2651],
        [0.7451, 0.2549],
        [0.7518, 0.2482],
        [0.7380, 0.2620],
        [0.7369, 0.2631],
        [0.7493, 0.2507],
        [0.7190, 0.2810],
        [0.7723, 0.2277],
        [0.6712, 0.3288],
        [0.7117, 0.2883],
        [0.7368, 0.2632],
        [0.7199, 0.2801],
        [0.7160, 0.2840],
        [0.7359, 0.2641],
        [0.7178, 0.2822],
        [0.7053, 0.2947],
        [0.7248, 0.2752],
        [0.6668, 0.3332],
        [0.7053, 0.2947],
        [0.7244, 0.2756],
        [0.6938, 0.3062],
        [0.7136, 0.2864],
        [0.7160, 0.2840],
        [0.6674, 0.3326],
        [0.7078, 0.2922],
        [0.7301, 0.2699],
        [0.7239, 0.2761],
        [0.7192, 0.2808],
        [0.7063, 0.2937],
        [0.7475, 0.2525],
        [0.7173, 0.2827],
        [0.7027, 0.2973],
        [0.7165, 0.2835],
        [0.7338, 0.2662],
        [0.7162, 0.2838],
        [0.6792, 0.3208],
        [0.7101, 0.2899],
        [0.7462, 0.2538],
        [0.7274, 0.2726],
        [0.7244, 0.2756],
        [0.7141, 0.2859],
        [0.7154, 0.2846],
        [0.7309, 0.2691],
        [0.7345, 0.2655],
        [0.6751, 0.3249],
        [0.6934, 0.3066],
        [0.6907, 0.3093],
        [0.7234, 0.2766],
        [0.7315, 0.2685],
        [0.7486, 0.2514],
        [0.7070, 0.2930],
        [0.7410, 0.2590],
        [0.7516, 0.2484],
        [0.6988, 0.3012],
        [0.7476, 0.2524],
        [0.7058, 0.2942],
        [0.6865, 0.3135],
        [0.7511, 0.2489],
        [0.7127, 0.2873],
        [0.7358, 0.2642],
        [0.7592, 0.2408],
        [0.7208, 0.2792],
        [0.6800, 0.3200],
        [0.7324, 0.2676],
        [0.7061, 0.2939],
        [0.7316, 0.2684],
        [0.7270, 0.2730],
        [0.7291, 0.2709],
        [0.7139, 0.2861],
        [0.7012, 0.2988],
        [0.7269, 0.2731],
        [0.7232, 0.2768],
        [0.7260, 0.2740],
        [0.6957, 0.3043],
        [0.7535, 0.2465],
        [0.6932, 0.3068],
        [0.7284, 0.2716],
        [0.7296, 0.2704],
        [0.7513, 0.2487],
        [0.7098, 0.2902],
        [0.7132, 0.2868],
        [0.7326, 0.2674],
        [0.7600, 0.2400],
        [0.7333, 0.2667],
        [0.7364, 0.2636],
        [0.7553, 0.2447],
        [0.7342, 0.2658],
        [0.7424, 0.2576],
        [0.7157, 0.2843],
        [0.7099, 0.2901],
        [0.7059, 0.2941],
        [0.7281, 0.2719],
        [0.7144, 0.2856],
        [0.7065, 0.2935],
        [0.7142, 0.2858],
        [0.7199, 0.2801],
        [0.7298, 0.2702],
        [0.7356, 0.2644],
        [0.7234, 0.2766],
        [0.7094, 0.2906],
        [0.7425, 0.2575],
        [0.7240, 0.2760],
        [0.7171, 0.2829],
        [0.7309, 0.2691],
        [0.7233, 0.2767],
        [0.7044, 0.2956],
        [0.7200, 0.2800],
        [0.7320, 0.2680],
        [0.7262, 0.2738],
        [0.7468, 0.2532],
        [0.7540, 0.2460],
        [0.7383, 0.2617],
        [0.7504, 0.2496],
        [0.7408, 0.2592],
        [0.7226, 0.2774],
        [0.7211, 0.2789],
        [0.7248, 0.2752],
        [0.6845, 0.3155],
        [0.7058, 0.2942],
        [0.7015, 0.2985],
        [0.7185, 0.2815],
        [0.7122, 0.2878],
        [0.7205, 0.2795],
        [0.7416, 0.2584],
        [0.7180, 0.2820]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0003 loss: 0.6631 acc_train: 0.6103 time: 0.1388s
tensor([[0.7165, 0.2835],
        [0.7732, 0.2268],
        [0.7625, 0.2375],
        [0.7207, 0.2792],
        [0.7878, 0.2122],
        [0.7327, 0.2673],
        [0.7096, 0.2904],
        [0.7571, 0.2429],
        [0.7287, 0.2713],
        [0.7503, 0.2497],
        [0.7583, 0.2417],
        [0.7079, 0.2921],
        [0.7133, 0.2867],
        [0.7136, 0.2864],
        [0.7534, 0.2466],
        [0.7497, 0.2503],
        [0.7716, 0.2284],
        [0.7458, 0.2542],
        [0.7052, 0.2948],
        [0.7282, 0.2718],
        [0.7559, 0.2441],
        [0.7215, 0.2785],
        [0.7838, 0.2162],
        [0.7695, 0.2305],
        [0.7301, 0.2699],
        [0.7165, 0.2835],
        [0.7312, 0.2688],
        [0.7652, 0.2348],
        [0.7536, 0.2464],
        [0.7625, 0.2375],
        [0.7617, 0.2383],
        [0.6922, 0.3078],
        [0.7322, 0.2678],
        [0.7626, 0.2374],
        [0.7369, 0.2631],
        [0.7494, 0.2506],
        [0.7506, 0.2494],
        [0.7213, 0.2787],
        [0.7650, 0.2350],
        [0.6919, 0.3081],
        [0.7541, 0.2459],
        [0.7892, 0.2108],
        [0.7079, 0.2921],
        [0.7434, 0.2566],
        [0.7306, 0.2694],
        [0.7393, 0.2607],
        [0.7735, 0.2265],
        [0.7798, 0.2202],
        [0.7447, 0.2553],
        [0.7596, 0.2404],
        [0.7384, 0.2616],
        [0.7543, 0.2457],
        [0.7219, 0.2781],
        [0.7540, 0.2460],
        [0.7773, 0.2227],
        [0.7761, 0.2239],
        [0.7669, 0.2331],
        [0.7562, 0.2438],
        [0.7275, 0.2725],
        [0.7252, 0.2748],
        [0.7303, 0.2697],
        [0.7215, 0.2785],
        [0.7476, 0.2524],
        [0.7819, 0.2181],
        [0.7454, 0.2546],
        [0.7241, 0.2759],
        [0.7174, 0.2826],
        [0.7156, 0.2844],
        [0.7698, 0.2302],
        [0.7595, 0.2405],
        [0.7235, 0.2765],
        [0.7315, 0.2685],
        [0.7771, 0.2229],
        [0.7554, 0.2446],
        [0.7267, 0.2733],
        [0.7266, 0.2734],
        [0.7838, 0.2162],
        [0.7468, 0.2532],
        [0.7646, 0.2354],
        [0.7131, 0.2869],
        [0.7089, 0.2911],
        [0.7522, 0.2478],
        [0.7258, 0.2742],
        [0.7352, 0.2648],
        [0.7383, 0.2617],
        [0.7336, 0.2664],
        [0.7572, 0.2428],
        [0.7260, 0.2740],
        [0.7211, 0.2789],
        [0.7605, 0.2395],
        [0.7231, 0.2769],
        [0.7481, 0.2519],
        [0.7406, 0.2594],
        [0.6917, 0.3083],
        [0.7417, 0.2583],
        [0.7704, 0.2296],
        [0.7697, 0.2303],
        [0.7030, 0.2970],
        [0.7518, 0.2482],
        [0.7491, 0.2509],
        [0.7557, 0.2443],
        [0.7280, 0.2720],
        [0.7319, 0.2681],
        [0.7342, 0.2658],
        [0.7605, 0.2395],
        [0.7527, 0.2473],
        [0.7598, 0.2402],
        [0.7506, 0.2494],
        [0.7212, 0.2788],
        [0.7485, 0.2515],
        [0.7217, 0.2783],
        [0.7354, 0.2646],
        [0.7626, 0.2374],
        [0.7538, 0.2462],
        [0.7256, 0.2744],
        [0.7352, 0.2648],
        [0.7586, 0.2414],
        [0.7672, 0.2328],
        [0.7577, 0.2423],
        [0.7271, 0.2729],
        [0.7392, 0.2608],
        [0.7395, 0.2605],
        [0.7401, 0.2599],
        [0.7509, 0.2491],
        [0.7488, 0.2512],
        [0.7555, 0.2445],
        [0.7083, 0.2917],
        [0.7441, 0.2559],
        [0.7335, 0.2665],
        [0.7110, 0.2890],
        [0.7596, 0.2404],
        [0.7521, 0.2479],
        [0.7707, 0.2293],
        [0.7078, 0.2922],
        [0.7352, 0.2648],
        [0.7230, 0.2770],
        [0.7067, 0.2933],
        [0.7725, 0.2275],
        [0.7259, 0.2741],
        [0.7300, 0.2700],
        [0.7190, 0.2810],
        [0.7515, 0.2485],
        [0.7249, 0.2751],
        [0.7325, 0.2675],
        [0.7243, 0.2757],
        [0.7524, 0.2476],
        [0.7495, 0.2505],
        [0.7544, 0.2456],
        [0.7649, 0.2351],
        [0.7733, 0.2267],
        [0.7550, 0.2450],
        [0.7751, 0.2249],
        [0.7847, 0.2153],
        [0.7685, 0.2315],
        [0.7904, 0.2096],
        [0.6922, 0.3078],
        [0.7535, 0.2465],
        [0.7628, 0.2372],
        [0.7428, 0.2572],
        [0.7464, 0.2536],
        [0.7692, 0.2308],
        [0.7602, 0.2398],
        [0.7190, 0.2810],
        [0.7472, 0.2528],
        [0.7024, 0.2976],
        [0.7354, 0.2646],
        [0.7387, 0.2613],
        [0.7206, 0.2794],
        [0.7453, 0.2547],
        [0.7240, 0.2760],
        [0.7105, 0.2895],
        [0.7199, 0.2801],
        [0.7529, 0.2471],
        [0.7443, 0.2557],
        [0.7530, 0.2470],
        [0.7480, 0.2520],
        [0.7784, 0.2216],
        [0.7315, 0.2685],
        [0.7253, 0.2747],
        [0.7638, 0.2362],
        [0.7623, 0.2377],
        [0.7434, 0.2566],
        [0.7048, 0.2952],
        [0.7326, 0.2674],
        [0.7728, 0.2272],
        [0.7632, 0.2368],
        [0.7269, 0.2731],
        [0.7403, 0.2597],
        [0.7391, 0.2609],
        [0.7599, 0.2401],
        [0.7727, 0.2273],
        [0.6822, 0.3178],
        [0.7096, 0.2904],
        [0.7102, 0.2898],
        [0.7605, 0.2395],
        [0.7586, 0.2414],
        [0.7680, 0.2320],
        [0.7220, 0.2780],
        [0.7698, 0.2302],
        [0.7752, 0.2248],
        [0.7181, 0.2819],
        [0.7769, 0.2231],
        [0.7371, 0.2629],
        [0.7137, 0.2863],
        [0.7812, 0.2188],
        [0.7456, 0.2544],
        [0.7686, 0.2314],
        [0.7941, 0.2059],
        [0.7270, 0.2730],
        [0.7080, 0.2920],
        [0.7605, 0.2395],
        [0.7244, 0.2756],
        [0.7651, 0.2349],
        [0.7457, 0.2543],
        [0.7615, 0.2385],
        [0.7496, 0.2504],
        [0.7315, 0.2685],
        [0.7598, 0.2402],
        [0.7322, 0.2678],
        [0.7542, 0.2458],
        [0.6947, 0.3053],
        [0.7880, 0.2120],
        [0.7143, 0.2857],
        [0.7693, 0.2307],
        [0.7575, 0.2425],
        [0.7902, 0.2098],
        [0.7243, 0.2757],
        [0.7519, 0.2481],
        [0.7565, 0.2435],
        [0.7903, 0.2097],
        [0.7652, 0.2348],
        [0.7582, 0.2418],
        [0.7803, 0.2197],
        [0.7593, 0.2407],
        [0.7828, 0.2172],
        [0.7616, 0.2384],
        [0.7208, 0.2792],
        [0.7391, 0.2609],
        [0.7527, 0.2473],
        [0.7242, 0.2758],
        [0.7374, 0.2626],
        [0.7397, 0.2603],
        [0.7375, 0.2625],
        [0.7457, 0.2543],
        [0.7727, 0.2273],
        [0.7517, 0.2483],
        [0.7467, 0.2533],
        [0.7764, 0.2236],
        [0.7562, 0.2438],
        [0.7488, 0.2512],
        [0.7487, 0.2513],
        [0.7628, 0.2372],
        [0.7340, 0.2660],
        [0.7381, 0.2619],
        [0.7606, 0.2394],
        [0.7592, 0.2408],
        [0.7572, 0.2428],
        [0.7747, 0.2253],
        [0.7690, 0.2310],
        [0.7721, 0.2279],
        [0.7599, 0.2401],
        [0.7354, 0.2646],
        [0.7399, 0.2601],
        [0.7504, 0.2496],
        [0.7061, 0.2939],
        [0.7368, 0.2632],
        [0.7355, 0.2645],
        [0.7569, 0.2431],
        [0.7451, 0.2549],
        [0.7406, 0.2594],
        [0.7765, 0.2235],
        [0.7524, 0.2476]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0004 loss: 0.6590 acc_train: 0.6103 time: 0.1460s
tensor([[0.6722, 0.3278],
        [0.7522, 0.2478],
        [0.7375, 0.2625],
        [0.6932, 0.3068],
        [0.7610, 0.2390],
        [0.7076, 0.2924],
        [0.6744, 0.3256],
        [0.7229, 0.2771],
        [0.7022, 0.2978],
        [0.7166, 0.2834],
        [0.7272, 0.2728],
        [0.6716, 0.3284],
        [0.6834, 0.3166],
        [0.6788, 0.3212],
        [0.7280, 0.2720],
        [0.7195, 0.2805],
        [0.7479, 0.2521],
        [0.7133, 0.2867],
        [0.6735, 0.3265],
        [0.6925, 0.3075],
        [0.7321, 0.2679],
        [0.6824, 0.3176],
        [0.7609, 0.2391],
        [0.7422, 0.2578],
        [0.7000, 0.3000],
        [0.6815, 0.3185],
        [0.6990, 0.3010],
        [0.7543, 0.2457],
        [0.7081, 0.2919],
        [0.7317, 0.2683],
        [0.7422, 0.2578],
        [0.6427, 0.3573],
        [0.6993, 0.3007],
        [0.7395, 0.2605],
        [0.7027, 0.2973],
        [0.7326, 0.2674],
        [0.7128, 0.2872],
        [0.6830, 0.3170],
        [0.7460, 0.2540],
        [0.6546, 0.3454],
        [0.7254, 0.2746],
        [0.7687, 0.2313],
        [0.6838, 0.3162],
        [0.7167, 0.2833],
        [0.7083, 0.2917],
        [0.7167, 0.2833],
        [0.7534, 0.2466],
        [0.7563, 0.2437],
        [0.7254, 0.2746],
        [0.7323, 0.2677],
        [0.7071, 0.2929],
        [0.7320, 0.2680],
        [0.6857, 0.3143],
        [0.7354, 0.2646],
        [0.7607, 0.2393],
        [0.7442, 0.2558],
        [0.7474, 0.2526],
        [0.7226, 0.2774],
        [0.6899, 0.3101],
        [0.6850, 0.3150],
        [0.6991, 0.3009],
        [0.6817, 0.3183],
        [0.7206, 0.2794],
        [0.7599, 0.2401],
        [0.7184, 0.2816],
        [0.6914, 0.3086],
        [0.6984, 0.3016],
        [0.6737, 0.3263],
        [0.7451, 0.2549],
        [0.7295, 0.2705],
        [0.6957, 0.3043],
        [0.6975, 0.3025],
        [0.7653, 0.2347],
        [0.7317, 0.2683],
        [0.7008, 0.2992],
        [0.6989, 0.3011],
        [0.7554, 0.2446],
        [0.7224, 0.2776],
        [0.7471, 0.2529],
        [0.6829, 0.3171],
        [0.6609, 0.3391],
        [0.7129, 0.2871],
        [0.6899, 0.3101],
        [0.7023, 0.2977],
        [0.7122, 0.2878],
        [0.7009, 0.2991],
        [0.7331, 0.2669],
        [0.6864, 0.3136],
        [0.6906, 0.3094],
        [0.7324, 0.2676],
        [0.6902, 0.3098],
        [0.7231, 0.2769],
        [0.7064, 0.2936],
        [0.6453, 0.3547],
        [0.7145, 0.2855],
        [0.7563, 0.2437],
        [0.7570, 0.2430],
        [0.6602, 0.3398],
        [0.7237, 0.2763],
        [0.7079, 0.2921],
        [0.7247, 0.2753],
        [0.6925, 0.3075],
        [0.6990, 0.3010],
        [0.6990, 0.3010],
        [0.7390, 0.2610],
        [0.7198, 0.2802],
        [0.7351, 0.2649],
        [0.7363, 0.2637],
        [0.6781, 0.3219],
        [0.7183, 0.2817],
        [0.7106, 0.2894],
        [0.7112, 0.2888],
        [0.7381, 0.2619],
        [0.7308, 0.2692],
        [0.6815, 0.3185],
        [0.7127, 0.2873],
        [0.7427, 0.2573],
        [0.7439, 0.2561],
        [0.7347, 0.2653],
        [0.7044, 0.2956],
        [0.7108, 0.2892],
        [0.7025, 0.2975],
        [0.7055, 0.2945],
        [0.7239, 0.2761],
        [0.7224, 0.2776],
        [0.7281, 0.2719],
        [0.6635, 0.3365],
        [0.7170, 0.2830],
        [0.7095, 0.2905],
        [0.6744, 0.3256],
        [0.7382, 0.2618],
        [0.7184, 0.2816],
        [0.7539, 0.2461],
        [0.6698, 0.3302],
        [0.7108, 0.2892],
        [0.6858, 0.3142],
        [0.6650, 0.3350],
        [0.7531, 0.2469],
        [0.6941, 0.3059],
        [0.7043, 0.2957],
        [0.6819, 0.3181],
        [0.7156, 0.2844],
        [0.6828, 0.3172],
        [0.6925, 0.3075],
        [0.6757, 0.3243],
        [0.7288, 0.2712],
        [0.7203, 0.2797],
        [0.7236, 0.2764],
        [0.7396, 0.2604],
        [0.7448, 0.2552],
        [0.7204, 0.2796],
        [0.7594, 0.2406],
        [0.7687, 0.2313],
        [0.7539, 0.2461],
        [0.7625, 0.2375],
        [0.6624, 0.3376],
        [0.7433, 0.2567],
        [0.7369, 0.2631],
        [0.7097, 0.2903],
        [0.7132, 0.2868],
        [0.7496, 0.2504],
        [0.7455, 0.2545],
        [0.6732, 0.3268],
        [0.7176, 0.2824],
        [0.6827, 0.3173],
        [0.7126, 0.2874],
        [0.7090, 0.2910],
        [0.6941, 0.3059],
        [0.7182, 0.2818],
        [0.6848, 0.3152],
        [0.6987, 0.3013],
        [0.6781, 0.3219],
        [0.7289, 0.2711],
        [0.7087, 0.2913],
        [0.7364, 0.2636],
        [0.7294, 0.2706],
        [0.7580, 0.2420],
        [0.6953, 0.3047],
        [0.6925, 0.3075],
        [0.7511, 0.2489],
        [0.7473, 0.2527],
        [0.7124, 0.2876],
        [0.6806, 0.3194],
        [0.6983, 0.3017],
        [0.7525, 0.2475],
        [0.7440, 0.2560],
        [0.6799, 0.3201],
        [0.7165, 0.2835],
        [0.7072, 0.2928],
        [0.7383, 0.2617],
        [0.7526, 0.2474],
        [0.6439, 0.3561],
        [0.6711, 0.3289],
        [0.6724, 0.3276],
        [0.7443, 0.2557],
        [0.7337, 0.2663],
        [0.7371, 0.2629],
        [0.6831, 0.3169],
        [0.7459, 0.2541],
        [0.7449, 0.2551],
        [0.6851, 0.3149],
        [0.7525, 0.2475],
        [0.7168, 0.2832],
        [0.6850, 0.3150],
        [0.7586, 0.2414],
        [0.7276, 0.2724],
        [0.7535, 0.2465],
        [0.7803, 0.2197],
        [0.6835, 0.3165],
        [0.6791, 0.3209],
        [0.7348, 0.2652],
        [0.6911, 0.3089],
        [0.7451, 0.2549],
        [0.7147, 0.2853],
        [0.7376, 0.2624],
        [0.7299, 0.2701],
        [0.7005, 0.2995],
        [0.7396, 0.2604],
        [0.6995, 0.3005],
        [0.7311, 0.2689],
        [0.6507, 0.3493],
        [0.7676, 0.2324],
        [0.6812, 0.3188],
        [0.7545, 0.2455],
        [0.7357, 0.2643],
        [0.7787, 0.2213],
        [0.6922, 0.3078],
        [0.7363, 0.2637],
        [0.7284, 0.2716],
        [0.7682, 0.2318],
        [0.7449, 0.2551],
        [0.7283, 0.2717],
        [0.7522, 0.2478],
        [0.7355, 0.2645],
        [0.7684, 0.2316],
        [0.7460, 0.2540],
        [0.6844, 0.3156],
        [0.7169, 0.2831],
        [0.7284, 0.2716],
        [0.6856, 0.3144],
        [0.7136, 0.2864],
        [0.7083, 0.2917],
        [0.6988, 0.3012],
        [0.7084, 0.2916],
        [0.7575, 0.2425],
        [0.7289, 0.2711],
        [0.7274, 0.2726],
        [0.7522, 0.2478],
        [0.7324, 0.2676],
        [0.7257, 0.2743],
        [0.7168, 0.2832],
        [0.7461, 0.2539],
        [0.7086, 0.2914],
        [0.7073, 0.2927],
        [0.7371, 0.2629],
        [0.7373, 0.2627],
        [0.7233, 0.2767],
        [0.7458, 0.2542],
        [0.7452, 0.2548],
        [0.7440, 0.2560],
        [0.7306, 0.2694],
        [0.6991, 0.3009],
        [0.7088, 0.2912],
        [0.7250, 0.2750],
        [0.6745, 0.3255],
        [0.7149, 0.2851],
        [0.7120, 0.2880],
        [0.7380, 0.2620],
        [0.7204, 0.2796],
        [0.7073, 0.2927],
        [0.7566, 0.2434],
        [0.7369, 0.2631]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0005 loss: 0.6549 acc_train: 0.6103 time: 0.1374s
tensor([[0.6220, 0.3780],
        [0.7202, 0.2798],
        [0.7002, 0.2998],
        [0.6538, 0.3462],
        [0.7244, 0.2756],
        [0.6678, 0.3322],
        [0.6199, 0.3801],
        [0.6797, 0.3203],
        [0.6646, 0.3354],
        [0.6742, 0.3258],
        [0.6829, 0.3171],
        [0.6295, 0.3705],
        [0.6437, 0.3563],
        [0.6339, 0.3661],
        [0.6929, 0.3071],
        [0.6779, 0.3221],
        [0.7165, 0.2835],
        [0.6740, 0.3260],
        [0.6286, 0.3714],
        [0.6461, 0.3539],
        [0.6942, 0.3058],
        [0.6356, 0.3644],
        [0.7257, 0.2743],
        [0.7048, 0.2952],
        [0.6618, 0.3382],
        [0.6385, 0.3615],
        [0.6555, 0.3445],
        [0.7327, 0.2673],
        [0.6541, 0.3459],
        [0.6890, 0.3110],
        [0.7112, 0.2888],
        [0.5897, 0.4103],
        [0.6550, 0.3450],
        [0.7048, 0.2952],
        [0.6601, 0.3399],
        [0.7072, 0.2928],
        [0.6622, 0.3378],
        [0.6373, 0.3627],
        [0.7130, 0.2870],
        [0.6079, 0.3921],
        [0.6874, 0.3126],
        [0.7365, 0.2635],
        [0.6462, 0.3538],
        [0.6790, 0.3210],
        [0.6733, 0.3267],
        [0.6816, 0.3184],
        [0.7214, 0.2786],
        [0.7212, 0.2788],
        [0.6916, 0.3084],
        [0.6948, 0.3052],
        [0.6662, 0.3338],
        [0.6980, 0.3020],
        [0.6396, 0.3604],
        [0.7070, 0.2930],
        [0.7325, 0.2675],
        [0.7042, 0.2958],
        [0.7165, 0.2835],
        [0.6791, 0.3209],
        [0.6423, 0.3577],
        [0.6386, 0.3614],
        [0.6588, 0.3412],
        [0.6330, 0.3670],
        [0.6809, 0.3191],
        [0.7285, 0.2715],
        [0.6805, 0.3195],
        [0.6473, 0.3527],
        [0.6613, 0.3387],
        [0.6248, 0.3752],
        [0.7095, 0.2905],
        [0.6898, 0.3102],
        [0.6579, 0.3421],
        [0.6526, 0.3474],
        [0.7378, 0.2622],
        [0.6953, 0.3047],
        [0.6645, 0.3355],
        [0.6583, 0.3417],
        [0.7146, 0.2854],
        [0.6860, 0.3140],
        [0.7147, 0.2853],
        [0.6386, 0.3614],
        [0.6091, 0.3909],
        [0.6655, 0.3345],
        [0.6448, 0.3552],
        [0.6578, 0.3422],
        [0.6733, 0.3267],
        [0.6613, 0.3387],
        [0.6938, 0.3062],
        [0.6353, 0.3647],
        [0.6524, 0.3476],
        [0.6915, 0.3085],
        [0.6461, 0.3539],
        [0.6840, 0.3160],
        [0.6629, 0.3371],
        [0.5951, 0.4049],
        [0.6785, 0.3215],
        [0.7327, 0.2673],
        [0.7326, 0.2674],
        [0.6124, 0.3876],
        [0.6831, 0.3169],
        [0.6591, 0.3409],
        [0.6860, 0.3140],
        [0.6466, 0.3534],
        [0.6571, 0.3429],
        [0.6539, 0.3461],
        [0.7044, 0.2956],
        [0.6767, 0.3233],
        [0.6982, 0.3018],
        [0.7103, 0.2897],
        [0.6271, 0.3729],
        [0.6807, 0.3193],
        [0.6851, 0.3149],
        [0.6787, 0.3213],
        [0.7014, 0.2986],
        [0.7009, 0.2991],
        [0.6240, 0.3760],
        [0.6799, 0.3201],
        [0.7081, 0.2919],
        [0.7103, 0.2897],
        [0.6975, 0.3025],
        [0.6673, 0.3327],
        [0.6705, 0.3295],
        [0.6566, 0.3434],
        [0.6577, 0.3423],
        [0.6870, 0.3130],
        [0.6854, 0.3146],
        [0.6896, 0.3104],
        [0.6130, 0.3870],
        [0.6765, 0.3235],
        [0.6743, 0.3257],
        [0.6280, 0.3720],
        [0.7068, 0.2932],
        [0.6743, 0.3257],
        [0.7240, 0.2760],
        [0.6183, 0.3817],
        [0.6710, 0.3290],
        [0.6422, 0.3578],
        [0.6161, 0.3839],
        [0.7233, 0.2767],
        [0.6532, 0.3468],
        [0.6657, 0.3343],
        [0.6368, 0.3632],
        [0.6706, 0.3294],
        [0.6338, 0.3662],
        [0.6436, 0.3564],
        [0.6206, 0.3794],
        [0.6946, 0.3054],
        [0.6807, 0.3193],
        [0.6857, 0.3143],
        [0.7053, 0.2947],
        [0.7064, 0.2936],
        [0.6719, 0.3281],
        [0.7319, 0.2681],
        [0.7411, 0.2589],
        [0.7253, 0.2747],
        [0.7211, 0.2789],
        [0.6232, 0.3768],
        [0.7185, 0.2815],
        [0.7012, 0.2988],
        [0.6640, 0.3360],
        [0.6693, 0.3307],
        [0.7167, 0.2833],
        [0.7154, 0.2846],
        [0.6204, 0.3796],
        [0.6777, 0.3223],
        [0.6518, 0.3482],
        [0.6774, 0.3226],
        [0.6705, 0.3295],
        [0.6551, 0.3449],
        [0.6803, 0.3197],
        [0.6379, 0.3621],
        [0.6721, 0.3279],
        [0.6264, 0.3736],
        [0.6932, 0.3068],
        [0.6609, 0.3391],
        [0.7041, 0.2959],
        [0.6986, 0.3014],
        [0.7260, 0.2740],
        [0.6512, 0.3488],
        [0.6487, 0.3513],
        [0.7247, 0.2753],
        [0.7222, 0.2778],
        [0.6725, 0.3275],
        [0.6466, 0.3534],
        [0.6530, 0.3470],
        [0.7229, 0.2771],
        [0.7131, 0.2869],
        [0.6223, 0.3777],
        [0.6800, 0.3200],
        [0.6646, 0.3354],
        [0.7077, 0.2923],
        [0.7249, 0.2751],
        [0.5985, 0.4015],
        [0.6242, 0.3758],
        [0.6249, 0.3751],
        [0.7130, 0.2870],
        [0.6940, 0.3060],
        [0.6955, 0.3045],
        [0.6308, 0.3692],
        [0.7091, 0.2909],
        [0.7047, 0.2953],
        [0.6422, 0.3578],
        [0.7164, 0.2836],
        [0.6849, 0.3151],
        [0.6458, 0.3542],
        [0.7248, 0.2752],
        [0.6981, 0.3019],
        [0.7325, 0.2675],
        [0.7554, 0.2446],
        [0.6305, 0.3695],
        [0.6363, 0.3637],
        [0.6980, 0.3020],
        [0.6472, 0.3528],
        [0.7114, 0.2886],
        [0.6733, 0.3267],
        [0.7015, 0.2985],
        [0.7006, 0.2994],
        [0.6513, 0.3487],
        [0.7110, 0.2890],
        [0.6627, 0.3373],
        [0.6957, 0.3043],
        [0.5989, 0.4011],
        [0.7370, 0.2630],
        [0.6342, 0.3658],
        [0.7294, 0.2706],
        [0.7011, 0.2989],
        [0.7538, 0.2462],
        [0.6508, 0.3492],
        [0.7067, 0.2933],
        [0.6889, 0.3111],
        [0.7343, 0.2657],
        [0.7167, 0.2833],
        [0.6878, 0.3122],
        [0.7119, 0.2881],
        [0.7024, 0.2976],
        [0.7393, 0.2607],
        [0.7166, 0.2834],
        [0.6409, 0.3591],
        [0.6805, 0.3195],
        [0.6921, 0.3079],
        [0.6381, 0.3619],
        [0.6766, 0.3234],
        [0.6691, 0.3309],
        [0.6511, 0.3489],
        [0.6638, 0.3362],
        [0.7302, 0.2698],
        [0.6968, 0.3032],
        [0.6946, 0.3054],
        [0.7145, 0.2855],
        [0.6987, 0.3013],
        [0.6894, 0.3106],
        [0.6764, 0.3236],
        [0.7171, 0.2829],
        [0.6691, 0.3309],
        [0.6687, 0.3313],
        [0.7004, 0.2996],
        [0.6985, 0.3015],
        [0.6783, 0.3217],
        [0.7043, 0.2957],
        [0.7100, 0.2900],
        [0.7056, 0.2944],
        [0.6918, 0.3082],
        [0.6521, 0.3479],
        [0.6710, 0.3290],
        [0.6865, 0.3135],
        [0.6319, 0.3681],
        [0.6837, 0.3163],
        [0.6773, 0.3227],
        [0.7050, 0.2950],
        [0.6813, 0.3187],
        [0.6619, 0.3381],
        [0.7229, 0.2771],
        [0.7077, 0.2923]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0006 loss: 0.6527 acc_train: 0.6103 time: 0.1597s
tensor([[0.5814, 0.4186],
        [0.6932, 0.3068],
        [0.6715, 0.3285],
        [0.6231, 0.3769],
        [0.6967, 0.3033],
        [0.6368, 0.3632],
        [0.5738, 0.4262],
        [0.6472, 0.3528],
        [0.6335, 0.3665],
        [0.6426, 0.3574],
        [0.6449, 0.3551],
        [0.5976, 0.4024],
        [0.6097, 0.3903],
        [0.6016, 0.3984],
        [0.6667, 0.3333],
        [0.6474, 0.3526],
        [0.6899, 0.3101],
        [0.6442, 0.3558],
        [0.5885, 0.4115],
        [0.6074, 0.3926],
        [0.6587, 0.3413],
        [0.5935, 0.4065],
        [0.6991, 0.3009],
        [0.6728, 0.3272],
        [0.6344, 0.3656],
        [0.6037, 0.3963],
        [0.6185, 0.3815],
        [0.7202, 0.2798],
        [0.6056, 0.3944],
        [0.6561, 0.3439],
        [0.6883, 0.3117],
        [0.5445, 0.4555],
        [0.6180, 0.3820],
        [0.6764, 0.3236],
        [0.6249, 0.3751],
        [0.6894, 0.3106],
        [0.6187, 0.3813],
        [0.6009, 0.3991],
        [0.6869, 0.3131],
        [0.5678, 0.4322],
        [0.6596, 0.3404],
        [0.7102, 0.2898],
        [0.6159, 0.3841],
        [0.6478, 0.3522],
        [0.6485, 0.3515],
        [0.6507, 0.3493],
        [0.6961, 0.3039],
        [0.6893, 0.3107],
        [0.6636, 0.3364],
        [0.6635, 0.3365],
        [0.6343, 0.3657],
        [0.6719, 0.3281],
        [0.5992, 0.4008],
        [0.6843, 0.3157],
        [0.7094, 0.2906],
        [0.6682, 0.3318],
        [0.6938, 0.3062],
        [0.6444, 0.3556],
        [0.6024, 0.3976],
        [0.6053, 0.3947],
        [0.6239, 0.3761],
        [0.5930, 0.4070],
        [0.6463, 0.3537],
        [0.7023, 0.2977],
        [0.6507, 0.3493],
        [0.6122, 0.3878],
        [0.6368, 0.3632],
        [0.5864, 0.4136],
        [0.6816, 0.3184],
        [0.6581, 0.3419],
        [0.6290, 0.3710],
        [0.6208, 0.3792],
        [0.7184, 0.2816],
        [0.6686, 0.3314],
        [0.6398, 0.3602],
        [0.6276, 0.3724],
        [0.6750, 0.3250],
        [0.6598, 0.3402],
        [0.6873, 0.3127],
        [0.6089, 0.3911],
        [0.5679, 0.4321],
        [0.6289, 0.3711],
        [0.6026, 0.3974],
        [0.6239, 0.3761],
        [0.6451, 0.3549],
        [0.6318, 0.3682],
        [0.6622, 0.3378],
        [0.5932, 0.4068],
        [0.6172, 0.3828],
        [0.6615, 0.3385],
        [0.6137, 0.3863],
        [0.6502, 0.3498],
        [0.6293, 0.3707],
        [0.5566, 0.4434],
        [0.6495, 0.3505],
        [0.7171, 0.2829],
        [0.7134, 0.2866],
        [0.5750, 0.4250],
        [0.6501, 0.3499],
        [0.6183, 0.3817],
        [0.6570, 0.3430],
        [0.6095, 0.3905],
        [0.6243, 0.3757],
        [0.6236, 0.3764],
        [0.6698, 0.3302],
        [0.6462, 0.3538],
        [0.6664, 0.3336],
        [0.6890, 0.3110],
        [0.5821, 0.4179],
        [0.6499, 0.3501],
        [0.6639, 0.3361],
        [0.6515, 0.3485],
        [0.6729, 0.3271],
        [0.6790, 0.3210],
        [0.5746, 0.4254],
        [0.6539, 0.3461],
        [0.6813, 0.3187],
        [0.6877, 0.3123],
        [0.6651, 0.3349],
        [0.6389, 0.3611],
        [0.6352, 0.3648],
        [0.6151, 0.3849],
        [0.6168, 0.3832],
        [0.6602, 0.3398],
        [0.6589, 0.3411],
        [0.6544, 0.3456],
        [0.5771, 0.4229],
        [0.6397, 0.3603],
        [0.6507, 0.3493],
        [0.5920, 0.4080],
        [0.6845, 0.3155],
        [0.6392, 0.3608],
        [0.7010, 0.2990],
        [0.5773, 0.4227],
        [0.6373, 0.3627],
        [0.6069, 0.3931],
        [0.5802, 0.4198],
        [0.6991, 0.3009],
        [0.6224, 0.3776],
        [0.6373, 0.3627],
        [0.5981, 0.4019],
        [0.6326, 0.3674],
        [0.5964, 0.4036],
        [0.6009, 0.3991],
        [0.5808, 0.4192],
        [0.6694, 0.3306],
        [0.6471, 0.3529],
        [0.6551, 0.3449],
        [0.6776, 0.3224],
        [0.6782, 0.3218],
        [0.6283, 0.3717],
        [0.7098, 0.2902],
        [0.7206, 0.2794],
        [0.7030, 0.2970],
        [0.6878, 0.3122],
        [0.5907, 0.4093],
        [0.7019, 0.2981],
        [0.6698, 0.3302],
        [0.6280, 0.3720],
        [0.6374, 0.3626],
        [0.6897, 0.3103],
        [0.6897, 0.3103],
        [0.5797, 0.4203],
        [0.6467, 0.3533],
        [0.6249, 0.3751],
        [0.6482, 0.3518],
        [0.6354, 0.3646],
        [0.6218, 0.3782],
        [0.6545, 0.3455],
        [0.6036, 0.3964],
        [0.6472, 0.3528],
        [0.5798, 0.4202],
        [0.6701, 0.3299],
        [0.6174, 0.3826],
        [0.6783, 0.3217],
        [0.6764, 0.3236],
        [0.7004, 0.2996],
        [0.6175, 0.3825],
        [0.6176, 0.3824],
        [0.7008, 0.2992],
        [0.7041, 0.2959],
        [0.6425, 0.3575],
        [0.6230, 0.3770],
        [0.6158, 0.3842],
        [0.6968, 0.3032],
        [0.6872, 0.3128],
        [0.5762, 0.4238],
        [0.6528, 0.3472],
        [0.6354, 0.3646],
        [0.6877, 0.3123],
        [0.7024, 0.2976],
        [0.5593, 0.4407],
        [0.5914, 0.4086],
        [0.5905, 0.4095],
        [0.6895, 0.3105],
        [0.6646, 0.3354],
        [0.6615, 0.3385],
        [0.5905, 0.4095],
        [0.6779, 0.3221],
        [0.6710, 0.3290],
        [0.6125, 0.3875],
        [0.6886, 0.3114],
        [0.6558, 0.3442],
        [0.6165, 0.3835],
        [0.6979, 0.3021],
        [0.6755, 0.3245],
        [0.7177, 0.2823],
        [0.7356, 0.2644],
        [0.5844, 0.4156],
        [0.6033, 0.3967],
        [0.6703, 0.3297],
        [0.6097, 0.3903],
        [0.6815, 0.3185],
        [0.6358, 0.3642],
        [0.6736, 0.3264],
        [0.6754, 0.3246],
        [0.6157, 0.3843],
        [0.6906, 0.3094],
        [0.6345, 0.3655],
        [0.6664, 0.3336],
        [0.5539, 0.4461],
        [0.7110, 0.2890],
        [0.5972, 0.4028],
        [0.7112, 0.2888],
        [0.6720, 0.3280],
        [0.7338, 0.2662],
        [0.6209, 0.3791],
        [0.6856, 0.3144],
        [0.6597, 0.3403],
        [0.7058, 0.2942],
        [0.6967, 0.3033],
        [0.6554, 0.3446],
        [0.6802, 0.3198],
        [0.6793, 0.3207],
        [0.7136, 0.2864],
        [0.6916, 0.3084],
        [0.6025, 0.3975],
        [0.6525, 0.3475],
        [0.6619, 0.3381],
        [0.5956, 0.4044],
        [0.6436, 0.3564],
        [0.6370, 0.3630],
        [0.6092, 0.3908],
        [0.6291, 0.3709],
        [0.7061, 0.2939],
        [0.6697, 0.3303],
        [0.6707, 0.3293],
        [0.6818, 0.3182],
        [0.6738, 0.3262],
        [0.6576, 0.3424],
        [0.6407, 0.3593],
        [0.6922, 0.3078],
        [0.6389, 0.3611],
        [0.6369, 0.3631],
        [0.6693, 0.3307],
        [0.6663, 0.3337],
        [0.6394, 0.3606],
        [0.6693, 0.3307],
        [0.6840, 0.3160],
        [0.6765, 0.3235],
        [0.6606, 0.3394],
        [0.6072, 0.3928],
        [0.6437, 0.3563],
        [0.6570, 0.3430],
        [0.5967, 0.4033],
        [0.6607, 0.3393],
        [0.6527, 0.3473],
        [0.6793, 0.3207],
        [0.6502, 0.3498],
        [0.6226, 0.3774],
        [0.6944, 0.3056],
        [0.6810, 0.3190]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0007 loss: 0.6517 acc_train: 0.6103 time: 0.1321s
tensor([[0.5641, 0.4359],
        [0.6864, 0.3136],
        [0.6648, 0.3352],
        [0.6164, 0.3836],
        [0.6902, 0.3098],
        [0.6272, 0.3728],
        [0.5550, 0.4450],
        [0.6393, 0.3607],
        [0.6225, 0.3775],
        [0.6323, 0.3677],
        [0.6332, 0.3668],
        [0.5905, 0.4095],
        [0.6004, 0.3996],
        [0.5921, 0.4079],
        [0.6645, 0.3355],
        [0.6357, 0.3643],
        [0.6838, 0.3162],
        [0.6383, 0.3617],
        [0.5705, 0.4295],
        [0.5898, 0.4102],
        [0.6477, 0.3523],
        [0.5751, 0.4249],
        [0.6903, 0.3097],
        [0.6615, 0.3385],
        [0.6284, 0.3716],
        [0.5960, 0.4040],
        [0.6031, 0.3969],
        [0.7253, 0.2747],
        [0.5801, 0.4199],
        [0.6470, 0.3530],
        [0.6842, 0.3158],
        [0.5266, 0.4734],
        [0.6044, 0.3956],
        [0.6666, 0.3334],
        [0.6142, 0.3858],
        [0.6865, 0.3135],
        [0.5981, 0.4019],
        [0.5839, 0.4161],
        [0.6799, 0.3201],
        [0.5519, 0.4481],
        [0.6532, 0.3468],
        [0.7040, 0.2960],
        [0.6093, 0.3907],
        [0.6366, 0.3634],
        [0.6421, 0.3579],
        [0.6464, 0.3536],
        [0.6890, 0.3110],
        [0.6743, 0.3257],
        [0.6510, 0.3490],
        [0.6545, 0.3455],
        [0.6260, 0.3740],
        [0.6607, 0.3393],
        [0.5813, 0.4187],
        [0.6817, 0.3183],
        [0.7065, 0.2935],
        [0.6507, 0.3493],
        [0.6906, 0.3094],
        [0.6317, 0.3683],
        [0.5852, 0.4148],
        [0.5943, 0.4057],
        [0.6109, 0.3891],
        [0.5829, 0.4171],
        [0.6346, 0.3654],
        [0.6966, 0.3034],
        [0.6426, 0.3574],
        [0.5983, 0.4017],
        [0.6327, 0.3673],
        [0.5736, 0.4264],
        [0.6767, 0.3233],
        [0.6491, 0.3509],
        [0.6240, 0.3760],
        [0.6102, 0.3898],
        [0.7155, 0.2845],
        [0.6640, 0.3360],
        [0.6361, 0.3639],
        [0.6209, 0.3791],
        [0.6603, 0.3397],
        [0.6538, 0.3462],
        [0.6798, 0.3202],
        [0.6033, 0.3967],
        [0.5497, 0.4503],
        [0.6146, 0.3854],
        [0.5864, 0.4136],
        [0.6104, 0.3896],
        [0.6370, 0.3630],
        [0.6264, 0.3736],
        [0.6541, 0.3459],
        [0.5751, 0.4249],
        [0.6050, 0.3950],
        [0.6523, 0.3477],
        [0.6020, 0.3980],
        [0.6408, 0.3592],
        [0.6200, 0.3800],
        [0.5443, 0.4557],
        [0.6408, 0.3592],
        [0.7221, 0.2779],
        [0.7142, 0.2858],
        [0.5655, 0.4345],
        [0.6393, 0.3607],
        [0.6022, 0.3978],
        [0.6481, 0.3519],
        [0.5957, 0.4043],
        [0.6153, 0.3847],
        [0.6142, 0.3858],
        [0.6554, 0.3446],
        [0.6448, 0.3552],
        [0.6599, 0.3401],
        [0.6849, 0.3151],
        [0.5639, 0.4361],
        [0.6363, 0.3637],
        [0.6616, 0.3384],
        [0.6430, 0.3570],
        [0.6692, 0.3308],
        [0.6785, 0.3215],
        [0.5501, 0.4499],
        [0.6470, 0.3530],
        [0.6749, 0.3251],
        [0.6835, 0.3165],
        [0.6534, 0.3466],
        [0.6320, 0.3680],
        [0.6226, 0.3774],
        [0.5964, 0.4036],
        [0.6040, 0.3960],
        [0.6552, 0.3448],
        [0.6549, 0.3451],
        [0.6404, 0.3596],
        [0.5634, 0.4366],
        [0.6257, 0.3743],
        [0.6487, 0.3513],
        [0.5797, 0.4203],
        [0.6787, 0.3213],
        [0.6287, 0.3713],
        [0.6976, 0.3024],
        [0.5640, 0.4360],
        [0.6245, 0.3755],
        [0.5959, 0.4041],
        [0.5703, 0.4297],
        [0.6939, 0.3061],
        [0.6095, 0.3905],
        [0.6289, 0.3711],
        [0.5793, 0.4207],
        [0.6190, 0.3810],
        [0.5786, 0.4214],
        [0.5814, 0.4186],
        [0.5652, 0.4348],
        [0.6640, 0.3360],
        [0.6332, 0.3668],
        [0.6428, 0.3572],
        [0.6677, 0.3323],
        [0.6717, 0.3283],
        [0.6069, 0.3931],
        [0.7057, 0.2943],
        [0.7204, 0.2796],
        [0.6986, 0.3014],
        [0.6793, 0.3207],
        [0.5793, 0.4207],
        [0.6997, 0.3003],
        [0.6611, 0.3389],
        [0.6128, 0.3872],
        [0.6287, 0.3713],
        [0.6792, 0.3208],
        [0.6819, 0.3181],
        [0.5642, 0.4358],
        [0.6390, 0.3610],
        [0.6203, 0.3797],
        [0.6390, 0.3610],
        [0.6232, 0.3768],
        [0.6081, 0.3919],
        [0.6519, 0.3481],
        [0.5912, 0.4088],
        [0.6417, 0.3583],
        [0.5610, 0.4390],
        [0.6669, 0.3331],
        [0.5973, 0.4027],
        [0.6750, 0.3250],
        [0.6738, 0.3262],
        [0.6947, 0.3053],
        [0.6075, 0.3924],
        [0.6103, 0.3897],
        [0.6955, 0.3045],
        [0.7038, 0.2962],
        [0.6316, 0.3684],
        [0.6176, 0.3824],
        [0.5980, 0.4020],
        [0.6877, 0.3123],
        [0.6816, 0.3184],
        [0.5546, 0.4454],
        [0.6459, 0.3541],
        [0.6273, 0.3727],
        [0.6874, 0.3126],
        [0.6992, 0.3008],
        [0.5420, 0.4580],
        [0.5848, 0.4152],
        [0.5780, 0.4220],
        [0.6875, 0.3125],
        [0.6560, 0.3440],
        [0.6486, 0.3514],
        [0.5770, 0.4230],
        [0.6683, 0.3317],
        [0.6625, 0.3375],
        [0.6061, 0.3939],
        [0.6817, 0.3183],
        [0.6449, 0.3551],
        [0.6090, 0.3910],
        [0.6934, 0.3066],
        [0.6698, 0.3302],
        [0.7202, 0.2798],
        [0.7332, 0.2668],
        [0.5643, 0.4357],
        [0.5922, 0.4078],
        [0.6634, 0.3366],
        [0.5950, 0.4050],
        [0.6731, 0.3269],
        [0.6205, 0.3795],
        [0.6677, 0.3323],
        [0.6727, 0.3273],
        [0.6084, 0.3916],
        [0.6905, 0.3095],
        [0.6314, 0.3686],
        [0.6574, 0.3426],
        [0.5324, 0.4676],
        [0.7040, 0.2960],
        [0.5841, 0.4159],
        [0.7117, 0.2883],
        [0.6635, 0.3365],
        [0.7330, 0.2670],
        [0.6124, 0.3876],
        [0.6844, 0.3156],
        [0.6551, 0.3449],
        [0.6982, 0.3018],
        [0.6979, 0.3021],
        [0.6483, 0.3517],
        [0.6744, 0.3256],
        [0.6768, 0.3232],
        [0.7085, 0.2915],
        [0.6848, 0.3152],
        [0.5835, 0.4165],
        [0.6445, 0.3555],
        [0.6509, 0.3491],
        [0.5788, 0.4212],
        [0.6321, 0.3679],
        [0.6268, 0.3732],
        [0.5914, 0.4086],
        [0.6154, 0.3846],
        [0.7000, 0.3000],
        [0.6620, 0.3380],
        [0.6658, 0.3342],
        [0.6699, 0.3301],
        [0.6719, 0.3281],
        [0.6473, 0.3527],
        [0.6282, 0.3718],
        [0.6841, 0.3159],
        [0.6311, 0.3689],
        [0.6283, 0.3717],
        [0.6588, 0.3412],
        [0.6557, 0.3443],
        [0.6224, 0.3776],
        [0.6570, 0.3430],
        [0.6777, 0.3223],
        [0.6683, 0.3317],
        [0.6511, 0.3489],
        [0.5870, 0.4130],
        [0.6404, 0.3596],
        [0.6515, 0.3485],
        [0.5875, 0.4125],
        [0.6590, 0.3410],
        [0.6491, 0.3509],
        [0.6754, 0.3246],
        [0.6467, 0.3533],
        [0.6039, 0.3961],
        [0.6855, 0.3145],
        [0.6719, 0.3281]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0008 loss: 0.6502 acc_train: 0.6103 time: 0.1399s
tensor([[0.5636, 0.4364],
        [0.6917, 0.3083],
        [0.6725, 0.3275],
        [0.6245, 0.3755],
        [0.6987, 0.3013],
        [0.6317, 0.3683],
        [0.5529, 0.4471],
        [0.6463, 0.3537],
        [0.6272, 0.3728],
        [0.6381, 0.3619],
        [0.6397, 0.3603],
        [0.5993, 0.4007],
        [0.6075, 0.3925],
        [0.5978, 0.4022],
        [0.6757, 0.3243],
        [0.6390, 0.3610],
        [0.6911, 0.3089],
        [0.6470, 0.3530],
        [0.5701, 0.4299],
        [0.5876, 0.4124],
        [0.6539, 0.3461],
        [0.5756, 0.4244],
        [0.6948, 0.3052],
        [0.6650, 0.3350],
        [0.6381, 0.3619],
        [0.6032, 0.3968],
        [0.6039, 0.3961],
        [0.7395, 0.2605],
        [0.5739, 0.4261],
        [0.6537, 0.3463],
        [0.6914, 0.3086],
        [0.5298, 0.4702],
        [0.6070, 0.3930],
        [0.6707, 0.3293],
        [0.6197, 0.3803],
        [0.6932, 0.3068],
        [0.5958, 0.4042],
        [0.5843, 0.4157],
        [0.6872, 0.3128],
        [0.5538, 0.4462],
        [0.6608, 0.3392],
        [0.7102, 0.2898],
        [0.6184, 0.3816],
        [0.6384, 0.3616],
        [0.6487, 0.3513],
        [0.6562, 0.3438],
        [0.6934, 0.3066],
        [0.6734, 0.3266],
        [0.6521, 0.3479],
        [0.6614, 0.3386],
        [0.6338, 0.3662],
        [0.6624, 0.3376],
        [0.5802, 0.4198],
        [0.6909, 0.3091],
        [0.7160, 0.2840],
        [0.6497, 0.3503],
        [0.7004, 0.2996],
        [0.6339, 0.3661],
        [0.5851, 0.4149],
        [0.5990, 0.4010],
        [0.6146, 0.3854],
        [0.5912, 0.4088],
        [0.6379, 0.3621],
        [0.7026, 0.2974],
        [0.6484, 0.3516],
        [0.6018, 0.3982],
        [0.6407, 0.3593],
        [0.5778, 0.4222],
        [0.6836, 0.3164],
        [0.6560, 0.3440],
        [0.6328, 0.3672],
        [0.6142, 0.3858],
        [0.7231, 0.2769],
        [0.6727, 0.3273],
        [0.6452, 0.3548],
        [0.6309, 0.3691],
        [0.6642, 0.3358],
        [0.6594, 0.3406],
        [0.6864, 0.3136],
        [0.6128, 0.3872],
        [0.5514, 0.4486],
        [0.6175, 0.3825],
        [0.5916, 0.4084],
        [0.6127, 0.3873],
        [0.6434, 0.3566],
        [0.6372, 0.3628],
        [0.6624, 0.3376],
        [0.5741, 0.4259],
        [0.6084, 0.3916],
        [0.6545, 0.3455],
        [0.6061, 0.3939],
        [0.6475, 0.3525],
        [0.6254, 0.3746],
        [0.5508, 0.4492],
        [0.6467, 0.3533],
        [0.7357, 0.2643],
        [0.7250, 0.2750],
        [0.5721, 0.4279],
        [0.6439, 0.3561],
        [0.6050, 0.3950],
        [0.6542, 0.3458],
        [0.5960, 0.4040],
        [0.6207, 0.3793],
        [0.6190, 0.3810],
        [0.6562, 0.3438],
        [0.6561, 0.3439],
        [0.6700, 0.3300],
        [0.6928, 0.3072],
        [0.5645, 0.4355],
        [0.6363, 0.3637],
        [0.6686, 0.3314],
        [0.6488, 0.3512],
        [0.6786, 0.3214],
        [0.6888, 0.3112],
        [0.5470, 0.4530],
        [0.6544, 0.3456],
        [0.6799, 0.3201],
        [0.6912, 0.3088],
        [0.6564, 0.3436],
        [0.6384, 0.3616],
        [0.6276, 0.3724],
        [0.5944, 0.4056],
        [0.6086, 0.3914],
        [0.6636, 0.3364],
        [0.6653, 0.3347],
        [0.6413, 0.3587],
        [0.5684, 0.4316],
        [0.6284, 0.3716],
        [0.6578, 0.3422],
        [0.5803, 0.4197],
        [0.6831, 0.3169],
        [0.6344, 0.3656],
        [0.7060, 0.2940],
        [0.5677, 0.4323],
        [0.6279, 0.3721],
        [0.6018, 0.3982],
        [0.5751, 0.4249],
        [0.6995, 0.3005],
        [0.6120, 0.3880],
        [0.6334, 0.3666],
        [0.5784, 0.4216],
        [0.6222, 0.3778],
        [0.5758, 0.4242],
        [0.5787, 0.4213],
        [0.5653, 0.4347],
        [0.6718, 0.3282],
        [0.6336, 0.3664],
        [0.6445, 0.3555],
        [0.6707, 0.3293],
        [0.6776, 0.3224],
        [0.6035, 0.3965],
        [0.7122, 0.2878],
        [0.7305, 0.2695],
        [0.7042, 0.2958],
        [0.6857, 0.3143],
        [0.5834, 0.4166],
        [0.7060, 0.2940],
        [0.6676, 0.3324],
        [0.6134, 0.3866],
        [0.6372, 0.3628],
        [0.6800, 0.3200],
        [0.6856, 0.3144],
        [0.5654, 0.4346],
        [0.6466, 0.3534],
        [0.6310, 0.3690],
        [0.6421, 0.3579],
        [0.6254, 0.3746],
        [0.6140, 0.3860],
        [0.6629, 0.3371],
        [0.5949, 0.4051],
        [0.6495, 0.3505],
        [0.5640, 0.4360],
        [0.6770, 0.3230],
        [0.5948, 0.4052],
        [0.6842, 0.3158],
        [0.6834, 0.3166],
        [0.7021, 0.2979],
        [0.6156, 0.3844],
        [0.6201, 0.3799],
        [0.7021, 0.2979],
        [0.7136, 0.2864],
        [0.6336, 0.3664],
        [0.6203, 0.3797],
        [0.5956, 0.4044],
        [0.6888, 0.3112],
        [0.6895, 0.3105],
        [0.5535, 0.4465],
        [0.6516, 0.3484],
        [0.6330, 0.3670],
        [0.6991, 0.3009],
        [0.7102, 0.2898],
        [0.5450, 0.4550],
        [0.5942, 0.4058],
        [0.5818, 0.4182],
        [0.6964, 0.3036],
        [0.6616, 0.3384],
        [0.6521, 0.3479],
        [0.5807, 0.4193],
        [0.6732, 0.3268],
        [0.6711, 0.3289],
        [0.6132, 0.3868],
        [0.6877, 0.3123],
        [0.6490, 0.3510],
        [0.6180, 0.3820],
        [0.7011, 0.2989],
        [0.6775, 0.3225],
        [0.7341, 0.2659],
        [0.7407, 0.2593],
        [0.5630, 0.4370],
        [0.5975, 0.4025],
        [0.6694, 0.3306],
        [0.5959, 0.4041],
        [0.6771, 0.3229],
        [0.6208, 0.3792],
        [0.6749, 0.3251],
        [0.6836, 0.3164],
        [0.6177, 0.3823],
        [0.7009, 0.2991],
        [0.6441, 0.3559],
        [0.6637, 0.3363],
        [0.5320, 0.4680],
        [0.7082, 0.2918],
        [0.5869, 0.4131],
        [0.7239, 0.2761],
        [0.6688, 0.3312],
        [0.7419, 0.2581],
        [0.6224, 0.3776],
        [0.6952, 0.3048],
        [0.6652, 0.3348],
        [0.7034, 0.2966],
        [0.7106, 0.2894],
        [0.6553, 0.3447],
        [0.6821, 0.3179],
        [0.6879, 0.3121],
        [0.7158, 0.2842],
        [0.6912, 0.3088],
        [0.5799, 0.4201],
        [0.6527, 0.3473],
        [0.6527, 0.3473],
        [0.5797, 0.4203],
        [0.6363, 0.3637],
        [0.6318, 0.3682],
        [0.5934, 0.4066],
        [0.6187, 0.3813],
        [0.7061, 0.2939],
        [0.6666, 0.3334],
        [0.6734, 0.3266],
        [0.6730, 0.3270],
        [0.6815, 0.3185],
        [0.6517, 0.3483],
        [0.6307, 0.3693],
        [0.6878, 0.3122],
        [0.6383, 0.3617],
        [0.6351, 0.3649],
        [0.6642, 0.3358],
        [0.6599, 0.3401],
        [0.6230, 0.3770],
        [0.6606, 0.3394],
        [0.6846, 0.3154],
        [0.6752, 0.3248],
        [0.6557, 0.3443],
        [0.5867, 0.4133],
        [0.6529, 0.3471],
        [0.6600, 0.3400],
        [0.5950, 0.4050],
        [0.6673, 0.3327],
        [0.6597, 0.3403],
        [0.6843, 0.3157],
        [0.6573, 0.3427],
        [0.6012, 0.3988],
        [0.6909, 0.3091],
        [0.6759, 0.3241]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0009 loss: 0.6483 acc_train: 0.6103 time: 0.1400s
tensor([[0.5697, 0.4303],
        [0.6985, 0.3015],
        [0.6828, 0.3172],
        [0.6354, 0.3646],
        [0.7097, 0.2903],
        [0.6418, 0.3582],
        [0.5576, 0.4424],
        [0.6561, 0.3439],
        [0.6355, 0.3645],
        [0.6474, 0.3526],
        [0.6499, 0.3501],
        [0.6099, 0.3901],
        [0.6200, 0.3800],
        [0.6085, 0.3915],
        [0.6874, 0.3126],
        [0.6464, 0.3536],
        [0.7006, 0.2994],
        [0.6588, 0.3412],
        [0.5770, 0.4230],
        [0.5935, 0.4065],
        [0.6647, 0.3353],
        [0.5838, 0.4162],
        [0.7013, 0.2987],
        [0.6717, 0.3283],
        [0.6513, 0.3487],
        [0.6141, 0.3859],
        [0.6091, 0.3909],
        [0.7510, 0.2490],
        [0.5767, 0.4233],
        [0.6639, 0.3361],
        [0.6983, 0.3017],
        [0.5407, 0.4593],
        [0.6150, 0.3850],
        [0.6780, 0.3220],
        [0.6302, 0.3698],
        [0.7002, 0.2998],
        [0.6010, 0.3990],
        [0.5922, 0.4078],
        [0.6968, 0.3032],
        [0.5618, 0.4382],
        [0.6724, 0.3276],
        [0.7168, 0.2832],
        [0.6310, 0.3690],
        [0.6439, 0.3561],
        [0.6564, 0.3436],
        [0.6680, 0.3320],
        [0.6994, 0.3006],
        [0.6765, 0.3235],
        [0.6567, 0.3433],
        [0.6716, 0.3284],
        [0.6447, 0.3553],
        [0.6682, 0.3318],
        [0.5859, 0.4141],
        [0.7009, 0.2991],
        [0.7269, 0.2731],
        [0.6555, 0.3445],
        [0.7126, 0.2874],
        [0.6399, 0.3601],
        [0.5886, 0.4114],
        [0.6080, 0.3920],
        [0.6235, 0.3765],
        [0.6046, 0.3954],
        [0.6463, 0.3537],
        [0.7101, 0.2899],
        [0.6563, 0.3437],
        [0.6113, 0.3887],
        [0.6506, 0.3494],
        [0.5873, 0.4127],
        [0.6922, 0.3078],
        [0.6654, 0.3346],
        [0.6434, 0.3566],
        [0.6220, 0.3780],
        [0.7329, 0.2671],
        [0.6836, 0.3164],
        [0.6558, 0.3442],
        [0.6441, 0.3559],
        [0.6732, 0.3268],
        [0.6683, 0.3317],
        [0.6954, 0.3046],
        [0.6247, 0.3753],
        [0.5604, 0.4396],
        [0.6252, 0.3748],
        [0.6034, 0.3966],
        [0.6206, 0.3794],
        [0.6546, 0.3454],
        [0.6512, 0.3488],
        [0.6738, 0.3262],
        [0.5788, 0.4212],
        [0.6167, 0.3833],
        [0.6598, 0.3402],
        [0.6158, 0.3842],
        [0.6589, 0.3411],
        [0.6353, 0.3647],
        [0.5637, 0.4363],
        [0.6566, 0.3434],
        [0.7469, 0.2531],
        [0.7361, 0.2639],
        [0.5837, 0.4163],
        [0.6517, 0.3483],
        [0.6116, 0.3884],
        [0.6631, 0.3369],
        [0.6023, 0.3977],
        [0.6285, 0.3715],
        [0.6274, 0.3726],
        [0.6615, 0.3385],
        [0.6678, 0.3322],
        [0.6831, 0.3169],
        [0.7021, 0.2979],
        [0.5724, 0.4276],
        [0.6399, 0.3601],
        [0.6767, 0.3233],
        [0.6586, 0.3414],
        [0.6890, 0.3110],
        [0.7004, 0.2996],
        [0.5518, 0.4482],
        [0.6650, 0.3350],
        [0.6873, 0.3127],
        [0.7012, 0.2988],
        [0.6647, 0.3353],
        [0.6503, 0.3497],
        [0.6399, 0.3601],
        [0.5994, 0.4006],
        [0.6185, 0.3815],
        [0.6737, 0.3263],
        [0.6775, 0.3225],
        [0.6461, 0.3539],
        [0.5794, 0.4206],
        [0.6359, 0.3641],
        [0.6685, 0.3315],
        [0.5871, 0.4129],
        [0.6887, 0.3113],
        [0.6446, 0.3554],
        [0.7155, 0.2845],
        [0.5773, 0.4227],
        [0.6360, 0.3640],
        [0.6119, 0.3881],
        [0.5837, 0.4163],
        [0.7057, 0.2943],
        [0.6197, 0.3803],
        [0.6410, 0.3590],
        [0.5849, 0.4151],
        [0.6304, 0.3696],
        [0.5791, 0.4209],
        [0.5832, 0.4168],
        [0.5713, 0.4287],
        [0.6816, 0.3184],
        [0.6389, 0.3611],
        [0.6503, 0.3497],
        [0.6774, 0.3226],
        [0.6860, 0.3140],
        [0.6062, 0.3938],
        [0.7192, 0.2808],
        [0.7411, 0.2589],
        [0.7116, 0.2884],
        [0.6959, 0.3041],
        [0.5928, 0.4072],
        [0.7117, 0.2883],
        [0.6787, 0.3213],
        [0.6195, 0.3805],
        [0.6489, 0.3511],
        [0.6831, 0.3169],
        [0.6916, 0.3084],
        [0.5723, 0.4277],
        [0.6564, 0.3436],
        [0.6436, 0.3564],
        [0.6479, 0.3521],
        [0.6316, 0.3684],
        [0.6248, 0.3752],
        [0.6758, 0.3242],
        [0.6025, 0.3975],
        [0.6605, 0.3395],
        [0.5769, 0.4231],
        [0.6874, 0.3126],
        [0.6007, 0.3993],
        [0.6951, 0.3049],
        [0.6950, 0.3050],
        [0.7119, 0.2881],
        [0.6285, 0.3715],
        [0.6334, 0.3666],
        [0.7101, 0.2899],
        [0.7232, 0.2768],
        [0.6396, 0.3604],
        [0.6255, 0.3745],
        [0.5994, 0.4006],
        [0.6928, 0.3072],
        [0.6993, 0.3007],
        [0.5609, 0.4391],
        [0.6581, 0.3419],
        [0.6421, 0.3579],
        [0.7107, 0.2893],
        [0.7235, 0.2765],
        [0.5552, 0.4448],
        [0.6073, 0.3927],
        [0.5917, 0.4083],
        [0.7050, 0.2950],
        [0.6690, 0.3310],
        [0.6600, 0.3400],
        [0.5891, 0.4109],
        [0.6811, 0.3189],
        [0.6828, 0.3172],
        [0.6241, 0.3759],
        [0.6958, 0.3042],
        [0.6568, 0.3432],
        [0.6301, 0.3699],
        [0.7110, 0.2890],
        [0.6880, 0.3120],
        [0.7475, 0.2525],
        [0.7477, 0.2523],
        [0.5681, 0.4319],
        [0.6059, 0.3941],
        [0.6773, 0.3227],
        [0.6014, 0.3986],
        [0.6845, 0.3155],
        [0.6245, 0.3755],
        [0.6836, 0.3164],
        [0.6959, 0.3041],
        [0.6307, 0.3693],
        [0.7111, 0.2889],
        [0.6589, 0.3411],
        [0.6747, 0.3253],
        [0.5398, 0.4602],
        [0.7144, 0.2856],
        [0.5960, 0.4040],
        [0.7353, 0.2647],
        [0.6768, 0.3232],
        [0.7502, 0.2498],
        [0.6352, 0.3648],
        [0.7069, 0.2931],
        [0.6771, 0.3229],
        [0.7100, 0.2900],
        [0.7232, 0.2768],
        [0.6652, 0.3348],
        [0.6914, 0.3086],
        [0.6999, 0.3001],
        [0.7245, 0.2755],
        [0.6991, 0.3009],
        [0.5829, 0.4171],
        [0.6639, 0.3361],
        [0.6583, 0.3417],
        [0.5865, 0.4135],
        [0.6458, 0.3542],
        [0.6399, 0.3601],
        [0.6017, 0.3983],
        [0.6279, 0.3721],
        [0.7131, 0.2869],
        [0.6746, 0.3254],
        [0.6828, 0.3172],
        [0.6805, 0.3195],
        [0.6916, 0.3084],
        [0.6594, 0.3406],
        [0.6374, 0.3626],
        [0.6933, 0.3067],
        [0.6507, 0.3493],
        [0.6466, 0.3534],
        [0.6737, 0.3263],
        [0.6670, 0.3330],
        [0.6294, 0.3706],
        [0.6685, 0.3315],
        [0.6928, 0.3072],
        [0.6845, 0.3155],
        [0.6636, 0.3364],
        [0.5947, 0.4053],
        [0.6665, 0.3335],
        [0.6717, 0.3283],
        [0.6063, 0.3937],
        [0.6769, 0.3231],
        [0.6727, 0.3273],
        [0.6938, 0.3062],
        [0.6682, 0.3318],
        [0.6040, 0.3960],
        [0.6996, 0.3004],
        [0.6825, 0.3175]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0010 loss: 0.6470 acc_train: 0.6103 time: 0.1424s
tensor([[0.5757, 0.4243],
        [0.7029, 0.2971],
        [0.6892, 0.3108],
        [0.6433, 0.3567],
        [0.7168, 0.2832],
        [0.6496, 0.3504],
        [0.5626, 0.4374],
        [0.6627, 0.3373],
        [0.6408, 0.3592],
        [0.6541, 0.3459],
        [0.6582, 0.3418],
        [0.6178, 0.3822],
        [0.6306, 0.3694],
        [0.6178, 0.3822],
        [0.6941, 0.3059],
        [0.6519, 0.3481],
        [0.7072, 0.2928],
        [0.6672, 0.3328],
        [0.5848, 0.4152],
        [0.6007, 0.3993],
        [0.6736, 0.3264],
        [0.5920, 0.4080],
        [0.7053, 0.2947],
        [0.6763, 0.3237],
        [0.6612, 0.3388],
        [0.6227, 0.3773],
        [0.6122, 0.3878],
        [0.7565, 0.2435],
        [0.5815, 0.4185],
        [0.6709, 0.3291],
        [0.7007, 0.2993],
        [0.5516, 0.4484],
        [0.6227, 0.3773],
        [0.6824, 0.3176],
        [0.6392, 0.3608],
        [0.7031, 0.2969],
        [0.6064, 0.3936],
        [0.6005, 0.3995],
        [0.7034, 0.2966],
        [0.5690, 0.4310],
        [0.6803, 0.3197],
        [0.7197, 0.2803],
        [0.6408, 0.3592],
        [0.6489, 0.3511],
        [0.6613, 0.3387],
        [0.6761, 0.3239],
        [0.7020, 0.2980],
        [0.6786, 0.3214],
        [0.6595, 0.3405],
        [0.6795, 0.3205],
        [0.6522, 0.3478],
        [0.6726, 0.3274],
        [0.5912, 0.4088],
        [0.7059, 0.2941],
        [0.7338, 0.2662],
        [0.6613, 0.3387],
        [0.7201, 0.2799],
        [0.6455, 0.3545],
        [0.5905, 0.4095],
        [0.6154, 0.3846],
        [0.6313, 0.3687],
        [0.6163, 0.3837],
        [0.6537, 0.3463],
        [0.7146, 0.2854],
        [0.6603, 0.3397],
        [0.6192, 0.3808],
        [0.6567, 0.3433],
        [0.5970, 0.4030],
        [0.6981, 0.3019],
        [0.6719, 0.3281],
        [0.6514, 0.3486],
        [0.6282, 0.3718],
        [0.7384, 0.2616],
        [0.6907, 0.3093],
        [0.6631, 0.3369],
        [0.6539, 0.3461],
        [0.6798, 0.3202],
        [0.6743, 0.3257],
        [0.7011, 0.2989],
        [0.6331, 0.3669],
        [0.5691, 0.4309],
        [0.6316, 0.3684],
        [0.6125, 0.3875],
        [0.6269, 0.3731],
        [0.6637, 0.3363],
        [0.6611, 0.3389],
        [0.6824, 0.3176],
        [0.5842, 0.4158],
        [0.6247, 0.3753],
        [0.6625, 0.3375],
        [0.6248, 0.3752],
        [0.6674, 0.3326],
        [0.6432, 0.3568],
        [0.5756, 0.4244],
        [0.6639, 0.3361],
        [0.7519, 0.2481],
        [0.7424, 0.2576],
        [0.5939, 0.4061],
        [0.6575, 0.3425],
        [0.6167, 0.3833],
        [0.6693, 0.3307],
        [0.6081, 0.3919],
        [0.6331, 0.3669],
        [0.6347, 0.3653],
        [0.6656, 0.3344],
        [0.6752, 0.3248],
        [0.6920, 0.3080],
        [0.7075, 0.2925],
        [0.5811, 0.4189],
        [0.6427, 0.3573],
        [0.6818, 0.3182],
        [0.6664, 0.3336],
        [0.6954, 0.3046],
        [0.7075, 0.2925],
        [0.5581, 0.4419],
        [0.6720, 0.3280],
        [0.6913, 0.3087],
        [0.7076, 0.2924],
        [0.6724, 0.3276],
        [0.6594, 0.3406],
        [0.6506, 0.3494],
        [0.6049, 0.3951],
        [0.6269, 0.3731],
        [0.6796, 0.3204],
        [0.6844, 0.3156],
        [0.6508, 0.3492],
        [0.5889, 0.4111],
        [0.6413, 0.3587],
        [0.6752, 0.3248],
        [0.5937, 0.4063],
        [0.6921, 0.3079],
        [0.6520, 0.3480],
        [0.7212, 0.2788],
        [0.5861, 0.4139],
        [0.6422, 0.3578],
        [0.6204, 0.3796],
        [0.5905, 0.4095],
        [0.7079, 0.2921],
        [0.6263, 0.3737],
        [0.6460, 0.3540],
        [0.5922, 0.4078],
        [0.6375, 0.3625],
        [0.5830, 0.4170],
        [0.5884, 0.4116],
        [0.5773, 0.4227],
        [0.6878, 0.3122],
        [0.6443, 0.3557],
        [0.6546, 0.3454],
        [0.6817, 0.3183],
        [0.6916, 0.3084],
        [0.6086, 0.3914],
        [0.7229, 0.2771],
        [0.7469, 0.2531],
        [0.7156, 0.2844],
        [0.7036, 0.2964],
        [0.6016, 0.3984],
        [0.7138, 0.2862],
        [0.6874, 0.3126],
        [0.6251, 0.3749],
        [0.6567, 0.3433],
        [0.6836, 0.3164],
        [0.6950, 0.3050],
        [0.5789, 0.4211],
        [0.6630, 0.3370],
        [0.6525, 0.3475],
        [0.6523, 0.3477],
        [0.6370, 0.3630],
        [0.6332, 0.3668],
        [0.6845, 0.3155],
        [0.6087, 0.3913],
        [0.6695, 0.3305],
        [0.5902, 0.4098],
        [0.6935, 0.3065],
        [0.6063, 0.3937],
        [0.7021, 0.2979],
        [0.7030, 0.2970],
        [0.7179, 0.2821],
        [0.6400, 0.3600],
        [0.6427, 0.3573],
        [0.7146, 0.2854],
        [0.7284, 0.2716],
        [0.6440, 0.3560],
        [0.6296, 0.3704],
        [0.6039, 0.3961],
        [0.6941, 0.3059],
        [0.7057, 0.2943],
        [0.5685, 0.4315],
        [0.6612, 0.3388],
        [0.6482, 0.3518],
        [0.7176, 0.2824],
        [0.7327, 0.2673],
        [0.5675, 0.4325],
        [0.6188, 0.3812],
        [0.6007, 0.3993],
        [0.7091, 0.2909],
        [0.6744, 0.3256],
        [0.6665, 0.3335],
        [0.5959, 0.4041],
        [0.6864, 0.3136],
        [0.6904, 0.3096],
        [0.6322, 0.3678],
        [0.7001, 0.2999],
        [0.6623, 0.3377],
        [0.6384, 0.3616],
        [0.7167, 0.2833],
        [0.6946, 0.3054],
        [0.7548, 0.2452],
        [0.7505, 0.2495],
        [0.5735, 0.4265],
        [0.6130, 0.3870],
        [0.6818, 0.3182],
        [0.6062, 0.3938],
        [0.6895, 0.3105],
        [0.6278, 0.3722],
        [0.6874, 0.3126],
        [0.7036, 0.2964],
        [0.6407, 0.3593],
        [0.7165, 0.2835],
        [0.6691, 0.3309],
        [0.6831, 0.3169],
        [0.5482, 0.4518],
        [0.7173, 0.2827],
        [0.6049, 0.3951],
        [0.7400, 0.2600],
        [0.6815, 0.3185],
        [0.7533, 0.2467],
        [0.6444, 0.3556],
        [0.7142, 0.2858],
        [0.6855, 0.3145],
        [0.7124, 0.2876],
        [0.7307, 0.2693],
        [0.6719, 0.3281],
        [0.6981, 0.3019],
        [0.7068, 0.2932],
        [0.7295, 0.2705],
        [0.7026, 0.2974],
        [0.5863, 0.4137],
        [0.6712, 0.3288],
        [0.6619, 0.3381],
        [0.5926, 0.4074],
        [0.6541, 0.3459],
        [0.6449, 0.3551],
        [0.6091, 0.3909],
        [0.6355, 0.3645],
        [0.7167, 0.2833],
        [0.6809, 0.3191],
        [0.6885, 0.3115],
        [0.6858, 0.3142],
        [0.6977, 0.3023],
        [0.6658, 0.3342],
        [0.6424, 0.3576],
        [0.6955, 0.3045],
        [0.6607, 0.3393],
        [0.6565, 0.3435],
        [0.6801, 0.3199],
        [0.6712, 0.3288],
        [0.6359, 0.3641],
        [0.6740, 0.3260],
        [0.6975, 0.3025],
        [0.6906, 0.3094],
        [0.6685, 0.3315],
        [0.6037, 0.3963],
        [0.6747, 0.3253],
        [0.6798, 0.3202],
        [0.6145, 0.3855],
        [0.6818, 0.3182],
        [0.6811, 0.3189],
        [0.6993, 0.3007],
        [0.6746, 0.3254],
        [0.6072, 0.3928],
        [0.7057, 0.2943],
        [0.6877, 0.3123]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0011 loss: 0.6466 acc_train: 0.6103 time: 0.1598s
tensor([[0.5795, 0.4205],
        [0.7033, 0.2967],
        [0.6905, 0.3095],
        [0.6464, 0.3536],
        [0.7182, 0.2818],
        [0.6515, 0.3485],
        [0.5655, 0.4345],
        [0.6646, 0.3354],
        [0.6420, 0.3580],
        [0.6553, 0.3447],
        [0.6613, 0.3387],
        [0.6208, 0.3792],
        [0.6369, 0.3631],
        [0.6231, 0.3769],
        [0.6940, 0.3060],
        [0.6533, 0.3467],
        [0.7084, 0.2916],
        [0.6698, 0.3302],
        [0.5903, 0.4097],
        [0.6065, 0.3935],
        [0.6779, 0.3221],
        [0.5976, 0.4024],
        [0.7047, 0.2953],
        [0.6768, 0.3232],
        [0.6653, 0.3347],
        [0.6265, 0.3735],
        [0.6115, 0.3885],
        [0.7552, 0.2448],
        [0.5850, 0.4150],
        [0.6728, 0.3272],
        [0.6979, 0.3021],
        [0.5596, 0.4404],
        [0.6269, 0.3731],
        [0.6827, 0.3173],
        [0.6440, 0.3560],
        [0.7009, 0.2991],
        [0.6095, 0.3905],
        [0.6053, 0.3947],
        [0.7050, 0.2950],
        [0.5726, 0.4274],
        [0.6828, 0.3172],
        [0.7175, 0.2825],
        [0.6457, 0.3543],
        [0.6508, 0.3492],
        [0.6619, 0.3381],
        [0.6788, 0.3212],
        [0.7000, 0.3000],
        [0.6778, 0.3222],
        [0.6584, 0.3416],
        [0.6826, 0.3174],
        [0.6543, 0.3457],
        [0.6742, 0.3258],
        [0.5942, 0.4058],
        [0.7046, 0.2954],
        [0.7339, 0.2661],
        [0.6640, 0.3360],
        [0.7214, 0.2786],
        [0.6480, 0.3520],
        [0.5890, 0.4110],
        [0.6186, 0.3814],
        [0.6351, 0.3649],
        [0.6229, 0.3771],
        [0.6567, 0.3433],
        [0.7137, 0.2863],
        [0.6592, 0.3408],
        [0.6228, 0.3772],
        [0.6579, 0.3421],
        [0.6034, 0.3966],
        [0.6991, 0.3009],
        [0.6735, 0.3265],
        [0.6547, 0.3453],
        [0.6299, 0.3701],
        [0.7385, 0.2615],
        [0.6915, 0.3085],
        [0.6652, 0.3348],
        [0.6572, 0.3428],
        [0.6822, 0.3178],
        [0.6749, 0.3251],
        [0.7017, 0.2983],
        [0.6366, 0.3634],
        [0.5745, 0.4255],
        [0.6345, 0.3655],
        [0.6168, 0.3832],
        [0.6287, 0.3713],
        [0.6673, 0.3327],
        [0.6650, 0.3350],
        [0.6858, 0.3142],
        [0.5874, 0.4126],
        [0.6290, 0.3710],
        [0.6609, 0.3391],
        [0.6301, 0.3699],
        [0.6705, 0.3295],
        [0.6459, 0.3541],
        [0.5842, 0.4158],
        [0.6663, 0.3337],
        [0.7499, 0.2501],
        [0.7418, 0.2582],
        [0.6005, 0.3995],
        [0.6594, 0.3406],
        [0.6190, 0.3810],
        [0.6708, 0.3292],
        [0.6115, 0.3885],
        [0.6337, 0.3663],
        [0.6379, 0.3621],
        [0.6663, 0.3337],
        [0.6770, 0.3230],
        [0.6952, 0.3048],
        [0.7075, 0.2925],
        [0.5879, 0.4121],
        [0.6423, 0.3577],
        [0.6828, 0.3172],
        [0.6697, 0.3303],
        [0.6963, 0.3037],
        [0.7090, 0.2910],
        [0.5628, 0.4372],
        [0.6735, 0.3265],
        [0.6904, 0.3096],
        [0.7081, 0.2919],
        [0.6764, 0.3236],
        [0.6641, 0.3359],
        [0.6559, 0.3441],
        [0.6083, 0.3917],
        [0.6311, 0.3689],
        [0.6789, 0.3211],
        [0.6849, 0.3151],
        [0.6528, 0.3472],
        [0.5945, 0.4055],
        [0.6420, 0.3580],
        [0.6761, 0.3239],
        [0.5966, 0.4034],
        [0.6907, 0.3093],
        [0.6541, 0.3459],
        [0.7218, 0.2782],
        [0.5913, 0.4087],
        [0.6440, 0.3560],
        [0.6245, 0.3755],
        [0.5942, 0.4058],
        [0.7044, 0.2956],
        [0.6297, 0.3703],
        [0.6464, 0.3536],
        [0.5973, 0.4027],
        [0.6401, 0.3599],
        [0.5849, 0.4151],
        [0.5913, 0.4087],
        [0.5805, 0.4195],
        [0.6890, 0.3110],
        [0.6476, 0.3524],
        [0.6554, 0.3446],
        [0.6816, 0.3184],
        [0.6926, 0.3074],
        [0.6088, 0.3912],
        [0.7215, 0.2785],
        [0.7461, 0.2539],
        [0.7142, 0.2858],
        [0.7058, 0.2942],
        [0.6075, 0.3925],
        [0.7118, 0.2882],
        [0.6912, 0.3088],
        [0.6283, 0.3717],
        [0.6592, 0.3408],
        [0.6798, 0.3202],
        [0.6935, 0.3065],
        [0.5825, 0.4175],
        [0.6646, 0.3354],
        [0.6561, 0.3439],
        [0.6525, 0.3475],
        [0.6393, 0.3607],
        [0.6375, 0.3625],
        [0.6863, 0.3137],
        [0.6111, 0.3889],
        [0.6736, 0.3264],
        [0.6002, 0.3998],
        [0.6937, 0.3063],
        [0.6088, 0.3912],
        [0.7030, 0.2970],
        [0.7045, 0.2955],
        [0.7179, 0.2821],
        [0.6471, 0.3529],
        [0.6467, 0.3533],
        [0.7130, 0.2870],
        [0.7271, 0.2729],
        [0.6446, 0.3554],
        [0.6308, 0.3692],
        [0.6056, 0.3944],
        [0.6911, 0.3089],
        [0.7068, 0.2932],
        [0.5726, 0.4274],
        [0.6593, 0.3407],
        [0.6495, 0.3505],
        [0.7173, 0.2827],
        [0.7355, 0.2645],
        [0.5780, 0.4220],
        [0.6261, 0.3739],
        [0.6053, 0.3947],
        [0.7077, 0.2923],
        [0.6762, 0.3238],
        [0.6691, 0.3309],
        [0.5986, 0.4014],
        [0.6869, 0.3131],
        [0.6936, 0.3064],
        [0.6344, 0.3656],
        [0.6990, 0.3010],
        [0.6635, 0.3365],
        [0.6411, 0.3589],
        [0.7162, 0.2838],
        [0.6948, 0.3052],
        [0.7554, 0.2446],
        [0.7476, 0.2524],
        [0.5766, 0.4234],
        [0.6160, 0.3840],
        [0.6814, 0.3186],
        [0.6079, 0.3921],
        [0.6898, 0.3102],
        [0.6283, 0.3717],
        [0.6860, 0.3140],
        [0.7056, 0.2944],
        [0.6449, 0.3551],
        [0.7154, 0.2846],
        [0.6731, 0.3269],
        [0.6865, 0.3135],
        [0.5541, 0.4459],
        [0.7149, 0.2851],
        [0.6106, 0.3894],
        [0.7375, 0.2625],
        [0.6809, 0.3191],
        [0.7504, 0.2496],
        [0.6480, 0.3520],
        [0.7155, 0.2845],
        [0.6881, 0.3119],
        [0.7097, 0.2903],
        [0.7317, 0.2683],
        [0.6735, 0.3265],
        [0.7004, 0.2996],
        [0.7073, 0.2927],
        [0.7291, 0.2709],
        [0.7004, 0.2996],
        [0.5873, 0.4127],
        [0.6729, 0.3271],
        [0.6617, 0.3383],
        [0.5955, 0.4045],
        [0.6586, 0.3414],
        [0.6450, 0.3550],
        [0.6128, 0.3872],
        [0.6392, 0.3608],
        [0.7154, 0.2846],
        [0.6833, 0.3167],
        [0.6890, 0.3110],
        [0.6869, 0.3131],
        [0.6982, 0.3018],
        [0.6680, 0.3320],
        [0.6440, 0.3560],
        [0.6941, 0.3059],
        [0.6655, 0.3345],
        [0.6619, 0.3381],
        [0.6815, 0.3185],
        [0.6706, 0.3294],
        [0.6398, 0.3602],
        [0.6751, 0.3249],
        [0.6964, 0.3036],
        [0.6918, 0.3082],
        [0.6681, 0.3319],
        [0.6102, 0.3898],
        [0.6755, 0.3245],
        [0.6820, 0.3180],
        [0.6178, 0.3822],
        [0.6815, 0.3185],
        [0.6835, 0.3165],
        [0.6985, 0.3015],
        [0.6743, 0.3257],
        [0.6089, 0.3911],
        [0.7064, 0.2936],
        [0.6894, 0.3106]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0012 loss: 0.6470 acc_train: 0.6103 time: 0.1485s
tensor([[0.5810, 0.4190],
        [0.6993, 0.3007],
        [0.6871, 0.3129],
        [0.6457, 0.3543],
        [0.7147, 0.2853],
        [0.6489, 0.3511],
        [0.5671, 0.4329],
        [0.6613, 0.3387],
        [0.6395, 0.3605],
        [0.6514, 0.3486],
        [0.6601, 0.3399],
        [0.6199, 0.3801],
        [0.6384, 0.3616],
        [0.6247, 0.3753],
        [0.6889, 0.3111],
        [0.6509, 0.3491],
        [0.7051, 0.2949],
        [0.6674, 0.3326],
        [0.5929, 0.4071],
        [0.6099, 0.3901],
        [0.6779, 0.3221],
        [0.6003, 0.3997],
        [0.7000, 0.3000],
        [0.6735, 0.3265],
        [0.6643, 0.3357],
        [0.6265, 0.3735],
        [0.6077, 0.3923],
        [0.7481, 0.2519],
        [0.5864, 0.4136],
        [0.6700, 0.3300],
        [0.6908, 0.3092],
        [0.5656, 0.4344],
        [0.6274, 0.3726],
        [0.6792, 0.3208],
        [0.6442, 0.3558],
        [0.6942, 0.3058],
        [0.6099, 0.3901],
        [0.6069, 0.3931],
        [0.7020, 0.2980],
        [0.5733, 0.4267],
        [0.6807, 0.3193],
        [0.7103, 0.2897],
        [0.6465, 0.3535],
        [0.6497, 0.3503],
        [0.6592, 0.3408],
        [0.6762, 0.3238],
        [0.6939, 0.3061],
        [0.6742, 0.3258],
        [0.6542, 0.3458],
        [0.6819, 0.3181],
        [0.6522, 0.3478],
        [0.6721, 0.3279],
        [0.5944, 0.4056],
        [0.6981, 0.3019],
        [0.7286, 0.2714],
        [0.6632, 0.3368],
        [0.7172, 0.2828],
        [0.6478, 0.3522],
        [0.5850, 0.4150],
        [0.6183, 0.3817],
        [0.6348, 0.3652],
        [0.6241, 0.3759],
        [0.6553, 0.3447],
        [0.7076, 0.2924],
        [0.6539, 0.3461],
        [0.6228, 0.3772],
        [0.6545, 0.3455],
        [0.6063, 0.3937],
        [0.6949, 0.3051],
        [0.6702, 0.3298],
        [0.6534, 0.3466],
        [0.6279, 0.3721],
        [0.7336, 0.2664],
        [0.6872, 0.3128],
        [0.6629, 0.3371],
        [0.6549, 0.3451],
        [0.6810, 0.3190],
        [0.6710, 0.3290],
        [0.6963, 0.3037],
        [0.6359, 0.3641],
        [0.5774, 0.4226],
        [0.6338, 0.3662],
        [0.6173, 0.3827],
        [0.6270, 0.3730],
        [0.6657, 0.3343],
        [0.6630, 0.3370],
        [0.6843, 0.3157],
        [0.5890, 0.4110],
        [0.6303, 0.3697],
        [0.6557, 0.3443],
        [0.6316, 0.3684],
        [0.6688, 0.3312],
        [0.6445, 0.3555],
        [0.5892, 0.4108],
        [0.6646, 0.3354],
        [0.7426, 0.2574],
        [0.7356, 0.2644],
        [0.6036, 0.3964],
        [0.6574, 0.3426],
        [0.6191, 0.3809],
        [0.6674, 0.3326],
        [0.6120, 0.3880],
        [0.6313, 0.3687],
        [0.6375, 0.3625],
        [0.6639, 0.3361],
        [0.6733, 0.3267],
        [0.6934, 0.3066],
        [0.7026, 0.2974],
        [0.5916, 0.4084],
        [0.6400, 0.3600],
        [0.6794, 0.3206],
        [0.6683, 0.3317],
        [0.6920, 0.3080],
        [0.7054, 0.2946],
        [0.5663, 0.4337],
        [0.6697, 0.3303],
        [0.6856, 0.3144],
        [0.7037, 0.2963],
        [0.6766, 0.3234],
        [0.6646, 0.3354],
        [0.6562, 0.3438],
        [0.6095, 0.3905],
        [0.6312, 0.3688],
        [0.6730, 0.3270],
        [0.6798, 0.3202],
        [0.6523, 0.3477],
        [0.5962, 0.4038],
        [0.6383, 0.3617],
        [0.6727, 0.3273],
        [0.5974, 0.4026],
        [0.6848, 0.3152],
        [0.6516, 0.3484],
        [0.7175, 0.2825],
        [0.5934, 0.4066],
        [0.6424, 0.3576],
        [0.6244, 0.3756],
        [0.5957, 0.4043],
        [0.6962, 0.3038],
        [0.6301, 0.3699],
        [0.6430, 0.3570],
        [0.5995, 0.4005],
        [0.6390, 0.3610],
        [0.5856, 0.4144],
        [0.5926, 0.4074],
        [0.5818, 0.4182],
        [0.6854, 0.3146],
        [0.6477, 0.3523],
        [0.6527, 0.3473],
        [0.6777, 0.3223],
        [0.6893, 0.3107],
        [0.6071, 0.3929],
        [0.7156, 0.2844],
        [0.7394, 0.2606],
        [0.7084, 0.2916],
        [0.7027, 0.2973],
        [0.6108, 0.3892],
        [0.7060, 0.2940],
        [0.6899, 0.3101],
        [0.6287, 0.3713],
        [0.6572, 0.3428],
        [0.6726, 0.3274],
        [0.6889, 0.3111],
        [0.5836, 0.4164],
        [0.6616, 0.3384],
        [0.6548, 0.3452],
        [0.6491, 0.3509],
        [0.6395, 0.3605],
        [0.6381, 0.3619],
        [0.6831, 0.3169],
        [0.6109, 0.3891],
        [0.6731, 0.3269],
        [0.6066, 0.3934],
        [0.6889, 0.3111],
        [0.6081, 0.3919],
        [0.6984, 0.3016],
        [0.7001, 0.2999],
        [0.7127, 0.2873],
        [0.6502, 0.3498],
        [0.6464, 0.3536],
        [0.7062, 0.2938],
        [0.7212, 0.2788],
        [0.6417, 0.3583],
        [0.6293, 0.3707],
        [0.6045, 0.3955],
        [0.6846, 0.3154],
        [0.7029, 0.2971],
        [0.5745, 0.4255],
        [0.6542, 0.3458],
        [0.6470, 0.3530],
        [0.7113, 0.2887],
        [0.7321, 0.2679],
        [0.5857, 0.4143],
        [0.6287, 0.3713],
        [0.6064, 0.3936],
        [0.7012, 0.2988],
        [0.6746, 0.3254],
        [0.6674, 0.3326],
        [0.5988, 0.4012],
        [0.6834, 0.3166],
        [0.6922, 0.3078],
        [0.6320, 0.3680],
        [0.6933, 0.3067],
        [0.6605, 0.3395],
        [0.6392, 0.3608],
        [0.7105, 0.2895],
        [0.6897, 0.3103],
        [0.7495, 0.2505],
        [0.7400, 0.2600],
        [0.5778, 0.4222],
        [0.6155, 0.3845],
        [0.6770, 0.3230],
        [0.6075, 0.3925],
        [0.6862, 0.3138],
        [0.6261, 0.3739],
        [0.6802, 0.3198],
        [0.7026, 0.2974],
        [0.6445, 0.3555],
        [0.7095, 0.2905],
        [0.6723, 0.3277],
        [0.6851, 0.3149],
        [0.5582, 0.4418],
        [0.7072, 0.2928],
        [0.6133, 0.3867],
        [0.7292, 0.2708],
        [0.6764, 0.3236],
        [0.7431, 0.2569],
        [0.6466, 0.3534],
        [0.7115, 0.2885],
        [0.6857, 0.3143],
        [0.7035, 0.2965],
        [0.7270, 0.2730],
        [0.6709, 0.3291],
        [0.6980, 0.3020],
        [0.7027, 0.2973],
        [0.7233, 0.2767],
        [0.6934, 0.3066],
        [0.5864, 0.4136],
        [0.6709, 0.3291],
        [0.6578, 0.3422],
        [0.5951, 0.4049],
        [0.6591, 0.3409],
        [0.6413, 0.3587],
        [0.6127, 0.3873],
        [0.6388, 0.3612],
        [0.7097, 0.2903],
        [0.6815, 0.3185],
        [0.6850, 0.3150],
        [0.6832, 0.3168],
        [0.6941, 0.3059],
        [0.6661, 0.3339],
        [0.6422, 0.3578],
        [0.6889, 0.3111],
        [0.6645, 0.3355],
        [0.6627, 0.3373],
        [0.6786, 0.3214],
        [0.6657, 0.3343],
        [0.6408, 0.3592],
        [0.6720, 0.3280],
        [0.6907, 0.3093],
        [0.6888, 0.3112],
        [0.6632, 0.3368],
        [0.6128, 0.3872],
        [0.6702, 0.3298],
        [0.6790, 0.3210],
        [0.6172, 0.3828],
        [0.6766, 0.3234],
        [0.6808, 0.3192],
        [0.6929, 0.3071],
        [0.6684, 0.3316],
        [0.6092, 0.3908],
        [0.7019, 0.2981],
        [0.6874, 0.3126]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0013 loss: 0.6482 acc_train: 0.6103 time: 0.1802s
tensor([[0.5823, 0.4177],
        [0.6928, 0.3072],
        [0.6813, 0.3187],
        [0.6433, 0.3567],
        [0.7078, 0.2922],
        [0.6442, 0.3558],
        [0.5687, 0.4313],
        [0.6559, 0.3441],
        [0.6357, 0.3643],
        [0.6448, 0.3552],
        [0.6565, 0.3435],
        [0.6183, 0.3817],
        [0.6365, 0.3635],
        [0.6239, 0.3761],
        [0.6816, 0.3184],
        [0.6471, 0.3529],
        [0.6991, 0.3009],
        [0.6631, 0.3369],
        [0.5944, 0.4056],
        [0.6121, 0.3879],
        [0.6751, 0.3249],
        [0.6015, 0.3985],
        [0.6928, 0.3072],
        [0.6680, 0.3320],
        [0.6599, 0.3401],
        [0.6258, 0.3742],
        [0.6025, 0.3975],
        [0.7376, 0.2624],
        [0.5877, 0.4123],
        [0.6648, 0.3352],
        [0.6808, 0.3192],
        [0.5707, 0.4293],
        [0.6263, 0.3737],
        [0.6727, 0.3273],
        [0.6424, 0.3576],
        [0.6849, 0.3151],
        [0.6088, 0.3912],
        [0.6071, 0.3929],
        [0.6961, 0.3039],
        [0.5740, 0.4260],
        [0.6759, 0.3241],
        [0.7004, 0.2996],
        [0.6448, 0.3552],
        [0.6478, 0.3522],
        [0.6541, 0.3459],
        [0.6712, 0.3288],
        [0.6859, 0.3141],
        [0.6693, 0.3307],
        [0.6489, 0.3511],
        [0.6787, 0.3213],
        [0.6485, 0.3515],
        [0.6680, 0.3320],
        [0.5940, 0.4060],
        [0.6891, 0.3109],
        [0.7203, 0.2797],
        [0.6605, 0.3395],
        [0.7095, 0.2905],
        [0.6465, 0.3535],
        [0.5813, 0.4187],
        [0.6166, 0.3834],
        [0.6323, 0.3677],
        [0.6229, 0.3771],
        [0.6516, 0.3484],
        [0.6985, 0.3015],
        [0.6466, 0.3534],
        [0.6212, 0.3788],
        [0.6489, 0.3511],
        [0.6082, 0.3918],
        [0.6882, 0.3118],
        [0.6643, 0.3357],
        [0.6502, 0.3498],
        [0.6238, 0.3762],
        [0.7250, 0.2750],
        [0.6796, 0.3204],
        [0.6582, 0.3418],
        [0.6494, 0.3506],
        [0.6772, 0.3228],
        [0.6646, 0.3354],
        [0.6885, 0.3115],
        [0.6336, 0.3664],
        [0.5798, 0.4202],
        [0.6307, 0.3693],
        [0.6157, 0.3843],
        [0.6235, 0.3765],
        [0.6616, 0.3384],
        [0.6585, 0.3415],
        [0.6793, 0.3207],
        [0.5903, 0.4097],
        [0.6301, 0.3699],
        [0.6492, 0.3508],
        [0.6308, 0.3692],
        [0.6645, 0.3355],
        [0.6412, 0.3588],
        [0.5927, 0.4073],
        [0.6608, 0.3392],
        [0.7319, 0.2681],
        [0.7263, 0.2737],
        [0.6058, 0.3942],
        [0.6532, 0.3468],
        [0.6193, 0.3807],
        [0.6625, 0.3375],
        [0.6112, 0.3888],
        [0.6272, 0.3728],
        [0.6351, 0.3649],
        [0.6598, 0.3402],
        [0.6674, 0.3326],
        [0.6886, 0.3114],
        [0.6948, 0.3052],
        [0.5943, 0.4057],
        [0.6367, 0.3633],
        [0.6736, 0.3264],
        [0.6645, 0.3355],
        [0.6847, 0.3153],
        [0.6994, 0.3006],
        [0.5702, 0.4298],
        [0.6633, 0.3367],
        [0.6782, 0.3218],
        [0.6959, 0.3041],
        [0.6739, 0.3261],
        [0.6626, 0.3374],
        [0.6542, 0.3458],
        [0.6099, 0.3901],
        [0.6293, 0.3707],
        [0.6650, 0.3350],
        [0.6721, 0.3279],
        [0.6503, 0.3497],
        [0.5970, 0.4030],
        [0.6321, 0.3679],
        [0.6668, 0.3332],
        [0.5983, 0.4017],
        [0.6767, 0.3233],
        [0.6475, 0.3525],
        [0.7101, 0.2899],
        [0.5943, 0.4057],
        [0.6391, 0.3609],
        [0.6219, 0.3781],
        [0.5969, 0.4031],
        [0.6863, 0.3137],
        [0.6287, 0.3713],
        [0.6375, 0.3625],
        [0.6003, 0.3997],
        [0.6360, 0.3640],
        [0.5872, 0.4128],
        [0.5936, 0.4064],
        [0.5827, 0.4173],
        [0.6788, 0.3212],
        [0.6460, 0.3540],
        [0.6477, 0.3523],
        [0.6725, 0.3275],
        [0.6835, 0.3165],
        [0.6049, 0.3951],
        [0.7071, 0.2929],
        [0.7289, 0.2711],
        [0.7003, 0.2997],
        [0.6961, 0.3039],
        [0.6127, 0.3873],
        [0.6977, 0.3023],
        [0.6852, 0.3148],
        [0.6283, 0.3717],
        [0.6526, 0.3474],
        [0.6636, 0.3364],
        [0.6824, 0.3176],
        [0.5840, 0.4160],
        [0.6556, 0.3444],
        [0.6510, 0.3490],
        [0.6446, 0.3554],
        [0.6386, 0.3614],
        [0.6362, 0.3638],
        [0.6769, 0.3231],
        [0.6098, 0.3902],
        [0.6696, 0.3304],
        [0.6111, 0.3889],
        [0.6820, 0.3180],
        [0.6059, 0.3941],
        [0.6907, 0.3093],
        [0.6923, 0.3077],
        [0.7044, 0.2956],
        [0.6506, 0.3494],
        [0.6434, 0.3566],
        [0.6967, 0.3033],
        [0.7128, 0.2872],
        [0.6369, 0.3631],
        [0.6268, 0.3732],
        [0.6024, 0.3976],
        [0.6763, 0.3237],
        [0.6961, 0.3039],
        [0.5768, 0.4232],
        [0.6470, 0.3530],
        [0.6427, 0.3573],
        [0.7017, 0.2983],
        [0.7243, 0.2757],
        [0.5924, 0.4076],
        [0.6288, 0.3712],
        [0.6062, 0.3938],
        [0.6923, 0.3077],
        [0.6711, 0.3289],
        [0.6635, 0.3365],
        [0.5981, 0.4019],
        [0.6772, 0.3228],
        [0.6878, 0.3122],
        [0.6275, 0.3725],
        [0.6854, 0.3146],
        [0.6555, 0.3445],
        [0.6350, 0.3650],
        [0.7013, 0.2987],
        [0.6813, 0.3187],
        [0.7393, 0.2607],
        [0.7292, 0.2708],
        [0.5785, 0.4215],
        [0.6135, 0.3865],
        [0.6711, 0.3289],
        [0.6062, 0.3938],
        [0.6805, 0.3195],
        [0.6231, 0.3769],
        [0.6723, 0.3277],
        [0.6969, 0.3031],
        [0.6417, 0.3583],
        [0.7013, 0.2987],
        [0.6688, 0.3312],
        [0.6809, 0.3191],
        [0.5624, 0.4376],
        [0.6969, 0.3031],
        [0.6145, 0.3855],
        [0.7181, 0.2819],
        [0.6698, 0.3302],
        [0.7329, 0.2671],
        [0.6418, 0.3582],
        [0.7042, 0.2958],
        [0.6810, 0.3190],
        [0.6951, 0.3049],
        [0.7192, 0.2808],
        [0.6662, 0.3338],
        [0.6929, 0.3071],
        [0.6957, 0.3043],
        [0.7144, 0.2856],
        [0.6837, 0.3163],
        [0.5860, 0.4140],
        [0.6666, 0.3334],
        [0.6525, 0.3475],
        [0.5940, 0.4060],
        [0.6571, 0.3429],
        [0.6363, 0.3637],
        [0.6116, 0.3884],
        [0.6360, 0.3640],
        [0.7003, 0.2997],
        [0.6774, 0.3226],
        [0.6783, 0.3217],
        [0.6770, 0.3230],
        [0.6876, 0.3124],
        [0.6614, 0.3386],
        [0.6394, 0.3606],
        [0.6819, 0.3181],
        [0.6598, 0.3402],
        [0.6607, 0.3393],
        [0.6734, 0.3266],
        [0.6591, 0.3409],
        [0.6397, 0.3603],
        [0.6672, 0.3328],
        [0.6823, 0.3177],
        [0.6836, 0.3164],
        [0.6568, 0.3432],
        [0.6132, 0.3868],
        [0.6625, 0.3375],
        [0.6734, 0.3266],
        [0.6151, 0.3849],
        [0.6698, 0.3302],
        [0.6762, 0.3238],
        [0.6848, 0.3152],
        [0.6596, 0.3404],
        [0.6088, 0.3912],
        [0.6943, 0.3057],
        [0.6831, 0.3169]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0014 loss: 0.6499 acc_train: 0.6103 time: 0.1561s
tensor([[0.5848, 0.4152],
        [0.6848, 0.3152],
        [0.6748, 0.3252],
        [0.6401, 0.3599],
        [0.6990, 0.3010],
        [0.6390, 0.3610],
        [0.5711, 0.4289],
        [0.6496, 0.3504],
        [0.6319, 0.3681],
        [0.6376, 0.3624],
        [0.6514, 0.3486],
        [0.6172, 0.3828],
        [0.6332, 0.3668],
        [0.6218, 0.3782],
        [0.6734, 0.3266],
        [0.6430, 0.3570],
        [0.6917, 0.3083],
        [0.6579, 0.3421],
        [0.5959, 0.4041],
        [0.6137, 0.3863],
        [0.6709, 0.3291],
        [0.6026, 0.3974],
        [0.6848, 0.3152],
        [0.6620, 0.3380],
        [0.6542, 0.3458],
        [0.6250, 0.3750],
        [0.5982, 0.4018],
        [0.7249, 0.2751],
        [0.5893, 0.4107],
        [0.6583, 0.3417],
        [0.6700, 0.3300],
        [0.5761, 0.4239],
        [0.6248, 0.3752],
        [0.6649, 0.3351],
        [0.6391, 0.3609],
        [0.6745, 0.3255],
        [0.6076, 0.3924],
        [0.6076, 0.3924],
        [0.6889, 0.3111],
        [0.5756, 0.4244],
        [0.6698, 0.3302],
        [0.6895, 0.3105],
        [0.6411, 0.3589],
        [0.6451, 0.3549],
        [0.6483, 0.3517],
        [0.6655, 0.3345],
        [0.6776, 0.3224],
        [0.6635, 0.3365],
        [0.6440, 0.3560],
        [0.6738, 0.3262],
        [0.6441, 0.3559],
        [0.6631, 0.3369],
        [0.5943, 0.4057],
        [0.6789, 0.3211],
        [0.7099, 0.2901],
        [0.6567, 0.3433],
        [0.6997, 0.3003],
        [0.6446, 0.3554],
        [0.5798, 0.4202],
        [0.6148, 0.3852],
        [0.6294, 0.3706],
        [0.6215, 0.3785],
        [0.6474, 0.3526],
        [0.6882, 0.3118],
        [0.6393, 0.3607],
        [0.6196, 0.3804],
        [0.6427, 0.3573],
        [0.6105, 0.3895],
        [0.6806, 0.3194],
        [0.6581, 0.3419],
        [0.6463, 0.3537],
        [0.6193, 0.3807],
        [0.7145, 0.2855],
        [0.6705, 0.3295],
        [0.6522, 0.3478],
        [0.6429, 0.3571],
        [0.6721, 0.3279],
        [0.6568, 0.3432],
        [0.6796, 0.3204],
        [0.6303, 0.3697],
        [0.5827, 0.4173],
        [0.6270, 0.3730],
        [0.6137, 0.3863],
        [0.6197, 0.3803],
        [0.6563, 0.3437],
        [0.6528, 0.3472],
        [0.6731, 0.3269],
        [0.5921, 0.4079],
        [0.6293, 0.3707],
        [0.6425, 0.3575],
        [0.6292, 0.3708],
        [0.6587, 0.3413],
        [0.6373, 0.3627],
        [0.5957, 0.4043],
        [0.6564, 0.3436],
        [0.7187, 0.2813],
        [0.7158, 0.2842],
        [0.6077, 0.3923],
        [0.6478, 0.3522],
        [0.6197, 0.3803],
        [0.6567, 0.3433],
        [0.6103, 0.3897],
        [0.6233, 0.3767],
        [0.6324, 0.3676],
        [0.6553, 0.3447],
        [0.6616, 0.3384],
        [0.6824, 0.3176],
        [0.6859, 0.3141],
        [0.5974, 0.4026],
        [0.6337, 0.3663],
        [0.6665, 0.3335],
        [0.6593, 0.3407],
        [0.6764, 0.3236],
        [0.6913, 0.3087],
        [0.5743, 0.4257],
        [0.6557, 0.3443],
        [0.6701, 0.3299],
        [0.6862, 0.3138],
        [0.6699, 0.3301],
        [0.6587, 0.3413],
        [0.6516, 0.3484],
        [0.6107, 0.3893],
        [0.6273, 0.3727],
        [0.6567, 0.3433],
        [0.6636, 0.3364],
        [0.6478, 0.3522],
        [0.5983, 0.4017],
        [0.6261, 0.3739],
        [0.6600, 0.3400],
        [0.5998, 0.4002],
        [0.6680, 0.3320],
        [0.6427, 0.3573],
        [0.7007, 0.2993],
        [0.5956, 0.4044],
        [0.6358, 0.3642],
        [0.6190, 0.3810],
        [0.5980, 0.4020],
        [0.6760, 0.3240],
        [0.6270, 0.3730],
        [0.6317, 0.3683],
        [0.6005, 0.3995],
        [0.6322, 0.3678],
        [0.5894, 0.4106],
        [0.5949, 0.4051],
        [0.5839, 0.4161],
        [0.6713, 0.3287],
        [0.6436, 0.3564],
        [0.6413, 0.3587],
        [0.6664, 0.3336],
        [0.6766, 0.3234],
        [0.6032, 0.3968],
        [0.6974, 0.3026],
        [0.7164, 0.2836],
        [0.6914, 0.3086],
        [0.6875, 0.3125],
        [0.6143, 0.3857],
        [0.6881, 0.3119],
        [0.6790, 0.3210],
        [0.6272, 0.3728],
        [0.6468, 0.3532],
        [0.6541, 0.3459],
        [0.6748, 0.3252],
        [0.5851, 0.4149],
        [0.6489, 0.3511],
        [0.6463, 0.3537],
        [0.6399, 0.3601],
        [0.6376, 0.3624],
        [0.6333, 0.3667],
        [0.6695, 0.3305],
        [0.6091, 0.3909],
        [0.6641, 0.3359],
        [0.6140, 0.3860],
        [0.6740, 0.3260],
        [0.6042, 0.3958],
        [0.6820, 0.3180],
        [0.6830, 0.3170],
        [0.6951, 0.3049],
        [0.6498, 0.3502],
        [0.6395, 0.3605],
        [0.6866, 0.3134],
        [0.7031, 0.2969],
        [0.6322, 0.3678],
        [0.6241, 0.3759],
        [0.6004, 0.3996],
        [0.6675, 0.3325],
        [0.6881, 0.3119],
        [0.5795, 0.4205],
        [0.6398, 0.3602],
        [0.6381, 0.3619],
        [0.6905, 0.3095],
        [0.7143, 0.2857],
        [0.5981, 0.4019],
        [0.6275, 0.3725],
        [0.6057, 0.3943],
        [0.6825, 0.3175],
        [0.6666, 0.3334],
        [0.6590, 0.3410],
        [0.5981, 0.4019],
        [0.6701, 0.3299],
        [0.6821, 0.3179],
        [0.6229, 0.3771],
        [0.6774, 0.3226],
        [0.6497, 0.3503],
        [0.6305, 0.3695],
        [0.6909, 0.3091],
        [0.6712, 0.3288],
        [0.7265, 0.2735],
        [0.7168, 0.2832],
        [0.5798, 0.4202],
        [0.6120, 0.3880],
        [0.6644, 0.3356],
        [0.6055, 0.3945],
        [0.6732, 0.3268],
        [0.6204, 0.3796],
        [0.6639, 0.3361],
        [0.6899, 0.3101],
        [0.6382, 0.3618],
        [0.6920, 0.3080],
        [0.6636, 0.3364],
        [0.6745, 0.3255],
        [0.5679, 0.4321],
        [0.6859, 0.3141],
        [0.6153, 0.3847],
        [0.7061, 0.2939],
        [0.6624, 0.3376],
        [0.7220, 0.2780],
        [0.6354, 0.3646],
        [0.6954, 0.3046],
        [0.6754, 0.3246],
        [0.6859, 0.3141],
        [0.7096, 0.2904],
        [0.6609, 0.3391],
        [0.6871, 0.3129],
        [0.6876, 0.3124],
        [0.7039, 0.2961],
        [0.6728, 0.3272],
        [0.5865, 0.4135],
        [0.6612, 0.3388],
        [0.6466, 0.3534],
        [0.5928, 0.4072],
        [0.6538, 0.3462],
        [0.6313, 0.3687],
        [0.6105, 0.3895],
        [0.6324, 0.3676],
        [0.6899, 0.3101],
        [0.6717, 0.3283],
        [0.6705, 0.3295],
        [0.6699, 0.3301],
        [0.6798, 0.3202],
        [0.6556, 0.3444],
        [0.6361, 0.3639],
        [0.6741, 0.3259],
        [0.6536, 0.3464],
        [0.6572, 0.3428],
        [0.6668, 0.3332],
        [0.6524, 0.3476],
        [0.6378, 0.3622],
        [0.6614, 0.3386],
        [0.6733, 0.3267],
        [0.6778, 0.3222],
        [0.6498, 0.3502],
        [0.6133, 0.3867],
        [0.6534, 0.3466],
        [0.6670, 0.3330],
        [0.6128, 0.3872],
        [0.6631, 0.3369],
        [0.6703, 0.3297],
        [0.6761, 0.3239],
        [0.6504, 0.3496],
        [0.6086, 0.3914],
        [0.6851, 0.3149],
        [0.6778, 0.3222]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0015 loss: 0.6520 acc_train: 0.6103 time: 0.1527s
tensor([[0.5900, 0.4100],
        [0.6778, 0.3222],
        [0.6696, 0.3304],
        [0.6384, 0.3616],
        [0.6909, 0.3091],
        [0.6354, 0.3646],
        [0.5761, 0.4239],
        [0.6452, 0.3548],
        [0.6303, 0.3697],
        [0.6328, 0.3672],
        [0.6477, 0.3523],
        [0.6185, 0.3815],
        [0.6310, 0.3690],
        [0.6212, 0.3788],
        [0.6666, 0.3334],
        [0.6404, 0.3596],
        [0.6846, 0.3154],
        [0.6535, 0.3465],
        [0.5996, 0.4004],
        [0.6172, 0.3828],
        [0.6679, 0.3321],
        [0.6055, 0.3945],
        [0.6779, 0.3221],
        [0.6580, 0.3420],
        [0.6500, 0.3500],
        [0.6259, 0.3741],
        [0.5972, 0.4028],
        [0.7123, 0.2877],
        [0.5940, 0.4060],
        [0.6532, 0.3468],
        [0.6614, 0.3386],
        [0.5833, 0.4167],
        [0.6249, 0.3751],
        [0.6581, 0.3419],
        [0.6371, 0.3629],
        [0.6658, 0.3342],
        [0.6084, 0.3916],
        [0.6099, 0.3901],
        [0.6827, 0.3173],
        [0.5803, 0.4197],
        [0.6642, 0.3358],
        [0.6800, 0.3200],
        [0.6384, 0.3616],
        [0.6437, 0.3563],
        [0.6441, 0.3559],
        [0.6608, 0.3392],
        [0.6711, 0.3289],
        [0.6591, 0.3409],
        [0.6414, 0.3586],
        [0.6696, 0.3304],
        [0.6412, 0.3588],
        [0.6593, 0.3407],
        [0.5976, 0.4024],
        [0.6705, 0.3295],
        [0.7001, 0.2999],
        [0.6539, 0.3461],
        [0.6901, 0.3099],
        [0.6443, 0.3557],
        [0.5820, 0.4180],
        [0.6152, 0.3848],
        [0.6276, 0.3724],
        [0.6215, 0.3785],
        [0.6447, 0.3553],
        [0.6790, 0.3210],
        [0.6345, 0.3655],
        [0.6194, 0.3806],
        [0.6388, 0.3612],
        [0.6144, 0.3856],
        [0.6744, 0.3256],
        [0.6533, 0.3467],
        [0.6436, 0.3564],
        [0.6171, 0.3829],
        [0.7044, 0.2956],
        [0.6627, 0.3373],
        [0.6478, 0.3522],
        [0.6378, 0.3622],
        [0.6679, 0.3321],
        [0.6506, 0.3494],
        [0.6719, 0.3281],
        [0.6287, 0.3713],
        [0.5880, 0.4120],
        [0.6245, 0.3755],
        [0.6137, 0.3863],
        [0.6181, 0.3819],
        [0.6520, 0.3480],
        [0.6482, 0.3518],
        [0.6679, 0.3321],
        [0.5964, 0.4036],
        [0.6296, 0.3704],
        [0.6380, 0.3620],
        [0.6286, 0.3714],
        [0.6543, 0.3457],
        [0.6353, 0.3647],
        [0.5995, 0.4005],
        [0.6529, 0.3471],
        [0.7062, 0.2938],
        [0.7058, 0.2942],
        [0.6109, 0.3891],
        [0.6441, 0.3559],
        [0.6216, 0.3784],
        [0.6528, 0.3472],
        [0.6115, 0.3885],
        [0.6218, 0.3782],
        [0.6314, 0.3686],
        [0.6524, 0.3476],
        [0.6573, 0.3427],
        [0.6770, 0.3230],
        [0.6784, 0.3216],
        [0.6022, 0.3978],
        [0.6333, 0.3667],
        [0.6606, 0.3394],
        [0.6556, 0.3444],
        [0.6693, 0.3307],
        [0.6839, 0.3161],
        [0.5808, 0.4192],
        [0.6490, 0.3510],
        [0.6635, 0.3365],
        [0.6774, 0.3226],
        [0.6664, 0.3336],
        [0.6556, 0.3444],
        [0.6506, 0.3494],
        [0.6132, 0.3868],
        [0.6274, 0.3726],
        [0.6509, 0.3491],
        [0.6566, 0.3434],
        [0.6468, 0.3532],
        [0.6018, 0.3982],
        [0.6231, 0.3769],
        [0.6550, 0.3450],
        [0.6033, 0.3967],
        [0.6610, 0.3390],
        [0.6393, 0.3607],
        [0.6917, 0.3083],
        [0.5990, 0.4010],
        [0.6345, 0.3655],
        [0.6183, 0.3817],
        [0.6012, 0.3988],
        [0.6679, 0.3321],
        [0.6269, 0.3731],
        [0.6280, 0.3720],
        [0.6017, 0.3983],
        [0.6304, 0.3696],
        [0.5940, 0.4060],
        [0.5986, 0.4014],
        [0.5878, 0.4122],
        [0.6651, 0.3349],
        [0.6422, 0.3578],
        [0.6365, 0.3635],
        [0.6616, 0.3384],
        [0.6708, 0.3292],
        [0.6047, 0.3953],
        [0.6889, 0.3111],
        [0.7043, 0.2957],
        [0.6840, 0.3160],
        [0.6797, 0.3203],
        [0.6174, 0.3826],
        [0.6793, 0.3207],
        [0.6735, 0.3265],
        [0.6276, 0.3724],
        [0.6426, 0.3574],
        [0.6467, 0.3533],
        [0.6683, 0.3317],
        [0.5888, 0.4112],
        [0.6439, 0.3561],
        [0.6427, 0.3573],
        [0.6371, 0.3629],
        [0.6383, 0.3617],
        [0.6317, 0.3683],
        [0.6638, 0.3362],
        [0.6105, 0.3895],
        [0.6588, 0.3412],
        [0.6175, 0.3825],
        [0.6672, 0.3328],
        [0.6054, 0.3946],
        [0.6745, 0.3255],
        [0.6748, 0.3252],
        [0.6867, 0.3133],
        [0.6494, 0.3506],
        [0.6369, 0.3631],
        [0.6773, 0.3227],
        [0.6943, 0.3057],
        [0.6296, 0.3704],
        [0.6233, 0.3767],
        [0.6009, 0.3991],
        [0.6605, 0.3395],
        [0.6809, 0.3191],
        [0.5847, 0.4153],
        [0.6350, 0.3650],
        [0.6353, 0.3647],
        [0.6807, 0.3193],
        [0.7043, 0.2957],
        [0.6043, 0.3957],
        [0.6276, 0.3724],
        [0.6070, 0.3930],
        [0.6743, 0.3257],
        [0.6631, 0.3369],
        [0.6556, 0.3444],
        [0.6010, 0.3990],
        [0.6645, 0.3355],
        [0.6769, 0.3231],
        [0.6204, 0.3796],
        [0.6706, 0.3294],
        [0.6455, 0.3545],
        [0.6282, 0.3718],
        [0.6818, 0.3182],
        [0.6631, 0.3369],
        [0.7139, 0.2861],
        [0.7052, 0.2948],
        [0.5837, 0.4163],
        [0.6124, 0.3876],
        [0.6595, 0.3405],
        [0.6070, 0.3930],
        [0.6669, 0.3331],
        [0.6198, 0.3802],
        [0.6576, 0.3424],
        [0.6837, 0.3163],
        [0.6362, 0.3638],
        [0.6832, 0.3168],
        [0.6597, 0.3403],
        [0.6688, 0.3312],
        [0.5758, 0.4242],
        [0.6768, 0.3232],
        [0.6175, 0.3825],
        [0.6957, 0.3043],
        [0.6568, 0.3432],
        [0.7115, 0.2885],
        [0.6309, 0.3691],
        [0.6873, 0.3127],
        [0.6706, 0.3294],
        [0.6787, 0.3213],
        [0.7006, 0.2994],
        [0.6573, 0.3427],
        [0.6823, 0.3177],
        [0.6807, 0.3193],
        [0.6940, 0.3060],
        [0.6640, 0.3360],
        [0.5895, 0.4105],
        [0.6568, 0.3432],
        [0.6422, 0.3578],
        [0.5946, 0.4054],
        [0.6516, 0.3484],
        [0.6289, 0.3711],
        [0.6119, 0.3881],
        [0.6296, 0.3704],
        [0.6808, 0.3192],
        [0.6670, 0.3330],
        [0.6646, 0.3354],
        [0.6640, 0.3360],
        [0.6729, 0.3271],
        [0.6515, 0.3485],
        [0.6348, 0.3652],
        [0.6678, 0.3322],
        [0.6486, 0.3514],
        [0.6547, 0.3453],
        [0.6614, 0.3386],
        [0.6476, 0.3524],
        [0.6374, 0.3626],
        [0.6570, 0.3430],
        [0.6659, 0.3341],
        [0.6733, 0.3267],
        [0.6450, 0.3550],
        [0.6151, 0.3849],
        [0.6461, 0.3539],
        [0.6618, 0.3382],
        [0.6128, 0.3872],
        [0.6582, 0.3418],
        [0.6651, 0.3349],
        [0.6683, 0.3317],
        [0.6436, 0.3564],
        [0.6103, 0.3897],
        [0.6771, 0.3229],
        [0.6734, 0.3266]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0016 loss: 0.6543 acc_train: 0.6103 time: 0.1481s
tensor([[0.5989, 0.4011],
        [0.6737, 0.3263],
        [0.6671, 0.3329],
        [0.6394, 0.3606],
        [0.6852, 0.3148],
        [0.6353, 0.3647],
        [0.5851, 0.4149],
        [0.6443, 0.3557],
        [0.6318, 0.3682],
        [0.6321, 0.3679],
        [0.6472, 0.3528],
        [0.6234, 0.3766],
        [0.6318, 0.3682],
        [0.6237, 0.3763],
        [0.6630, 0.3370],
        [0.6410, 0.3590],
        [0.6798, 0.3202],
        [0.6520, 0.3480],
        [0.6060, 0.3940],
        [0.6232, 0.3768],
        [0.6667, 0.3333],
        [0.6113, 0.3887],
        [0.6740, 0.3260],
        [0.6569, 0.3431],
        [0.6488, 0.3512],
        [0.6294, 0.3706],
        [0.6008, 0.3993],
        [0.7021, 0.2979],
        [0.6016, 0.3984],
        [0.6512, 0.3488],
        [0.6567, 0.3433],
        [0.5930, 0.4070],
        [0.6283, 0.3717],
        [0.6546, 0.3454],
        [0.6379, 0.3621],
        [0.6604, 0.3396],
        [0.6120, 0.3880],
        [0.6153, 0.3847],
        [0.6788, 0.3212],
        [0.5888, 0.4112],
        [0.6613, 0.3387],
        [0.6738, 0.3262],
        [0.6384, 0.3616],
        [0.6448, 0.3552],
        [0.6430, 0.3570],
        [0.6588, 0.3412],
        [0.6676, 0.3324],
        [0.6577, 0.3423],
        [0.6422, 0.3578],
        [0.6679, 0.3321],
        [0.6415, 0.3585],
        [0.6584, 0.3416],
        [0.6047, 0.3953],
        [0.6654, 0.3346],
        [0.6926, 0.3074],
        [0.6537, 0.3463],
        [0.6830, 0.3170],
        [0.6463, 0.3537],
        [0.5890, 0.4110],
        [0.6188, 0.3812],
        [0.6294, 0.3706],
        [0.6244, 0.3756],
        [0.6448, 0.3552],
        [0.6731, 0.3269],
        [0.6336, 0.3664],
        [0.6219, 0.3781],
        [0.6382, 0.3618],
        [0.6207, 0.3793],
        [0.6710, 0.3290],
        [0.6514, 0.3486],
        [0.6436, 0.3564],
        [0.6189, 0.3811],
        [0.6964, 0.3036],
        [0.6575, 0.3425],
        [0.6466, 0.3534],
        [0.6361, 0.3639],
        [0.6663, 0.3337],
        [0.6477, 0.3523],
        [0.6667, 0.3333],
        [0.6300, 0.3700],
        [0.5964, 0.4036],
        [0.6254, 0.3746],
        [0.6173, 0.3827],
        [0.6199, 0.3801],
        [0.6501, 0.3499],
        [0.6464, 0.3536],
        [0.6653, 0.3347],
        [0.6044, 0.3956],
        [0.6326, 0.3674],
        [0.6371, 0.3629],
        [0.6306, 0.3694],
        [0.6525, 0.3475],
        [0.6363, 0.3637],
        [0.6059, 0.3941],
        [0.6521, 0.3479],
        [0.6966, 0.3034],
        [0.6983, 0.3017],
        [0.6163, 0.3837],
        [0.6437, 0.3563],
        [0.6265, 0.3735],
        [0.6522, 0.3478],
        [0.6161, 0.3839],
        [0.6241, 0.3759],
        [0.6333, 0.3667],
        [0.6521, 0.3479],
        [0.6557, 0.3443],
        [0.6740, 0.3260],
        [0.6736, 0.3264],
        [0.6099, 0.3901],
        [0.6360, 0.3640],
        [0.6568, 0.3432],
        [0.6548, 0.3452],
        [0.6654, 0.3346],
        [0.6792, 0.3208],
        [0.5905, 0.4095],
        [0.6452, 0.3548],
        [0.6600, 0.3400],
        [0.6714, 0.3286],
        [0.6653, 0.3347],
        [0.6547, 0.3453],
        [0.6520, 0.3480],
        [0.6192, 0.3808],
        [0.6306, 0.3694],
        [0.6490, 0.3510],
        [0.6528, 0.3472],
        [0.6484, 0.3516],
        [0.6084, 0.3916],
        [0.6243, 0.3757],
        [0.6529, 0.3471],
        [0.6101, 0.3899],
        [0.6572, 0.3428],
        [0.6390, 0.3610],
        [0.6848, 0.3152],
        [0.6053, 0.3947],
        [0.6360, 0.3640],
        [0.6211, 0.3789],
        [0.6076, 0.3924],
        [0.6634, 0.3366],
        [0.6297, 0.3703],
        [0.6282, 0.3718],
        [0.6061, 0.3939],
        [0.6319, 0.3681],
        [0.6016, 0.3984],
        [0.6056, 0.3944],
        [0.5953, 0.4047],
        [0.6621, 0.3379],
        [0.6435, 0.3565],
        [0.6352, 0.3648],
        [0.6595, 0.3405],
        [0.6676, 0.3324],
        [0.6101, 0.3899],
        [0.6832, 0.3168],
        [0.6945, 0.3055],
        [0.6794, 0.3206],
        [0.6741, 0.3259],
        [0.6232, 0.3768],
        [0.6737, 0.3263],
        [0.6703, 0.3297],
        [0.6309, 0.3691],
        [0.6415, 0.3585],
        [0.6435, 0.3565],
        [0.6647, 0.3353],
        [0.5958, 0.4042],
        [0.6423, 0.3577],
        [0.6416, 0.3584],
        [0.6375, 0.3625],
        [0.6413, 0.3587],
        [0.6328, 0.3672],
        [0.6608, 0.3392],
        [0.6149, 0.3851],
        [0.6553, 0.3447],
        [0.6229, 0.3771],
        [0.6632, 0.3368],
        [0.6101, 0.3899],
        [0.6695, 0.3305],
        [0.6694, 0.3306],
        [0.6812, 0.3188],
        [0.6507, 0.3493],
        [0.6373, 0.3627],
        [0.6711, 0.3289],
        [0.6879, 0.3121],
        [0.6306, 0.3694],
        [0.6255, 0.3745],
        [0.6051, 0.3949],
        [0.6567, 0.3433],
        [0.6761, 0.3239],
        [0.5932, 0.4068],
        [0.6340, 0.3660],
        [0.6356, 0.3644],
        [0.6742, 0.3258],
        [0.6964, 0.3036],
        [0.6121, 0.3879],
        [0.6305, 0.3695],
        [0.6119, 0.3881],
        [0.6693, 0.3307],
        [0.6620, 0.3380],
        [0.6550, 0.3450],
        [0.6074, 0.3926],
        [0.6616, 0.3384],
        [0.6737, 0.3263],
        [0.6217, 0.3783],
        [0.6672, 0.3328],
        [0.6448, 0.3552],
        [0.6296, 0.3704],
        [0.6757, 0.3243],
        [0.6585, 0.3415],
        [0.7036, 0.2964],
        [0.6961, 0.3039],
        [0.5914, 0.4086],
        [0.6162, 0.3838],
        [0.6578, 0.3422],
        [0.6120, 0.3880],
        [0.6637, 0.3363],
        [0.6226, 0.3774],
        [0.6547, 0.3453],
        [0.6797, 0.3203],
        [0.6369, 0.3631],
        [0.6771, 0.3229],
        [0.6582, 0.3418],
        [0.6659, 0.3341],
        [0.5869, 0.4131],
        [0.6711, 0.3289],
        [0.6220, 0.3780],
        [0.6883, 0.3117],
        [0.6544, 0.3456],
        [0.7032, 0.2968],
        [0.6298, 0.3702],
        [0.6818, 0.3182],
        [0.6680, 0.3320],
        [0.6747, 0.3253],
        [0.6934, 0.3066],
        [0.6565, 0.3435],
        [0.6796, 0.3204],
        [0.6764, 0.3236],
        [0.6870, 0.3130],
        [0.6592, 0.3408],
        [0.5961, 0.4039],
        [0.6553, 0.3447],
        [0.6409, 0.3591],
        [0.6002, 0.3998],
        [0.6517, 0.3483],
        [0.6304, 0.3696],
        [0.6165, 0.3835],
        [0.6298, 0.3702],
        [0.6749, 0.3251],
        [0.6648, 0.3352],
        [0.6620, 0.3380],
        [0.6610, 0.3390],
        [0.6685, 0.3315],
        [0.6505, 0.3495],
        [0.6366, 0.3634],
        [0.6644, 0.3356],
        [0.6467, 0.3533],
        [0.6545, 0.3455],
        [0.6589, 0.3411],
        [0.6464, 0.3536],
        [0.6396, 0.3604],
        [0.6555, 0.3445],
        [0.6616, 0.3384],
        [0.6709, 0.3291],
        [0.6438, 0.3562],
        [0.6197, 0.3803],
        [0.6427, 0.3573],
        [0.6598, 0.3402],
        [0.6164, 0.3836],
        [0.6565, 0.3435],
        [0.6622, 0.3378],
        [0.6630, 0.3370],
        [0.6411, 0.3589],
        [0.6152, 0.3848],
        [0.6724, 0.3276],
        [0.6713, 0.3287]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0017 loss: 0.6566 acc_train: 0.6103 time: 0.1550s
tensor([[0.6094, 0.3906],
        [0.6716, 0.3284],
        [0.6663, 0.3337],
        [0.6424, 0.3576],
        [0.6811, 0.3189],
        [0.6377, 0.3623],
        [0.5959, 0.4041],
        [0.6456, 0.3544],
        [0.6358, 0.3642],
        [0.6342, 0.3658],
        [0.6490, 0.3510],
        [0.6302, 0.3698],
        [0.6348, 0.3652],
        [0.6281, 0.3719],
        [0.6617, 0.3383],
        [0.6434, 0.3566],
        [0.6768, 0.3232],
        [0.6526, 0.3474],
        [0.6143, 0.3857],
        [0.6300, 0.3700],
        [0.6669, 0.3331],
        [0.6190, 0.3810],
        [0.6719, 0.3281],
        [0.6580, 0.3420],
        [0.6498, 0.3502],
        [0.6346, 0.3654],
        [0.6071, 0.3929],
        [0.6941, 0.3059],
        [0.6108, 0.3892],
        [0.6512, 0.3488],
        [0.6547, 0.3453],
        [0.6043, 0.3957],
        [0.6332, 0.3668],
        [0.6532, 0.3468],
        [0.6407, 0.3593],
        [0.6572, 0.3428],
        [0.6177, 0.3823],
        [0.6223, 0.3777],
        [0.6768, 0.3232],
        [0.5994, 0.4006],
        [0.6605, 0.3395],
        [0.6701, 0.3299],
        [0.6397, 0.3603],
        [0.6472, 0.3528],
        [0.6441, 0.3559],
        [0.6585, 0.3415],
        [0.6664, 0.3336],
        [0.6583, 0.3417],
        [0.6449, 0.3551],
        [0.6676, 0.3324],
        [0.6438, 0.3562],
        [0.6593, 0.3407],
        [0.6137, 0.3863],
        [0.6628, 0.3372],
        [0.6870, 0.3130],
        [0.6548, 0.3452],
        [0.6780, 0.3220],
        [0.6498, 0.3502],
        [0.5987, 0.4013],
        [0.6241, 0.3759],
        [0.6336, 0.3664],
        [0.6291, 0.3709],
        [0.6466, 0.3534],
        [0.6695, 0.3305],
        [0.6356, 0.3644],
        [0.6264, 0.3736],
        [0.6398, 0.3602],
        [0.6280, 0.3720],
        [0.6693, 0.3307],
        [0.6518, 0.3482],
        [0.6455, 0.3545],
        [0.6231, 0.3769],
        [0.6903, 0.3097],
        [0.6551, 0.3449],
        [0.6475, 0.3525],
        [0.6372, 0.3628],
        [0.6664, 0.3336],
        [0.6475, 0.3525],
        [0.6639, 0.3361],
        [0.6333, 0.3667],
        [0.6067, 0.3933],
        [0.6285, 0.3715],
        [0.6232, 0.3768],
        [0.6240, 0.3760],
        [0.6500, 0.3500],
        [0.6469, 0.3531],
        [0.6642, 0.3358],
        [0.6141, 0.3859],
        [0.6367, 0.3633],
        [0.6387, 0.3613],
        [0.6342, 0.3658],
        [0.6526, 0.3474],
        [0.6394, 0.3606],
        [0.6140, 0.3860],
        [0.6527, 0.3473],
        [0.6894, 0.3106],
        [0.6922, 0.3078],
        [0.6233, 0.3767],
        [0.6451, 0.3549],
        [0.6329, 0.3671],
        [0.6538, 0.3462],
        [0.6226, 0.3774],
        [0.6283, 0.3717],
        [0.6369, 0.3631],
        [0.6534, 0.3466],
        [0.6563, 0.3437],
        [0.6728, 0.3272],
        [0.6708, 0.3292],
        [0.6189, 0.3811],
        [0.6399, 0.3601],
        [0.6547, 0.3453],
        [0.6558, 0.3442],
        [0.6635, 0.3365],
        [0.6759, 0.3241],
        [0.6016, 0.3984],
        [0.6436, 0.3564],
        [0.6587, 0.3413],
        [0.6676, 0.3324],
        [0.6655, 0.3345],
        [0.6555, 0.3445],
        [0.6547, 0.3453],
        [0.6269, 0.3731],
        [0.6354, 0.3646],
        [0.6497, 0.3503],
        [0.6515, 0.3485],
        [0.6511, 0.3489],
        [0.6164, 0.3836],
        [0.6281, 0.3719],
        [0.6530, 0.3470],
        [0.6188, 0.3812],
        [0.6559, 0.3441],
        [0.6404, 0.3596],
        [0.6795, 0.3205],
        [0.6136, 0.3864],
        [0.6396, 0.3604],
        [0.6260, 0.3740],
        [0.6154, 0.3846],
        [0.6616, 0.3384],
        [0.6341, 0.3659],
        [0.6307, 0.3693],
        [0.6128, 0.3872],
        [0.6359, 0.3641],
        [0.6109, 0.3891],
        [0.6144, 0.3856],
        [0.6049, 0.3951],
        [0.6611, 0.3389],
        [0.6461, 0.3539],
        [0.6363, 0.3637],
        [0.6596, 0.3404],
        [0.6661, 0.3339],
        [0.6177, 0.3823],
        [0.6796, 0.3204],
        [0.6870, 0.3130],
        [0.6765, 0.3235],
        [0.6706, 0.3294],
        [0.6304, 0.3696],
        [0.6703, 0.3297],
        [0.6685, 0.3315],
        [0.6355, 0.3645],
        [0.6426, 0.3574],
        [0.6434, 0.3566],
        [0.6632, 0.3368],
        [0.6048, 0.3952],
        [0.6430, 0.3570],
        [0.6423, 0.3577],
        [0.6398, 0.3602],
        [0.6457, 0.3543],
        [0.6360, 0.3640],
        [0.6600, 0.3400],
        [0.6211, 0.3789],
        [0.6533, 0.3467],
        [0.6294, 0.3706],
        [0.6612, 0.3388],
        [0.6169, 0.3831],
        [0.6662, 0.3338],
        [0.6664, 0.3336],
        [0.6778, 0.3222],
        [0.6529, 0.3471],
        [0.6397, 0.3603],
        [0.6674, 0.3326],
        [0.6835, 0.3165],
        [0.6340, 0.3660],
        [0.6297, 0.3703],
        [0.6115, 0.3885],
        [0.6551, 0.3449],
        [0.6733, 0.3267],
        [0.6028, 0.3972],
        [0.6355, 0.3645],
        [0.6382, 0.3618],
        [0.6700, 0.3300],
        [0.6901, 0.3099],
        [0.6206, 0.3794],
        [0.6348, 0.3652],
        [0.6187, 0.3813],
        [0.6668, 0.3332],
        [0.6624, 0.3376],
        [0.6560, 0.3440],
        [0.6159, 0.3841],
        [0.6609, 0.3391],
        [0.6721, 0.3279],
        [0.6257, 0.3743],
        [0.6663, 0.3337],
        [0.6464, 0.3536],
        [0.6329, 0.3671],
        [0.6720, 0.3280],
        [0.6565, 0.3435],
        [0.6955, 0.3045],
        [0.6889, 0.3111],
        [0.6013, 0.3987],
        [0.6221, 0.3779],
        [0.6577, 0.3423],
        [0.6192, 0.3808],
        [0.6625, 0.3375],
        [0.6274, 0.3726],
        [0.6544, 0.3456],
        [0.6774, 0.3226],
        [0.6395, 0.3605],
        [0.6728, 0.3272],
        [0.6584, 0.3416],
        [0.6649, 0.3351],
        [0.5995, 0.4005],
        [0.6681, 0.3319],
        [0.6279, 0.3721],
        [0.6833, 0.3167],
        [0.6545, 0.3455],
        [0.6964, 0.3036],
        [0.6310, 0.3690],
        [0.6780, 0.3220],
        [0.6668, 0.3332],
        [0.6728, 0.3272],
        [0.6879, 0.3121],
        [0.6575, 0.3425],
        [0.6781, 0.3219],
        [0.6738, 0.3262],
        [0.6820, 0.3180],
        [0.6571, 0.3429],
        [0.6048, 0.3952],
        [0.6559, 0.3441],
        [0.6422, 0.3578],
        [0.6081, 0.3919],
        [0.6533, 0.3467],
        [0.6342, 0.3658],
        [0.6229, 0.3771],
        [0.6325, 0.3675],
        [0.6716, 0.3284],
        [0.6643, 0.3357],
        [0.6614, 0.3386],
        [0.6600, 0.3400],
        [0.6665, 0.3335],
        [0.6513, 0.3487],
        [0.6403, 0.3597],
        [0.6631, 0.3369],
        [0.6468, 0.3532],
        [0.6556, 0.3444],
        [0.6586, 0.3414],
        [0.6477, 0.3523],
        [0.6432, 0.3568],
        [0.6562, 0.3438],
        [0.6598, 0.3402],
        [0.6701, 0.3299],
        [0.6446, 0.3554],
        [0.6257, 0.3743],
        [0.6422, 0.3578],
        [0.6596, 0.3404],
        [0.6221, 0.3779],
        [0.6565, 0.3435],
        [0.6611, 0.3389],
        [0.6598, 0.3402],
        [0.6420, 0.3580],
        [0.6220, 0.3780],
        [0.6699, 0.3301],
        [0.6708, 0.3292]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0018 loss: 0.6587 acc_train: 0.6103 time: 0.2189s
tensor([[0.6202, 0.3798],
        [0.6705, 0.3295],
        [0.6665, 0.3335],
        [0.6462, 0.3538],
        [0.6781, 0.3219],
        [0.6414, 0.3586],
        [0.6072, 0.3928],
        [0.6480, 0.3520],
        [0.6409, 0.3591],
        [0.6378, 0.3622],
        [0.6520, 0.3480],
        [0.6376, 0.3624],
        [0.6389, 0.3611],
        [0.6335, 0.3665],
        [0.6616, 0.3384],
        [0.6469, 0.3531],
        [0.6749, 0.3251],
        [0.6544, 0.3456],
        [0.6232, 0.3768],
        [0.6369, 0.3631],
        [0.6677, 0.3323],
        [0.6271, 0.3729],
        [0.6708, 0.3292],
        [0.6602, 0.3398],
        [0.6520, 0.3480],
        [0.6405, 0.3595],
        [0.6150, 0.3850],
        [0.6876, 0.3124],
        [0.6203, 0.3797],
        [0.6525, 0.3475],
        [0.6546, 0.3454],
        [0.6158, 0.3842],
        [0.6389, 0.3611],
        [0.6533, 0.3467],
        [0.6445, 0.3555],
        [0.6553, 0.3447],
        [0.6244, 0.3756],
        [0.6299, 0.3701],
        [0.6758, 0.3242],
        [0.6105, 0.3895],
        [0.6611, 0.3389],
        [0.6678, 0.3322],
        [0.6415, 0.3585],
        [0.6503, 0.3497],
        [0.6464, 0.3536],
        [0.6593, 0.3407],
        [0.6664, 0.3336],
        [0.6597, 0.3403],
        [0.6485, 0.3515],
        [0.6678, 0.3322],
        [0.6471, 0.3529],
        [0.6610, 0.3390],
        [0.6230, 0.3770],
        [0.6619, 0.3381],
        [0.6830, 0.3170],
        [0.6567, 0.3433],
        [0.6745, 0.3255],
        [0.6536, 0.3464],
        [0.6096, 0.3904],
        [0.6303, 0.3697],
        [0.6388, 0.3612],
        [0.6348, 0.3652],
        [0.6491, 0.3509],
        [0.6676, 0.3324],
        [0.6393, 0.3607],
        [0.6319, 0.3681],
        [0.6430, 0.3570],
        [0.6356, 0.3644],
        [0.6688, 0.3312],
        [0.6536, 0.3464],
        [0.6484, 0.3516],
        [0.6288, 0.3712],
        [0.6855, 0.3145],
        [0.6548, 0.3452],
        [0.6497, 0.3503],
        [0.6400, 0.3600],
        [0.6673, 0.3327],
        [0.6488, 0.3512],
        [0.6626, 0.3374],
        [0.6376, 0.3624],
        [0.6173, 0.3827],
        [0.6330, 0.3670],
        [0.6300, 0.3700],
        [0.6295, 0.3705],
        [0.6511, 0.3489],
        [0.6490, 0.3510],
        [0.6641, 0.3359],
        [0.6242, 0.3758],
        [0.6411, 0.3589],
        [0.6415, 0.3585],
        [0.6388, 0.3612],
        [0.6541, 0.3459],
        [0.6434, 0.3566],
        [0.6227, 0.3773],
        [0.6540, 0.3460],
        [0.6836, 0.3164],
        [0.6876, 0.3124],
        [0.6306, 0.3694],
        [0.6477, 0.3523],
        [0.6395, 0.3605],
        [0.6560, 0.3440],
        [0.6299, 0.3701],
        [0.6336, 0.3664],
        [0.6412, 0.3588],
        [0.6555, 0.3445],
        [0.6579, 0.3421],
        [0.6725, 0.3275],
        [0.6694, 0.3306],
        [0.6280, 0.3720],
        [0.6446, 0.3554],
        [0.6539, 0.3461],
        [0.6575, 0.3425],
        [0.6630, 0.3370],
        [0.6737, 0.3263],
        [0.6128, 0.3872],
        [0.6431, 0.3569],
        [0.6586, 0.3414],
        [0.6654, 0.3346],
        [0.6661, 0.3339],
        [0.6573, 0.3427],
        [0.6580, 0.3420],
        [0.6349, 0.3651],
        [0.6410, 0.3590],
        [0.6517, 0.3483],
        [0.6519, 0.3481],
        [0.6542, 0.3458],
        [0.6250, 0.3750],
        [0.6334, 0.3666],
        [0.6541, 0.3459],
        [0.6278, 0.3722],
        [0.6561, 0.3439],
        [0.6429, 0.3571],
        [0.6757, 0.3243],
        [0.6226, 0.3774],
        [0.6441, 0.3559],
        [0.6319, 0.3681],
        [0.6238, 0.3762],
        [0.6615, 0.3385],
        [0.6393, 0.3607],
        [0.6348, 0.3652],
        [0.6209, 0.3791],
        [0.6408, 0.3592],
        [0.6208, 0.3792],
        [0.6235, 0.3765],
        [0.6154, 0.3846],
        [0.6615, 0.3385],
        [0.6494, 0.3506],
        [0.6390, 0.3610],
        [0.6608, 0.3392],
        [0.6657, 0.3343],
        [0.6258, 0.3742],
        [0.6770, 0.3230],
        [0.6813, 0.3187],
        [0.6745, 0.3255],
        [0.6686, 0.3314],
        [0.6379, 0.3621],
        [0.6684, 0.3316],
        [0.6678, 0.3322],
        [0.6409, 0.3591],
        [0.6451, 0.3549],
        [0.6455, 0.3545],
        [0.6630, 0.3370],
        [0.6143, 0.3857],
        [0.6451, 0.3549],
        [0.6440, 0.3560],
        [0.6430, 0.3570],
        [0.6504, 0.3496],
        [0.6402, 0.3598],
        [0.6605, 0.3395],
        [0.6278, 0.3722],
        [0.6522, 0.3478],
        [0.6360, 0.3640],
        [0.6606, 0.3394],
        [0.6240, 0.3760],
        [0.6644, 0.3356],
        [0.6650, 0.3350],
        [0.6758, 0.3242],
        [0.6549, 0.3451],
        [0.6431, 0.3569],
        [0.6654, 0.3346],
        [0.6800, 0.3200],
        [0.6387, 0.3613],
        [0.6349, 0.3651],
        [0.6191, 0.3809],
        [0.6548, 0.3452],
        [0.6717, 0.3283],
        [0.6127, 0.3873],
        [0.6387, 0.3613],
        [0.6419, 0.3581],
        [0.6675, 0.3325],
        [0.6851, 0.3149],
        [0.6290, 0.3710],
        [0.6397, 0.3603],
        [0.6262, 0.3738],
        [0.6660, 0.3340],
        [0.6636, 0.3364],
        [0.6580, 0.3420],
        [0.6251, 0.3749],
        [0.6614, 0.3386],
        [0.6713, 0.3287],
        [0.6310, 0.3690],
        [0.6669, 0.3331],
        [0.6492, 0.3508],
        [0.6372, 0.3628],
        [0.6700, 0.3300],
        [0.6562, 0.3438],
        [0.6891, 0.3109],
        [0.6834, 0.3166],
        [0.6118, 0.3882],
        [0.6289, 0.3711],
        [0.6590, 0.3410],
        [0.6273, 0.3727],
        [0.6625, 0.3375],
        [0.6332, 0.3668],
        [0.6557, 0.3443],
        [0.6761, 0.3239],
        [0.6431, 0.3569],
        [0.6700, 0.3300],
        [0.6593, 0.3407],
        [0.6650, 0.3350],
        [0.6120, 0.3880],
        [0.6667, 0.3333],
        [0.6343, 0.3657],
        [0.6794, 0.3206],
        [0.6560, 0.3440],
        [0.6908, 0.3092],
        [0.6332, 0.3668],
        [0.6755, 0.3245],
        [0.6661, 0.3339],
        [0.6721, 0.3279],
        [0.6835, 0.3165],
        [0.6594, 0.3406],
        [0.6772, 0.3228],
        [0.6723, 0.3277],
        [0.6785, 0.3215],
        [0.6568, 0.3432],
        [0.6142, 0.3858],
        [0.6575, 0.3425],
        [0.6446, 0.3554],
        [0.6174, 0.3826],
        [0.6556, 0.3444],
        [0.6393, 0.3607],
        [0.6298, 0.3702],
        [0.6364, 0.3636],
        [0.6698, 0.3302],
        [0.6649, 0.3351],
        [0.6620, 0.3380],
        [0.6602, 0.3398],
        [0.6658, 0.3342],
        [0.6532, 0.3468],
        [0.6451, 0.3549],
        [0.6629, 0.3371],
        [0.6483, 0.3517],
        [0.6573, 0.3427],
        [0.6594, 0.3406],
        [0.6504, 0.3496],
        [0.6473, 0.3527],
        [0.6579, 0.3421],
        [0.6594, 0.3406],
        [0.6701, 0.3299],
        [0.6465, 0.3535],
        [0.6323, 0.3677],
        [0.6434, 0.3566],
        [0.6606, 0.3394],
        [0.6287, 0.3713],
        [0.6579, 0.3421],
        [0.6611, 0.3389],
        [0.6579, 0.3421],
        [0.6448, 0.3552],
        [0.6295, 0.3705],
        [0.6687, 0.3313],
        [0.6710, 0.3290]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0019 loss: 0.6607 acc_train: 0.6103 time: 0.1457s
tensor([[0.6304, 0.3696],
        [0.6700, 0.3300],
        [0.6670, 0.3330],
        [0.6503, 0.3497],
        [0.6757, 0.3243],
        [0.6458, 0.3542],
        [0.6181, 0.3819],
        [0.6511, 0.3489],
        [0.6463, 0.3537],
        [0.6421, 0.3579],
        [0.6554, 0.3446],
        [0.6448, 0.3552],
        [0.6434, 0.3566],
        [0.6392, 0.3608],
        [0.6623, 0.3377],
        [0.6507, 0.3493],
        [0.6736, 0.3264],
        [0.6568, 0.3432],
        [0.6319, 0.3681],
        [0.6433, 0.3567],
        [0.6685, 0.3315],
        [0.6349, 0.3651],
        [0.6702, 0.3298],
        [0.6626, 0.3374],
        [0.6550, 0.3450],
        [0.6462, 0.3538],
        [0.6235, 0.3765],
        [0.6824, 0.3176],
        [0.6294, 0.3706],
        [0.6546, 0.3454],
        [0.6558, 0.3442],
        [0.6266, 0.3734],
        [0.6449, 0.3551],
        [0.6545, 0.3455],
        [0.6487, 0.3513],
        [0.6541, 0.3459],
        [0.6313, 0.3687],
        [0.6373, 0.3627],
        [0.6752, 0.3248],
        [0.6215, 0.3785],
        [0.6623, 0.3377],
        [0.6665, 0.3335],
        [0.6435, 0.3565],
        [0.6537, 0.3463],
        [0.6495, 0.3505],
        [0.6605, 0.3395],
        [0.6671, 0.3329],
        [0.6615, 0.3385],
        [0.6522, 0.3478],
        [0.6683, 0.3317],
        [0.6507, 0.3493],
        [0.6629, 0.3371],
        [0.6321, 0.3679],
        [0.6620, 0.3380],
        [0.6800, 0.3200],
        [0.6587, 0.3413],
        [0.6721, 0.3279],
        [0.6571, 0.3429],
        [0.6207, 0.3793],
        [0.6367, 0.3633],
        [0.6445, 0.3555],
        [0.6407, 0.3593],
        [0.6522, 0.3478],
        [0.6669, 0.3331],
        [0.6438, 0.3562],
        [0.6377, 0.3623],
        [0.6471, 0.3529],
        [0.6427, 0.3573],
        [0.6689, 0.3311],
        [0.6560, 0.3440],
        [0.6518, 0.3482],
        [0.6351, 0.3649],
        [0.6817, 0.3183],
        [0.6560, 0.3440],
        [0.6525, 0.3475],
        [0.6441, 0.3559],
        [0.6684, 0.3316],
        [0.6513, 0.3487],
        [0.6623, 0.3377],
        [0.6422, 0.3578],
        [0.6273, 0.3727],
        [0.6383, 0.3617],
        [0.6371, 0.3629],
        [0.6355, 0.3645],
        [0.6529, 0.3471],
        [0.6519, 0.3481],
        [0.6643, 0.3357],
        [0.6336, 0.3664],
        [0.6457, 0.3543],
        [0.6452, 0.3548],
        [0.6436, 0.3564],
        [0.6563, 0.3437],
        [0.6476, 0.3524],
        [0.6312, 0.3688],
        [0.6557, 0.3443],
        [0.6794, 0.3206],
        [0.6839, 0.3161],
        [0.6378, 0.3622],
        [0.6509, 0.3491],
        [0.6457, 0.3543],
        [0.6585, 0.3415],
        [0.6373, 0.3627],
        [0.6392, 0.3608],
        [0.6457, 0.3543],
        [0.6581, 0.3419],
        [0.6598, 0.3402],
        [0.6724, 0.3276],
        [0.6691, 0.3309],
        [0.6363, 0.3637],
        [0.6492, 0.3508],
        [0.6535, 0.3465],
        [0.6597, 0.3403],
        [0.6634, 0.3366],
        [0.6721, 0.3279],
        [0.6233, 0.3767],
        [0.6436, 0.3564],
        [0.6593, 0.3407],
        [0.6643, 0.3357],
        [0.6669, 0.3331],
        [0.6596, 0.3404],
        [0.6611, 0.3389],
        [0.6425, 0.3575],
        [0.6468, 0.3532],
        [0.6545, 0.3455],
        [0.6535, 0.3465],
        [0.6573, 0.3427],
        [0.6334, 0.3666],
        [0.6391, 0.3609],
        [0.6558, 0.3442],
        [0.6362, 0.3638],
        [0.6574, 0.3426],
        [0.6460, 0.3540],
        [0.6729, 0.3271],
        [0.6312, 0.3688],
        [0.6488, 0.3512],
        [0.6382, 0.3618],
        [0.6320, 0.3680],
        [0.6624, 0.3376],
        [0.6445, 0.3555],
        [0.6396, 0.3604],
        [0.6295, 0.3705],
        [0.6459, 0.3541],
        [0.6303, 0.3697],
        [0.6324, 0.3676],
        [0.6257, 0.3743],
        [0.6626, 0.3374],
        [0.6530, 0.3470],
        [0.6427, 0.3573],
        [0.6625, 0.3375],
        [0.6660, 0.3340],
        [0.6338, 0.3662],
        [0.6752, 0.3248],
        [0.6769, 0.3231],
        [0.6732, 0.3268],
        [0.6677, 0.3323],
        [0.6449, 0.3551],
        [0.6675, 0.3325],
        [0.6677, 0.3323],
        [0.6462, 0.3538],
        [0.6484, 0.3516],
        [0.6488, 0.3512],
        [0.6635, 0.3365],
        [0.6237, 0.3763],
        [0.6478, 0.3522],
        [0.6463, 0.3537],
        [0.6466, 0.3534],
        [0.6548, 0.3452],
        [0.6447, 0.3553],
        [0.6616, 0.3384],
        [0.6346, 0.3654],
        [0.6518, 0.3482],
        [0.6423, 0.3577],
        [0.6610, 0.3390],
        [0.6313, 0.3687],
        [0.6637, 0.3363],
        [0.6648, 0.3352],
        [0.6746, 0.3254],
        [0.6570, 0.3430],
        [0.6470, 0.3530],
        [0.6647, 0.3353],
        [0.6774, 0.3226],
        [0.6437, 0.3563],
        [0.6406, 0.3594],
        [0.6272, 0.3728],
        [0.6554, 0.3446],
        [0.6708, 0.3292],
        [0.6224, 0.3776],
        [0.6426, 0.3574],
        [0.6460, 0.3540],
        [0.6661, 0.3339],
        [0.6811, 0.3189],
        [0.6367, 0.3633],
        [0.6448, 0.3552],
        [0.6337, 0.3663],
        [0.6660, 0.3340],
        [0.6649, 0.3351],
        [0.6602, 0.3398],
        [0.6340, 0.3660],
        [0.6624, 0.3376],
        [0.6710, 0.3290],
        [0.6371, 0.3629],
        [0.6682, 0.3318],
        [0.6526, 0.3474],
        [0.6421, 0.3579],
        [0.6691, 0.3309],
        [0.6572, 0.3428],
        [0.6842, 0.3158],
        [0.6791, 0.3209],
        [0.6221, 0.3779],
        [0.6358, 0.3642],
        [0.6610, 0.3390],
        [0.6352, 0.3648],
        [0.6631, 0.3369],
        [0.6394, 0.3606],
        [0.6578, 0.3422],
        [0.6752, 0.3248],
        [0.6471, 0.3529],
        [0.6683, 0.3317],
        [0.6606, 0.3394],
        [0.6657, 0.3343],
        [0.6236, 0.3764],
        [0.6664, 0.3336],
        [0.6406, 0.3594],
        [0.6766, 0.3234],
        [0.6581, 0.3419],
        [0.6861, 0.3139],
        [0.6359, 0.3641],
        [0.6738, 0.3262],
        [0.6658, 0.3342],
        [0.6720, 0.3280],
        [0.6800, 0.3200],
        [0.6615, 0.3385],
        [0.6766, 0.3234],
        [0.6713, 0.3287],
        [0.6763, 0.3237],
        [0.6579, 0.3421],
        [0.6235, 0.3765],
        [0.6597, 0.3403],
        [0.6477, 0.3523],
        [0.6269, 0.3731],
        [0.6581, 0.3419],
        [0.6448, 0.3552],
        [0.6365, 0.3635],
        [0.6410, 0.3590],
        [0.6691, 0.3309],
        [0.6660, 0.3340],
        [0.6632, 0.3368],
        [0.6610, 0.3390],
        [0.6659, 0.3341],
        [0.6556, 0.3444],
        [0.6502, 0.3498],
        [0.6634, 0.3366],
        [0.6506, 0.3494],
        [0.6593, 0.3407],
        [0.6610, 0.3390],
        [0.6537, 0.3463],
        [0.6515, 0.3485],
        [0.6601, 0.3399],
        [0.6599, 0.3401],
        [0.6706, 0.3294],
        [0.6491, 0.3509],
        [0.6388, 0.3612],
        [0.6459, 0.3541],
        [0.6622, 0.3378],
        [0.6357, 0.3643],
        [0.6597, 0.3403],
        [0.6618, 0.3382],
        [0.6570, 0.3430],
        [0.6487, 0.3513],
        [0.6369, 0.3631],
        [0.6685, 0.3315],
        [0.6716, 0.3284]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0020 loss: 0.6625 acc_train: 0.6103 time: 0.1483s
tensor([[0.6396, 0.3604],
        [0.6698, 0.3302],
        [0.6677, 0.3323],
        [0.6543, 0.3457],
        [0.6737, 0.3263],
        [0.6506, 0.3494],
        [0.6282, 0.3718],
        [0.6544, 0.3456],
        [0.6516, 0.3484],
        [0.6467, 0.3533],
        [0.6590, 0.3410],
        [0.6514, 0.3486],
        [0.6481, 0.3519],
        [0.6450, 0.3550],
        [0.6634, 0.3366],
        [0.6544, 0.3456],
        [0.6729, 0.3271],
        [0.6596, 0.3404],
        [0.6399, 0.3601],
        [0.6489, 0.3511],
        [0.6694, 0.3306],
        [0.6422, 0.3578],
        [0.6700, 0.3300],
        [0.6650, 0.3350],
        [0.6584, 0.3416],
        [0.6514, 0.3486],
        [0.6321, 0.3679],
        [0.6785, 0.3215],
        [0.6378, 0.3622],
        [0.6571, 0.3429],
        [0.6576, 0.3424],
        [0.6363, 0.3637],
        [0.6507, 0.3493],
        [0.6565, 0.3435],
        [0.6530, 0.3470],
        [0.6537, 0.3463],
        [0.6382, 0.3618],
        [0.6442, 0.3558],
        [0.6747, 0.3253],
        [0.6316, 0.3684],
        [0.6638, 0.3362],
        [0.6661, 0.3339],
        [0.6457, 0.3543],
        [0.6570, 0.3430],
        [0.6532, 0.3468],
        [0.6621, 0.3379],
        [0.6680, 0.3320],
        [0.6634, 0.3366],
        [0.6559, 0.3441],
        [0.6688, 0.3312],
        [0.6544, 0.3456],
        [0.6649, 0.3351],
        [0.6407, 0.3593],
        [0.6628, 0.3372],
        [0.6777, 0.3223],
        [0.6608, 0.3392],
        [0.6706, 0.3294],
        [0.6603, 0.3397],
        [0.6312, 0.3688],
        [0.6428, 0.3572],
        [0.6500, 0.3500],
        [0.6464, 0.3536],
        [0.6554, 0.3446],
        [0.6669, 0.3331],
        [0.6486, 0.3514],
        [0.6436, 0.3564],
        [0.6516, 0.3484],
        [0.6492, 0.3508],
        [0.6692, 0.3308],
        [0.6587, 0.3413],
        [0.6552, 0.3448],
        [0.6417, 0.3583],
        [0.6787, 0.3213],
        [0.6580, 0.3420],
        [0.6555, 0.3445],
        [0.6487, 0.3513],
        [0.6694, 0.3306],
        [0.6543, 0.3457],
        [0.6626, 0.3374],
        [0.6470, 0.3530],
        [0.6364, 0.3636],
        [0.6440, 0.3560],
        [0.6440, 0.3560],
        [0.6416, 0.3584],
        [0.6551, 0.3449],
        [0.6552, 0.3448],
        [0.6648, 0.3352],
        [0.6420, 0.3580],
        [0.6502, 0.3498],
        [0.6494, 0.3506],
        [0.6484, 0.3516],
        [0.6589, 0.3411],
        [0.6517, 0.3483],
        [0.6393, 0.3607],
        [0.6577, 0.3423],
        [0.6764, 0.3236],
        [0.6810, 0.3190],
        [0.6444, 0.3556],
        [0.6543, 0.3457],
        [0.6512, 0.3488],
        [0.6610, 0.3390],
        [0.6445, 0.3555],
        [0.6447, 0.3553],
        [0.6501, 0.3499],
        [0.6608, 0.3392],
        [0.6618, 0.3382],
        [0.6724, 0.3276],
        [0.6693, 0.3307],
        [0.6438, 0.3562],
        [0.6537, 0.3463],
        [0.6537, 0.3463],
        [0.6622, 0.3378],
        [0.6642, 0.3358],
        [0.6710, 0.3290],
        [0.6329, 0.3671],
        [0.6450, 0.3550],
        [0.6606, 0.3394],
        [0.6642, 0.3358],
        [0.6679, 0.3321],
        [0.6618, 0.3382],
        [0.6638, 0.3362],
        [0.6493, 0.3507],
        [0.6523, 0.3477],
        [0.6576, 0.3424],
        [0.6558, 0.3442],
        [0.6603, 0.3397],
        [0.6413, 0.3587],
        [0.6448, 0.3552],
        [0.6578, 0.3422],
        [0.6438, 0.3562],
        [0.6592, 0.3408],
        [0.6495, 0.3505],
        [0.6710, 0.3290],
        [0.6392, 0.3608],
        [0.6532, 0.3468],
        [0.6446, 0.3554],
        [0.6396, 0.3604],
        [0.6638, 0.3362],
        [0.6496, 0.3504],
        [0.6448, 0.3552],
        [0.6381, 0.3619],
        [0.6508, 0.3492],
        [0.6390, 0.3610],
        [0.6406, 0.3594],
        [0.6354, 0.3646],
        [0.6641, 0.3359],
        [0.6566, 0.3434],
        [0.6469, 0.3531],
        [0.6644, 0.3356],
        [0.6668, 0.3332],
        [0.6415, 0.3585],
        [0.6739, 0.3261],
        [0.6739, 0.3261],
        [0.6723, 0.3277],
        [0.6676, 0.3324],
        [0.6511, 0.3489],
        [0.6673, 0.3327],
        [0.6681, 0.3319],
        [0.6512, 0.3488],
        [0.6521, 0.3479],
        [0.6528, 0.3472],
        [0.6645, 0.3355],
        [0.6326, 0.3674],
        [0.6511, 0.3489],
        [0.6489, 0.3511],
        [0.6505, 0.3495],
        [0.6588, 0.3412],
        [0.6493, 0.3507],
        [0.6629, 0.3371],
        [0.6412, 0.3588],
        [0.6522, 0.3478],
        [0.6481, 0.3519],
        [0.6619, 0.3381],
        [0.6383, 0.3617],
        [0.6638, 0.3362],
        [0.6654, 0.3346],
        [0.6738, 0.3262],
        [0.6590, 0.3410],
        [0.6509, 0.3491],
        [0.6648, 0.3352],
        [0.6755, 0.3245],
        [0.6487, 0.3513],
        [0.6462, 0.3538],
        [0.6355, 0.3645],
        [0.6568, 0.3432],
        [0.6705, 0.3295],
        [0.6315, 0.3685],
        [0.6469, 0.3531],
        [0.6503, 0.3497],
        [0.6656, 0.3344],
        [0.6781, 0.3219],
        [0.6436, 0.3564],
        [0.6497, 0.3503],
        [0.6410, 0.3590],
        [0.6666, 0.3334],
        [0.6663, 0.3337],
        [0.6625, 0.3375],
        [0.6421, 0.3579],
        [0.6638, 0.3362],
        [0.6710, 0.3290],
        [0.6434, 0.3566],
        [0.6697, 0.3303],
        [0.6562, 0.3438],
        [0.6470, 0.3530],
        [0.6689, 0.3311],
        [0.6591, 0.3409],
        [0.6806, 0.3194],
        [0.6760, 0.3240],
        [0.6318, 0.3682],
        [0.6425, 0.3575],
        [0.6632, 0.3368],
        [0.6425, 0.3575],
        [0.6639, 0.3361],
        [0.6456, 0.3544],
        [0.6604, 0.3396],
        [0.6747, 0.3253],
        [0.6513, 0.3487],
        [0.6674, 0.3326],
        [0.6621, 0.3379],
        [0.6667, 0.3333],
        [0.6338, 0.3662],
        [0.6667, 0.3333],
        [0.6463, 0.3537],
        [0.6745, 0.3255],
        [0.6604, 0.3396],
        [0.6824, 0.3176],
        [0.6391, 0.3609],
        [0.6728, 0.3272],
        [0.6658, 0.3342],
        [0.6721, 0.3279],
        [0.6774, 0.3226],
        [0.6635, 0.3365],
        [0.6760, 0.3240],
        [0.6708, 0.3292],
        [0.6749, 0.3251],
        [0.6598, 0.3402],
        [0.6324, 0.3676],
        [0.6623, 0.3377],
        [0.6512, 0.3488],
        [0.6361, 0.3639],
        [0.6607, 0.3393],
        [0.6502, 0.3498],
        [0.6430, 0.3570],
        [0.6459, 0.3541],
        [0.6692, 0.3308],
        [0.6674, 0.3326],
        [0.6647, 0.3353],
        [0.6623, 0.3377],
        [0.6665, 0.3335],
        [0.6582, 0.3418],
        [0.6552, 0.3448],
        [0.6644, 0.3356],
        [0.6534, 0.3466],
        [0.6615, 0.3385],
        [0.6629, 0.3371],
        [0.6572, 0.3428],
        [0.6555, 0.3445],
        [0.6624, 0.3376],
        [0.6610, 0.3390],
        [0.6712, 0.3288],
        [0.6520, 0.3480],
        [0.6449, 0.3551],
        [0.6493, 0.3507],
        [0.6639, 0.3361],
        [0.6424, 0.3576],
        [0.6618, 0.3382],
        [0.6630, 0.3370],
        [0.6571, 0.3429],
        [0.6530, 0.3470],
        [0.6438, 0.3562],
        [0.6689, 0.3311],
        [0.6725, 0.3275]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0021 loss: 0.6641 acc_train: 0.6103 time: 0.1391s
tensor([[0.6471, 0.3529],
        [0.6694, 0.3306],
        [0.6680, 0.3320],
        [0.6576, 0.3424],
        [0.6719, 0.3281],
        [0.6548, 0.3452],
        [0.6369, 0.3631],
        [0.6572, 0.3428],
        [0.6560, 0.3440],
        [0.6507, 0.3493],
        [0.6619, 0.3381],
        [0.6566, 0.3434],
        [0.6522, 0.3478],
        [0.6500, 0.3500],
        [0.6643, 0.3357],
        [0.6573, 0.3427],
        [0.6721, 0.3279],
        [0.6619, 0.3381],
        [0.6467, 0.3533],
        [0.6534, 0.3466],
        [0.6697, 0.3303],
        [0.6482, 0.3518],
        [0.6697, 0.3303],
        [0.6667, 0.3333],
        [0.6613, 0.3387],
        [0.6557, 0.3443],
        [0.6398, 0.3602],
        [0.6753, 0.3247],
        [0.6448, 0.3552],
        [0.6592, 0.3408],
        [0.6594, 0.3406],
        [0.6443, 0.3557],
        [0.6555, 0.3445],
        [0.6585, 0.3415],
        [0.6566, 0.3434],
        [0.6537, 0.3463],
        [0.6442, 0.3558],
        [0.6499, 0.3501],
        [0.6739, 0.3261],
        [0.6403, 0.3597],
        [0.6651, 0.3349],
        [0.6658, 0.3342],
        [0.6475, 0.3525],
        [0.6598, 0.3402],
        [0.6565, 0.3435],
        [0.6633, 0.3367],
        [0.6685, 0.3315],
        [0.6649, 0.3351],
        [0.6588, 0.3412],
        [0.6690, 0.3310],
        [0.6575, 0.3425],
        [0.6663, 0.3337],
        [0.6478, 0.3522],
        [0.6635, 0.3365],
        [0.6755, 0.3245],
        [0.6623, 0.3377],
        [0.6692, 0.3308],
        [0.6625, 0.3375],
        [0.6401, 0.3599],
        [0.6481, 0.3519],
        [0.6546, 0.3454],
        [0.6512, 0.3488],
        [0.6581, 0.3419],
        [0.6670, 0.3330],
        [0.6528, 0.3472],
        [0.6487, 0.3513],
        [0.6558, 0.3442],
        [0.6545, 0.3455],
        [0.6693, 0.3307],
        [0.6609, 0.3391],
        [0.6582, 0.3418],
        [0.6477, 0.3523],
        [0.6759, 0.3241],
        [0.6601, 0.3399],
        [0.6581, 0.3419],
        [0.6528, 0.3472],
        [0.6700, 0.3300],
        [0.6571, 0.3429],
        [0.6630, 0.3370],
        [0.6511, 0.3489],
        [0.6439, 0.3561],
        [0.6491, 0.3509],
        [0.6500, 0.3500],
        [0.6470, 0.3530],
        [0.6571, 0.3429],
        [0.6581, 0.3419],
        [0.6651, 0.3349],
        [0.6488, 0.3512],
        [0.6539, 0.3461],
        [0.6532, 0.3468],
        [0.6526, 0.3474],
        [0.6610, 0.3390],
        [0.6551, 0.3449],
        [0.6461, 0.3539],
        [0.6593, 0.3407],
        [0.6741, 0.3259],
        [0.6783, 0.3217],
        [0.6498, 0.3502],
        [0.6571, 0.3429],
        [0.6556, 0.3444],
        [0.6629, 0.3371],
        [0.6505, 0.3495],
        [0.6496, 0.3504],
        [0.6539, 0.3461],
        [0.6631, 0.3369],
        [0.6631, 0.3369],
        [0.6720, 0.3280],
        [0.6693, 0.3307],
        [0.6498, 0.3502],
        [0.6573, 0.3427],
        [0.6540, 0.3460],
        [0.6641, 0.3359],
        [0.6649, 0.3351],
        [0.6698, 0.3302],
        [0.6410, 0.3590],
        [0.6466, 0.3534],
        [0.6618, 0.3382],
        [0.6643, 0.3357],
        [0.6685, 0.3315],
        [0.6635, 0.3365],
        [0.6656, 0.3344],
        [0.6547, 0.3453],
        [0.6567, 0.3433],
        [0.6601, 0.3399],
        [0.6580, 0.3420],
        [0.6625, 0.3375],
        [0.6479, 0.3521],
        [0.6497, 0.3503],
        [0.6595, 0.3405],
        [0.6499, 0.3501],
        [0.6608, 0.3392],
        [0.6528, 0.3472],
        [0.6695, 0.3305],
        [0.6459, 0.3541],
        [0.6568, 0.3432],
        [0.6502, 0.3498],
        [0.6460, 0.3540],
        [0.6649, 0.3351],
        [0.6538, 0.3462],
        [0.6494, 0.3506],
        [0.6457, 0.3543],
        [0.6548, 0.3452],
        [0.6464, 0.3536],
        [0.6474, 0.3526],
        [0.6436, 0.3564],
        [0.6653, 0.3347],
        [0.6595, 0.3405],
        [0.6508, 0.3492],
        [0.6660, 0.3340],
        [0.6673, 0.3327],
        [0.6481, 0.3519],
        [0.6727, 0.3273],
        [0.6715, 0.3285],
        [0.6714, 0.3286],
        [0.6676, 0.3324],
        [0.6558, 0.3442],
        [0.6672, 0.3328],
        [0.6683, 0.3317],
        [0.6552, 0.3448],
        [0.6554, 0.3446],
        [0.6566, 0.3434],
        [0.6653, 0.3347],
        [0.6401, 0.3599],
        [0.6541, 0.3459],
        [0.6512, 0.3488],
        [0.6538, 0.3462],
        [0.6619, 0.3381],
        [0.6531, 0.3469],
        [0.6638, 0.3362],
        [0.6468, 0.3532],
        [0.6525, 0.3475],
        [0.6528, 0.3472],
        [0.6629, 0.3371],
        [0.6445, 0.3555],
        [0.6640, 0.3360],
        [0.6660, 0.3340],
        [0.6729, 0.3271],
        [0.6604, 0.3396],
        [0.6542, 0.3458],
        [0.6652, 0.3348],
        [0.6737, 0.3263],
        [0.6529, 0.3471],
        [0.6512, 0.3488],
        [0.6429, 0.3571],
        [0.6582, 0.3418],
        [0.6700, 0.3300],
        [0.6392, 0.3608],
        [0.6507, 0.3493],
        [0.6540, 0.3460],
        [0.6652, 0.3348],
        [0.6755, 0.3245],
        [0.6491, 0.3509],
        [0.6537, 0.3463],
        [0.6470, 0.3530],
        [0.6671, 0.3329],
        [0.6672, 0.3328],
        [0.6642, 0.3358],
        [0.6487, 0.3513],
        [0.6649, 0.3351],
        [0.6707, 0.3293],
        [0.6490, 0.3510],
        [0.6706, 0.3294],
        [0.6591, 0.3409],
        [0.6513, 0.3487],
        [0.6687, 0.3313],
        [0.6609, 0.3391],
        [0.6776, 0.3224],
        [0.6734, 0.3266],
        [0.6400, 0.3600],
        [0.6482, 0.3518],
        [0.6650, 0.3350],
        [0.6486, 0.3514],
        [0.6646, 0.3354],
        [0.6510, 0.3490],
        [0.6624, 0.3376],
        [0.6740, 0.3260],
        [0.6548, 0.3452],
        [0.6667, 0.3333],
        [0.6632, 0.3368],
        [0.6674, 0.3326],
        [0.6421, 0.3579],
        [0.6669, 0.3331],
        [0.6510, 0.3490],
        [0.6728, 0.3272],
        [0.6623, 0.3377],
        [0.6790, 0.3210],
        [0.6421, 0.3579],
        [0.6718, 0.3282],
        [0.6655, 0.3345],
        [0.6718, 0.3282],
        [0.6750, 0.3250],
        [0.6649, 0.3351],
        [0.6752, 0.3248],
        [0.6702, 0.3298],
        [0.6738, 0.3262],
        [0.6618, 0.3382],
        [0.6402, 0.3598],
        [0.6643, 0.3357],
        [0.6543, 0.3457],
        [0.6442, 0.3558],
        [0.6628, 0.3372],
        [0.6547, 0.3453],
        [0.6484, 0.3516],
        [0.6503, 0.3497],
        [0.6692, 0.3308],
        [0.6684, 0.3316],
        [0.6658, 0.3342],
        [0.6635, 0.3365],
        [0.6668, 0.3332],
        [0.6603, 0.3397],
        [0.6593, 0.3407],
        [0.6652, 0.3348],
        [0.6559, 0.3441],
        [0.6634, 0.3366],
        [0.6644, 0.3356],
        [0.6601, 0.3399],
        [0.6587, 0.3413],
        [0.6642, 0.3358],
        [0.6621, 0.3379],
        [0.6713, 0.3287],
        [0.6547, 0.3453],
        [0.6500, 0.3500],
        [0.6525, 0.3475],
        [0.6651, 0.3349],
        [0.6481, 0.3519],
        [0.6633, 0.3367],
        [0.6641, 0.3359],
        [0.6576, 0.3424],
        [0.6567, 0.3433],
        [0.6496, 0.3504],
        [0.6692, 0.3308],
        [0.6729, 0.3271]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0022 loss: 0.6655 acc_train: 0.6103 time: 0.1417s
tensor([[0.6526, 0.3474],
        [0.6685, 0.3315],
        [0.6677, 0.3323],
        [0.6599, 0.3401],
        [0.6697, 0.3303],
        [0.6579, 0.3421],
        [0.6437, 0.3563],
        [0.6591, 0.3409],
        [0.6591, 0.3409],
        [0.6537, 0.3463],
        [0.6637, 0.3363],
        [0.6602, 0.3398],
        [0.6554, 0.3446],
        [0.6538, 0.3462],
        [0.6646, 0.3354],
        [0.6592, 0.3408],
        [0.6710, 0.3290],
        [0.6633, 0.3367],
        [0.6518, 0.3482],
        [0.6563, 0.3437],
        [0.6693, 0.3307],
        [0.6525, 0.3475],
        [0.6688, 0.3312],
        [0.6675, 0.3325],
        [0.6631, 0.3369],
        [0.6585, 0.3415],
        [0.6460, 0.3540],
        [0.6724, 0.3276],
        [0.6500, 0.3500],
        [0.6605, 0.3395],
        [0.6606, 0.3394],
        [0.6502, 0.3498],
        [0.6590, 0.3410],
        [0.6597, 0.3403],
        [0.6591, 0.3409],
        [0.6535, 0.3465],
        [0.6490, 0.3510],
        [0.6540, 0.3460],
        [0.6724, 0.3276],
        [0.6469, 0.3531],
        [0.6654, 0.3346],
        [0.6653, 0.3347],
        [0.6486, 0.3514],
        [0.6615, 0.3385],
        [0.6590, 0.3410],
        [0.6637, 0.3363],
        [0.6685, 0.3315],
        [0.6656, 0.3344],
        [0.6605, 0.3395],
        [0.6685, 0.3315],
        [0.6595, 0.3405],
        [0.6667, 0.3333],
        [0.6531, 0.3469],
        [0.6638, 0.3362],
        [0.6732, 0.3268],
        [0.6631, 0.3369],
        [0.6677, 0.3323],
        [0.6635, 0.3365],
        [0.6469, 0.3531],
        [0.6521, 0.3479],
        [0.6578, 0.3422],
        [0.6547, 0.3453],
        [0.6599, 0.3401],
        [0.6668, 0.3332],
        [0.6560, 0.3440],
        [0.6525, 0.3475],
        [0.6590, 0.3410],
        [0.6581, 0.3419],
        [0.6686, 0.3314],
        [0.6624, 0.3376],
        [0.6601, 0.3399],
        [0.6523, 0.3477],
        [0.6732, 0.3268],
        [0.6616, 0.3384],
        [0.6598, 0.3402],
        [0.6560, 0.3440],
        [0.6696, 0.3304],
        [0.6590, 0.3410],
        [0.6631, 0.3369],
        [0.6542, 0.3458],
        [0.6493, 0.3507],
        [0.6532, 0.3468],
        [0.6543, 0.3457],
        [0.6512, 0.3488],
        [0.6586, 0.3414],
        [0.6601, 0.3399],
        [0.6648, 0.3352],
        [0.6537, 0.3463],
        [0.6565, 0.3435],
        [0.6560, 0.3440],
        [0.6557, 0.3443],
        [0.6624, 0.3376],
        [0.6574, 0.3426],
        [0.6513, 0.3487],
        [0.6601, 0.3399],
        [0.6718, 0.3282],
        [0.6755, 0.3245],
        [0.6536, 0.3464],
        [0.6592, 0.3408],
        [0.6586, 0.3414],
        [0.6639, 0.3361],
        [0.6549, 0.3451],
        [0.6533, 0.3467],
        [0.6565, 0.3435],
        [0.6643, 0.3357],
        [0.6635, 0.3365],
        [0.6709, 0.3291],
        [0.6689, 0.3311],
        [0.6540, 0.3460],
        [0.6598, 0.3402],
        [0.6540, 0.3460],
        [0.6651, 0.3349],
        [0.6650, 0.3350],
        [0.6683, 0.3317],
        [0.6472, 0.3528],
        [0.6478, 0.3522],
        [0.6625, 0.3375],
        [0.6641, 0.3359],
        [0.6684, 0.3316],
        [0.6642, 0.3358],
        [0.6664, 0.3336],
        [0.6583, 0.3417],
        [0.6598, 0.3402],
        [0.6617, 0.3383],
        [0.6595, 0.3405],
        [0.6636, 0.3364],
        [0.6528, 0.3472],
        [0.6535, 0.3465],
        [0.6606, 0.3394],
        [0.6543, 0.3457],
        [0.6618, 0.3382],
        [0.6554, 0.3446],
        [0.6680, 0.3320],
        [0.6508, 0.3492],
        [0.6591, 0.3409],
        [0.6543, 0.3457],
        [0.6509, 0.3491],
        [0.6655, 0.3345],
        [0.6568, 0.3432],
        [0.6531, 0.3469],
        [0.6517, 0.3483],
        [0.6577, 0.3423],
        [0.6518, 0.3482],
        [0.6524, 0.3476],
        [0.6497, 0.3503],
        [0.6658, 0.3342],
        [0.6615, 0.3385],
        [0.6539, 0.3461],
        [0.6666, 0.3334],
        [0.6672, 0.3328],
        [0.6530, 0.3470],
        [0.6712, 0.3288],
        [0.6693, 0.3307],
        [0.6700, 0.3300],
        [0.6672, 0.3328],
        [0.6589, 0.3411],
        [0.6669, 0.3331],
        [0.6679, 0.3321],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6594, 0.3406],
        [0.6655, 0.3345],
        [0.6459, 0.3541],
        [0.6563, 0.3437],
        [0.6525, 0.3475],
        [0.6562, 0.3438],
        [0.6636, 0.3364],
        [0.6558, 0.3442],
        [0.6641, 0.3359],
        [0.6511, 0.3489],
        [0.6527, 0.3473],
        [0.6561, 0.3439],
        [0.6633, 0.3367],
        [0.6492, 0.3508],
        [0.6638, 0.3362],
        [0.6661, 0.3339],
        [0.6715, 0.3285],
        [0.6611, 0.3389],
        [0.6565, 0.3435],
        [0.6653, 0.3347],
        [0.6717, 0.3283],
        [0.6559, 0.3441],
        [0.6549, 0.3451],
        [0.6487, 0.3513],
        [0.6592, 0.3408],
        [0.6690, 0.3310],
        [0.6452, 0.3548],
        [0.6536, 0.3464],
        [0.6566, 0.3434],
        [0.6646, 0.3354],
        [0.6731, 0.3269],
        [0.6532, 0.3468],
        [0.6566, 0.3434],
        [0.6516, 0.3484],
        [0.6671, 0.3329],
        [0.6673, 0.3327],
        [0.6651, 0.3349],
        [0.6535, 0.3465],
        [0.6654, 0.3346],
        [0.6698, 0.3302],
        [0.6532, 0.3468],
        [0.6706, 0.3294],
        [0.6610, 0.3390],
        [0.6545, 0.3455],
        [0.6680, 0.3320],
        [0.6622, 0.3378],
        [0.6748, 0.3252],
        [0.6709, 0.3291],
        [0.6463, 0.3537],
        [0.6524, 0.3476],
        [0.6659, 0.3341],
        [0.6530, 0.3470],
        [0.6647, 0.3353],
        [0.6552, 0.3448],
        [0.6637, 0.3363],
        [0.6727, 0.3273],
        [0.6572, 0.3428],
        [0.6659, 0.3341],
        [0.6636, 0.3364],
        [0.6674, 0.3326],
        [0.6482, 0.3518],
        [0.6667, 0.3333],
        [0.6543, 0.3457],
        [0.6709, 0.3291],
        [0.6633, 0.3367],
        [0.6757, 0.3243],
        [0.6444, 0.3556],
        [0.6706, 0.3294],
        [0.6647, 0.3353],
        [0.6708, 0.3292],
        [0.6725, 0.3275],
        [0.6655, 0.3345],
        [0.6737, 0.3263],
        [0.6691, 0.3309],
        [0.6724, 0.3276],
        [0.6632, 0.3368],
        [0.6462, 0.3538],
        [0.6655, 0.3345],
        [0.6566, 0.3434],
        [0.6504, 0.3496],
        [0.6640, 0.3360],
        [0.6578, 0.3422],
        [0.6525, 0.3475],
        [0.6538, 0.3462],
        [0.6688, 0.3312],
        [0.6685, 0.3315],
        [0.6662, 0.3338],
        [0.6640, 0.3360],
        [0.6667, 0.3333],
        [0.6617, 0.3383],
        [0.6620, 0.3380],
        [0.6655, 0.3345],
        [0.6577, 0.3423],
        [0.6645, 0.3355],
        [0.6651, 0.3349],
        [0.6619, 0.3381],
        [0.6609, 0.3391],
        [0.6651, 0.3349],
        [0.6626, 0.3374],
        [0.6708, 0.3292],
        [0.6568, 0.3432],
        [0.6540, 0.3460],
        [0.6551, 0.3449],
        [0.6656, 0.3344],
        [0.6525, 0.3475],
        [0.6640, 0.3360],
        [0.6647, 0.3353],
        [0.6581, 0.3419],
        [0.6593, 0.3407],
        [0.6538, 0.3462],
        [0.6690, 0.3310],
        [0.6725, 0.3275]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0023 loss: 0.6667 acc_train: 0.6103 time: 0.1599s
tensor([[0.6561, 0.3439],
        [0.6670, 0.3330],
        [0.6666, 0.3334],
        [0.6610, 0.3390],
        [0.6674, 0.3326],
        [0.6596, 0.3404],
        [0.6485, 0.3515],
        [0.6599, 0.3401],
        [0.6608, 0.3392],
        [0.6555, 0.3445],
        [0.6643, 0.3357],
        [0.6620, 0.3380],
        [0.6573, 0.3427],
        [0.6563, 0.3437],
        [0.6643, 0.3357],
        [0.6600, 0.3400],
        [0.6694, 0.3306],
        [0.6637, 0.3363],
        [0.6552, 0.3448],
        [0.6578, 0.3422],
        [0.6681, 0.3319],
        [0.6552, 0.3448],
        [0.6674, 0.3326],
        [0.6672, 0.3328],
        [0.6637, 0.3363],
        [0.6600, 0.3400],
        [0.6505, 0.3495],
        [0.6696, 0.3304],
        [0.6534, 0.3466],
        [0.6609, 0.3391],
        [0.6612, 0.3388],
        [0.6542, 0.3458],
        [0.6609, 0.3391],
        [0.6602, 0.3398],
        [0.6603, 0.3397],
        [0.6530, 0.3470],
        [0.6524, 0.3476],
        [0.6566, 0.3434],
        [0.6703, 0.3297],
        [0.6514, 0.3486],
        [0.6650, 0.3350],
        [0.6644, 0.3356],
        [0.6490, 0.3510],
        [0.6621, 0.3379],
        [0.6604, 0.3396],
        [0.6633, 0.3367],
        [0.6677, 0.3323],
        [0.6655, 0.3345],
        [0.6612, 0.3388],
        [0.6673, 0.3327],
        [0.6604, 0.3396],
        [0.6663, 0.3337],
        [0.6564, 0.3436],
        [0.6635, 0.3365],
        [0.6705, 0.3295],
        [0.6630, 0.3370],
        [0.6660, 0.3340],
        [0.6635, 0.3365],
        [0.6517, 0.3483],
        [0.6548, 0.3452],
        [0.6595, 0.3405],
        [0.6569, 0.3431],
        [0.6607, 0.3393],
        [0.6660, 0.3340],
        [0.6579, 0.3421],
        [0.6550, 0.3450],
        [0.6610, 0.3390],
        [0.6601, 0.3399],
        [0.6673, 0.3327],
        [0.6629, 0.3371],
        [0.6610, 0.3390],
        [0.6554, 0.3446],
        [0.6703, 0.3297],
        [0.6623, 0.3377],
        [0.6604, 0.3396],
        [0.6580, 0.3420],
        [0.6683, 0.3317],
        [0.6599, 0.3401],
        [0.6627, 0.3373],
        [0.6562, 0.3438],
        [0.6529, 0.3471],
        [0.6558, 0.3442],
        [0.6570, 0.3430],
        [0.6539, 0.3461],
        [0.6592, 0.3408],
        [0.6611, 0.3389],
        [0.6639, 0.3361],
        [0.6567, 0.3433],
        [0.6579, 0.3421],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6627, 0.3373],
        [0.6585, 0.3415],
        [0.6547, 0.3453],
        [0.6602, 0.3398],
        [0.6695, 0.3305],
        [0.6725, 0.3275],
        [0.6560, 0.3440],
        [0.6602, 0.3398],
        [0.6602, 0.3398],
        [0.6639, 0.3361],
        [0.6577, 0.3423],
        [0.6558, 0.3442],
        [0.6580, 0.3420],
        [0.6646, 0.3354],
        [0.6631, 0.3369],
        [0.6693, 0.3307],
        [0.6678, 0.3322],
        [0.6566, 0.3434],
        [0.6611, 0.3389],
        [0.6534, 0.3466],
        [0.6651, 0.3349],
        [0.6645, 0.3355],
        [0.6664, 0.3336],
        [0.6513, 0.3487],
        [0.6484, 0.3516],
        [0.6626, 0.3374],
        [0.6636, 0.3364],
        [0.6675, 0.3325],
        [0.6640, 0.3360],
        [0.6661, 0.3339],
        [0.6602, 0.3398],
        [0.6614, 0.3386],
        [0.6622, 0.3378],
        [0.6602, 0.3398],
        [0.6638, 0.3362],
        [0.6558, 0.3442],
        [0.6560, 0.3440],
        [0.6608, 0.3392],
        [0.6570, 0.3430],
        [0.6621, 0.3379],
        [0.6570, 0.3430],
        [0.6664, 0.3336],
        [0.6540, 0.3460],
        [0.6603, 0.3397],
        [0.6569, 0.3431],
        [0.6542, 0.3458],
        [0.6653, 0.3347],
        [0.6585, 0.3415],
        [0.6555, 0.3445],
        [0.6557, 0.3443],
        [0.6594, 0.3406],
        [0.6552, 0.3448],
        [0.6556, 0.3444],
        [0.6537, 0.3463],
        [0.6655, 0.3345],
        [0.6623, 0.3377],
        [0.6558, 0.3442],
        [0.6663, 0.3337],
        [0.6664, 0.3336],
        [0.6563, 0.3437],
        [0.6693, 0.3307],
        [0.6671, 0.3329],
        [0.6682, 0.3318],
        [0.6663, 0.3337],
        [0.6605, 0.3395],
        [0.6661, 0.3339],
        [0.6669, 0.3331],
        [0.6592, 0.3408],
        [0.6592, 0.3408],
        [0.6611, 0.3389],
        [0.6650, 0.3350],
        [0.6501, 0.3499],
        [0.6577, 0.3423],
        [0.6530, 0.3470],
        [0.6576, 0.3424],
        [0.6642, 0.3358],
        [0.6573, 0.3427],
        [0.6635, 0.3365],
        [0.6540, 0.3460],
        [0.6523, 0.3477],
        [0.6579, 0.3421],
        [0.6630, 0.3370],
        [0.6526, 0.3474],
        [0.6631, 0.3369],
        [0.6656, 0.3344],
        [0.6696, 0.3304],
        [0.6610, 0.3390],
        [0.6577, 0.3423],
        [0.6648, 0.3352],
        [0.6695, 0.3305],
        [0.6576, 0.3424],
        [0.6571, 0.3429],
        [0.6527, 0.3473],
        [0.6596, 0.3404],
        [0.6676, 0.3324],
        [0.6493, 0.3507],
        [0.6554, 0.3446],
        [0.6581, 0.3419],
        [0.6637, 0.3363],
        [0.6706, 0.3294],
        [0.6558, 0.3442],
        [0.6583, 0.3417],
        [0.6545, 0.3455],
        [0.6664, 0.3336],
        [0.6666, 0.3334],
        [0.6650, 0.3350],
        [0.6566, 0.3434],
        [0.6650, 0.3350],
        [0.6681, 0.3319],
        [0.6559, 0.3441],
        [0.6697, 0.3303],
        [0.6617, 0.3383],
        [0.6565, 0.3435],
        [0.6667, 0.3333],
        [0.6625, 0.3375],
        [0.6718, 0.3282],
        [0.6685, 0.3315],
        [0.6506, 0.3494],
        [0.6552, 0.3448],
        [0.6658, 0.3342],
        [0.6557, 0.3443],
        [0.6642, 0.3358],
        [0.6578, 0.3422],
        [0.6640, 0.3360],
        [0.6707, 0.3293],
        [0.6585, 0.3415],
        [0.6647, 0.3353],
        [0.6633, 0.3367],
        [0.6666, 0.3334],
        [0.6523, 0.3477],
        [0.6657, 0.3343],
        [0.6562, 0.3438],
        [0.6688, 0.3312],
        [0.6633, 0.3367],
        [0.6725, 0.3275],
        [0.6459, 0.3541],
        [0.6688, 0.3312],
        [0.6635, 0.3365],
        [0.6691, 0.3309],
        [0.6701, 0.3299],
        [0.6653, 0.3347],
        [0.6716, 0.3284],
        [0.6675, 0.3325],
        [0.6705, 0.3295],
        [0.6637, 0.3363],
        [0.6506, 0.3494],
        [0.6657, 0.3343],
        [0.6580, 0.3420],
        [0.6547, 0.3453],
        [0.6642, 0.3358],
        [0.6595, 0.3405],
        [0.6552, 0.3448],
        [0.6560, 0.3440],
        [0.6678, 0.3322],
        [0.6678, 0.3322],
        [0.6657, 0.3343],
        [0.6638, 0.3362],
        [0.6659, 0.3341],
        [0.6621, 0.3379],
        [0.6632, 0.3368],
        [0.6651, 0.3349],
        [0.6587, 0.3413],
        [0.6648, 0.3352],
        [0.6648, 0.3352],
        [0.6625, 0.3375],
        [0.6619, 0.3381],
        [0.6651, 0.3349],
        [0.6624, 0.3376],
        [0.6696, 0.3304],
        [0.6580, 0.3420],
        [0.6565, 0.3435],
        [0.6567, 0.3433],
        [0.6651, 0.3349],
        [0.6553, 0.3447],
        [0.6638, 0.3362],
        [0.6645, 0.3355],
        [0.6582, 0.3418],
        [0.6607, 0.3393],
        [0.6564, 0.3436],
        [0.6681, 0.3319],
        [0.6713, 0.3287]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0024 loss: 0.6677 acc_train: 0.6103 time: 0.1533s
tensor([[0.6581, 0.3419],
        [0.6655, 0.3345],
        [0.6653, 0.3347],
        [0.6613, 0.3387],
        [0.6651, 0.3349],
        [0.6604, 0.3396],
        [0.6519, 0.3481],
        [0.6602, 0.3398],
        [0.6615, 0.3385],
        [0.6566, 0.3434],
        [0.6641, 0.3359],
        [0.6627, 0.3373],
        [0.6584, 0.3416],
        [0.6578, 0.3422],
        [0.6636, 0.3364],
        [0.6602, 0.3398],
        [0.6676, 0.3324],
        [0.6636, 0.3364],
        [0.6572, 0.3428],
        [0.6584, 0.3416],
        [0.6667, 0.3333],
        [0.6568, 0.3432],
        [0.6659, 0.3341],
        [0.6663, 0.3337],
        [0.6635, 0.3365],
        [0.6606, 0.3394],
        [0.6534, 0.3466],
        [0.6672, 0.3328],
        [0.6554, 0.3446],
        [0.6608, 0.3392],
        [0.6612, 0.3388],
        [0.6568, 0.3432],
        [0.6618, 0.3382],
        [0.6601, 0.3399],
        [0.6608, 0.3392],
        [0.6525, 0.3475],
        [0.6547, 0.3453],
        [0.6581, 0.3419],
        [0.6680, 0.3320],
        [0.6544, 0.3456],
        [0.6641, 0.3359],
        [0.6633, 0.3367],
        [0.6489, 0.3511],
        [0.6621, 0.3379],
        [0.6612, 0.3388],
        [0.6625, 0.3375],
        [0.6665, 0.3335],
        [0.6650, 0.3350],
        [0.6613, 0.3387],
        [0.6658, 0.3342],
        [0.6607, 0.3393],
        [0.6653, 0.3347],
        [0.6584, 0.3416],
        [0.6630, 0.3370],
        [0.6680, 0.3320],
        [0.6625, 0.3375],
        [0.6643, 0.3357],
        [0.6629, 0.3371],
        [0.6548, 0.3452],
        [0.6565, 0.3435],
        [0.6601, 0.3399],
        [0.6581, 0.3419],
        [0.6608, 0.3392],
        [0.6649, 0.3351],
        [0.6590, 0.3410],
        [0.6565, 0.3435],
        [0.6620, 0.3380],
        [0.6611, 0.3389],
        [0.6657, 0.3343],
        [0.6627, 0.3373],
        [0.6612, 0.3388],
        [0.6573, 0.3427],
        [0.6677, 0.3323],
        [0.6624, 0.3376],
        [0.6605, 0.3395],
        [0.6590, 0.3410],
        [0.6666, 0.3334],
        [0.6602, 0.3398],
        [0.6620, 0.3380],
        [0.6574, 0.3426],
        [0.6551, 0.3449],
        [0.6573, 0.3427],
        [0.6586, 0.3414],
        [0.6557, 0.3443],
        [0.6594, 0.3406],
        [0.6613, 0.3387],
        [0.6627, 0.3373],
        [0.6584, 0.3416],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6625, 0.3375],
        [0.6591, 0.3409],
        [0.6568, 0.3432],
        [0.6600, 0.3400],
        [0.6673, 0.3327],
        [0.6696, 0.3304],
        [0.6575, 0.3425],
        [0.6605, 0.3395],
        [0.6607, 0.3393],
        [0.6633, 0.3367],
        [0.6594, 0.3406],
        [0.6573, 0.3427],
        [0.6588, 0.3412],
        [0.6643, 0.3357],
        [0.6623, 0.3377],
        [0.6675, 0.3325],
        [0.6664, 0.3336],
        [0.6579, 0.3421],
        [0.6615, 0.3385],
        [0.6526, 0.3474],
        [0.6644, 0.3356],
        [0.6636, 0.3364],
        [0.6645, 0.3355],
        [0.6541, 0.3459],
        [0.6487, 0.3513],
        [0.6623, 0.3377],
        [0.6628, 0.3372],
        [0.6663, 0.3337],
        [0.6633, 0.3367],
        [0.6652, 0.3348],
        [0.6609, 0.3391],
        [0.6619, 0.3381],
        [0.6621, 0.3379],
        [0.6604, 0.3396],
        [0.6633, 0.3367],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6607, 0.3393],
        [0.6585, 0.3415],
        [0.6618, 0.3382],
        [0.6580, 0.3420],
        [0.6648, 0.3352],
        [0.6559, 0.3441],
        [0.6606, 0.3394],
        [0.6584, 0.3416],
        [0.6563, 0.3437],
        [0.6645, 0.3355],
        [0.6593, 0.3407],
        [0.6570, 0.3430],
        [0.6582, 0.3418],
        [0.6601, 0.3399],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6562, 0.3438],
        [0.6647, 0.3353],
        [0.6624, 0.3376],
        [0.6570, 0.3430],
        [0.6655, 0.3345],
        [0.6653, 0.3347],
        [0.6583, 0.3417],
        [0.6673, 0.3327],
        [0.6652, 0.3348],
        [0.6662, 0.3338],
        [0.6651, 0.3349],
        [0.6609, 0.3391],
        [0.6652, 0.3348],
        [0.6656, 0.3344],
        [0.6598, 0.3402],
        [0.6598, 0.3402],
        [0.6618, 0.3382],
        [0.6642, 0.3358],
        [0.6529, 0.3471],
        [0.6584, 0.3416],
        [0.6529, 0.3471],
        [0.6584, 0.3416],
        [0.6640, 0.3360],
        [0.6580, 0.3420],
        [0.6626, 0.3374],
        [0.6558, 0.3442],
        [0.6518, 0.3482],
        [0.6588, 0.3412],
        [0.6623, 0.3377],
        [0.6548, 0.3452],
        [0.6623, 0.3377],
        [0.6647, 0.3353],
        [0.6675, 0.3325],
        [0.6606, 0.3394],
        [0.6583, 0.3417],
        [0.6641, 0.3359],
        [0.6674, 0.3326],
        [0.6586, 0.3414],
        [0.6582, 0.3418],
        [0.6551, 0.3449],
        [0.6597, 0.3403],
        [0.6660, 0.3340],
        [0.6520, 0.3480],
        [0.6565, 0.3435],
        [0.6589, 0.3411],
        [0.6627, 0.3373],
        [0.6683, 0.3317],
        [0.6572, 0.3428],
        [0.6592, 0.3408],
        [0.6562, 0.3438],
        [0.6653, 0.3347],
        [0.6655, 0.3345],
        [0.6642, 0.3358],
        [0.6584, 0.3416],
        [0.6642, 0.3358],
        [0.6662, 0.3338],
        [0.6576, 0.3424],
        [0.6682, 0.3318],
        [0.6618, 0.3382],
        [0.6577, 0.3423],
        [0.6652, 0.3348],
        [0.6624, 0.3376],
        [0.6690, 0.3310],
        [0.6662, 0.3338],
        [0.6535, 0.3465],
        [0.6568, 0.3432],
        [0.6651, 0.3349],
        [0.6573, 0.3427],
        [0.6634, 0.3366],
        [0.6593, 0.3407],
        [0.6637, 0.3363],
        [0.6686, 0.3314],
        [0.6591, 0.3409],
        [0.6635, 0.3365],
        [0.6627, 0.3373],
        [0.6655, 0.3345],
        [0.6548, 0.3452],
        [0.6644, 0.3356],
        [0.6573, 0.3427],
        [0.6666, 0.3334],
        [0.6628, 0.3372],
        [0.6695, 0.3305],
        [0.6470, 0.3530],
        [0.6668, 0.3332],
        [0.6622, 0.3378],
        [0.6672, 0.3328],
        [0.6677, 0.3323],
        [0.6645, 0.3355],
        [0.6694, 0.3306],
        [0.6658, 0.3342],
        [0.6686, 0.3314],
        [0.6638, 0.3362],
        [0.6535, 0.3465],
        [0.6651, 0.3349],
        [0.6587, 0.3413],
        [0.6573, 0.3427],
        [0.6638, 0.3362],
        [0.6603, 0.3397],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6665, 0.3335],
        [0.6666, 0.3334],
        [0.6648, 0.3352],
        [0.6631, 0.3369],
        [0.6649, 0.3351],
        [0.6619, 0.3381],
        [0.6635, 0.3365],
        [0.6642, 0.3358],
        [0.6593, 0.3407],
        [0.6644, 0.3356],
        [0.6642, 0.3358],
        [0.6625, 0.3375],
        [0.6621, 0.3379],
        [0.6646, 0.3354],
        [0.6619, 0.3381],
        [0.6679, 0.3321],
        [0.6586, 0.3414],
        [0.6581, 0.3419],
        [0.6576, 0.3424],
        [0.6642, 0.3358],
        [0.6570, 0.3430],
        [0.6632, 0.3368],
        [0.6639, 0.3361],
        [0.6583, 0.3417],
        [0.6612, 0.3388],
        [0.6579, 0.3421],
        [0.6667, 0.3333],
        [0.6697, 0.3303]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0025 loss: 0.6686 acc_train: 0.6103 time: 0.1550s
tensor([[0.6591, 0.3409],
        [0.6641, 0.3359],
        [0.6640, 0.3360],
        [0.6612, 0.3388],
        [0.6632, 0.3368],
        [0.6605, 0.3395],
        [0.6540, 0.3460],
        [0.6601, 0.3399],
        [0.6615, 0.3385],
        [0.6572, 0.3428],
        [0.6634, 0.3366],
        [0.6626, 0.3374],
        [0.6589, 0.3411],
        [0.6587, 0.3413],
        [0.6627, 0.3373],
        [0.6600, 0.3400],
        [0.6658, 0.3342],
        [0.6631, 0.3369],
        [0.6582, 0.3418],
        [0.6584, 0.3416],
        [0.6651, 0.3349],
        [0.6575, 0.3425],
        [0.6644, 0.3356],
        [0.6652, 0.3348],
        [0.6629, 0.3371],
        [0.6607, 0.3393],
        [0.6552, 0.3448],
        [0.6652, 0.3348],
        [0.6565, 0.3435],
        [0.6603, 0.3397],
        [0.6608, 0.3392],
        [0.6582, 0.3418],
        [0.6618, 0.3382],
        [0.6597, 0.3403],
        [0.6607, 0.3393],
        [0.6519, 0.3481],
        [0.6562, 0.3438],
        [0.6587, 0.3413],
        [0.6658, 0.3342],
        [0.6562, 0.3438],
        [0.6631, 0.3369],
        [0.6622, 0.3378],
        [0.6487, 0.3513],
        [0.6617, 0.3383],
        [0.6615, 0.3385],
        [0.6615, 0.3385],
        [0.6653, 0.3347],
        [0.6642, 0.3358],
        [0.6610, 0.3390],
        [0.6642, 0.3358],
        [0.6605, 0.3395],
        [0.6640, 0.3360],
        [0.6593, 0.3407],
        [0.6624, 0.3376],
        [0.6656, 0.3344],
        [0.6618, 0.3382],
        [0.6628, 0.3372],
        [0.6620, 0.3380],
        [0.6567, 0.3433],
        [0.6575, 0.3425],
        [0.6600, 0.3400],
        [0.6587, 0.3413],
        [0.6605, 0.3395],
        [0.6638, 0.3362],
        [0.6595, 0.3405],
        [0.6573, 0.3427],
        [0.6623, 0.3377],
        [0.6613, 0.3387],
        [0.6641, 0.3359],
        [0.6622, 0.3378],
        [0.6610, 0.3390],
        [0.6583, 0.3417],
        [0.6652, 0.3348],
        [0.6621, 0.3379],
        [0.6603, 0.3397],
        [0.6593, 0.3407],
        [0.6648, 0.3352],
        [0.6601, 0.3399],
        [0.6612, 0.3388],
        [0.6580, 0.3420],
        [0.6563, 0.3437],
        [0.6581, 0.3419],
        [0.6593, 0.3407],
        [0.6567, 0.3433],
        [0.6593, 0.3407],
        [0.6611, 0.3389],
        [0.6616, 0.3384],
        [0.6593, 0.3407],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6620, 0.3380],
        [0.6591, 0.3409],
        [0.6580, 0.3420],
        [0.6597, 0.3403],
        [0.6654, 0.3346],
        [0.6670, 0.3330],
        [0.6582, 0.3418],
        [0.6604, 0.3396],
        [0.6607, 0.3393],
        [0.6624, 0.3376],
        [0.6601, 0.3399],
        [0.6581, 0.3419],
        [0.6590, 0.3410],
        [0.6635, 0.3365],
        [0.6613, 0.3387],
        [0.6656, 0.3344],
        [0.6650, 0.3350],
        [0.6585, 0.3415],
        [0.6614, 0.3386],
        [0.6517, 0.3483],
        [0.6634, 0.3366],
        [0.6627, 0.3373],
        [0.6627, 0.3373],
        [0.6557, 0.3443],
        [0.6487, 0.3513],
        [0.6618, 0.3382],
        [0.6620, 0.3380],
        [0.6648, 0.3352],
        [0.6625, 0.3375],
        [0.6640, 0.3360],
        [0.6609, 0.3391],
        [0.6617, 0.3383],
        [0.6617, 0.3383],
        [0.6603, 0.3397],
        [0.6624, 0.3376],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6604, 0.3396],
        [0.6592, 0.3408],
        [0.6614, 0.3386],
        [0.6585, 0.3415],
        [0.6632, 0.3368],
        [0.6568, 0.3432],
        [0.6604, 0.3396],
        [0.6591, 0.3409],
        [0.6574, 0.3426],
        [0.6635, 0.3365],
        [0.6595, 0.3405],
        [0.6578, 0.3422],
        [0.6595, 0.3405],
        [0.6603, 0.3397],
        [0.6583, 0.3417],
        [0.6585, 0.3415],
        [0.6576, 0.3424],
        [0.6636, 0.3364],
        [0.6620, 0.3380],
        [0.6577, 0.3423],
        [0.6644, 0.3356],
        [0.6640, 0.3360],
        [0.6593, 0.3407],
        [0.6654, 0.3346],
        [0.6635, 0.3365],
        [0.6643, 0.3357],
        [0.6639, 0.3361],
        [0.6607, 0.3393],
        [0.6640, 0.3360],
        [0.6641, 0.3359],
        [0.6597, 0.3403],
        [0.6599, 0.3401],
        [0.6618, 0.3382],
        [0.6632, 0.3368],
        [0.6548, 0.3452],
        [0.6587, 0.3413],
        [0.6523, 0.3477],
        [0.6588, 0.3412],
        [0.6633, 0.3367],
        [0.6582, 0.3418],
        [0.6616, 0.3384],
        [0.6569, 0.3431],
        [0.6512, 0.3488],
        [0.6591, 0.3409],
        [0.6615, 0.3385],
        [0.6562, 0.3438],
        [0.6614, 0.3386],
        [0.6636, 0.3364],
        [0.6655, 0.3345],
        [0.6601, 0.3399],
        [0.6586, 0.3414],
        [0.6632, 0.3368],
        [0.6655, 0.3345],
        [0.6588, 0.3412],
        [0.6586, 0.3414],
        [0.6564, 0.3436],
        [0.6596, 0.3404],
        [0.6644, 0.3356],
        [0.6537, 0.3463],
        [0.6571, 0.3429],
        [0.6592, 0.3408],
        [0.6618, 0.3382],
        [0.6663, 0.3337],
        [0.6580, 0.3420],
        [0.6596, 0.3404],
        [0.6571, 0.3429],
        [0.6641, 0.3359],
        [0.6642, 0.3358],
        [0.6632, 0.3368],
        [0.6594, 0.3406],
        [0.6632, 0.3368],
        [0.6643, 0.3357],
        [0.6584, 0.3416],
        [0.6666, 0.3334],
        [0.6613, 0.3387],
        [0.6583, 0.3417],
        [0.6637, 0.3363],
        [0.6618, 0.3382],
        [0.6665, 0.3335],
        [0.6643, 0.3357],
        [0.6553, 0.3447],
        [0.6577, 0.3423],
        [0.6641, 0.3359],
        [0.6581, 0.3419],
        [0.6625, 0.3375],
        [0.6599, 0.3401],
        [0.6629, 0.3371],
        [0.6666, 0.3334],
        [0.6592, 0.3408],
        [0.6624, 0.3376],
        [0.6620, 0.3380],
        [0.6642, 0.3358],
        [0.6562, 0.3438],
        [0.6631, 0.3369],
        [0.6577, 0.3423],
        [0.6647, 0.3353],
        [0.6621, 0.3379],
        [0.6669, 0.3331],
        [0.6477, 0.3523],
        [0.6650, 0.3350],
        [0.6612, 0.3388],
        [0.6654, 0.3346],
        [0.6656, 0.3344],
        [0.6636, 0.3364],
        [0.6673, 0.3327],
        [0.6641, 0.3359],
        [0.6666, 0.3334],
        [0.6634, 0.3366],
        [0.6554, 0.3446],
        [0.6641, 0.3359],
        [0.6589, 0.3411],
        [0.6588, 0.3412],
        [0.6630, 0.3370],
        [0.6604, 0.3396],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6650, 0.3350],
        [0.6651, 0.3349],
        [0.6637, 0.3363],
        [0.6622, 0.3378],
        [0.6638, 0.3362],
        [0.6613, 0.3387],
        [0.6631, 0.3369],
        [0.6631, 0.3369],
        [0.6594, 0.3406],
        [0.6638, 0.3362],
        [0.6632, 0.3368],
        [0.6620, 0.3380],
        [0.6617, 0.3383],
        [0.6638, 0.3362],
        [0.6612, 0.3388],
        [0.6662, 0.3338],
        [0.6588, 0.3412],
        [0.6590, 0.3410],
        [0.6580, 0.3420],
        [0.6632, 0.3368],
        [0.6579, 0.3421],
        [0.6623, 0.3377],
        [0.6631, 0.3369],
        [0.6583, 0.3417],
        [0.6612, 0.3388],
        [0.6585, 0.3415],
        [0.6651, 0.3349],
        [0.6678, 0.3322]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0026 loss: 0.6692 acc_train: 0.6103 time: 0.1557s
tensor([[0.6592, 0.3408],
        [0.6628, 0.3372],
        [0.6627, 0.3373],
        [0.6607, 0.3393],
        [0.6616, 0.3384],
        [0.6602, 0.3398],
        [0.6553, 0.3447],
        [0.6596, 0.3404],
        [0.6611, 0.3389],
        [0.6574, 0.3426],
        [0.6624, 0.3376],
        [0.6620, 0.3380],
        [0.6590, 0.3410],
        [0.6590, 0.3410],
        [0.6617, 0.3383],
        [0.6595, 0.3405],
        [0.6641, 0.3359],
        [0.6625, 0.3375],
        [0.6585, 0.3415],
        [0.6581, 0.3419],
        [0.6636, 0.3364],
        [0.6576, 0.3424],
        [0.6629, 0.3371],
        [0.6638, 0.3362],
        [0.6620, 0.3380],
        [0.6604, 0.3396],
        [0.6561, 0.3439],
        [0.6635, 0.3365],
        [0.6569, 0.3431],
        [0.6597, 0.3403],
        [0.6602, 0.3398],
        [0.6588, 0.3412],
        [0.6613, 0.3387],
        [0.6590, 0.3410],
        [0.6602, 0.3398],
        [0.6513, 0.3487],
        [0.6570, 0.3430],
        [0.6588, 0.3412],
        [0.6638, 0.3362],
        [0.6571, 0.3429],
        [0.6620, 0.3380],
        [0.6610, 0.3390],
        [0.6485, 0.3515],
        [0.6612, 0.3388],
        [0.6614, 0.3386],
        [0.6604, 0.3396],
        [0.6639, 0.3361],
        [0.6632, 0.3368],
        [0.6604, 0.3396],
        [0.6627, 0.3373],
        [0.6600, 0.3400],
        [0.6626, 0.3374],
        [0.6594, 0.3406],
        [0.6617, 0.3383],
        [0.6634, 0.3366],
        [0.6610, 0.3390],
        [0.6615, 0.3385],
        [0.6610, 0.3390],
        [0.6576, 0.3424],
        [0.6579, 0.3421],
        [0.6596, 0.3404],
        [0.6588, 0.3412],
        [0.6599, 0.3401],
        [0.6626, 0.3374],
        [0.6594, 0.3406],
        [0.6576, 0.3424],
        [0.6620, 0.3380],
        [0.6608, 0.3392],
        [0.6626, 0.3374],
        [0.6614, 0.3386],
        [0.6605, 0.3395],
        [0.6587, 0.3413],
        [0.6631, 0.3369],
        [0.6613, 0.3387],
        [0.6599, 0.3401],
        [0.6592, 0.3408],
        [0.6631, 0.3369],
        [0.6595, 0.3405],
        [0.6605, 0.3395],
        [0.6582, 0.3418],
        [0.6567, 0.3433],
        [0.6583, 0.3417],
        [0.6594, 0.3406],
        [0.6572, 0.3428],
        [0.6589, 0.3411],
        [0.6606, 0.3394],
        [0.6605, 0.3395],
        [0.6595, 0.3405],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6611, 0.3389],
        [0.6590, 0.3410],
        [0.6585, 0.3415],
        [0.6592, 0.3408],
        [0.6637, 0.3363],
        [0.6647, 0.3353],
        [0.6583, 0.3417],
        [0.6601, 0.3399],
        [0.6601, 0.3399],
        [0.6615, 0.3385],
        [0.6602, 0.3398],
        [0.6584, 0.3416],
        [0.6589, 0.3411],
        [0.6625, 0.3375],
        [0.6603, 0.3397],
        [0.6638, 0.3362],
        [0.6635, 0.3365],
        [0.6585, 0.3415],
        [0.6609, 0.3391],
        [0.6508, 0.3492],
        [0.6622, 0.3378],
        [0.6617, 0.3383],
        [0.6612, 0.3388],
        [0.6566, 0.3434],
        [0.6486, 0.3514],
        [0.6611, 0.3389],
        [0.6611, 0.3389],
        [0.6633, 0.3367],
        [0.6617, 0.3383],
        [0.6627, 0.3373],
        [0.6604, 0.3396],
        [0.6611, 0.3389],
        [0.6611, 0.3389],
        [0.6599, 0.3401],
        [0.6613, 0.3387],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6599, 0.3401],
        [0.6593, 0.3407],
        [0.6608, 0.3392],
        [0.6586, 0.3414],
        [0.6619, 0.3381],
        [0.6572, 0.3428],
        [0.6600, 0.3400],
        [0.6593, 0.3407],
        [0.6579, 0.3421],
        [0.6624, 0.3376],
        [0.6592, 0.3408],
        [0.6582, 0.3418],
        [0.6600, 0.3400],
        [0.6601, 0.3399],
        [0.6585, 0.3415],
        [0.6588, 0.3412],
        [0.6582, 0.3418],
        [0.6624, 0.3376],
        [0.6612, 0.3388],
        [0.6579, 0.3421],
        [0.6631, 0.3369],
        [0.6627, 0.3373],
        [0.6596, 0.3404],
        [0.6636, 0.3364],
        [0.6619, 0.3381],
        [0.6626, 0.3374],
        [0.6626, 0.3374],
        [0.6602, 0.3398],
        [0.6628, 0.3372],
        [0.6627, 0.3373],
        [0.6593, 0.3407],
        [0.6596, 0.3404],
        [0.6613, 0.3387],
        [0.6622, 0.3378],
        [0.6560, 0.3440],
        [0.6587, 0.3413],
        [0.6516, 0.3484],
        [0.6588, 0.3412],
        [0.6624, 0.3376],
        [0.6580, 0.3420],
        [0.6606, 0.3394],
        [0.6574, 0.3426],
        [0.6505, 0.3495],
        [0.6590, 0.3410],
        [0.6605, 0.3395],
        [0.6569, 0.3431],
        [0.6605, 0.3395],
        [0.6624, 0.3376],
        [0.6635, 0.3365],
        [0.6595, 0.3405],
        [0.6585, 0.3415],
        [0.6622, 0.3378],
        [0.6638, 0.3362],
        [0.6587, 0.3413],
        [0.6585, 0.3415],
        [0.6569, 0.3431],
        [0.6594, 0.3406],
        [0.6628, 0.3372],
        [0.6547, 0.3453],
        [0.6572, 0.3428],
        [0.6590, 0.3410],
        [0.6609, 0.3391],
        [0.6644, 0.3356],
        [0.6583, 0.3417],
        [0.6595, 0.3405],
        [0.6574, 0.3426],
        [0.6628, 0.3372],
        [0.6630, 0.3370],
        [0.6620, 0.3380],
        [0.6596, 0.3404],
        [0.6620, 0.3380],
        [0.6626, 0.3374],
        [0.6586, 0.3414],
        [0.6648, 0.3352],
        [0.6606, 0.3394],
        [0.6584, 0.3416],
        [0.6623, 0.3377],
        [0.6611, 0.3389],
        [0.6644, 0.3356],
        [0.6627, 0.3373],
        [0.6562, 0.3438],
        [0.6579, 0.3421],
        [0.6630, 0.3370],
        [0.6583, 0.3417],
        [0.6616, 0.3384],
        [0.6598, 0.3402],
        [0.6619, 0.3381],
        [0.6647, 0.3353],
        [0.6590, 0.3410],
        [0.6613, 0.3387],
        [0.6612, 0.3388],
        [0.6629, 0.3371],
        [0.6569, 0.3431],
        [0.6617, 0.3383],
        [0.6578, 0.3422],
        [0.6630, 0.3370],
        [0.6613, 0.3387],
        [0.6647, 0.3353],
        [0.6482, 0.3518],
        [0.6632, 0.3368],
        [0.6603, 0.3397],
        [0.6636, 0.3364],
        [0.6637, 0.3363],
        [0.6625, 0.3375],
        [0.6653, 0.3347],
        [0.6625, 0.3375],
        [0.6647, 0.3353],
        [0.6627, 0.3373],
        [0.6564, 0.3436],
        [0.6630, 0.3370],
        [0.6587, 0.3413],
        [0.6594, 0.3406],
        [0.6619, 0.3381],
        [0.6600, 0.3400],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6635, 0.3365],
        [0.6637, 0.3363],
        [0.6625, 0.3375],
        [0.6612, 0.3388],
        [0.6627, 0.3373],
        [0.6606, 0.3394],
        [0.6622, 0.3378],
        [0.6619, 0.3381],
        [0.6591, 0.3409],
        [0.6628, 0.3372],
        [0.6621, 0.3379],
        [0.6613, 0.3387],
        [0.6610, 0.3390],
        [0.6627, 0.3373],
        [0.6604, 0.3396],
        [0.6644, 0.3356],
        [0.6586, 0.3414],
        [0.6594, 0.3406],
        [0.6580, 0.3420],
        [0.6621, 0.3379],
        [0.6582, 0.3418],
        [0.6613, 0.3387],
        [0.6621, 0.3379],
        [0.6582, 0.3418],
        [0.6607, 0.3393],
        [0.6586, 0.3414],
        [0.6636, 0.3364],
        [0.6659, 0.3341]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0027 loss: 0.6696 acc_train: 0.6103 time: 0.1641s
tensor([[0.6590, 0.3410],
        [0.6617, 0.3383],
        [0.6615, 0.3385],
        [0.6600, 0.3400],
        [0.6603, 0.3397],
        [0.6596, 0.3404],
        [0.6560, 0.3440],
        [0.6591, 0.3409],
        [0.6605, 0.3395],
        [0.6574, 0.3426],
        [0.6613, 0.3387],
        [0.6611, 0.3389],
        [0.6588, 0.3412],
        [0.6590, 0.3410],
        [0.6607, 0.3393],
        [0.6590, 0.3410],
        [0.6626, 0.3374],
        [0.6617, 0.3383],
        [0.6584, 0.3416],
        [0.6577, 0.3423],
        [0.6622, 0.3378],
        [0.6575, 0.3425],
        [0.6617, 0.3383],
        [0.6625, 0.3375],
        [0.6611, 0.3389],
        [0.6599, 0.3401],
        [0.6564, 0.3436],
        [0.6620, 0.3380],
        [0.6570, 0.3430],
        [0.6591, 0.3409],
        [0.6595, 0.3405],
        [0.6590, 0.3410],
        [0.6606, 0.3394],
        [0.6583, 0.3417],
        [0.6596, 0.3404],
        [0.6507, 0.3493],
        [0.6574, 0.3426],
        [0.6585, 0.3415],
        [0.6622, 0.3378],
        [0.6575, 0.3425],
        [0.6610, 0.3390],
        [0.6600, 0.3400],
        [0.6482, 0.3518],
        [0.6605, 0.3395],
        [0.6609, 0.3391],
        [0.6595, 0.3405],
        [0.6627, 0.3373],
        [0.6622, 0.3378],
        [0.6597, 0.3403],
        [0.6613, 0.3387],
        [0.6595, 0.3405],
        [0.6613, 0.3387],
        [0.6592, 0.3408],
        [0.6610, 0.3390],
        [0.6617, 0.3383],
        [0.6602, 0.3398],
        [0.6605, 0.3395],
        [0.6601, 0.3399],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6590, 0.3410],
        [0.6586, 0.3414],
        [0.6592, 0.3408],
        [0.6614, 0.3386],
        [0.6591, 0.3409],
        [0.6576, 0.3424],
        [0.6614, 0.3386],
        [0.6601, 0.3399],
        [0.6612, 0.3388],
        [0.6606, 0.3394],
        [0.6598, 0.3402],
        [0.6586, 0.3414],
        [0.6614, 0.3386],
        [0.6604, 0.3396],
        [0.6594, 0.3406],
        [0.6589, 0.3411],
        [0.6616, 0.3384],
        [0.6589, 0.3411],
        [0.6597, 0.3403],
        [0.6581, 0.3419],
        [0.6568, 0.3432],
        [0.6582, 0.3418],
        [0.6591, 0.3409],
        [0.6573, 0.3427],
        [0.6584, 0.3416],
        [0.6598, 0.3402],
        [0.6596, 0.3404],
        [0.6593, 0.3407],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6603, 0.3397],
        [0.6587, 0.3413],
        [0.6585, 0.3415],
        [0.6588, 0.3412],
        [0.6623, 0.3377],
        [0.6628, 0.3372],
        [0.6581, 0.3419],
        [0.6596, 0.3404],
        [0.6593, 0.3407],
        [0.6605, 0.3395],
        [0.6599, 0.3401],
        [0.6584, 0.3416],
        [0.6586, 0.3414],
        [0.6615, 0.3385],
        [0.6593, 0.3407],
        [0.6622, 0.3378],
        [0.6622, 0.3378],
        [0.6584, 0.3416],
        [0.6603, 0.3397],
        [0.6499, 0.3501],
        [0.6611, 0.3389],
        [0.6607, 0.3393],
        [0.6600, 0.3400],
        [0.6570, 0.3430],
        [0.6483, 0.3517],
        [0.6604, 0.3396],
        [0.6602, 0.3398],
        [0.6620, 0.3380],
        [0.6609, 0.3391],
        [0.6614, 0.3386],
        [0.6597, 0.3403],
        [0.6603, 0.3397],
        [0.6604, 0.3396],
        [0.6594, 0.3406],
        [0.6603, 0.3397],
        [0.6586, 0.3414],
        [0.6589, 0.3411],
        [0.6593, 0.3407],
        [0.6591, 0.3409],
        [0.6601, 0.3399],
        [0.6586, 0.3414],
        [0.6607, 0.3393],
        [0.6572, 0.3428],
        [0.6594, 0.3406],
        [0.6591, 0.3409],
        [0.6579, 0.3421],
        [0.6614, 0.3386],
        [0.6587, 0.3413],
        [0.6581, 0.3419],
        [0.6599, 0.3401],
        [0.6596, 0.3404],
        [0.6583, 0.3417],
        [0.6586, 0.3414],
        [0.6582, 0.3418],
        [0.6613, 0.3387],
        [0.6603, 0.3397],
        [0.6579, 0.3421],
        [0.6618, 0.3382],
        [0.6614, 0.3386],
        [0.6594, 0.3406],
        [0.6620, 0.3380],
        [0.6607, 0.3393],
        [0.6610, 0.3390],
        [0.6614, 0.3386],
        [0.6594, 0.3406],
        [0.6616, 0.3384],
        [0.6614, 0.3386],
        [0.6588, 0.3412],
        [0.6592, 0.3408],
        [0.6605, 0.3395],
        [0.6612, 0.3388],
        [0.6566, 0.3434],
        [0.6585, 0.3415],
        [0.6508, 0.3492],
        [0.6587, 0.3413],
        [0.6614, 0.3386],
        [0.6576, 0.3424],
        [0.6598, 0.3402],
        [0.6575, 0.3425],
        [0.6498, 0.3502],
        [0.6586, 0.3414],
        [0.6596, 0.3404],
        [0.6572, 0.3428],
        [0.6597, 0.3403],
        [0.6612, 0.3388],
        [0.6619, 0.3381],
        [0.6591, 0.3409],
        [0.6584, 0.3416],
        [0.6612, 0.3388],
        [0.6623, 0.3377],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6570, 0.3430],
        [0.6590, 0.3410],
        [0.6614, 0.3386],
        [0.6551, 0.3449],
        [0.6572, 0.3428],
        [0.6587, 0.3413],
        [0.6601, 0.3399],
        [0.6629, 0.3371],
        [0.6583, 0.3417],
        [0.6592, 0.3408],
        [0.6574, 0.3426],
        [0.6616, 0.3384],
        [0.6618, 0.3382],
        [0.6609, 0.3391],
        [0.6595, 0.3405],
        [0.6608, 0.3392],
        [0.6612, 0.3388],
        [0.6586, 0.3414],
        [0.6631, 0.3369],
        [0.6598, 0.3402],
        [0.6583, 0.3417],
        [0.6610, 0.3390],
        [0.6603, 0.3397],
        [0.6628, 0.3372],
        [0.6614, 0.3386],
        [0.6566, 0.3434],
        [0.6578, 0.3422],
        [0.6619, 0.3381],
        [0.6582, 0.3418],
        [0.6607, 0.3393],
        [0.6594, 0.3406],
        [0.6608, 0.3392],
        [0.6630, 0.3370],
        [0.6586, 0.3414],
        [0.6604, 0.3396],
        [0.6604, 0.3396],
        [0.6617, 0.3383],
        [0.6572, 0.3428],
        [0.6605, 0.3395],
        [0.6576, 0.3424],
        [0.6616, 0.3384],
        [0.6604, 0.3396],
        [0.6628, 0.3372],
        [0.6484, 0.3516],
        [0.6616, 0.3384],
        [0.6596, 0.3404],
        [0.6620, 0.3380],
        [0.6621, 0.3379],
        [0.6615, 0.3385],
        [0.6636, 0.3364],
        [0.6611, 0.3389],
        [0.6630, 0.3370],
        [0.6619, 0.3381],
        [0.6569, 0.3431],
        [0.6617, 0.3383],
        [0.6584, 0.3416],
        [0.6594, 0.3406],
        [0.6607, 0.3393],
        [0.6594, 0.3406],
        [0.6581, 0.3419],
        [0.6578, 0.3422],
        [0.6621, 0.3379],
        [0.6623, 0.3377],
        [0.6615, 0.3385],
        [0.6603, 0.3397],
        [0.6616, 0.3384],
        [0.6599, 0.3401],
        [0.6612, 0.3388],
        [0.6606, 0.3394],
        [0.6587, 0.3413],
        [0.6619, 0.3381],
        [0.6611, 0.3389],
        [0.6604, 0.3396],
        [0.6602, 0.3398],
        [0.6616, 0.3384],
        [0.6596, 0.3404],
        [0.6628, 0.3372],
        [0.6584, 0.3416],
        [0.6595, 0.3405],
        [0.6578, 0.3422],
        [0.6611, 0.3389],
        [0.6581, 0.3419],
        [0.6603, 0.3397],
        [0.6611, 0.3389],
        [0.6580, 0.3420],
        [0.6601, 0.3399],
        [0.6583, 0.3417],
        [0.6621, 0.3379],
        [0.6641, 0.3359]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0028 loss: 0.6700 acc_train: 0.6103 time: 0.1932s
tensor([[0.6585, 0.3415],
        [0.6609, 0.3391],
        [0.6605, 0.3395],
        [0.6593, 0.3407],
        [0.6594, 0.3406],
        [0.6591, 0.3409],
        [0.6563, 0.3437],
        [0.6586, 0.3414],
        [0.6598, 0.3402],
        [0.6573, 0.3427],
        [0.6603, 0.3397],
        [0.6603, 0.3397],
        [0.6585, 0.3415],
        [0.6587, 0.3413],
        [0.6598, 0.3402],
        [0.6585, 0.3415],
        [0.6613, 0.3387],
        [0.6609, 0.3391],
        [0.6580, 0.3420],
        [0.6574, 0.3426],
        [0.6612, 0.3388],
        [0.6572, 0.3428],
        [0.6607, 0.3393],
        [0.6613, 0.3387],
        [0.6602, 0.3398],
        [0.6593, 0.3407],
        [0.6565, 0.3435],
        [0.6608, 0.3392],
        [0.6568, 0.3432],
        [0.6585, 0.3415],
        [0.6589, 0.3411],
        [0.6588, 0.3412],
        [0.6598, 0.3402],
        [0.6577, 0.3423],
        [0.6589, 0.3411],
        [0.6502, 0.3498],
        [0.6574, 0.3426],
        [0.6582, 0.3418],
        [0.6609, 0.3391],
        [0.6575, 0.3425],
        [0.6601, 0.3399],
        [0.6591, 0.3409],
        [0.6481, 0.3519],
        [0.6597, 0.3403],
        [0.6603, 0.3397],
        [0.6587, 0.3413],
        [0.6615, 0.3385],
        [0.6612, 0.3388],
        [0.6590, 0.3410],
        [0.6603, 0.3397],
        [0.6589, 0.3411],
        [0.6602, 0.3398],
        [0.6587, 0.3413],
        [0.6604, 0.3396],
        [0.6604, 0.3396],
        [0.6595, 0.3405],
        [0.6597, 0.3403],
        [0.6592, 0.3408],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6586, 0.3414],
        [0.6604, 0.3396],
        [0.6587, 0.3413],
        [0.6576, 0.3424],
        [0.6607, 0.3393],
        [0.6593, 0.3407],
        [0.6601, 0.3399],
        [0.6598, 0.3402],
        [0.6591, 0.3409],
        [0.6584, 0.3416],
        [0.6601, 0.3399],
        [0.6595, 0.3405],
        [0.6590, 0.3410],
        [0.6585, 0.3415],
        [0.6605, 0.3395],
        [0.6584, 0.3416],
        [0.6590, 0.3410],
        [0.6579, 0.3421],
        [0.6568, 0.3432],
        [0.6579, 0.3421],
        [0.6587, 0.3413],
        [0.6573, 0.3427],
        [0.6580, 0.3420],
        [0.6591, 0.3409],
        [0.6590, 0.3410],
        [0.6589, 0.3411],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6595, 0.3405],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6585, 0.3415],
        [0.6611, 0.3389],
        [0.6613, 0.3387],
        [0.6578, 0.3422],
        [0.6590, 0.3410],
        [0.6585, 0.3415],
        [0.6597, 0.3403],
        [0.6595, 0.3405],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6605, 0.3395],
        [0.6585, 0.3415],
        [0.6609, 0.3391],
        [0.6611, 0.3389],
        [0.6581, 0.3419],
        [0.6596, 0.3404],
        [0.6493, 0.3507],
        [0.6602, 0.3398],
        [0.6599, 0.3401],
        [0.6591, 0.3409],
        [0.6572, 0.3428],
        [0.6482, 0.3518],
        [0.6598, 0.3402],
        [0.6595, 0.3405],
        [0.6609, 0.3391],
        [0.6602, 0.3398],
        [0.6603, 0.3397],
        [0.6591, 0.3409],
        [0.6595, 0.3405],
        [0.6597, 0.3403],
        [0.6589, 0.3411],
        [0.6595, 0.3405],
        [0.6582, 0.3418],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6595, 0.3405],
        [0.6584, 0.3416],
        [0.6598, 0.3402],
        [0.6570, 0.3430],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6578, 0.3422],
        [0.6605, 0.3395],
        [0.6582, 0.3418],
        [0.6579, 0.3421],
        [0.6594, 0.3406],
        [0.6591, 0.3409],
        [0.6580, 0.3420],
        [0.6583, 0.3417],
        [0.6580, 0.3420],
        [0.6603, 0.3397],
        [0.6594, 0.3406],
        [0.6577, 0.3423],
        [0.6607, 0.3393],
        [0.6603, 0.3397],
        [0.6590, 0.3410],
        [0.6607, 0.3393],
        [0.6597, 0.3403],
        [0.6599, 0.3401],
        [0.6604, 0.3396],
        [0.6588, 0.3412],
        [0.6605, 0.3395],
        [0.6603, 0.3397],
        [0.6584, 0.3416],
        [0.6587, 0.3413],
        [0.6597, 0.3403],
        [0.6603, 0.3397],
        [0.6568, 0.3432],
        [0.6582, 0.3418],
        [0.6502, 0.3498],
        [0.6584, 0.3416],
        [0.6605, 0.3395],
        [0.6572, 0.3428],
        [0.6592, 0.3408],
        [0.6575, 0.3425],
        [0.6494, 0.3506],
        [0.6582, 0.3418],
        [0.6589, 0.3411],
        [0.6573, 0.3427],
        [0.6591, 0.3409],
        [0.6602, 0.3398],
        [0.6606, 0.3394],
        [0.6586, 0.3414],
        [0.6581, 0.3419],
        [0.6602, 0.3398],
        [0.6611, 0.3389],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6569, 0.3431],
        [0.6587, 0.3413],
        [0.6603, 0.3397],
        [0.6553, 0.3447],
        [0.6570, 0.3430],
        [0.6583, 0.3417],
        [0.6594, 0.3406],
        [0.6616, 0.3384],
        [0.6582, 0.3418],
        [0.6588, 0.3412],
        [0.6573, 0.3427],
        [0.6605, 0.3395],
        [0.6608, 0.3392],
        [0.6600, 0.3400],
        [0.6591, 0.3409],
        [0.6598, 0.3402],
        [0.6601, 0.3399],
        [0.6584, 0.3416],
        [0.6617, 0.3383],
        [0.6590, 0.3410],
        [0.6581, 0.3419],
        [0.6599, 0.3401],
        [0.6596, 0.3404],
        [0.6615, 0.3385],
        [0.6604, 0.3396],
        [0.6567, 0.3433],
        [0.6577, 0.3423],
        [0.6610, 0.3390],
        [0.6579, 0.3421],
        [0.6599, 0.3401],
        [0.6589, 0.3411],
        [0.6598, 0.3402],
        [0.6616, 0.3384],
        [0.6582, 0.3418],
        [0.6597, 0.3403],
        [0.6597, 0.3403],
        [0.6607, 0.3393],
        [0.6572, 0.3428],
        [0.6594, 0.3406],
        [0.6574, 0.3426],
        [0.6606, 0.3394],
        [0.6597, 0.3403],
        [0.6613, 0.3387],
        [0.6485, 0.3515],
        [0.6603, 0.3397],
        [0.6591, 0.3409],
        [0.6608, 0.3392],
        [0.6608, 0.3392],
        [0.6605, 0.3395],
        [0.6621, 0.3379],
        [0.6600, 0.3400],
        [0.6616, 0.3384],
        [0.6610, 0.3390],
        [0.6570, 0.3430],
        [0.6607, 0.3393],
        [0.6580, 0.3420],
        [0.6590, 0.3410],
        [0.6597, 0.3403],
        [0.6589, 0.3411],
        [0.6579, 0.3421],
        [0.6576, 0.3424],
        [0.6608, 0.3392],
        [0.6610, 0.3390],
        [0.6606, 0.3394],
        [0.6595, 0.3405],
        [0.6608, 0.3392],
        [0.6592, 0.3408],
        [0.6601, 0.3399],
        [0.6596, 0.3404],
        [0.6583, 0.3417],
        [0.6610, 0.3390],
        [0.6602, 0.3398],
        [0.6597, 0.3403],
        [0.6593, 0.3407],
        [0.6606, 0.3394],
        [0.6590, 0.3410],
        [0.6614, 0.3386],
        [0.6581, 0.3419],
        [0.6594, 0.3406],
        [0.6576, 0.3424],
        [0.6602, 0.3398],
        [0.6580, 0.3420],
        [0.6595, 0.3405],
        [0.6602, 0.3398],
        [0.6578, 0.3422],
        [0.6595, 0.3405],
        [0.6580, 0.3420],
        [0.6609, 0.3391],
        [0.6626, 0.3374]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0029 loss: 0.6702 acc_train: 0.6103 time: 0.1715s
tensor([[0.6580, 0.3420],
        [0.6602, 0.3398],
        [0.6596, 0.3404],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6565, 0.3435],
        [0.6581, 0.3419],
        [0.6592, 0.3408],
        [0.6573, 0.3427],
        [0.6594, 0.3406],
        [0.6595, 0.3405],
        [0.6582, 0.3418],
        [0.6585, 0.3415],
        [0.6591, 0.3409],
        [0.6581, 0.3419],
        [0.6604, 0.3396],
        [0.6601, 0.3399],
        [0.6577, 0.3423],
        [0.6572, 0.3428],
        [0.6603, 0.3397],
        [0.6569, 0.3431],
        [0.6598, 0.3402],
        [0.6603, 0.3397],
        [0.6595, 0.3405],
        [0.6587, 0.3413],
        [0.6564, 0.3436],
        [0.6599, 0.3401],
        [0.6567, 0.3433],
        [0.6581, 0.3419],
        [0.6583, 0.3417],
        [0.6586, 0.3414],
        [0.6591, 0.3409],
        [0.6572, 0.3428],
        [0.6584, 0.3416],
        [0.6498, 0.3502],
        [0.6573, 0.3427],
        [0.6578, 0.3422],
        [0.6600, 0.3400],
        [0.6574, 0.3426],
        [0.6595, 0.3405],
        [0.6585, 0.3415],
        [0.6481, 0.3519],
        [0.6591, 0.3409],
        [0.6597, 0.3403],
        [0.6582, 0.3418],
        [0.6606, 0.3394],
        [0.6603, 0.3397],
        [0.6585, 0.3415],
        [0.6595, 0.3405],
        [0.6585, 0.3415],
        [0.6594, 0.3406],
        [0.6583, 0.3417],
        [0.6598, 0.3402],
        [0.6594, 0.3406],
        [0.6590, 0.3410],
        [0.6591, 0.3409],
        [0.6586, 0.3414],
        [0.6577, 0.3423],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6596, 0.3404],
        [0.6583, 0.3417],
        [0.6575, 0.3425],
        [0.6599, 0.3401],
        [0.6585, 0.3415],
        [0.6594, 0.3406],
        [0.6592, 0.3408],
        [0.6585, 0.3415],
        [0.6581, 0.3419],
        [0.6592, 0.3408],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6581, 0.3419],
        [0.6597, 0.3403],
        [0.6579, 0.3421],
        [0.6585, 0.3415],
        [0.6577, 0.3423],
        [0.6567, 0.3433],
        [0.6576, 0.3424],
        [0.6583, 0.3417],
        [0.6572, 0.3428],
        [0.6577, 0.3423],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6578, 0.3422],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6588, 0.3412],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6582, 0.3418],
        [0.6602, 0.3398],
        [0.6603, 0.3397],
        [0.6575, 0.3425],
        [0.6585, 0.3415],
        [0.6579, 0.3421],
        [0.6591, 0.3409],
        [0.6589, 0.3411],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6596, 0.3404],
        [0.6580, 0.3420],
        [0.6600, 0.3400],
        [0.6601, 0.3399],
        [0.6579, 0.3421],
        [0.6591, 0.3409],
        [0.6488, 0.3512],
        [0.6595, 0.3405],
        [0.6592, 0.3408],
        [0.6586, 0.3414],
        [0.6572, 0.3428],
        [0.6482, 0.3518],
        [0.6592, 0.3408],
        [0.6589, 0.3411],
        [0.6600, 0.3400],
        [0.6596, 0.3404],
        [0.6594, 0.3406],
        [0.6585, 0.3415],
        [0.6588, 0.3412],
        [0.6591, 0.3409],
        [0.6585, 0.3415],
        [0.6589, 0.3411],
        [0.6578, 0.3422],
        [0.6585, 0.3415],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6589, 0.3411],
        [0.6581, 0.3419],
        [0.6590, 0.3410],
        [0.6569, 0.3431],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6576, 0.3424],
        [0.6597, 0.3403],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6588, 0.3412],
        [0.6586, 0.3414],
        [0.6577, 0.3423],
        [0.6580, 0.3420],
        [0.6577, 0.3423],
        [0.6596, 0.3404],
        [0.6587, 0.3413],
        [0.6575, 0.3425],
        [0.6598, 0.3402],
        [0.6595, 0.3405],
        [0.6586, 0.3414],
        [0.6598, 0.3402],
        [0.6589, 0.3411],
        [0.6590, 0.3410],
        [0.6595, 0.3405],
        [0.6583, 0.3417],
        [0.6597, 0.3403],
        [0.6595, 0.3405],
        [0.6580, 0.3420],
        [0.6582, 0.3418],
        [0.6590, 0.3410],
        [0.6595, 0.3405],
        [0.6569, 0.3431],
        [0.6579, 0.3421],
        [0.6497, 0.3503],
        [0.6582, 0.3418],
        [0.6597, 0.3403],
        [0.6569, 0.3431],
        [0.6588, 0.3412],
        [0.6574, 0.3426],
        [0.6491, 0.3509],
        [0.6579, 0.3421],
        [0.6585, 0.3415],
        [0.6573, 0.3427],
        [0.6586, 0.3414],
        [0.6593, 0.3407],
        [0.6596, 0.3404],
        [0.6583, 0.3417],
        [0.6579, 0.3421],
        [0.6594, 0.3406],
        [0.6601, 0.3399],
        [0.6576, 0.3424],
        [0.6574, 0.3426],
        [0.6568, 0.3432],
        [0.6584, 0.3416],
        [0.6594, 0.3406],
        [0.6555, 0.3445],
        [0.6569, 0.3431],
        [0.6579, 0.3421],
        [0.6589, 0.3411],
        [0.6606, 0.3394],
        [0.6579, 0.3421],
        [0.6584, 0.3416],
        [0.6571, 0.3429],
        [0.6596, 0.3404],
        [0.6600, 0.3400],
        [0.6592, 0.3408],
        [0.6586, 0.3414],
        [0.6591, 0.3409],
        [0.6592, 0.3408],
        [0.6581, 0.3419],
        [0.6605, 0.3395],
        [0.6585, 0.3415],
        [0.6579, 0.3421],
        [0.6591, 0.3409],
        [0.6590, 0.3410],
        [0.6606, 0.3394],
        [0.6597, 0.3403],
        [0.6566, 0.3434],
        [0.6575, 0.3425],
        [0.6602, 0.3398],
        [0.6577, 0.3423],
        [0.6593, 0.3407],
        [0.6584, 0.3416],
        [0.6590, 0.3410],
        [0.6605, 0.3395],
        [0.6579, 0.3421],
        [0.6592, 0.3408],
        [0.6592, 0.3408],
        [0.6598, 0.3402],
        [0.6571, 0.3429],
        [0.6586, 0.3414],
        [0.6572, 0.3428],
        [0.6598, 0.3402],
        [0.6590, 0.3410],
        [0.6603, 0.3397],
        [0.6486, 0.3514],
        [0.6593, 0.3407],
        [0.6587, 0.3413],
        [0.6599, 0.3401],
        [0.6599, 0.3401],
        [0.6598, 0.3402],
        [0.6610, 0.3390],
        [0.6593, 0.3407],
        [0.6606, 0.3394],
        [0.6602, 0.3398],
        [0.6570, 0.3430],
        [0.6598, 0.3402],
        [0.6577, 0.3423],
        [0.6586, 0.3414],
        [0.6590, 0.3410],
        [0.6584, 0.3416],
        [0.6577, 0.3423],
        [0.6574, 0.3426],
        [0.6598, 0.3402],
        [0.6601, 0.3399],
        [0.6599, 0.3401],
        [0.6588, 0.3412],
        [0.6601, 0.3399],
        [0.6586, 0.3414],
        [0.6592, 0.3408],
        [0.6588, 0.3412],
        [0.6579, 0.3421],
        [0.6601, 0.3399],
        [0.6595, 0.3405],
        [0.6590, 0.3410],
        [0.6586, 0.3414],
        [0.6598, 0.3402],
        [0.6585, 0.3415],
        [0.6603, 0.3397],
        [0.6577, 0.3423],
        [0.6592, 0.3408],
        [0.6573, 0.3427],
        [0.6594, 0.3406],
        [0.6578, 0.3422],
        [0.6589, 0.3411],
        [0.6594, 0.3406],
        [0.6576, 0.3424],
        [0.6589, 0.3411],
        [0.6576, 0.3424],
        [0.6599, 0.3401],
        [0.6613, 0.3387]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0030 loss: 0.6704 acc_train: 0.6103 time: 0.1391s
tensor([[0.6576, 0.3424],
        [0.6596, 0.3404],
        [0.6590, 0.3410],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6565, 0.3435],
        [0.6578, 0.3422],
        [0.6587, 0.3413],
        [0.6573, 0.3427],
        [0.6587, 0.3413],
        [0.6589, 0.3411],
        [0.6580, 0.3420],
        [0.6582, 0.3418],
        [0.6585, 0.3415],
        [0.6578, 0.3422],
        [0.6596, 0.3404],
        [0.6595, 0.3405],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6596, 0.3404],
        [0.6568, 0.3432],
        [0.6592, 0.3408],
        [0.6595, 0.3405],
        [0.6590, 0.3410],
        [0.6583, 0.3417],
        [0.6564, 0.3436],
        [0.6592, 0.3408],
        [0.6565, 0.3435],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6583, 0.3417],
        [0.6586, 0.3414],
        [0.6569, 0.3431],
        [0.6579, 0.3421],
        [0.6496, 0.3504],
        [0.6572, 0.3428],
        [0.6576, 0.3424],
        [0.6594, 0.3406],
        [0.6573, 0.3427],
        [0.6590, 0.3410],
        [0.6580, 0.3420],
        [0.6483, 0.3517],
        [0.6586, 0.3414],
        [0.6591, 0.3409],
        [0.6579, 0.3421],
        [0.6599, 0.3401],
        [0.6596, 0.3404],
        [0.6581, 0.3419],
        [0.6589, 0.3411],
        [0.6582, 0.3418],
        [0.6588, 0.3412],
        [0.6579, 0.3421],
        [0.6593, 0.3407],
        [0.6588, 0.3412],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6582, 0.3418],
        [0.6575, 0.3425],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6590, 0.3410],
        [0.6579, 0.3421],
        [0.6574, 0.3426],
        [0.6592, 0.3408],
        [0.6580, 0.3420],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6581, 0.3419],
        [0.6579, 0.3421],
        [0.6587, 0.3413],
        [0.6580, 0.3420],
        [0.6583, 0.3417],
        [0.6579, 0.3421],
        [0.6591, 0.3409],
        [0.6576, 0.3424],
        [0.6581, 0.3419],
        [0.6575, 0.3425],
        [0.6567, 0.3433],
        [0.6574, 0.3426],
        [0.6579, 0.3421],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6579, 0.3421],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6576, 0.3424],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6584, 0.3416],
        [0.6579, 0.3421],
        [0.6577, 0.3423],
        [0.6580, 0.3420],
        [0.6595, 0.3405],
        [0.6597, 0.3403],
        [0.6572, 0.3428],
        [0.6581, 0.3419],
        [0.6574, 0.3426],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6590, 0.3410],
        [0.6577, 0.3423],
        [0.6593, 0.3407],
        [0.6594, 0.3406],
        [0.6578, 0.3422],
        [0.6587, 0.3413],
        [0.6486, 0.3514],
        [0.6590, 0.3410],
        [0.6587, 0.3413],
        [0.6583, 0.3417],
        [0.6572, 0.3428],
        [0.6483, 0.3517],
        [0.6588, 0.3412],
        [0.6585, 0.3415],
        [0.6594, 0.3406],
        [0.6591, 0.3409],
        [0.6587, 0.3413],
        [0.6581, 0.3419],
        [0.6583, 0.3417],
        [0.6587, 0.3413],
        [0.6582, 0.3418],
        [0.6584, 0.3416],
        [0.6574, 0.3426],
        [0.6582, 0.3418],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6585, 0.3415],
        [0.6578, 0.3422],
        [0.6585, 0.3415],
        [0.6568, 0.3432],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6574, 0.3426],
        [0.6591, 0.3409],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6574, 0.3426],
        [0.6577, 0.3423],
        [0.6574, 0.3426],
        [0.6590, 0.3410],
        [0.6582, 0.3418],
        [0.6573, 0.3427],
        [0.6591, 0.3409],
        [0.6590, 0.3410],
        [0.6582, 0.3418],
        [0.6591, 0.3409],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6589, 0.3411],
        [0.6579, 0.3421],
        [0.6592, 0.3408],
        [0.6589, 0.3411],
        [0.6577, 0.3423],
        [0.6579, 0.3421],
        [0.6584, 0.3416],
        [0.6589, 0.3411],
        [0.6569, 0.3431],
        [0.6577, 0.3423],
        [0.6495, 0.3505],
        [0.6580, 0.3420],
        [0.6591, 0.3409],
        [0.6567, 0.3433],
        [0.6585, 0.3415],
        [0.6573, 0.3427],
        [0.6490, 0.3510],
        [0.6576, 0.3424],
        [0.6582, 0.3418],
        [0.6573, 0.3427],
        [0.6583, 0.3417],
        [0.6587, 0.3413],
        [0.6589, 0.3411],
        [0.6581, 0.3419],
        [0.6578, 0.3422],
        [0.6588, 0.3412],
        [0.6594, 0.3406],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6567, 0.3433],
        [0.6582, 0.3418],
        [0.6588, 0.3412],
        [0.6556, 0.3444],
        [0.6568, 0.3432],
        [0.6576, 0.3424],
        [0.6585, 0.3415],
        [0.6598, 0.3402],
        [0.6577, 0.3423],
        [0.6581, 0.3419],
        [0.6570, 0.3430],
        [0.6589, 0.3411],
        [0.6594, 0.3406],
        [0.6587, 0.3413],
        [0.6582, 0.3418],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6579, 0.3421],
        [0.6596, 0.3404],
        [0.6581, 0.3419],
        [0.6577, 0.3423],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6599, 0.3401],
        [0.6592, 0.3408],
        [0.6565, 0.3435],
        [0.6574, 0.3426],
        [0.6595, 0.3405],
        [0.6575, 0.3425],
        [0.6588, 0.3412],
        [0.6579, 0.3421],
        [0.6584, 0.3416],
        [0.6598, 0.3402],
        [0.6577, 0.3423],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6592, 0.3408],
        [0.6571, 0.3429],
        [0.6580, 0.3420],
        [0.6571, 0.3429],
        [0.6593, 0.3407],
        [0.6585, 0.3415],
        [0.6595, 0.3405],
        [0.6488, 0.3512],
        [0.6587, 0.3413],
        [0.6584, 0.3416],
        [0.6593, 0.3407],
        [0.6592, 0.3408],
        [0.6592, 0.3408],
        [0.6602, 0.3398],
        [0.6587, 0.3413],
        [0.6598, 0.3402],
        [0.6596, 0.3404],
        [0.6568, 0.3432],
        [0.6592, 0.3408],
        [0.6574, 0.3426],
        [0.6581, 0.3419],
        [0.6584, 0.3416],
        [0.6580, 0.3420],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6590, 0.3410],
        [0.6594, 0.3406],
        [0.6594, 0.3406],
        [0.6584, 0.3416],
        [0.6596, 0.3404],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6576, 0.3424],
        [0.6595, 0.3405],
        [0.6589, 0.3411],
        [0.6584, 0.3416],
        [0.6580, 0.3420],
        [0.6592, 0.3408],
        [0.6581, 0.3419],
        [0.6596, 0.3404],
        [0.6575, 0.3425],
        [0.6589, 0.3411],
        [0.6572, 0.3428],
        [0.6589, 0.3411],
        [0.6576, 0.3424],
        [0.6585, 0.3415],
        [0.6587, 0.3413],
        [0.6575, 0.3425],
        [0.6585, 0.3415],
        [0.6573, 0.3427],
        [0.6592, 0.3408],
        [0.6603, 0.3397]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0031 loss: 0.6705 acc_train: 0.6103 time: 0.1426s
tensor([[0.6574, 0.3426],
        [0.6592, 0.3408],
        [0.6586, 0.3414],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6566, 0.3434],
        [0.6575, 0.3425],
        [0.6583, 0.3417],
        [0.6572, 0.3428],
        [0.6582, 0.3418],
        [0.6585, 0.3415],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6581, 0.3419],
        [0.6576, 0.3424],
        [0.6591, 0.3409],
        [0.6590, 0.3410],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6592, 0.3408],
        [0.6567, 0.3433],
        [0.6587, 0.3413],
        [0.6589, 0.3411],
        [0.6586, 0.3414],
        [0.6580, 0.3420],
        [0.6564, 0.3436],
        [0.6587, 0.3413],
        [0.6565, 0.3435],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6568, 0.3432],
        [0.6576, 0.3424],
        [0.6494, 0.3506],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6589, 0.3411],
        [0.6572, 0.3428],
        [0.6586, 0.3414],
        [0.6577, 0.3423],
        [0.6485, 0.3515],
        [0.6581, 0.3419],
        [0.6585, 0.3415],
        [0.6578, 0.3422],
        [0.6594, 0.3406],
        [0.6589, 0.3411],
        [0.6578, 0.3422],
        [0.6586, 0.3414],
        [0.6580, 0.3420],
        [0.6584, 0.3416],
        [0.6576, 0.3424],
        [0.6589, 0.3411],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6579, 0.3421],
        [0.6573, 0.3427],
        [0.6576, 0.3424],
        [0.6574, 0.3426],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6585, 0.3415],
        [0.6577, 0.3423],
        [0.6573, 0.3427],
        [0.6586, 0.3414],
        [0.6576, 0.3424],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6583, 0.3417],
        [0.6575, 0.3425],
        [0.6580, 0.3420],
        [0.6576, 0.3424],
        [0.6588, 0.3412],
        [0.6573, 0.3427],
        [0.6578, 0.3422],
        [0.6574, 0.3426],
        [0.6567, 0.3433],
        [0.6573, 0.3427],
        [0.6576, 0.3424],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6580, 0.3420],
        [0.6578, 0.3422],
        [0.6575, 0.3425],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6580, 0.3420],
        [0.6578, 0.3422],
        [0.6575, 0.3425],
        [0.6578, 0.3422],
        [0.6589, 0.3411],
        [0.6592, 0.3408],
        [0.6570, 0.3430],
        [0.6578, 0.3422],
        [0.6570, 0.3430],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6585, 0.3415],
        [0.6575, 0.3425],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6577, 0.3423],
        [0.6583, 0.3417],
        [0.6486, 0.3514],
        [0.6586, 0.3414],
        [0.6583, 0.3417],
        [0.6581, 0.3419],
        [0.6572, 0.3428],
        [0.6484, 0.3516],
        [0.6585, 0.3415],
        [0.6581, 0.3419],
        [0.6589, 0.3411],
        [0.6587, 0.3413],
        [0.6583, 0.3417],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6583, 0.3417],
        [0.6579, 0.3421],
        [0.6581, 0.3419],
        [0.6571, 0.3429],
        [0.6579, 0.3421],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6582, 0.3418],
        [0.6576, 0.3424],
        [0.6581, 0.3419],
        [0.6568, 0.3432],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6573, 0.3427],
        [0.6586, 0.3414],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6576, 0.3424],
        [0.6579, 0.3421],
        [0.6571, 0.3429],
        [0.6575, 0.3425],
        [0.6572, 0.3428],
        [0.6587, 0.3413],
        [0.6579, 0.3421],
        [0.6571, 0.3429],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6578, 0.3422],
        [0.6587, 0.3413],
        [0.6580, 0.3420],
        [0.6582, 0.3418],
        [0.6584, 0.3416],
        [0.6577, 0.3423],
        [0.6588, 0.3412],
        [0.6584, 0.3416],
        [0.6574, 0.3426],
        [0.6576, 0.3424],
        [0.6579, 0.3421],
        [0.6584, 0.3416],
        [0.6569, 0.3431],
        [0.6575, 0.3425],
        [0.6494, 0.3506],
        [0.6577, 0.3423],
        [0.6586, 0.3414],
        [0.6566, 0.3434],
        [0.6583, 0.3417],
        [0.6571, 0.3429],
        [0.6490, 0.3510],
        [0.6574, 0.3426],
        [0.6579, 0.3421],
        [0.6572, 0.3428],
        [0.6580, 0.3420],
        [0.6582, 0.3418],
        [0.6584, 0.3416],
        [0.6579, 0.3421],
        [0.6576, 0.3424],
        [0.6583, 0.3417],
        [0.6589, 0.3411],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6566, 0.3434],
        [0.6579, 0.3421],
        [0.6584, 0.3416],
        [0.6557, 0.3443],
        [0.6568, 0.3432],
        [0.6574, 0.3426],
        [0.6582, 0.3418],
        [0.6592, 0.3408],
        [0.6575, 0.3425],
        [0.6579, 0.3421],
        [0.6569, 0.3431],
        [0.6583, 0.3417],
        [0.6589, 0.3411],
        [0.6583, 0.3417],
        [0.6579, 0.3421],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6576, 0.3424],
        [0.6590, 0.3410],
        [0.6579, 0.3421],
        [0.6575, 0.3425],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6594, 0.3406],
        [0.6589, 0.3411],
        [0.6565, 0.3435],
        [0.6572, 0.3428],
        [0.6590, 0.3410],
        [0.6573, 0.3427],
        [0.6585, 0.3415],
        [0.6576, 0.3424],
        [0.6580, 0.3420],
        [0.6593, 0.3407],
        [0.6576, 0.3424],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6588, 0.3412],
        [0.6570, 0.3430],
        [0.6576, 0.3424],
        [0.6570, 0.3430],
        [0.6589, 0.3411],
        [0.6582, 0.3418],
        [0.6589, 0.3411],
        [0.6489, 0.3511],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6589, 0.3411],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6597, 0.3403],
        [0.6584, 0.3416],
        [0.6593, 0.3407],
        [0.6591, 0.3409],
        [0.6567, 0.3433],
        [0.6587, 0.3413],
        [0.6573, 0.3427],
        [0.6576, 0.3424],
        [0.6581, 0.3419],
        [0.6577, 0.3423],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6585, 0.3415],
        [0.6589, 0.3411],
        [0.6590, 0.3410],
        [0.6580, 0.3420],
        [0.6592, 0.3408],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6574, 0.3426],
        [0.6590, 0.3410],
        [0.6584, 0.3416],
        [0.6581, 0.3419],
        [0.6576, 0.3424],
        [0.6587, 0.3413],
        [0.6578, 0.3422],
        [0.6590, 0.3410],
        [0.6573, 0.3427],
        [0.6586, 0.3414],
        [0.6570, 0.3430],
        [0.6585, 0.3415],
        [0.6575, 0.3425],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6574, 0.3426],
        [0.6582, 0.3418],
        [0.6571, 0.3429],
        [0.6587, 0.3413],
        [0.6596, 0.3404]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0032 loss: 0.6706 acc_train: 0.6103 time: 0.1413s
tensor([[0.6572, 0.3428],
        [0.6588, 0.3412],
        [0.6583, 0.3417],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6566, 0.3434],
        [0.6573, 0.3427],
        [0.6580, 0.3420],
        [0.6572, 0.3428],
        [0.6579, 0.3421],
        [0.6581, 0.3419],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6575, 0.3425],
        [0.6587, 0.3413],
        [0.6585, 0.3415],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6588, 0.3412],
        [0.6567, 0.3433],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6578, 0.3422],
        [0.6564, 0.3436],
        [0.6583, 0.3417],
        [0.6565, 0.3435],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6567, 0.3433],
        [0.6574, 0.3426],
        [0.6494, 0.3506],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6586, 0.3414],
        [0.6571, 0.3429],
        [0.6583, 0.3417],
        [0.6576, 0.3424],
        [0.6487, 0.3513],
        [0.6578, 0.3422],
        [0.6581, 0.3419],
        [0.6576, 0.3424],
        [0.6589, 0.3411],
        [0.6584, 0.3416],
        [0.6576, 0.3424],
        [0.6584, 0.3416],
        [0.6579, 0.3421],
        [0.6581, 0.3419],
        [0.6574, 0.3426],
        [0.6585, 0.3415],
        [0.6581, 0.3419],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6577, 0.3423],
        [0.6571, 0.3429],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6582, 0.3418],
        [0.6575, 0.3425],
        [0.6572, 0.3428],
        [0.6582, 0.3418],
        [0.6574, 0.3426],
        [0.6582, 0.3418],
        [0.6580, 0.3420],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6581, 0.3419],
        [0.6572, 0.3428],
        [0.6578, 0.3422],
        [0.6575, 0.3425],
        [0.6585, 0.3415],
        [0.6571, 0.3429],
        [0.6576, 0.3424],
        [0.6573, 0.3427],
        [0.6567, 0.3433],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6578, 0.3422],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6568, 0.3432],
        [0.6569, 0.3431],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6573, 0.3427],
        [0.6577, 0.3423],
        [0.6585, 0.3415],
        [0.6589, 0.3411],
        [0.6569, 0.3431],
        [0.6575, 0.3425],
        [0.6568, 0.3432],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6582, 0.3418],
        [0.6574, 0.3426],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6576, 0.3424],
        [0.6581, 0.3419],
        [0.6487, 0.3513],
        [0.6584, 0.3416],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6571, 0.3429],
        [0.6486, 0.3514],
        [0.6582, 0.3418],
        [0.6579, 0.3421],
        [0.6586, 0.3414],
        [0.6584, 0.3416],
        [0.6579, 0.3421],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6581, 0.3419],
        [0.6577, 0.3423],
        [0.6579, 0.3421],
        [0.6569, 0.3431],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6580, 0.3420],
        [0.6574, 0.3426],
        [0.6578, 0.3422],
        [0.6568, 0.3432],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6573, 0.3427],
        [0.6583, 0.3417],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6577, 0.3423],
        [0.6569, 0.3431],
        [0.6574, 0.3426],
        [0.6570, 0.3430],
        [0.6584, 0.3416],
        [0.6577, 0.3423],
        [0.6570, 0.3430],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6576, 0.3424],
        [0.6584, 0.3416],
        [0.6578, 0.3422],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6576, 0.3424],
        [0.6585, 0.3415],
        [0.6581, 0.3419],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6581, 0.3419],
        [0.6569, 0.3431],
        [0.6574, 0.3426],
        [0.6494, 0.3506],
        [0.6575, 0.3425],
        [0.6583, 0.3417],
        [0.6564, 0.3436],
        [0.6582, 0.3418],
        [0.6571, 0.3429],
        [0.6490, 0.3510],
        [0.6573, 0.3427],
        [0.6578, 0.3422],
        [0.6572, 0.3428],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6581, 0.3419],
        [0.6578, 0.3422],
        [0.6575, 0.3425],
        [0.6580, 0.3420],
        [0.6585, 0.3415],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6567, 0.3433],
        [0.6578, 0.3422],
        [0.6581, 0.3419],
        [0.6559, 0.3441],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6580, 0.3420],
        [0.6587, 0.3413],
        [0.6573, 0.3427],
        [0.6577, 0.3423],
        [0.6568, 0.3432],
        [0.6580, 0.3420],
        [0.6585, 0.3415],
        [0.6581, 0.3419],
        [0.6576, 0.3424],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6575, 0.3425],
        [0.6585, 0.3415],
        [0.6577, 0.3423],
        [0.6574, 0.3426],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6591, 0.3409],
        [0.6586, 0.3414],
        [0.6565, 0.3435],
        [0.6571, 0.3429],
        [0.6587, 0.3413],
        [0.6572, 0.3428],
        [0.6583, 0.3417],
        [0.6573, 0.3427],
        [0.6577, 0.3423],
        [0.6589, 0.3411],
        [0.6575, 0.3425],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6570, 0.3430],
        [0.6586, 0.3414],
        [0.6579, 0.3421],
        [0.6585, 0.3415],
        [0.6489, 0.3511],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6586, 0.3414],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6593, 0.3407],
        [0.6582, 0.3418],
        [0.6589, 0.3411],
        [0.6587, 0.3413],
        [0.6565, 0.3435],
        [0.6584, 0.3416],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6579, 0.3421],
        [0.6575, 0.3425],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6581, 0.3419],
        [0.6585, 0.3415],
        [0.6587, 0.3413],
        [0.6578, 0.3422],
        [0.6588, 0.3412],
        [0.6578, 0.3422],
        [0.6575, 0.3425],
        [0.6579, 0.3421],
        [0.6573, 0.3427],
        [0.6586, 0.3414],
        [0.6581, 0.3419],
        [0.6578, 0.3422],
        [0.6573, 0.3427],
        [0.6584, 0.3416],
        [0.6576, 0.3424],
        [0.6587, 0.3413],
        [0.6572, 0.3428],
        [0.6583, 0.3417],
        [0.6570, 0.3430],
        [0.6582, 0.3418],
        [0.6574, 0.3426],
        [0.6581, 0.3419],
        [0.6578, 0.3422],
        [0.6573, 0.3427],
        [0.6580, 0.3420],
        [0.6570, 0.3430],
        [0.6583, 0.3417],
        [0.6590, 0.3410]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0033 loss: 0.6706 acc_train: 0.6103 time: 0.1354s
tensor([[0.6571, 0.3429],
        [0.6585, 0.3415],
        [0.6581, 0.3419],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6566, 0.3434],
        [0.6572, 0.3428],
        [0.6578, 0.3422],
        [0.6571, 0.3429],
        [0.6577, 0.3423],
        [0.6579, 0.3421],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6574, 0.3426],
        [0.6583, 0.3417],
        [0.6581, 0.3419],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6584, 0.3416],
        [0.6567, 0.3433],
        [0.6581, 0.3419],
        [0.6581, 0.3419],
        [0.6581, 0.3419],
        [0.6576, 0.3424],
        [0.6564, 0.3436],
        [0.6581, 0.3419],
        [0.6565, 0.3435],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6567, 0.3433],
        [0.6572, 0.3428],
        [0.6494, 0.3506],
        [0.6568, 0.3432],
        [0.6572, 0.3428],
        [0.6584, 0.3416],
        [0.6570, 0.3430],
        [0.6580, 0.3420],
        [0.6574, 0.3426],
        [0.6489, 0.3511],
        [0.6576, 0.3424],
        [0.6578, 0.3422],
        [0.6575, 0.3425],
        [0.6586, 0.3414],
        [0.6581, 0.3419],
        [0.6575, 0.3425],
        [0.6582, 0.3418],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6572, 0.3428],
        [0.6582, 0.3418],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6575, 0.3425],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6579, 0.3421],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6579, 0.3421],
        [0.6573, 0.3427],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6579, 0.3421],
        [0.6570, 0.3430],
        [0.6577, 0.3423],
        [0.6573, 0.3427],
        [0.6583, 0.3417],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6568, 0.3432],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6576, 0.3424],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6568, 0.3432],
        [0.6568, 0.3432],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6572, 0.3428],
        [0.6575, 0.3425],
        [0.6582, 0.3418],
        [0.6586, 0.3414],
        [0.6568, 0.3432],
        [0.6573, 0.3427],
        [0.6568, 0.3432],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6579, 0.3421],
        [0.6574, 0.3426],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6575, 0.3425],
        [0.6579, 0.3421],
        [0.6489, 0.3511],
        [0.6582, 0.3418],
        [0.6577, 0.3423],
        [0.6579, 0.3421],
        [0.6571, 0.3429],
        [0.6488, 0.3512],
        [0.6580, 0.3420],
        [0.6577, 0.3423],
        [0.6583, 0.3417],
        [0.6581, 0.3419],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6579, 0.3421],
        [0.6575, 0.3425],
        [0.6577, 0.3423],
        [0.6568, 0.3432],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6578, 0.3422],
        [0.6572, 0.3428],
        [0.6576, 0.3424],
        [0.6568, 0.3432],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6580, 0.3420],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6574, 0.3426],
        [0.6567, 0.3433],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6582, 0.3418],
        [0.6575, 0.3425],
        [0.6569, 0.3431],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6574, 0.3426],
        [0.6582, 0.3418],
        [0.6576, 0.3424],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6574, 0.3426],
        [0.6584, 0.3416],
        [0.6579, 0.3421],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6578, 0.3422],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6495, 0.3505],
        [0.6574, 0.3426],
        [0.6580, 0.3420],
        [0.6563, 0.3437],
        [0.6580, 0.3420],
        [0.6570, 0.3430],
        [0.6492, 0.3508],
        [0.6572, 0.3428],
        [0.6577, 0.3423],
        [0.6571, 0.3429],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6579, 0.3421],
        [0.6576, 0.3424],
        [0.6574, 0.3426],
        [0.6578, 0.3422],
        [0.6581, 0.3419],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6567, 0.3433],
        [0.6576, 0.3424],
        [0.6578, 0.3422],
        [0.6561, 0.3439],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6578, 0.3422],
        [0.6584, 0.3416],
        [0.6571, 0.3429],
        [0.6575, 0.3425],
        [0.6567, 0.3433],
        [0.6577, 0.3423],
        [0.6582, 0.3418],
        [0.6579, 0.3421],
        [0.6574, 0.3426],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6574, 0.3426],
        [0.6582, 0.3418],
        [0.6576, 0.3424],
        [0.6572, 0.3428],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6588, 0.3412],
        [0.6584, 0.3416],
        [0.6565, 0.3435],
        [0.6570, 0.3430],
        [0.6584, 0.3416],
        [0.6571, 0.3429],
        [0.6580, 0.3420],
        [0.6571, 0.3429],
        [0.6575, 0.3425],
        [0.6586, 0.3414],
        [0.6575, 0.3425],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6582, 0.3418],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6570, 0.3430],
        [0.6583, 0.3417],
        [0.6577, 0.3423],
        [0.6583, 0.3417],
        [0.6490, 0.3510],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6584, 0.3416],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6589, 0.3411],
        [0.6580, 0.3420],
        [0.6586, 0.3414],
        [0.6583, 0.3417],
        [0.6564, 0.3436],
        [0.6581, 0.3419],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6578, 0.3422],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6579, 0.3421],
        [0.6582, 0.3418],
        [0.6584, 0.3416],
        [0.6576, 0.3424],
        [0.6584, 0.3416],
        [0.6577, 0.3423],
        [0.6573, 0.3427],
        [0.6578, 0.3422],
        [0.6572, 0.3428],
        [0.6583, 0.3417],
        [0.6578, 0.3422],
        [0.6576, 0.3424],
        [0.6572, 0.3428],
        [0.6581, 0.3419],
        [0.6575, 0.3425],
        [0.6584, 0.3416],
        [0.6571, 0.3429],
        [0.6580, 0.3420],
        [0.6569, 0.3431],
        [0.6579, 0.3421],
        [0.6573, 0.3427],
        [0.6580, 0.3420],
        [0.6576, 0.3424],
        [0.6572, 0.3428],
        [0.6578, 0.3422],
        [0.6570, 0.3430],
        [0.6580, 0.3420],
        [0.6586, 0.3414]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0034 loss: 0.6707 acc_train: 0.6103 time: 0.1411s
tensor([[0.6570, 0.3430],
        [0.6582, 0.3418],
        [0.6579, 0.3421],
        [0.6574, 0.3426],
        [0.6576, 0.3424],
        [0.6573, 0.3427],
        [0.6567, 0.3433],
        [0.6571, 0.3429],
        [0.6576, 0.3424],
        [0.6570, 0.3430],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6580, 0.3420],
        [0.6578, 0.3422],
        [0.6569, 0.3431],
        [0.6570, 0.3430],
        [0.6581, 0.3419],
        [0.6567, 0.3433],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6574, 0.3426],
        [0.6564, 0.3436],
        [0.6579, 0.3421],
        [0.6565, 0.3435],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6576, 0.3424],
        [0.6567, 0.3433],
        [0.6571, 0.3429],
        [0.6494, 0.3506],
        [0.6567, 0.3433],
        [0.6571, 0.3429],
        [0.6581, 0.3419],
        [0.6569, 0.3431],
        [0.6578, 0.3422],
        [0.6573, 0.3427],
        [0.6491, 0.3509],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6583, 0.3417],
        [0.6578, 0.3422],
        [0.6573, 0.3427],
        [0.6580, 0.3420],
        [0.6576, 0.3424],
        [0.6578, 0.3422],
        [0.6571, 0.3429],
        [0.6579, 0.3421],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6574, 0.3426],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6577, 0.3423],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6576, 0.3424],
        [0.6572, 0.3428],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6577, 0.3423],
        [0.6568, 0.3432],
        [0.6575, 0.3425],
        [0.6571, 0.3429],
        [0.6581, 0.3419],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6568, 0.3432],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6567, 0.3433],
        [0.6567, 0.3433],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6579, 0.3421],
        [0.6583, 0.3417],
        [0.6567, 0.3433],
        [0.6572, 0.3428],
        [0.6567, 0.3433],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6577, 0.3423],
        [0.6574, 0.3426],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6574, 0.3426],
        [0.6577, 0.3423],
        [0.6491, 0.3509],
        [0.6580, 0.3420],
        [0.6575, 0.3425],
        [0.6577, 0.3423],
        [0.6570, 0.3430],
        [0.6489, 0.3511],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6580, 0.3420],
        [0.6578, 0.3422],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6577, 0.3423],
        [0.6573, 0.3427],
        [0.6576, 0.3424],
        [0.6567, 0.3433],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6576, 0.3424],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6568, 0.3432],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6578, 0.3422],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6566, 0.3434],
        [0.6572, 0.3428],
        [0.6567, 0.3433],
        [0.6571, 0.3429],
        [0.6568, 0.3432],
        [0.6579, 0.3421],
        [0.6574, 0.3426],
        [0.6568, 0.3432],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6572, 0.3428],
        [0.6580, 0.3420],
        [0.6574, 0.3426],
        [0.6578, 0.3422],
        [0.6576, 0.3424],
        [0.6573, 0.3427],
        [0.6582, 0.3418],
        [0.6578, 0.3422],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6576, 0.3424],
        [0.6568, 0.3432],
        [0.6572, 0.3428],
        [0.6496, 0.3504],
        [0.6572, 0.3428],
        [0.6577, 0.3423],
        [0.6562, 0.3438],
        [0.6578, 0.3422],
        [0.6569, 0.3431],
        [0.6493, 0.3507],
        [0.6571, 0.3429],
        [0.6575, 0.3425],
        [0.6570, 0.3430],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6577, 0.3423],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6576, 0.3424],
        [0.6579, 0.3421],
        [0.6569, 0.3431],
        [0.6568, 0.3432],
        [0.6567, 0.3433],
        [0.6574, 0.3426],
        [0.6576, 0.3424],
        [0.6562, 0.3438],
        [0.6568, 0.3432],
        [0.6571, 0.3429],
        [0.6576, 0.3424],
        [0.6581, 0.3419],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6567, 0.3433],
        [0.6574, 0.3426],
        [0.6579, 0.3421],
        [0.6577, 0.3423],
        [0.6572, 0.3428],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6572, 0.3428],
        [0.6579, 0.3421],
        [0.6575, 0.3425],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6585, 0.3415],
        [0.6581, 0.3419],
        [0.6565, 0.3435],
        [0.6569, 0.3431],
        [0.6581, 0.3419],
        [0.6570, 0.3430],
        [0.6578, 0.3422],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6583, 0.3417],
        [0.6574, 0.3426],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6580, 0.3420],
        [0.6575, 0.3425],
        [0.6580, 0.3420],
        [0.6491, 0.3509],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6581, 0.3419],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6586, 0.3414],
        [0.6579, 0.3421],
        [0.6583, 0.3417],
        [0.6581, 0.3419],
        [0.6564, 0.3436],
        [0.6579, 0.3421],
        [0.6571, 0.3429],
        [0.6568, 0.3432],
        [0.6576, 0.3424],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6577, 0.3423],
        [0.6580, 0.3420],
        [0.6582, 0.3418],
        [0.6574, 0.3426],
        [0.6581, 0.3419],
        [0.6575, 0.3425],
        [0.6572, 0.3428],
        [0.6577, 0.3423],
        [0.6571, 0.3429],
        [0.6580, 0.3420],
        [0.6576, 0.3424],
        [0.6574, 0.3426],
        [0.6570, 0.3430],
        [0.6579, 0.3421],
        [0.6573, 0.3427],
        [0.6582, 0.3418],
        [0.6571, 0.3429],
        [0.6577, 0.3423],
        [0.6568, 0.3432],
        [0.6577, 0.3423],
        [0.6572, 0.3428],
        [0.6578, 0.3422],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6576, 0.3424],
        [0.6569, 0.3431],
        [0.6578, 0.3422],
        [0.6583, 0.3417]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0035 loss: 0.6707 acc_train: 0.6103 time: 0.1446s
tensor([[0.6569, 0.3431],
        [0.6579, 0.3421],
        [0.6577, 0.3423],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6567, 0.3433],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6569, 0.3431],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6569, 0.3431],
        [0.6569, 0.3431],
        [0.6579, 0.3421],
        [0.6566, 0.3434],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6578, 0.3422],
        [0.6573, 0.3427],
        [0.6564, 0.3436],
        [0.6577, 0.3423],
        [0.6565, 0.3435],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6566, 0.3434],
        [0.6570, 0.3430],
        [0.6494, 0.3506],
        [0.6567, 0.3433],
        [0.6570, 0.3430],
        [0.6578, 0.3422],
        [0.6569, 0.3431],
        [0.6575, 0.3425],
        [0.6572, 0.3428],
        [0.6493, 0.3507],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6580, 0.3420],
        [0.6576, 0.3424],
        [0.6571, 0.3429],
        [0.6578, 0.3422],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6569, 0.3431],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6575, 0.3425],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6567, 0.3433],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6579, 0.3421],
        [0.6568, 0.3432],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6567, 0.3433],
        [0.6566, 0.3434],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6576, 0.3424],
        [0.6580, 0.3420],
        [0.6566, 0.3434],
        [0.6570, 0.3430],
        [0.6567, 0.3433],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6572, 0.3428],
        [0.6575, 0.3425],
        [0.6492, 0.3508],
        [0.6578, 0.3422],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6569, 0.3431],
        [0.6490, 0.3510],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6575, 0.3425],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6567, 0.3433],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6567, 0.3433],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6576, 0.3424],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6565, 0.3435],
        [0.6571, 0.3429],
        [0.6566, 0.3434],
        [0.6571, 0.3429],
        [0.6568, 0.3432],
        [0.6577, 0.3423],
        [0.6573, 0.3427],
        [0.6567, 0.3433],
        [0.6576, 0.3424],
        [0.6578, 0.3422],
        [0.6571, 0.3429],
        [0.6578, 0.3422],
        [0.6573, 0.3427],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6572, 0.3428],
        [0.6580, 0.3420],
        [0.6576, 0.3424],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6568, 0.3432],
        [0.6571, 0.3429],
        [0.6497, 0.3503],
        [0.6570, 0.3430],
        [0.6575, 0.3425],
        [0.6561, 0.3439],
        [0.6576, 0.3424],
        [0.6569, 0.3431],
        [0.6494, 0.3506],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6569, 0.3431],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6576, 0.3424],
        [0.6569, 0.3431],
        [0.6568, 0.3432],
        [0.6566, 0.3434],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6563, 0.3437],
        [0.6568, 0.3432],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6578, 0.3422],
        [0.6568, 0.3432],
        [0.6571, 0.3429],
        [0.6566, 0.3434],
        [0.6572, 0.3428],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6577, 0.3423],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6582, 0.3418],
        [0.6579, 0.3421],
        [0.6565, 0.3435],
        [0.6568, 0.3432],
        [0.6579, 0.3421],
        [0.6569, 0.3431],
        [0.6576, 0.3424],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6580, 0.3420],
        [0.6573, 0.3427],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6578, 0.3422],
        [0.6574, 0.3426],
        [0.6577, 0.3423],
        [0.6492, 0.3508],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6580, 0.3420],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6583, 0.3417],
        [0.6577, 0.3423],
        [0.6581, 0.3419],
        [0.6578, 0.3422],
        [0.6564, 0.3436],
        [0.6576, 0.3424],
        [0.6570, 0.3430],
        [0.6566, 0.3434],
        [0.6575, 0.3425],
        [0.6571, 0.3429],
        [0.6568, 0.3432],
        [0.6571, 0.3429],
        [0.6575, 0.3425],
        [0.6577, 0.3423],
        [0.6579, 0.3421],
        [0.6573, 0.3427],
        [0.6578, 0.3422],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6577, 0.3423],
        [0.6570, 0.3430],
        [0.6578, 0.3422],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6577, 0.3423],
        [0.6572, 0.3428],
        [0.6580, 0.3420],
        [0.6570, 0.3430],
        [0.6575, 0.3425],
        [0.6567, 0.3433],
        [0.6575, 0.3425],
        [0.6571, 0.3429],
        [0.6577, 0.3423],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6569, 0.3431],
        [0.6576, 0.3424],
        [0.6580, 0.3420]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0036 loss: 0.6707 acc_train: 0.6103 time: 0.1545s
tensor([[0.6569, 0.3431],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6567, 0.3433],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6569, 0.3431],
        [0.6568, 0.3432],
        [0.6576, 0.3424],
        [0.6566, 0.3434],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6576, 0.3424],
        [0.6572, 0.3428],
        [0.6565, 0.3435],
        [0.6575, 0.3425],
        [0.6565, 0.3435],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6566, 0.3434],
        [0.6569, 0.3431],
        [0.6496, 0.3504],
        [0.6566, 0.3434],
        [0.6570, 0.3430],
        [0.6576, 0.3424],
        [0.6568, 0.3432],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6494, 0.3506],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6578, 0.3422],
        [0.6574, 0.3426],
        [0.6570, 0.3430],
        [0.6576, 0.3424],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6569, 0.3431],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6568, 0.3432],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6568, 0.3432],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6567, 0.3433],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6577, 0.3423],
        [0.6567, 0.3433],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6568, 0.3432],
        [0.6569, 0.3431],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6569, 0.3431],
        [0.6567, 0.3433],
        [0.6566, 0.3434],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6570, 0.3430],
        [0.6575, 0.3425],
        [0.6577, 0.3423],
        [0.6566, 0.3434],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6494, 0.3506],
        [0.6576, 0.3424],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6569, 0.3431],
        [0.6492, 0.3508],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6566, 0.3434],
        [0.6568, 0.3432],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6567, 0.3433],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6575, 0.3425],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6564, 0.3436],
        [0.6570, 0.3430],
        [0.6566, 0.3434],
        [0.6570, 0.3430],
        [0.6567, 0.3433],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6567, 0.3433],
        [0.6574, 0.3426],
        [0.6576, 0.3424],
        [0.6570, 0.3430],
        [0.6576, 0.3424],
        [0.6572, 0.3428],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6578, 0.3422],
        [0.6575, 0.3425],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6567, 0.3433],
        [0.6570, 0.3430],
        [0.6498, 0.3502],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6561, 0.3439],
        [0.6574, 0.3426],
        [0.6568, 0.3432],
        [0.6495, 0.3505],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6568, 0.3432],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6568, 0.3432],
        [0.6568, 0.3432],
        [0.6566, 0.3434],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6563, 0.3437],
        [0.6568, 0.3432],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6576, 0.3424],
        [0.6567, 0.3433],
        [0.6569, 0.3431],
        [0.6566, 0.3434],
        [0.6571, 0.3429],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6576, 0.3424],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6579, 0.3421],
        [0.6577, 0.3423],
        [0.6565, 0.3435],
        [0.6567, 0.3433],
        [0.6577, 0.3423],
        [0.6568, 0.3432],
        [0.6575, 0.3425],
        [0.6568, 0.3432],
        [0.6572, 0.3428],
        [0.6578, 0.3422],
        [0.6572, 0.3428],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6576, 0.3424],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6576, 0.3424],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6493, 0.3507],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6578, 0.3422],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6580, 0.3420],
        [0.6575, 0.3425],
        [0.6578, 0.3422],
        [0.6576, 0.3424],
        [0.6564, 0.3436],
        [0.6574, 0.3426],
        [0.6570, 0.3430],
        [0.6566, 0.3434],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6567, 0.3433],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6571, 0.3429],
        [0.6576, 0.3424],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6576, 0.3424],
        [0.6570, 0.3430],
        [0.6576, 0.3424],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6575, 0.3425],
        [0.6571, 0.3429],
        [0.6578, 0.3422],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6567, 0.3433],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6575, 0.3425],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6568, 0.3432],
        [0.6574, 0.3426],
        [0.6578, 0.3422]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0037 loss: 0.6708 acc_train: 0.6103 time: 0.1506s
tensor([[0.6568, 0.3432],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6568, 0.3432],
        [0.6568, 0.3432],
        [0.6572, 0.3428],
        [0.6568, 0.3432],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6568, 0.3432],
        [0.6574, 0.3426],
        [0.6566, 0.3434],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6571, 0.3429],
        [0.6565, 0.3435],
        [0.6573, 0.3427],
        [0.6566, 0.3434],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6566, 0.3434],
        [0.6569, 0.3431],
        [0.6497, 0.3503],
        [0.6566, 0.3434],
        [0.6569, 0.3431],
        [0.6575, 0.3425],
        [0.6568, 0.3432],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6495, 0.3505],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6576, 0.3424],
        [0.6573, 0.3427],
        [0.6569, 0.3431],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6568, 0.3432],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6569, 0.3431],
        [0.6569, 0.3431],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6567, 0.3433],
        [0.6571, 0.3429],
        [0.6568, 0.3432],
        [0.6575, 0.3425],
        [0.6567, 0.3433],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6568, 0.3432],
        [0.6568, 0.3432],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6569, 0.3431],
        [0.6569, 0.3431],
        [0.6568, 0.3432],
        [0.6567, 0.3433],
        [0.6566, 0.3434],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6566, 0.3434],
        [0.6569, 0.3431],
        [0.6568, 0.3432],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6495, 0.3505],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6493, 0.3507],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6567, 0.3433],
        [0.6567, 0.3433],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6570, 0.3430],
        [0.6566, 0.3434],
        [0.6571, 0.3429],
        [0.6568, 0.3432],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6567, 0.3433],
        [0.6563, 0.3437],
        [0.6569, 0.3430],
        [0.6567, 0.3433],
        [0.6570, 0.3430],
        [0.6567, 0.3433],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6567, 0.3433],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6569, 0.3431],
        [0.6575, 0.3425],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6570, 0.3430],
        [0.6577, 0.3423],
        [0.6574, 0.3426],
        [0.6568, 0.3432],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6567, 0.3433],
        [0.6569, 0.3431],
        [0.6499, 0.3501],
        [0.6568, 0.3432],
        [0.6572, 0.3428],
        [0.6561, 0.3439],
        [0.6573, 0.3427],
        [0.6568, 0.3432],
        [0.6496, 0.3504],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6567, 0.3433],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6568, 0.3432],
        [0.6568, 0.3432],
        [0.6565, 0.3435],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6564, 0.3436],
        [0.6567, 0.3433],
        [0.6568, 0.3432],
        [0.6572, 0.3428],
        [0.6575, 0.3425],
        [0.6567, 0.3433],
        [0.6568, 0.3432],
        [0.6566, 0.3434],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6568, 0.3432],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6566, 0.3434],
        [0.6567, 0.3433],
        [0.6575, 0.3425],
        [0.6568, 0.3432],
        [0.6573, 0.3427],
        [0.6568, 0.3432],
        [0.6571, 0.3429],
        [0.6576, 0.3424],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6568, 0.3432],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6494, 0.3506],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6577, 0.3423],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6578, 0.3422],
        [0.6573, 0.3427],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6564, 0.3436],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6565, 0.3435],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6567, 0.3433],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6575, 0.3425],
        [0.6569, 0.3431],
        [0.6575, 0.3425],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6570, 0.3430],
        [0.6577, 0.3423],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6566, 0.3434],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6574, 0.3426],
        [0.6569, 0.3431],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6576, 0.3424]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0038 loss: 0.6708 acc_train: 0.6103 time: 0.1461s
tensor([[0.6569, 0.3431],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6569, 0.3431],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6568, 0.3432],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6567, 0.3433],
        [0.6573, 0.3427],
        [0.6566, 0.3434],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6566, 0.3434],
        [0.6572, 0.3428],
        [0.6567, 0.3433],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6567, 0.3433],
        [0.6569, 0.3431],
        [0.6500, 0.3500],
        [0.6567, 0.3433],
        [0.6569, 0.3431],
        [0.6574, 0.3426],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6497, 0.3503],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6568, 0.3432],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6569, 0.3431],
        [0.6568, 0.3432],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6570, 0.3430],
        [0.6567, 0.3433],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6574, 0.3426],
        [0.6567, 0.3433],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6568, 0.3432],
        [0.6568, 0.3432],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6568, 0.3432],
        [0.6569, 0.3431],
        [0.6568, 0.3432],
        [0.6567, 0.3433],
        [0.6567, 0.3433],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6568, 0.3432],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6566, 0.3434],
        [0.6569, 0.3431],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6497, 0.3503],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6495, 0.3505],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6567, 0.3433],
        [0.6567, 0.3433],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6570, 0.3430],
        [0.6566, 0.3434],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6567, 0.3433],
        [0.6563, 0.3437],
        [0.6570, 0.3430],
        [0.6567, 0.3433],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6567, 0.3433],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6569, 0.3431],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6568, 0.3432],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6567, 0.3433],
        [0.6569, 0.3431],
        [0.6500, 0.3500],
        [0.6568, 0.3432],
        [0.6571, 0.3429],
        [0.6562, 0.3438],
        [0.6572, 0.3428],
        [0.6568, 0.3432],
        [0.6497, 0.3503],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6567, 0.3433],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6568, 0.3432],
        [0.6569, 0.3431],
        [0.6566, 0.3434],
        [0.6568, 0.3432],
        [0.6572, 0.3428],
        [0.6565, 0.3435],
        [0.6567, 0.3433],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6567, 0.3433],
        [0.6568, 0.3432],
        [0.6566, 0.3434],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6567, 0.3433],
        [0.6567, 0.3433],
        [0.6574, 0.3426],
        [0.6568, 0.3432],
        [0.6572, 0.3428],
        [0.6568, 0.3432],
        [0.6571, 0.3429],
        [0.6575, 0.3425],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6497, 0.3503],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6576, 0.3424],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6576, 0.3424],
        [0.6572, 0.3428],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6565, 0.3435],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6566, 0.3434],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6567, 0.3433],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6569, 0.3431],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6575, 0.3425],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6567, 0.3433],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6569, 0.3431],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6575, 0.3425]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0039 loss: 0.6708 acc_train: 0.6103 time: 0.1445s
tensor([[0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6572, 0.3428],
        [0.6567, 0.3433],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6568, 0.3432],
        [0.6572, 0.3428],
        [0.6568, 0.3432],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6568, 0.3432],
        [0.6569, 0.3431],
        [0.6502, 0.3498],
        [0.6568, 0.3432],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6499, 0.3501],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6573, 0.3427],
        [0.6568, 0.3432],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6568, 0.3432],
        [0.6569, 0.3431],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6569, 0.3431],
        [0.6569, 0.3431],
        [0.6568, 0.3432],
        [0.6568, 0.3432],
        [0.6568, 0.3432],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6567, 0.3433],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6499, 0.3501],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6497, 0.3503],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6568, 0.3432],
        [0.6568, 0.3432],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6567, 0.3433],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6564, 0.3436],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6568, 0.3432],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6570, 0.3430],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6569, 0.3431],
        [0.6502, 0.3498],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6563, 0.3437],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6500, 0.3500],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6567, 0.3433],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6570, 0.3430],
        [0.6566, 0.3434],
        [0.6567, 0.3433],
        [0.6572, 0.3428],
        [0.6566, 0.3434],
        [0.6568, 0.3432],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6568, 0.3432],
        [0.6568, 0.3432],
        [0.6567, 0.3433],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6568, 0.3432],
        [0.6568, 0.3432],
        [0.6574, 0.3426],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6499, 0.3501],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6576, 0.3424],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6567, 0.3433],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6567, 0.3433],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6568, 0.3432],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6569, 0.3431],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6575, 0.3425],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6567, 0.3433],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6575, 0.3425]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0040 loss: 0.6708 acc_train: 0.6103 time: 0.1418s
tensor([[0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6568, 0.3432],
        [0.6573, 0.3427],
        [0.6568, 0.3432],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6569, 0.3431],
        [0.6570, 0.3430],
        [0.6505, 0.3495],
        [0.6569, 0.3431],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6502, 0.3498],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6569, 0.3431],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6502, 0.3498],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6501, 0.3499],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6568, 0.3432],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6566, 0.3434],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6571, 0.3429],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6570, 0.3430],
        [0.6504, 0.3496],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6564, 0.3436],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6502, 0.3498],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6568, 0.3432],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6568, 0.3432],
        [0.6567, 0.3433],
        [0.6573, 0.3427],
        [0.6567, 0.3433],
        [0.6569, 0.3431],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6569, 0.3431],
        [0.6569, 0.3431],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6569, 0.3431],
        [0.6569, 0.3431],
        [0.6574, 0.3426],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6503, 0.3498],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6576, 0.3424],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6569, 0.3431],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6575, 0.3425],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6575, 0.3425]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0041 loss: 0.6708 acc_train: 0.6103 time: 0.1464s
tensor([[0.6572, 0.3428],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6575, 0.3425],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6569, 0.3431],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6575, 0.3425],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6509, 0.3491],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6505, 0.3495],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6505, 0.3495],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6504, 0.3496],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6568, 0.3432],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6576, 0.3424],
        [0.6572, 0.3428],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6571, 0.3429],
        [0.6508, 0.3492],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6567, 0.3433],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6506, 0.3494],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6568, 0.3432],
        [0.6574, 0.3426],
        [0.6569, 0.3431],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6506, 0.3494],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6576, 0.3424],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6576, 0.3424],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6570, 0.3430],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6575, 0.3425],
        [0.6575, 0.3425]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0042 loss: 0.6708 acc_train: 0.6103 time: 0.1794s
tensor([[0.6574, 0.3426],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6576, 0.3424],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6575, 0.3425],
        [0.6571, 0.3429],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6576, 0.3424],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6513, 0.3487],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6510, 0.3490],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6576, 0.3424],
        [0.6574, 0.3426],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6510, 0.3490],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6509, 0.3491],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6571, 0.3429],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6573, 0.3427],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6573, 0.3427],
        [0.6512, 0.3488],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6569, 0.3431],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6510, 0.3490],
        [0.6573, 0.3427],
        [0.6576, 0.3424],
        [0.6572, 0.3428],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6570, 0.3430],
        [0.6575, 0.3425],
        [0.6571, 0.3429],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6572, 0.3428],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6576, 0.3424],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6576, 0.3424],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6572, 0.3428],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6511, 0.3489],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6572, 0.3428],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6574, 0.3426],
        [0.6576, 0.3424],
        [0.6576, 0.3424]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0043 loss: 0.6708 acc_train: 0.6103 time: 0.2556s
tensor([[0.6576, 0.3424],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6574, 0.3426],
        [0.6577, 0.3423],
        [0.6574, 0.3426],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6578, 0.3422],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6518, 0.3482],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6514, 0.3486],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6578, 0.3422],
        [0.6576, 0.3424],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6577, 0.3423],
        [0.6514, 0.3486],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6514, 0.3486],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6573, 0.3427],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6573, 0.3427],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6579, 0.3421],
        [0.6575, 0.3425],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6516, 0.3484],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6572, 0.3428],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6515, 0.3485],
        [0.6575, 0.3425],
        [0.6577, 0.3423],
        [0.6574, 0.3426],
        [0.6578, 0.3422],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6577, 0.3423],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6578, 0.3422],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6574, 0.3426],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6515, 0.3485],
        [0.6575, 0.3425],
        [0.6577, 0.3423],
        [0.6579, 0.3421],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6575, 0.3425],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6574, 0.3426],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6574, 0.3426],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6576, 0.3424],
        [0.6578, 0.3422],
        [0.6578, 0.3422]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0044 loss: 0.6708 acc_train: 0.6103 time: 0.2979s
tensor([[0.6578, 0.3422],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6577, 0.3423],
        [0.6579, 0.3421],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6576, 0.3424],
        [0.6579, 0.3421],
        [0.6576, 0.3424],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6522, 0.3478],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6519, 0.3481],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6577, 0.3423],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6519, 0.3481],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6519, 0.3481],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6576, 0.3424],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6576, 0.3424],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6577, 0.3423],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6521, 0.3479],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6574, 0.3426],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6520, 0.3480],
        [0.6577, 0.3423],
        [0.6579, 0.3421],
        [0.6576, 0.3424],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6576, 0.3424],
        [0.6574, 0.3426],
        [0.6579, 0.3421],
        [0.6575, 0.3425],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6577, 0.3423],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6580, 0.3420],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6577, 0.3423],
        [0.6577, 0.3423],
        [0.6579, 0.3421],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6576, 0.3424],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6520, 0.3480],
        [0.6577, 0.3423],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6576, 0.3424],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6577, 0.3423],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6579, 0.3421],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6580, 0.3420]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0045 loss: 0.6708 acc_train: 0.6103 time: 0.2660s
tensor([[0.6580, 0.3420],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6579, 0.3421],
        [0.6581, 0.3419],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6581, 0.3419],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6578, 0.3422],
        [0.6581, 0.3419],
        [0.6578, 0.3422],
        [0.6581, 0.3419],
        [0.6581, 0.3419],
        [0.6581, 0.3419],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6527, 0.3473],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6525, 0.3475],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6581, 0.3419],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6581, 0.3419],
        [0.6579, 0.3421],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6581, 0.3419],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6525, 0.3475],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6525, 0.3475],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6578, 0.3422],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6579, 0.3421],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6526, 0.3474],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6577, 0.3423],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6525, 0.3475],
        [0.6579, 0.3421],
        [0.6581, 0.3419],
        [0.6579, 0.3421],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6577, 0.3423],
        [0.6581, 0.3419],
        [0.6577, 0.3423],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6581, 0.3419],
        [0.6581, 0.3419],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6582, 0.3418],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6581, 0.3419],
        [0.6579, 0.3421],
        [0.6579, 0.3421],
        [0.6581, 0.3419],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6526, 0.3474],
        [0.6579, 0.3421],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6581, 0.3419],
        [0.6581, 0.3419],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6581, 0.3419],
        [0.6579, 0.3421],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6579, 0.3421],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6581, 0.3419]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0046 loss: 0.6708 acc_train: 0.6103 time: 0.1511s
tensor([[0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6583, 0.3417],
        [0.6581, 0.3419],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6532, 0.3468],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6530, 0.3470],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6583, 0.3417],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6581, 0.3419],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6581, 0.3419],
        [0.6583, 0.3417],
        [0.6530, 0.3470],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6530, 0.3470],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6581, 0.3419],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6531, 0.3469],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6580, 0.3420],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6531, 0.3469],
        [0.6581, 0.3419],
        [0.6583, 0.3417],
        [0.6581, 0.3419],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6580, 0.3420],
        [0.6583, 0.3417],
        [0.6580, 0.3420],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6531, 0.3469],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6581, 0.3419],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6581, 0.3419],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6583, 0.3417]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0047 loss: 0.6708 acc_train: 0.6103 time: 0.2032s
tensor([[0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6585, 0.3415],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6536, 0.3464],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6535, 0.3465],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6535, 0.3465],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6535, 0.3465],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6583, 0.3417],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6583, 0.3417],
        [0.6536, 0.3464],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6582, 0.3418],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6536, 0.3464],
        [0.6583, 0.3417],
        [0.6585, 0.3415],
        [0.6583, 0.3417],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6585, 0.3415],
        [0.6582, 0.3418],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6536, 0.3464],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6583, 0.3417],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6583, 0.3417],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6585, 0.3415]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0048 loss: 0.6708 acc_train: 0.6103 time: 0.1548s
tensor([[0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6587, 0.3413],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6541, 0.3459],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6540, 0.3460],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6587, 0.3413],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6540, 0.3460],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6540, 0.3460],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6540, 0.3460],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6584, 0.3416],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6540, 0.3460],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6587, 0.3413],
        [0.6584, 0.3416],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6540, 0.3460],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6585, 0.3415],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6586, 0.3414]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0049 loss: 0.6708 acc_train: 0.6103 time: 0.1639s
tensor([[0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6588, 0.3412],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6545, 0.3455],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6544, 0.3456],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6544, 0.3456],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6544, 0.3456],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6586, 0.3414],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6544, 0.3456],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6544, 0.3456],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6588, 0.3412],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6586, 0.3414],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6544, 0.3456],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6586, 0.3414],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6587, 0.3413]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0050 loss: 0.6708 acc_train: 0.6103 time: 0.1926s
tensor([[0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6589, 0.3411],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6548, 0.3452],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6548, 0.3452],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6589, 0.3411],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6548, 0.3452],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6548, 0.3452],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6548, 0.3452],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6548, 0.3452],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6587, 0.3413],
        [0.6589, 0.3411],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6548, 0.3452],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6589, 0.3411],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6588, 0.3412],
        [0.6589, 0.3411],
        [0.6587, 0.3413],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412],
        [0.6588, 0.3412]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0051 loss: 0.6707 acc_train: 0.6103 time: 0.1820s
[Epoch 50] Loss: 0.67074 Forward: 0.114s Backward: 0.068s Train Accuracy: 61.03 Test Accuracy: 66.18
Training is complete!
(0, tensor(12917, device='cuda:7'))
12917
tensor(indices=tensor([[12917],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  301,   301,   301,  ..., 22447, 22447, 22447],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-3.8317e-06,  1.2402e-05,  1.9405e-04,  ...,
                       2.0112e-05,  1.7475e-05,  9.1093e-05]),
       size=(22540, 50), nnz=2565, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(1, tensor(21950, device='cuda:7'))
21950
tensor(indices=tensor([[21950],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1004,  1004,  1004,  ..., 22400, 22400, 22400],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-1.0329e-04,  2.3132e-05,  2.6484e-04,  ...,
                       1.8004e-05,  1.7976e-05,  8.8808e-05]),
       size=(22540, 50), nnz=2695, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(2, tensor(3144, device='cuda:7'))
3144
tensor(indices=tensor([[3144],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  888,   888,   888,  ..., 22146, 22146, 22146],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-5.4150e-06,  1.7725e-05,  2.7345e-04,  ...,
                       2.8105e-05,  7.7571e-06,  1.6991e-04]),
       size=(22540, 50), nnz=1902, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(3, tensor(20225, device='cuda:7'))
20225
tensor(indices=tensor([[20225],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  169,   169,   169,  ..., 22530, 22530, 22530],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-1.1246e-06,  3.6584e-06,  5.7236e-05,  ...,
                       5.5694e-06,  5.2962e-06,  2.6701e-05]),
       size=(22540, 50), nnz=9545, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(4, tensor(7271, device='cuda:7'))
7271
tensor(indices=tensor([[7271],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  406,   406,   406,  ..., 22441, 22441, 22441],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-7.1206e-05,  1.6241e-05,  1.7392e-04,  ...,
                       4.3957e-05,  1.6278e-05,  2.9134e-05]),
       size=(22540, 50), nnz=3927, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(5, tensor(10768, device='cuda:7'))
10768
tensor(indices=tensor([[10768],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  604,   604,   604,  ..., 21768, 21768, 21768],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-8.4736e-06,  2.6418e-05,  4.3476e-04,  ...,
                       4.6447e-05,  1.2838e-05,  2.5803e-04]),
       size=(22540, 50), nnz=1260, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
1
(6, tensor(11934, device='cuda:7'))
11934
tensor(indices=tensor([[11934],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1570,  1570,  1570,  ..., 22510, 22510, 22510],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-1.6918e-04,  3.8548e-05,  4.1727e-04,  ...,
                       6.7135e-05,  2.7638e-05,  4.8898e-05]),
       size=(22540, 50), nnz=1738, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(7, tensor(4336, device='cuda:7'))
4336
tensor(indices=tensor([[4336],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   93,    93,    93,  ..., 22478, 22478, 22478],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-1.3797e-04,  2.7756e-05,  3.4750e-04,  ...,
                       2.5548e-05,  2.5286e-05,  1.1736e-04]),
       size=(22540, 50), nnz=2192, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
1
2
(8, tensor(10172, device='cuda:7'))
10172
tensor(indices=tensor([[10172],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  154,   154,   154,  ..., 22502, 22502, 22502],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-9.5970e-05,  2.0864e-05,  2.2953e-04,  ...,
                       1.7220e-05,  1.8223e-05,  7.9434e-05]),
       size=(22540, 50), nnz=2914, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(9, tensor(13510, device='cuda:7'))
13510
tensor(indices=tensor([[13510],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   42,    42,    42,  ..., 22429, 22429, 22429],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-3.6591e-06,  1.1931e-05,  1.9053e-04,  ...,
                       1.9356e-05,  1.6610e-05,  8.7901e-05]),
       size=(22540, 50), nnz=2779, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
2
3
(10, tensor(19233, device='cuda:7'))
19233
tensor(indices=tensor([[19233],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1667,  1667,  1667,  ..., 21474, 21474, 21474],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-3.3173e-05, -2.6877e-05,  2.0731e-04,  ...,
                       2.3347e-05,  6.6377e-06,  1.2793e-04]),
       size=(22540, 50), nnz=2608, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
3
4
(11, tensor(19260, device='cuda:7'))
19260
tensor(indices=tensor([[19260],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  112,   112,   112,  ..., 22455, 22455, 22455],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-2.8521e-06,  8.6709e-06,  1.4679e-04,  ...,
                       1.3528e-05,  1.2639e-05,  6.5419e-05]),
       size=(22540, 50), nnz=3705, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
5
(12, tensor(7860, device='cuda:7'))
7860
tensor(indices=tensor([[7860],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  206,   206,   206,  ..., 22444, 22444, 22444],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-3.1067e-06,  9.3492e-06,  1.6216e-04,  ...,
                       1.7737e-05,  1.3367e-05,  8.0656e-05]),
       size=(22540, 50), nnz=4181, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(13, tensor(9637, device='cuda:7'))
9637
tensor(indices=tensor([[9637],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   16,    16,    16,  ..., 22208, 22208, 22208],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-1.1356e-04,  2.5323e-05,  2.8205e-04,  ...,
                       2.5292e-05,  6.6167e-06,  1.3510e-04]),
       size=(22540, 50), nnz=2778, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(14, tensor(7315, device='cuda:7'))
7315
tensor(indices=tensor([[7315],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  135,   135,   135,  ..., 21920, 21920, 21920],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-6.5709e-05, -5.6970e-05,  4.0991e-04,  ...,
                       2.8488e-05,  8.3197e-06,  1.7872e-04]),
       size=(22540, 50), nnz=1906, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(15, tensor(21185, device='cuda:7'))
21185
tensor(indices=tensor([[21185],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 2547,  2547,  2547,  ..., 22453, 22453, 22453],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-7.4659e-06,  2.1407e-05,  3.7740e-04,  ...,
                       3.3840e-05,  3.0844e-05,  1.6495e-04]),
       size=(22540, 50), nnz=1447, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(16, tensor(9704, device='cuda:7'))
9704
tensor(indices=tensor([[9704],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   44,    44,    44,  ..., 21806, 21806, 21806],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-1.4260e-04,  2.9042e-05,  3.5842e-04,  ...,
                       2.5969e-05,  2.5397e-05,  1.2470e-04]),
       size=(22540, 50), nnz=1976, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(17, tensor(15542, device='cuda:7'))
15542
tensor(indices=tensor([[15542],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1508,  1508,  1508,  ..., 22413, 22413, 22413],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-5.0961e-05, -4.4035e-05,  3.2459e-04,  ...,
                       8.1730e-05,  2.2800e-05,  4.4598e-04]),
       size=(22540, 50), nnz=1099, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
4
6
(18, tensor(1543, device='cuda:7'))
1543
tensor(indices=tensor([[1543],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  170,   170,   170,  ..., 22535, 22535, 22535],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-8.6976e-05,  1.9974e-05,  2.1627e-04,  ...,
                       1.4806e-05,  1.5670e-05,  7.3794e-05]),
       size=(22540, 50), nnz=3030, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
5
(19, tensor(9956, device='cuda:7'))
9956
tensor(indices=tensor([[9956],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   77,    77,    77,  ..., 22356, 22356, 22356],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-6.3343e-06,  2.0672e-05,  3.2146e-04,  ...,
                       3.1205e-05,  3.2554e-05,  1.4576e-04]),
       size=(22540, 50), nnz=1723, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
6
7
(20, tensor(19946, device='cuda:7'))
19946
tensor(indices=tensor([[19946],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  104,   104,   104,  ..., 21864, 21864, 21864],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-8.5191e-05,  1.7183e-05,  2.1608e-04,  ...,
                       1.5995e-05,  4.2628e-06,  9.7419e-05]),
       size=(22540, 50), nnz=3239, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
8
(21, tensor(2144, device='cuda:7'))
2144
tensor(indices=tensor([[2144],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   29,    29,    29,  ..., 22515, 22515, 22515],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-4.2966e-06,  1.2596e-05,  2.1982e-04,  ...,
                       2.3185e-05,  6.7772e-06,  1.2872e-04]),
       size=(22540, 50), nnz=2656, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(22, tensor(17777, device='cuda:7'))
17777
tensor(indices=tensor([[17777],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  977,   977,   977,  ..., 21095, 21095, 21095],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-2.1218e-04,  4.6871e-05,  5.1625e-04,  ...,
                       3.7187e-05,  4.0969e-05,  1.7895e-04]),
       size=(22540, 50), nnz=1441, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(23, tensor(13745, device='cuda:7'))
13745
tensor(indices=tensor([[13745],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  839,   839,   839,  ..., 22233, 22233, 22233],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-1.1421e-04, -9.9195e-05,  7.2070e-04,  ...,
                       3.5565e-05,  2.9007e-05,  1.6626e-04]),
       size=(22540, 50), nnz=1431, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(24, tensor(5234, device='cuda:7'))
5234
tensor(indices=tensor([[5234],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  397,   397,   397,  ..., 22290, 22290, 22290],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-1.6391e-04,  3.7436e-05,  3.9473e-04,  ...,
                       2.9969e-05,  7.4243e-06,  1.8171e-04]),
       size=(22540, 50), nnz=1809, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(25, tensor(20943, device='cuda:7'))
20943
tensor(indices=tensor([[20943],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   10,    10,    10,  ..., 22483, 22483, 22483],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-7.3160e-07,  2.3424e-06,  3.8022e-05,  ...,
                       4.1261e-06,  9.9692e-07,  2.2361e-05]),
       size=(22540, 50), nnz=14093, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(26, tensor(3410, device='cuda:7'))
3410
tensor(indices=tensor([[3410],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  160,   160,   160,  ..., 22330, 22330, 22330],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-7.2986e-06,  2.1900e-05,  3.8065e-04,  ...,
                       3.5077e-05,  3.2811e-05,  1.7014e-04]),
       size=(22540, 50), nnz=1644, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(27, tensor(5643, device='cuda:7'))
5643
tensor(indices=tensor([[5643],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  577,   577,   577,  ..., 22279, 22279, 22279],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-2.6871e-05, -2.2477e-05,  1.6909e-04,  ...,
                       1.0921e-05,  1.0555e-05,  5.2247e-05]),
       size=(22540, 50), nnz=4714, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(28, tensor(211, device='cuda:7'))
211
tensor(indices=tensor([[211],
                       [  0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  211,   211,   211,  ..., 22270, 22270, 22270],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-2.7819e-03, -4.5232e-05,  5.7030e-03,  ...,
                       2.6945e-04,  9.9208e-05,  1.9323e-04]),
       size=(22540, 50), nnz=1177, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(29, tensor(3969, device='cuda:7'))
3969
tensor(indices=tensor([[3969],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1274,  1274,  1274,  ..., 21527, 21527, 21527],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-4.1390e-06,  1.2434e-05,  2.0957e-04,  ...,
                       2.1268e-05,  5.6280e-06,  1.2878e-04]),
       size=(22540, 50), nnz=2441, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
7
9
(30, tensor(11213, device='cuda:7'))
11213
tensor(indices=tensor([[11213],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[    1,     1,     1,  ..., 22191, 22191, 22191],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-6.9617e-05,  1.3416e-05,  1.7021e-04,  ...,
                       1.2597e-05,  1.1644e-05,  5.9892e-05]),
       size=(22540, 50), nnz=4006, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0.0000, 0.0019, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
       grad_fn=<SumBackward1>)
(31, tensor(10620, device='cuda:7'))
10620
tensor(indices=tensor([[10620],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   20,    20,    20,  ..., 22527, 22527, 22527],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-1.0614e-04,  2.5054e-05,  2.6576e-04,  ...,
                       2.0920e-05,  6.1185e-06,  1.2229e-04]),
       size=(22540, 50), nnz=2607, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(32, tensor(11150, device='cuda:7'))
11150
tensor(indices=tensor([[11150],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  410,   410,   410,  ..., 22484, 22484, 22484],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-1.5304e-04,  3.0171e-05,  4.0467e-04,  ...,
                       8.1603e-05,  2.8172e-05,  5.4619e-05]),
       size=(22540, 50), nnz=1852, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(33, tensor(10248, device='cuda:7'))
10248
tensor(indices=tensor([[10248],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1484,  1484,  1484,  ..., 22397, 22397, 22397],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-1.0295e-05,  2.6281e-05,  5.3411e-04,  ...,
                       4.7699e-05,  4.8288e-05,  2.1428e-04]),
       size=(22540, 50), nnz=1014, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(34, tensor(19890, device='cuda:7'))
19890
tensor(indices=tensor([[19890],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   23,    23,    23,  ..., 22079, 22079, 22079],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-8.0388e-06,  2.2538e-05,  4.1186e-04,  ...,
                       4.0607e-05,  1.1783e-05,  2.4170e-04]),
       size=(22540, 50), nnz=1303, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(35, tensor(18276, device='cuda:7'))
18276
tensor(indices=tensor([[18276],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1296,  1296,  1296,  ..., 22095, 22095, 22095],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-2.7214e-04,  5.8362e-05,  6.7879e-04,  ...,
                       5.2435e-05,  5.4194e-05,  2.4232e-04]),
       size=(22540, 50), nnz=1351, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(36, tensor(1166, device='cuda:7'))
1166
tensor(indices=tensor([[1166],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  593,   593,   593,  ..., 20686, 20686, 20686],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-1.3817e-04,  3.1918e-05,  3.5953e-04,  ...,
                       2.6209e-05,  2.4627e-05,  1.2410e-04]),
       size=(22540, 50), nnz=1977, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(37, tensor(10336, device='cuda:7'))
10336
tensor(indices=tensor([[10336],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  201,   201,   201,  ..., 22311, 22311, 22311],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-9.4364e-05,  2.0621e-05,  2.3256e-04,  ...,
                       1.7671e-05,  1.7477e-05,  8.0495e-05]),
       size=(22540, 50), nnz=2916, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(38, tensor(4256, device='cuda:7'))
4256
tensor(indices=tensor([[4256],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  486,   486,   486,  ..., 20095, 20095, 20095],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-6.0857e-06,  1.7479e-05,  3.1226e-04,  ...,
                       2.9080e-05,  2.8212e-05,  1.3860e-04]),
       size=(22540, 50), nnz=1859, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(39, tensor(963, device='cuda:7'))
963
tensor(indices=tensor([[963],
                       [  0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  347,   347,   347,  ..., 21723, 21723, 21723],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-2.2310e-04,  4.0089e-05,  5.6599e-04,  ...,
                       1.3665e-04,  4.8924e-05,  9.5065e-05]),
       size=(22540, 50), nnz=1224, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(40, tensor(4369, device='cuda:7'))
4369
tensor(indices=tensor([[4369],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  517,   517,   517,  ..., 22472, 22472, 22472],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-3.6744e-06,  1.1431e-05,  1.9041e-04,  ...,
                       1.8039e-05,  1.5573e-05,  8.4305e-05]),
       size=(22540, 50), nnz=2989, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
10
(41, tensor(6785, device='cuda:7'))
6785
tensor(indices=tensor([[6785],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1074,  1074,  1074,  ..., 22522, 22522, 22522],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-7.6627e-05,  1.6615e-05,  1.9284e-04,  ...,
                       1.4722e-05,  1.4121e-05,  6.7378e-05]),
       size=(22540, 50), nnz=3503, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(42, tensor(2579, device='cuda:7'))
2579
tensor(indices=tensor([[2579],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  278,   278,   278,  ..., 21657, 21657, 21657],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-4.9000e-06,  1.5806e-05,  2.5711e-04,  ...,
                       2.3574e-05,  2.1865e-05,  1.0883e-04]),
       size=(22540, 50), nnz=2569, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(43, tensor(17531, device='cuda:7'))
17531
tensor(indices=tensor([[17531],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   91,    91,    91,  ..., 22300, 22300, 22300],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-6.6329e-05,  1.3250e-05,  1.6401e-04,  ...,
                       1.1683e-05,  1.1468e-05,  5.5879e-05]),
       size=(22540, 50), nnz=4253, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(44, tensor(541, device='cuda:7'))
541
tensor(indices=tensor([[541],
                       [  0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  541,   541,   541,  ..., 21195, 21195, 21195],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-2.8480e-03, -4.5123e-05,  5.7053e-03,  ...,
                       6.9792e-05,  2.1829e-05,  4.8082e-05]),
       size=(22540, 50), nnz=1316, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(45, tensor(13333, device='cuda:7'))
13333
tensor(indices=tensor([[13333],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  222,   222,   222,  ..., 22334, 22334, 22334],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-3.4440e-06,  1.0590e-05,  1.7732e-04,  ...,
                       1.7443e-05,  1.4067e-05,  7.9701e-05]),
       size=(22540, 50), nnz=3211, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(46, tensor(19769, device='cuda:7'))
19769
tensor(indices=tensor([[19769],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  848,   848,   848,   848,   848,   848,   848,   848,
                          848,   848,   848,   848,   848,   848,   848,   848,
                          848,   848,   848,   848,   848,   848,   848,   848,
                          848,   848,   848,   848,   848,   848,   848,   848,
                          848,   848,   848,   848,   848,   848,   848,   848,
                          848,   848,  3369,  3369,  3369,  3369,  3369,  3369,
                         3369,  3369,  3369,  3369,  3369,  3369,  3369,  3369,
                         3369,  3369,  3369,  3369,  3369,  3369,  3369,  3369,
                         3369,  3369,  3369,  3369,  3369,  3369,  3369,  3369,
                         3369,  3369,  3369,  3369,  3369,  3369,  3369,  3369,
                         3369,  3369,  3369,  3369,  4374,  4374,  4374,  4374,
                         4374,  4374,  4374,  4374,  4374,  4374,  4374,  4374,
                         4374,  4374,  4374,  4374,  4374,  4374,  4374,  4374,
                         4374,  4374,  4374,  4374,  4374,  4374,  4374,  4374,
                         4374,  4374,  4374,  4374,  4374,  4374,  4374,  4374,
                         4374,  4374,  4374,  4374,  4374,  4374, 13556, 13556,
                        13556, 13556, 13556, 13556, 13556, 13556, 13556, 13556,
                        13556, 13556, 13556, 13556, 13556, 13556, 13556, 13556,
                        13556, 13556, 13556, 13556, 13556, 13556, 13556, 13556,
                        13556, 13556, 13556, 13556, 13556, 13556, 13556, 13556,
                        13556, 13556, 13556, 13556, 13556, 13556, 13556, 13556,
                        15665, 15665, 15665, 15665, 15665, 15665, 15665, 15665,
                        15665, 15665, 15665, 15665, 15665, 15665, 15665, 15665,
                        15665, 15665, 15665, 15665, 15665, 15665, 15665, 15665,
                        15665, 15665, 15665, 15665, 15665, 15665, 15665, 15665,
                        15665, 15665, 15665, 15665, 15665, 15665, 15665, 15665,
                        15665, 15665, 17492, 17492, 17492, 17492, 17492, 17492,
                        17492, 17492, 17492, 17492, 17492, 17492, 17492, 17492,
                        17492, 17492, 17492, 17492, 17492, 17492, 17492, 17492,
                        17492, 17492, 17492, 17492, 17492, 17492, 17492, 17492,
                        17492, 17492, 17492, 17492, 17492, 17492, 17492, 17492,
                        17492, 17492, 17492, 17492, 19769, 19769, 19769, 19769,
                        19769, 19769, 19769, 19769, 19769, 19769, 19769, 19769,
                        19769, 19769, 19769, 19769, 19769, 19769, 19769, 19769,
                        19769, 19769, 19769, 19769, 19769, 19769, 19769, 19769,
                        19769, 19769, 19769, 19769, 19769, 19769, 19769, 19769,
                        19769, 19769, 19769, 19769, 19769, 19769, 20523, 20523,
                        20523, 20523, 20523, 20523, 20523, 20523, 20523, 20523,
                        20523, 20523, 20523, 20523, 20523, 20523, 20523, 20523,
                        20523, 20523, 20523, 20523, 20523, 20523, 20523, 20523,
                        20523, 20523, 20523, 20523, 20523, 20523, 20523, 20523,
                        20523, 20523, 20523, 20523, 20523, 20523, 20523, 20523,
                        21110, 21110, 21110, 21110, 21110, 21110, 21110, 21110,
                        21110, 21110, 21110, 21110, 21110, 21110, 21110, 21110,
                        21110, 21110, 21110, 21110, 21110, 21110, 21110, 21110,
                        21110, 21110, 21110, 21110, 21110, 21110, 21110, 21110,
                        21110, 21110, 21110, 21110, 21110, 21110, 21110, 21110,
                        21110, 21110],
                       [    1,     2,     4,     5,     6,     7,     8,     9,
                           10,    11,    13,    14,    15,    16,    19,    20,
                           21,    22,    23,    24,    25,    26,    27,    28,
                           30,    32,    33,    34,    35,    36,    37,    38,
                           39,    40,    41,    42,    43,    44,    45,    46,
                           47,    48,     1,     2,     4,     5,     6,     7,
                            8,     9,    10,    11,    13,    14,    15,    16,
                           19,    20,    21,    22,    23,    24,    25,    26,
                           27,    28,    30,    32,    33,    34,    35,    36,
                           37,    38,    39,    40,    41,    42,    43,    44,
                           45,    46,    47,    48,     1,     2,     4,     5,
                            6,     7,     8,     9,    10,    11,    13,    14,
                           15,    16,    19,    20,    21,    22,    23,    24,
                           25,    26,    27,    28,    30,    32,    33,    34,
                           35,    36,    37,    38,    39,    40,    41,    42,
                           43,    44,    45,    46,    47,    48,     1,     2,
                            4,     5,     6,     7,     8,     9,    10,    11,
                           13,    14,    15,    16,    19,    20,    21,    22,
                           23,    24,    25,    26,    27,    28,    30,    32,
                           33,    34,    35,    36,    37,    38,    39,    40,
                           41,    42,    43,    44,    45,    46,    47,    48,
                            1,     2,     4,     5,     6,     7,     8,     9,
                           10,    11,    13,    14,    15,    16,    19,    20,
                           21,    22,    23,    24,    25,    26,    27,    28,
                           30,    32,    33,    34,    35,    36,    37,    38,
                           39,    40,    41,    42,    43,    44,    45,    46,
                           47,    48,     1,     2,     4,     5,     6,     7,
                            8,     9,    10,    11,    13,    14,    15,    16,
                           19,    20,    21,    22,    23,    24,    25,    26,
                           27,    28,    30,    32,    33,    34,    35,    36,
                           37,    38,    39,    40,    41,    42,    43,    44,
                           45,    46,    47,    48,     1,     2,     4,     5,
                            6,     7,     8,     9,    10,    11,    13,    14,
                           15,    16,    19,    20,    21,    22,    23,    24,
                           25,    26,    27,    28,    30,    32,    33,    34,
                           35,    36,    37,    38,    39,    40,    41,    42,
                           43,    44,    45,    46,    47,    48,     1,     2,
                            4,     5,     6,     7,     8,     9,    10,    11,
                           13,    14,    15,    16,    19,    20,    21,    22,
                           23,    24,    25,    26,    27,    28,    30,    32,
                           33,    34,    35,    36,    37,    38,    39,    40,
                           41,    42,    43,    44,    45,    46,    47,    48,
                            1,     2,     4,     5,     6,     7,     8,     9,
                           10,    11,    13,    14,    15,    16,    19,    20,
                           21,    22,    23,    24,    25,    26,    27,    28,
                           30,    32,    33,    34,    35,    36,    37,    38,
                           39,    40,    41,    42,    43,    44,    45,    46,
                           47,    48]]),
       values=tensor([-7.7964e-04,  1.8275e-04,  1.9367e-03,  8.8199e-03,
                      -7.6618e-05,  1.1078e-03,  5.5040e-04,  2.0984e-03,
                       1.3313e-02,  1.4861e-04,  1.4122e-04,  3.8234e-04,
                       9.2854e-03, -3.2938e-04,  5.1606e-04,  2.0671e-04,
                       6.4975e-04,  2.3679e-03,  1.0886e-03,  7.3582e-04,
                       2.2375e-03, -5.5409e-05,  9.7998e-03,  2.7949e-03,
                       1.6082e-03,  6.8501e-04,  4.3909e-04, -8.5379e-05,
                      -2.8710e-04,  3.4951e-04,  1.7231e-03,  3.4881e-03,
                       2.5031e-03,  6.5459e-04,  1.8029e-04,  1.3549e-04,
                       2.3392e-05,  6.0607e-04,  5.9148e-06,  1.4788e-04,
                       1.1345e-04,  6.7388e-04, -7.9753e-04,  1.7355e-04,
                       1.9467e-03,  8.8148e-03, -6.8595e-05,  1.1225e-03,
                       5.5119e-04,  2.1061e-03,  1.3242e-02,  1.5559e-04,
                       1.3836e-04,  3.8596e-04,  9.2702e-03, -3.2719e-04,
                       5.1371e-04,  2.0988e-04,  6.3573e-04,  2.3361e-03,
                       1.0828e-03,  7.3335e-04,  2.2200e-03, -5.5658e-05,
                       9.7737e-03,  2.7582e-03,  1.5846e-03,  6.7275e-04,
                       4.3024e-04, -6.1987e-05, -2.9541e-04,  3.6355e-04,
                       1.7512e-03,  3.5123e-03,  2.4276e-03,  6.6183e-04,
                       1.8087e-04,  1.3417e-04,  2.3138e-05,  6.1513e-04,
                       6.0203e-06,  1.4853e-04,  1.4048e-04,  6.8219e-04,
                      -3.7017e-05,  1.2079e-04,  2.0412e-03,  2.2938e-03,
                      -1.0540e-04,  6.9490e-04,  4.9094e-04,  3.9863e-03,
                       1.0321e-02,  4.3571e-05,  9.3782e-04,  3.1772e-04,
                       9.4069e-03,  7.6879e-04,  2.1589e-04,  7.0290e-04,
                       4.4552e-04,  3.6882e-03,  6.5990e-04,  1.9984e-03,
                       4.2791e-03, -2.4844e-04,  6.3156e-03,  1.3224e-03,
                       3.0317e-03,  1.7502e-03,  3.6457e-04,  1.5728e-04,
                       4.6641e-04,  7.3817e-05,  2.1481e-03, -1.4578e-03,
                       3.2458e-04, -2.7998e-04,  8.8275e-04,  3.1781e-04,
                      -2.2529e-05,  1.8771e-03,  2.0445e-03,  2.1981e-04,
                       4.7959e-05,  1.2170e-03, -3.9585e-05,  1.2230e-04,
                       2.0044e-03,  2.3015e-03, -1.5162e-04,  7.2877e-04,
                       4.7114e-04,  3.9730e-03,  1.0354e-02,  4.5736e-05,
                       9.6722e-04,  3.1720e-04,  9.4403e-03,  7.7719e-04,
                       2.1822e-04,  7.3700e-04,  4.5832e-04,  3.6215e-03,
                       6.6773e-04,  2.0223e-03,  4.2697e-03, -2.6350e-04,
                       6.3206e-03,  1.3555e-03,  2.9609e-03,  1.7344e-03,
                       3.5854e-04,  1.4677e-04,  4.7969e-04,  7.0233e-05,
                       2.1408e-03, -1.4272e-03,  3.3508e-04, -2.8212e-04,
                       9.0068e-04,  3.2263e-04, -2.2699e-05,  1.9017e-03,
                       2.0579e-03,  2.1132e-04,  4.7668e-05,  1.2223e-03,
                       1.9503e-03,  1.5972e-04,  1.4784e-02,  1.8781e-02,
                      -2.1977e-04, -2.5469e-03,  5.2149e-03,  5.7821e-03,
                       4.6512e-02,  3.6149e-04, -1.3485e-04,  6.5436e-03,
                       4.8366e-02,  2.7333e-03,  6.8416e-04,  1.4933e-02,
                      -1.3994e-04,  6.8327e-03,  1.0529e-02, -3.1877e-03,
                       7.8629e-04,  9.6189e-04,  1.4919e-02,  7.1516e-03,
                       1.4297e-02,  1.2315e-02,  5.6080e-03,  1.9871e-04,
                       1.8852e-03,  1.3043e-03,  8.4287e-03,  2.2141e-02,
                       9.7063e-03, -4.3991e-03,  2.6269e-03, -2.1608e-04,
                      -3.1977e-05,  7.5437e-04,  3.4248e-03,  1.0669e-03,
                       8.1640e-04,  4.7745e-03, -3.9403e-05,  1.2576e-04,
                       2.0317e-03,  2.2741e-03, -1.3457e-04,  7.2882e-04,
                       4.8968e-04,  3.9181e-03,  1.0237e-02,  4.3280e-05,
                       1.0561e-03,  3.2510e-04,  9.5309e-03,  7.6535e-04,
                       2.1779e-04,  7.4117e-04,  4.4558e-04,  3.7295e-03,
                       6.4505e-04,  1.9892e-03,  4.1687e-03, -2.7519e-04,
                       6.3411e-03,  1.3466e-03,  2.8861e-03,  1.7457e-03,
                       3.5282e-04,  1.6574e-04,  4.7261e-04,  7.1447e-05,
                       2.1268e-03, -1.4534e-03,  3.2231e-04, -2.7974e-04,
                       8.8625e-04,  2.8607e-04, -2.2178e-05,  1.8701e-03,
                       2.0745e-03,  2.1488e-04,  5.5758e-05,  1.2034e-03,
                      -3.3035e-03, -5.5440e-05,  6.5617e-03,  1.9662e-02,
                       7.1870e-04,  3.7861e-03, -5.8552e-04,  1.8076e-03,
                       9.3664e-02, -6.3148e-04,  1.1738e-03, -1.0209e-03,
                       1.3809e-02,  5.7168e-03, -3.8615e-04,  3.0846e-03,
                       1.0913e-03,  5.2508e-03,  3.4679e-04,  2.3223e-03,
                       2.3494e-02,  3.4550e-04,  4.1167e-03, -7.4919e-04,
                       5.8337e-03, -3.0945e-03,  9.3806e-03,  4.9097e-05,
                       8.3012e-03, -1.0412e-03,  7.5361e-03,  1.1195e-02,
                       1.0078e-02,  2.4568e-04,  3.3609e-03,  1.8349e-04,
                       1.0381e-05,  9.0580e-04,  2.4558e-03,  7.0895e-04,
                      -3.9508e-05,  6.4213e-03, -8.0861e-04,  2.0392e-04,
                       1.9258e-03,  8.7661e-03, -7.5545e-05,  1.1015e-03,
                       5.4499e-04,  2.1333e-03,  1.3251e-02,  1.4673e-04,
                       1.3199e-04,  4.0520e-04,  9.3618e-03, -3.2428e-04,
                       5.1700e-04,  2.1015e-04,  5.9993e-04,  2.3261e-03,
                       1.0455e-03,  7.4776e-04,  2.1995e-03, -5.4624e-05,
                       9.6948e-03,  2.6982e-03,  1.6159e-03,  6.7241e-04,
                       4.2382e-04, -8.8597e-05, -2.8742e-04,  3.4620e-04,
                       1.7390e-03,  3.4149e-03,  2.4900e-03,  6.5861e-04,
                       1.8091e-04,  1.3663e-04,  3.6368e-05,  6.1527e-04,
                       5.9613e-06,  1.4908e-04,  1.4837e-04,  6.7843e-04,
                      -7.9526e-04,  1.7719e-04,  1.9771e-03,  8.7674e-03,
                      -5.2441e-05,  1.1173e-03,  5.5732e-04,  2.1114e-03,
                       1.3297e-02,  1.5076e-04,  1.4053e-04,  3.9782e-04,
                       9.2942e-03, -3.2477e-04,  5.2043e-04,  2.1070e-04,
                       6.2462e-04,  2.3229e-03,  1.0538e-03,  7.3910e-04,
                       2.2201e-03, -5.6977e-05,  9.7086e-03,  2.7148e-03,
                       1.5875e-03,  6.6721e-04,  4.2710e-04, -6.6573e-05,
                      -2.9956e-04,  3.6165e-04,  1.7380e-03,  3.4582e-03,
                       2.4272e-03,  6.5844e-04,  1.8561e-04,  1.3272e-04,
                       2.6498e-05,  6.1161e-04,  6.1062e-06,  1.5354e-04,
                       1.4712e-04,  6.8640e-04]),
       size=(22540, 50), nnz=378, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(47, tensor(16980, device='cuda:7'))
16980
tensor(indices=tensor([[16980],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   73,    73,    73,  ..., 22209, 22209, 22209],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-4.2612e-05, -3.4372e-05,  2.6419e-04,  ...,
                       1.7943e-05,  1.6318e-05,  8.5682e-05]),
       size=(22540, 50), nnz=2863, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(48, tensor(14021, device='cuda:7'))
14021
tensor(indices=tensor([[14021],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  370,   370,   370,  ..., 22418, 22418, 22418],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-9.9981e-07,  3.3309e-06,  5.2701e-05,  ...,
                       5.4813e-06,  1.3215e-06,  3.0500e-05]),
       size=(22540, 50), nnz=9369, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(49, tensor(9082, device='cuda:7'))
9082
tensor(indices=tensor([[9082],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   94,    94,    94,  ..., 22128, 22128, 22128],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-9.6196e-05,  2.2707e-05,  2.4104e-04,  ...,
                       1.7265e-05,  1.7661e-05,  8.5077e-05]),
       size=(22540, 50), nnz=2996, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
8
11
(50, tensor(15956, device='cuda:7'))
15956
tensor(indices=tensor([[15956],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  121,   121,   121,  ..., 21697, 21697, 21697],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-4.5118e-06,  1.3863e-05,  2.2851e-04,  ...,
                       2.5556e-05,  6.9131e-06,  1.3815e-04]),
       size=(22540, 50), nnz=2313, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(51, tensor(19216, device='cuda:7'))
19216
tensor(indices=tensor([[19216],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  242,   242,   242,  ..., 22516, 22516, 22516],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-1.1047e-06,  3.9468e-06,  5.7708e-05,  ...,
                       6.3862e-06,  1.4988e-06,  3.5149e-05]),
       size=(22540, 50), nnz=8557, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
9
12
(52, tensor(18218, device='cuda:7'))
18218
tensor(indices=tensor([[18218],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   38,    38,    38,  ..., 22531, 22531, 22531],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-4.1455e-05,  9.1751e-06,  1.0256e-04,  ...,
                       6.9984e-06,  7.2853e-06,  3.4472e-05]),
       size=(22540, 50), nnz=6692, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(53, tensor(101, device='cuda:7'))
101
tensor(indices=tensor([[101],
                       [  0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  101,   101,   101,  ..., 22479, 22479, 22479],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-2.8406e-03, -4.7446e-05,  5.6617e-03,  ...,
                       2.3196e-05,  2.2804e-05,  1.1503e-04]),
       size=(22540, 50), nnz=2145, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
13
(54, tensor(5170, device='cuda:7'))
5170
tensor(indices=tensor([[5170],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1324,  1324,  1324,  ..., 22331, 22331, 22331],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-1.9022e-04,  4.9918e-05,  4.8123e-04,  ...,
                       3.5607e-05,  3.4722e-05,  1.6998e-04]),
       size=(22540, 50), nnz=1519, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(55, tensor(6744, device='cuda:7'))
6744
tensor(indices=tensor([[6744],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  539,   539,   539,  ..., 22480, 22480, 22480],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-6.2002e-06,  1.8041e-05,  3.2074e-04,  ...,
                       6.3972e-05,  2.6758e-05,  4.8671e-05]),
       size=(22540, 50), nnz=1777, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(56, tensor(10582, device='cuda:7'))
10582
tensor(indices=tensor([[10582],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  337,   337,   337,  ..., 22391, 22391, 22391],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-6.5718e-05,  1.5943e-05,  1.6349e-04,  ...,
                       1.1832e-05,  1.0018e-05,  5.6011e-05]),
       size=(22540, 50), nnz=4342, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(57, tensor(7417, device='cuda:7'))
7417
tensor(indices=tensor([[7417],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  349,   349,   349,  ..., 21585, 21585, 21585],
                       [    0,     1,     2,  ...,    46,    47,    48]]),
       values=tensor([ 6.0734e-08, -1.5605e-04,  3.2852e-05,  ...,
                       3.0085e-05,  6.5894e-06,  1.7744e-04]),
       size=(22540, 50), nnz=2066, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(58, tensor(15108, device='cuda:7'))
15108
tensor(indices=tensor([[15108],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  905,   905,   905,  ..., 21522, 21522, 21522],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-5.5399e-06,  1.6188e-05,  2.8214e-04,  ...,
                       9.0439e-05,  2.7503e-05,  6.5437e-05]),
       size=(22540, 50), nnz=1942, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(59, tensor(22241, device='cuda:7'))
22241
tensor(indices=tensor([[22241],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  340,   340,   340,  ..., 22488, 22488, 22488],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-6.7368e-05,  1.5696e-05,  1.7287e-04,  ...,
                       1.2362e-05,  1.3544e-05,  5.9091e-05]),
       size=(22540, 50), nnz=3927, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
10
14
(60, tensor(21863, device='cuda:7'))
21863
tensor(indices=tensor([[21863],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   49,    49,    49,  ..., 22495, 22495, 22495],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-3.4164e-04,  7.1608e-05,  8.5211e-04,  3.7867e-03,
                      -2.8293e-05,  4.8550e-04,  2.4404e-04,  9.2060e-04,
                       5.7455e-03,  6.2115e-05,  5.7525e-05,  1.7141e-04,
                       4.0176e-03, -1.4343e-04,  2.2058e-04,  9.1860e-05,
                       2.6862e-04,  1.0023e-03,  4.5077e-04,  3.2018e-04,
                       9.6636e-04, -2.4793e-05,  4.2772e-03,  1.1614e-03,
                       6.7882e-04,  2.9115e-04,  1.8666e-04, -3.9915e-05,
                      -1.2956e-04,  1.5883e-04,  7.6771e-04,  1.4793e-03,
                       1.0677e-03,  2.7429e-04,  7.8352e-05,  5.4413e-05,
                       9.3028e-06,  2.6137e-04,  2.6325e-06,  6.6054e-05,
                       5.5794e-05,  2.9748e-04, -7.7961e-05, -6.5726e-05,
                       4.8119e-04,  1.5754e-03,  1.1485e-05,  3.4727e-04,
                      -4.8523e-04,  3.0727e-03,  4.2520e-03,  5.2098e-04,
                      -5.5933e-05, -6.9651e-04,  2.8706e-03,  3.1747e-04,
                       9.2283e-04,  9.4281e-04,  6.3893e-05,  3.0336e-05,
                       3.3635e-04,  3.6687e-04,  6.0890e-04,  5.5459e-05,
                       1.9110e-03,  8.9030e-04, -3.2285e-04,  1.1017e-03,
                       6.7137e-04,  1.3785e-04,  3.3204e-04,  2.8838e-04,
                       6.5619e-04, -4.5983e-04, -6.4324e-04,  2.9773e-04,
                       4.1742e-04, -3.8461e-05, -8.1840e-05,  8.1414e-04,
                       1.2436e-03,  8.9466e-05,  2.7905e-05,  6.4810e-05,
                      -1.5063e-05,  4.1153e-05,  7.7061e-04,  8.4452e-04,
                      -5.9495e-05,  2.7058e-04,  1.8491e-04,  1.4530e-03,
                       3.8206e-03,  1.6633e-05,  3.5395e-04,  1.2350e-04,
                       3.5662e-03,  2.9097e-04,  5.8842e-06,  8.0843e-05,
                       2.9301e-04,  1.7106e-04,  1.4055e-03,  2.4925e-04,
                       7.4522e-04,  1.5080e-03, -1.0849e-04,  2.3764e-03,
                       4.9221e-04,  1.0836e-03,  6.5668e-04,  1.3104e-04,
                       5.3675e-05,  1.6942e-04,  2.6794e-05,  7.9299e-04,
                      -5.3738e-04,  1.1802e-04, -1.0253e-04,  3.3397e-04,
                       1.2931e-04, -6.1556e-06,  6.7858e-04,  7.8098e-04,
                       8.0278e-05,  1.8954e-05,  4.5938e-04, -1.4737e-05,
                       4.8949e-05,  7.4622e-04,  8.4679e-04, -3.5594e-05,
                       2.7369e-04,  1.7784e-04,  1.4662e-03,  3.8351e-03,
                       1.6248e-05,  3.5790e-04,  1.1909e-04,  3.5275e-03,
                       2.8434e-04,  7.9911e-05,  2.7088e-04,  1.6744e-04,
                       1.3903e-03,  2.4208e-04,  7.4018e-04,  1.5434e-03,
                      -1.0634e-04,  2.3508e-03,  5.0388e-04,  1.0911e-03,
                       6.4422e-04,  1.3233e-04,  6.1649e-05,  1.7088e-04,
                       2.7144e-05,  7.8745e-04, -5.3350e-04,  1.1810e-04,
                      -9.8675e-05,  3.3570e-04,  1.1759e-04, -7.7819e-06,
                       7.0490e-04,  7.6449e-04,  7.7720e-05,  1.7716e-05,
                       4.4645e-04, -7.7787e-05, -6.6713e-05,  4.9036e-04,
                       1.5789e-03,  1.0939e-05,  3.4378e-04, -5.1504e-04,
                       3.0656e-03,  4.2255e-03,  5.3624e-04, -5.7226e-05,
                      -7.2946e-04,  2.8713e-03,  3.1314e-04,  9.0884e-04,
                       9.6293e-04,  6.2554e-05,  3.0089e-05,  3.1664e-04,
                       3.7150e-04,  6.0590e-04,  5.4465e-05,  1.9225e-03,
                       8.7848e-04, -3.2410e-04,  1.1059e-03,  6.7474e-04,
                       9.5519e-05,  3.2741e-04,  2.8560e-04,  6.7160e-04,
                      -4.5301e-04, -6.4375e-04,  2.9790e-04,  4.1998e-04,
                      -3.6679e-05, -1.1409e-04,  7.8310e-04,  1.2451e-03,
                       8.9789e-05,  3.1273e-05,  6.3393e-05, -3.4383e-04,
                       7.8247e-05,  8.4798e-04,  3.8031e-03, -4.6615e-05,
                       5.0115e-04,  2.4113e-04,  9.3580e-04,  5.7462e-03,
                       6.4953e-05,  6.5157e-05,  1.8011e-04,  3.9783e-03,
                      -1.3937e-04,  2.0637e-04,  9.0411e-05,  2.6040e-04,
                       9.7768e-04,  4.5436e-04,  3.1172e-04,  9.8099e-04,
                      -2.4139e-05,  4.2448e-03,  1.1686e-03,  6.8620e-04,
                       2.9775e-04,  1.8892e-04, -4.7043e-05, -1.2771e-04,
                       1.6210e-04,  7.7470e-04,  1.4809e-03,  1.0542e-03,
                       2.6383e-04,  7.8896e-05,  5.7202e-05,  1.0997e-05,
                       2.6723e-04,  2.6336e-06,  6.3601e-05,  6.3293e-05,
                       2.9381e-04, -3.3406e-04,  7.2999e-05,  8.5338e-04,
                       3.7848e-03, -1.7090e-05,  4.5484e-04,  2.2302e-04,
                       9.2051e-04,  5.6974e-03,  6.0188e-05,  5.7113e-05,
                       1.6504e-04,  3.9820e-03, -1.4540e-04,  2.1892e-04,
                       8.7902e-05,  2.8732e-04,  9.9748e-04,  4.2362e-04,
                       3.4639e-04,  1.0011e-03, -2.5481e-05,  4.0924e-03,
                       1.1870e-03,  6.9990e-04,  2.9339e-04,  1.8352e-04,
                      -3.1694e-05, -1.3191e-04,  1.4720e-04,  7.5486e-04,
                       1.4905e-03,  1.0302e-03,  2.6414e-04,  8.0643e-05,
                       5.4167e-05,  6.4737e-06,  2.5611e-04,  2.6278e-06,
                       5.9445e-05,  5.9239e-05,  2.8863e-04, -3.4537e-04,
                       6.6214e-05,  8.3955e-04,  3.7656e-03, -1.2206e-05,
                       4.5335e-04,  2.2070e-04,  9.1744e-04,  5.7022e-03,
                       5.9024e-05,  5.4365e-05,  1.7104e-04,  3.9904e-03,
                      -1.4672e-04,  2.1914e-04,  9.0628e-05,  2.9180e-04,
                       1.0064e-03,  4.3663e-04,  3.4580e-04,  9.9480e-04,
                      -2.7610e-05,  4.0745e-03,  1.1827e-03,  6.9524e-04,
                       2.9216e-04,  1.8336e-04, -3.4991e-05, -1.3037e-04,
                       1.4854e-04,  7.5055e-04,  1.4885e-03,  1.0531e-03,
                       2.7535e-04,  8.0415e-05,  5.5751e-05,  4.5447e-06,
                       2.5444e-04,  2.5936e-06,  6.1491e-05,  6.1054e-05,
                       2.8925e-04, -7.9425e-05, -6.3568e-05,  4.8357e-04,
                       1.5837e-03,  1.2323e-05,  3.3811e-04, -4.9392e-04,
                       3.0139e-03,  4.2682e-03,  5.2564e-04, -5.5491e-05,
                      -7.0827e-04,  2.9114e-03,  3.1969e-04,  9.2543e-04,
                       9.5644e-04,  6.4604e-05,  3.0359e-05,  3.2490e-04,
                       3.8239e-04,  6.0506e-04,  5.6666e-05,  1.9277e-03,
                       8.7795e-04, -3.1996e-04,  1.1123e-03,  6.8532e-04,
                       1.2305e-04,  3.2985e-04,  2.8798e-04,  6.7434e-04,
                      -4.6086e-04, -6.5841e-04,  2.9300e-04,  4.2196e-04,
                      -3.6666e-05, -1.0052e-04,  7.8899e-04,  1.2505e-03,
                       9.0010e-05,  3.3818e-05,  6.3476e-05, -3.4715e-04,
                       7.5554e-05,  8.5766e-04,  3.7898e-03, -3.2113e-05,
                       4.8145e-04,  2.3938e-04,  9.3113e-04,  5.7253e-03,
                       6.3252e-05,  6.3603e-05,  1.6882e-04,  3.9926e-03,
                      -1.4457e-04,  9.4165e-06,  2.1239e-04,  9.3876e-05,
                       2.8098e-04,  9.9419e-04,  4.5685e-04,  3.2104e-04,
                       9.6420e-04, -2.2037e-05,  4.2288e-03,  1.1865e-03,
                       6.8934e-04,  2.9262e-04,  1.8757e-04, -3.1010e-05,
                      -1.3118e-04,  1.5253e-04,  7.5193e-04,  1.4904e-03,
                       1.0837e-03,  2.6809e-04,  8.1113e-05,  5.5409e-05,
                       1.0633e-05,  2.6029e-04,  2.6006e-06,  6.1819e-05,
                       5.2852e-05,  2.9668e-04, -3.4488e-04,  6.5721e-05,
                       8.5574e-04,  3.7585e-03, -1.6122e-05,  4.5994e-04,
                       2.2615e-04,  9.2650e-04,  5.6776e-03,  5.9746e-05,
                       5.5070e-05,  1.7069e-04,  4.0005e-03, -1.4370e-04,
                       2.1440e-04,  9.1446e-05,  2.8171e-04,  1.0020e-03,
                       4.2939e-04,  3.4325e-04,  9.9135e-04, -2.5723e-05,
                       4.1065e-03,  1.1862e-03,  6.9719e-04,  2.9562e-04,
                       1.8285e-04, -3.1660e-05, -1.2972e-04,  1.5112e-04,
                       7.6600e-04,  1.4895e-03,  1.0315e-03,  2.7705e-04,
                       8.0636e-05,  5.3194e-05,  5.9204e-06,  2.5182e-04,
                       2.6498e-06,  6.3021e-05,  6.5951e-05,  2.9524e-04,
                      -7.8436e-05, -6.5953e-05,  4.8471e-04,  1.5823e-03,
                       1.2279e-05,  3.3927e-04, -4.9894e-04,  3.0464e-03,
                       4.2322e-03,  5.4371e-04, -5.6730e-05, -7.1678e-04,
                       2.8798e-03,  3.1386e-04,  9.0736e-04,  9.4082e-04,
                       6.3771e-05,  3.0246e-05,  3.2433e-04,  3.7105e-04,
                       6.1072e-04,  5.5237e-05,  1.9220e-03,  8.8747e-04,
                      -3.2334e-04,  1.1226e-03,  6.7935e-04,  1.1429e-04,
                       3.2758e-04,  2.8469e-04,  6.7351e-04, -4.5697e-04,
                      -6.5347e-04,  2.9715e-04,  4.1673e-04, -3.5800e-05,
                      -9.7136e-05,  7.7215e-04,  1.2367e-03,  9.1133e-05,
                       2.9433e-05,  6.3526e-05, -1.4906e-05,  4.1384e-05,
                       7.4643e-04,  8.5099e-04, -5.9311e-05,  2.6716e-04,
                       1.8231e-04,  1.4592e-03,  3.8017e-03,  1.6771e-05,
                       3.8645e-04,  1.1764e-04,  3.5084e-03,  2.8927e-04,
                       7.7430e-05,  2.7495e-04,  1.6849e-04,  1.3953e-03,
                       2.3634e-04,  7.4573e-04,  1.5453e-03, -1.0064e-04,
                       2.3228e-03,  4.9323e-04,  1.0611e-03,  6.4468e-04,
                       1.3151e-04,  6.6239e-05,  1.6878e-04,  2.6245e-05,
                       7.8545e-04, -5.3207e-04,  1.1907e-04, -1.0474e-04,
                       3.3742e-04,  1.0959e-04, -7.8728e-06,  6.7178e-04,
                       7.5738e-04,  8.0372e-05,  2.0874e-05,  4.3848e-04,
                      -1.4861e-05,  4.6787e-05,  7.5793e-04,  8.4258e-04,
                      -4.8888e-05,  2.7596e-04,  1.8856e-04,  1.4631e-03,
                       3.8130e-03,  1.7019e-05,  4.1265e-04,  1.1992e-04,
                       3.5160e-03,  2.7913e-04,  7.9167e-05,  2.7693e-04,
                       1.6030e-04,  1.3789e-03,  2.2938e-04,  7.4897e-04,
                       1.5673e-03, -1.0408e-04,  2.3355e-03,  5.0179e-04,
                       1.0664e-03,  6.6580e-04,  1.3316e-04,  7.1215e-05,
                       1.7521e-04,  2.5830e-05,  7.8445e-04, -5.3677e-04,
                       1.1703e-04, -9.8150e-05,  3.3406e-04,  1.1149e-04,
                      -8.5811e-06,  7.0725e-04,  7.8506e-04,  8.0665e-05,
                       2.1493e-05,  4.4818e-04, -1.4638e-05,  4.6482e-05,
                       7.4343e-04,  8.4866e-04, -6.0389e-05,  2.6563e-04,
                       1.7974e-04,  1.4526e-03,  3.7981e-03,  1.6431e-05,
                       3.7221e-04,  1.1687e-04,  3.5202e-03,  2.8505e-04,
                       8.1508e-05,  2.7324e-04,  1.6770e-04,  1.3703e-03,
                       2.3323e-04,  7.3904e-04,  1.5576e-03, -9.9579e-05,
                       2.3078e-03,  4.9848e-04,  1.0606e-03,  6.4152e-04,
                       1.3101e-04,  6.4308e-05,  1.6990e-04,  2.6016e-05,
                       7.8398e-04, -5.4034e-04,  1.1821e-04, -1.0433e-04,
                       3.2753e-04,  1.0488e-04, -8.4428e-06,  6.9990e-04,
                       7.6045e-04,  8.2232e-05,  2.1583e-05,  4.4547e-04,
                       1.6874e-03,  1.3819e-04,  1.2791e-02,  1.6249e-02,
                      -1.9014e-04, -2.2036e-03,  4.5119e-03,  5.0026e-03,
                       4.0241e-02,  3.1275e-04, -1.1667e-04,  5.6615e-03,
                       4.1845e-02,  2.3648e-03,  5.9192e-04,  1.2919e-02,
                      -1.2108e-04,  5.9116e-03,  9.1093e-03, -2.7579e-03,
                       6.8029e-04,  8.3221e-04,  1.2908e-02,  6.1875e-03,
                       1.2370e-02,  1.0655e-02,  4.8520e-03,  1.7192e-04,
                       1.6310e-03,  1.1284e-03,  7.2924e-03,  1.9156e-02,
                       8.3978e-03, -3.8061e-03,  2.2728e-03, -1.8695e-04,
                      -2.7666e-05,  6.5267e-04,  2.9631e-03,  9.2304e-04,
                       7.0634e-04,  4.1308e-03, -1.4804e-05,  4.7602e-05,
                       7.5478e-04,  8.4957e-04, -5.1036e-05,  2.7058e-04,
                       1.7986e-04,  1.4642e-03,  3.8142e-03,  1.6219e-05,
                       3.5313e-04,  1.2121e-04,  3.5290e-03,  2.8539e-04,
                       8.0935e-05,  2.7373e-04,  1.6609e-04,  1.3784e-03,
                       2.3257e-04,  7.5543e-04,  1.5431e-03, -1.0261e-04,
                       2.3317e-03,  5.0117e-04,  1.0653e-03,  6.4677e-04,
                       1.3140e-04,  6.1700e-05,  1.6858e-04,  2.6639e-05,
                       7.9476e-04, -5.3522e-04,  1.1806e-04, -1.0246e-04,
                       3.3418e-04,  1.1578e-04, -8.1369e-06,  7.0039e-04,
                       7.6615e-04,  8.1594e-05,  2.1648e-05,  4.4663e-04,
                      -7.6020e-05, -6.0835e-05,  4.8421e-04,  1.5840e-03,
                       6.7501e-06,  3.4529e-04, -5.0466e-04,  3.0354e-03,
                       4.2371e-03,  5.2330e-04, -5.8910e-05, -7.0289e-04,
                       2.8727e-03,  3.1578e-04,  9.2775e-04,  9.4687e-04,
                       6.4629e-05,  3.0037e-05,  3.3776e-04,  3.6994e-04,
                       6.1515e-04,  5.4801e-05,  1.9242e-03,  8.9330e-04,
                      -3.1985e-04,  1.1055e-03,  6.8373e-04,  1.3263e-04,
                       3.3948e-04,  2.9360e-04,  6.6577e-04, -4.6029e-04,
                      -6.4894e-04,  2.9247e-04,  4.2573e-04, -3.6614e-05,
                      -5.9112e-05,  7.9513e-04,  1.2393e-03,  8.9717e-05,
                       3.0681e-05,  6.4785e-05, -3.4754e-04,  6.5901e-05,
                       8.4660e-04,  3.7558e-03, -1.9100e-05,  4.6257e-04,
                       2.2795e-04,  9.2638e-04,  5.6780e-03,  6.0538e-05,
                       5.3239e-05,  1.7047e-04,  4.0181e-03, -1.4396e-04,
                       2.1249e-04,  8.9629e-05,  2.8495e-04,  1.0063e-03,
                       4.3045e-04,  3.4275e-04,  9.9624e-04, -2.7042e-05,
                       4.1028e-03,  1.1888e-03,  7.0149e-04,  2.9338e-04,
                       1.8446e-04, -3.3973e-05, -1.3019e-04,  1.4871e-04,
                       7.5924e-04,  1.4855e-03,  1.0236e-03,  2.7301e-04,
                       7.9239e-05,  5.5671e-05,  5.1916e-06,  2.4889e-04,
                       2.6019e-06,  6.0949e-05,  6.2852e-05,  2.9204e-04,
                      -1.4656e-05,  4.3841e-05,  7.5484e-04,  8.4968e-04,
                      -5.1940e-05,  2.6403e-04,  1.8206e-04,  1.4544e-03,
                       3.8195e-03,  1.6255e-05,  3.8659e-04,  1.1894e-04,
                       3.5482e-03,  2.8699e-04,  8.0221e-05,  2.7675e-04,
                       1.6637e-04,  1.3813e-03,  2.4040e-04,  7.3477e-04,
                       1.5405e-03, -1.0049e-04,  2.3255e-03,  4.9411e-04,
                       1.0642e-03,  6.4423e-04,  1.3259e-04,  6.0410e-05,
                       1.6948e-04,  2.6584e-05,  7.8825e-04, -5.3524e-04,
                       1.1821e-04, -1.0302e-04,  3.3072e-04,  1.1251e-04,
                      -7.3690e-06,  7.0064e-04,  7.6263e-04,  8.2134e-05,
                       2.1455e-05,  4.4848e-04, -7.7179e-05, -6.3323e-05,
                       4.8679e-04,  1.5947e-03,  9.6156e-06,  3.2876e-04,
                      -4.8393e-04,  3.0465e-03,  4.2525e-03,  5.2955e-04,
                      -5.7472e-05, -7.0824e-04,  2.8772e-03,  3.1038e-04,
                       8.9247e-04,  8.9977e-04,  6.3569e-05,  3.0180e-05,
                       3.1768e-04,  3.7361e-04,  6.1887e-04,  5.0967e-05,
                       1.9017e-03,  8.8050e-04, -3.2307e-04,  1.1076e-03,
                       6.9061e-04,  1.2851e-04,  3.2538e-04,  2.8385e-04,
                       6.7609e-04, -4.5779e-04, -6.5066e-04,  3.0116e-04,
                       4.1243e-04, -3.8920e-05, -9.3110e-05,  8.0786e-04,
                       1.2429e-03,  9.1666e-05,  3.0493e-05,  6.3529e-05,
                      -2.8386e-03, -4.7262e-05,  5.7170e-03,  1.7059e-02,
                       6.8149e-04,  3.1957e-03, -5.2157e-04,  1.5571e-03,
                       8.1374e-02, -5.5309e-04,  9.9712e-04, -8.8902e-04,
                       1.1975e-02,  4.9490e-03, -3.2453e-04,  2.6668e-03,
                       9.3732e-04,  4.5808e-03,  2.9899e-04,  2.0198e-03,
                       2.0400e-02,  2.9381e-04,  3.5870e-03, -6.4793e-04,
                       5.0085e-03, -2.6528e-03,  8.0197e-03,  4.5301e-05,
                       7.2732e-03, -9.2212e-04,  6.4969e-03,  9.7741e-03,
                       8.4044e-03,  2.1047e-04,  2.9493e-03,  1.5916e-04,
                       1.0311e-05,  7.7197e-04,  2.1349e-03,  6.1150e-04,
                      -3.0843e-05,  5.5643e-03, -3.4714e-04,  8.1016e-05,
                       8.5724e-04,  3.8013e-03, -3.3196e-05,  4.7498e-04,
                       2.3728e-04,  9.1717e-04,  5.7080e-03,  6.4881e-05,
                       6.3186e-05,  1.5985e-04,  3.9654e-03, -1.4180e-04,
                       3.7716e-06,  2.1487e-04,  8.9360e-05,  2.8101e-04,
                       9.8893e-04,  4.5275e-04,  3.2269e-04,  9.6750e-04,
                      -2.3405e-05,  4.1638e-03,  1.1984e-03,  6.8648e-04,
                       2.9030e-04,  1.8442e-04, -3.7452e-05, -1.3046e-04,
                       1.5039e-04,  7.4670e-04,  1.4983e-03,  1.0614e-03,
                       2.7145e-04,  8.0131e-05,  5.4068e-05,  1.1682e-05,
                       2.5411e-04,  2.5704e-06,  6.4824e-05,  5.0413e-05,
                       2.9478e-04]),
       size=(22540, 50), nnz=969, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(61, tensor(2846, device='cuda:7'))
2846
tensor(indices=tensor([[2846],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  645,   645,   645,  ..., 22102, 22102, 22102],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-1.8279e-04,  3.4820e-05,  4.5241e-04,  ...,
                       3.9039e-05,  1.1280e-05,  2.2745e-04]),
       size=(22540, 50), nnz=1597, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(62, tensor(6607, device='cuda:7'))
6607
tensor(indices=tensor([[6607],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  285,   285,   285,  ..., 22448, 22448, 22448],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-2.6030e-06,  7.9957e-06,  1.3665e-04,  ...,
                       1.3585e-05,  1.3382e-05,  6.3854e-05]),
       size=(22540, 50), nnz=3707, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
11
15
(63, tensor(22189, device='cuda:7'))
22189
tensor(indices=tensor([[22189],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  840,   840,   840,  ..., 22189, 22189, 22189],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-2.5953e-06,  7.1846e-06,  1.3567e-04,  ...,
                       6.0569e-04, -3.2696e-05,  5.5846e-03]),
       size=(22540, 50), nnz=3716, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
12
16
(64, tensor(8783, device='cuda:7'))
8783
tensor(indices=tensor([[8783],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   26,    26,    26,  ..., 22463, 22463, 22463],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-3.3597e-06,  1.1291e-05,  1.7419e-04,  ...,
                       1.8363e-05,  5.1195e-06,  1.0534e-04]),
       size=(22540, 50), nnz=2987, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
13
17
(65, tensor(9376, device='cuda:7'))
9376
tensor(indices=tensor([[9376],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  745,   745,   745,  ..., 22492, 22492, 22492],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-3.1648e-06,  1.0177e-05,  1.6134e-04,  ...,
                       5.4416e-05,  1.8807e-05,  3.8834e-05]),
       size=(22540, 50), nnz=3220, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(66, tensor(12544, device='cuda:7'))
12544
tensor(indices=tensor([[12544],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  799,   799,   799,  ..., 22462, 22462, 22462],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-1.3689e-04,  3.2317e-05,  3.3365e-04,  ...,
                       2.4483e-05,  2.5239e-05,  1.1614e-04]),
       size=(22540, 50), nnz=2192, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
18
(67, tensor(20261, device='cuda:7'))
20261
tensor(indices=tensor([[20261],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   41,    41,    41,  ..., 21504, 21504, 21504],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-3.2551e-06,  9.5399e-06,  1.6715e-04,  ...,
                       1.7690e-05,  4.2785e-06,  1.0054e-04]),
       size=(22540, 50), nnz=3164, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
4256
torch.Size([2, 149304])
tensor(indices=tensor([[4256],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[    4,     4,     4,  ..., 20095, 20095, 20095],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-1.6392e-04,  3.5893e-05,  3.9973e-04,  ...,
                       2.9082e-05,  2.8214e-05,  1.3861e-04]),
       size=(22540, 50), nnz=1859, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
4256 8707 4
10336
torch.Size([2, 149304])
tensor(indices=tensor([[10336],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[    5,     5,     5,  ..., 22311, 22311, 22311],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([1.6368e-03, 1.2707e-04, 1.2353e-02,  ...,
                      1.7844e-05, 1.7648e-05, 8.1285e-05]),
       size=(22540, 50), nnz=2916, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
10336 15665 5
14021
torch.Size([2, 149304])
tensor(indices=tensor([[14021],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[    6,     6,     6,  ..., 22418, 22418, 22418],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-1.0144e-06,  3.2555e-06,  5.1754e-05,  ...,
                       5.4813e-06,  1.3215e-06,  3.0500e-05]),
       size=(22540, 50), nnz=9369, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
14021 11620 6
4256
tensor(indices=tensor([[4256],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  486,   486,   486,  ..., 20095, 20095, 20095],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-6.0857e-06,  1.7479e-05,  3.1226e-04,  ...,
                       2.9080e-05,  2.8212e-05,  1.3860e-04]),
       size=(22540, 50), nnz=1859, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
10336
tensor(indices=tensor([[10336],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  201,   201,   201,  ..., 22311, 22311, 22311],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-9.4580e-05,  2.0668e-05,  2.3310e-04,  ...,
                       1.7711e-05,  1.7517e-05,  8.0679e-05]),
       size=(22540, 50), nnz=2916, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
14021
tensor(indices=tensor([[14021],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  370,   370,   370,  ..., 22418, 22418, 22418],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-9.9982e-07,  3.3309e-06,  5.2702e-05,  ...,
                       5.4813e-06,  1.3215e-06,  3.0500e-05]),
       size=(22540, 50), nnz=9369, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
8783
tensor(indices=tensor([[8783],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   26,    26,    26,  ..., 22463, 22463, 22463],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-3.3598e-06,  1.1292e-05,  1.7419e-04,  ...,
                       1.8364e-05,  5.1197e-06,  1.0535e-04]),
       size=(22540, 50), nnz=2987, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
14021
tensor(indices=tensor([[14021],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  370,   370,   370,  ..., 22418, 22418, 22418],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-9.9981e-07,  3.3309e-06,  5.2701e-05,  ...,
                       5.4813e-06,  1.3215e-06,  3.0500e-05]),
       size=(22540, 50), nnz=9369, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
6607
tensor(indices=tensor([[6607],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  285,   285,   285,  ..., 22448, 22448, 22448],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-2.6106e-06,  8.0190e-06,  1.3705e-04,  ...,
                       1.3625e-05,  1.3421e-05,  6.4040e-05]),
       size=(22540, 50), nnz=3707, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
8783
torch.Size([2, 149304])
tensor(indices=tensor([[8783],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   16,    16,    16,  ..., 22463, 22463, 22463],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-4.6149e-05, -3.9163e-05,  2.9008e-04,  ...,
                       1.8363e-05,  5.1195e-06,  1.0534e-04]),
       size=(22540, 50), nnz=2987, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
8783 18185 16
14021
torch.Size([2, 149304])
tensor(indices=tensor([[14021],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[    1,     1,     1,  ..., 22418, 22418, 22418],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-2.8519e-05,  5.7024e-06,  6.9928e-05,  ...,
                       5.4813e-06,  1.3215e-06,  3.0500e-05]),
       size=(22540, 50), nnz=9369, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
14021 15104 1
15542
torch.Size([2, 149304])
tensor(indices=tensor([[15542],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1508,  1508,  1508,  ..., 22413, 22413, 22413],
                       [    1,     2,     4,  ...,    46,    47,    48]]),
       values=tensor([-5.0961e-05, -4.4035e-05,  3.2459e-04,  ...,
                       8.1730e-05,  2.2800e-05,  4.4598e-04]),
       size=(22540, 50), nnz=1099, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
15542 3985 14
count_nodes_self:  13
count_edges_self:  18
Starting evaluation...
[Evaluation] Test Accuracy: 66.18
model:  RGCN_emb
emb_type:  TransE
Labels loaded.
RDF loaded.
Graph loaded.
cuda:  True
shape edges:  torch.Size([63382, 3])
test_idx:  tensor([12917, 21950,  3144, 20225,  7271, 10768, 11934,  4336, 10172, 13510,
        19233, 19260,  7860,  9637,  7315, 21185,  9704, 15542,  1543,  9956,
        19946,  2144, 17777, 13745,  5234, 20943,  3410,  5643,   211,  3969,
        11213, 10620, 11150, 10248, 19890, 18276,  1166, 10336,  4256,   963,
         4369,  6785,  2579, 17531,   541, 13333, 19769, 16980, 14021,  9082,
        15956, 19216, 18218,   101,  5170,  6744, 10582,  7417, 15108, 22241,
        21863,  2846,  6607, 22189,  8783,  9376, 12544, 20261],
       device='cuda:7')
num_classes:  2
num_nodes:  22540
num_relations:  9
tensor([[0.4540, 0.5460],
        [0.4980, 0.5020],
        [0.4842, 0.5158],
        [0.4815, 0.5185],
        [0.4816, 0.5184],
        [0.4454, 0.5546],
        [0.4889, 0.5111],
        [0.4800, 0.5200],
        [0.4519, 0.5481],
        [0.5131, 0.4869],
        [0.4774, 0.5226],
        [0.5109, 0.4891],
        [0.4714, 0.5286],
        [0.4815, 0.5185],
        [0.4957, 0.5043],
        [0.4741, 0.5259],
        [0.4804, 0.5196],
        [0.4875, 0.5125],
        [0.4590, 0.5410],
        [0.4912, 0.5088],
        [0.4993, 0.5007],
        [0.4523, 0.5477],
        [0.4884, 0.5116],
        [0.4799, 0.5201],
        [0.4920, 0.5080],
        [0.4926, 0.5074],
        [0.4760, 0.5240],
        [0.4962, 0.5038],
        [0.4776, 0.5224],
        [0.4884, 0.5116],
        [0.4576, 0.5424],
        [0.4792, 0.5208],
        [0.4656, 0.5344],
        [0.5144, 0.4856],
        [0.4907, 0.5093],
        [0.5116, 0.4884],
        [0.4863, 0.5137],
        [0.4704, 0.5296],
        [0.4896, 0.5104],
        [0.4890, 0.5110],
        [0.5047, 0.4953],
        [0.4737, 0.5263],
        [0.4305, 0.5695],
        [0.4903, 0.5097],
        [0.4828, 0.5172],
        [0.4717, 0.5283],
        [0.4829, 0.5171],
        [0.4868, 0.5132],
        [0.5166, 0.4834],
        [0.4656, 0.5344],
        [0.4676, 0.5324],
        [0.4754, 0.5246],
        [0.4974, 0.5026],
        [0.5132, 0.4868],
        [0.4937, 0.5063],
        [0.4605, 0.5395],
        [0.4806, 0.5194],
        [0.4695, 0.5305],
        [0.4836, 0.5164],
        [0.5017, 0.4983],
        [0.5186, 0.4814],
        [0.4602, 0.5398],
        [0.5072, 0.4928],
        [0.4938, 0.5062],
        [0.5013, 0.4987],
        [0.4535, 0.5465],
        [0.4702, 0.5298],
        [0.4982, 0.5018],
        [0.4608, 0.5392],
        [0.4889, 0.5111],
        [0.4756, 0.5244],
        [0.5018, 0.4982],
        [0.4966, 0.5034],
        [0.4695, 0.5305],
        [0.4683, 0.5317],
        [0.4807, 0.5193],
        [0.4716, 0.5284],
        [0.5010, 0.4990],
        [0.4847, 0.5153],
        [0.4908, 0.5092],
        [0.4768, 0.5232],
        [0.4683, 0.5317],
        [0.4689, 0.5311],
        [0.4723, 0.5277],
        [0.4959, 0.5041],
        [0.4808, 0.5192],
        [0.4898, 0.5102],
        [0.4773, 0.5227],
        [0.4928, 0.5072],
        [0.5090, 0.4910],
        [0.4721, 0.5279],
        [0.4804, 0.5196],
        [0.5133, 0.4867],
        [0.4827, 0.5173],
        [0.4734, 0.5266],
        [0.4561, 0.5439],
        [0.4882, 0.5118],
        [0.4794, 0.5206],
        [0.4586, 0.5414],
        [0.4660, 0.5340],
        [0.4918, 0.5082],
        [0.4733, 0.5267],
        [0.4540, 0.5460],
        [0.4460, 0.5540],
        [0.5133, 0.4867],
        [0.4787, 0.5213],
        [0.5064, 0.4936],
        [0.4616, 0.5384],
        [0.5068, 0.4932],
        [0.5161, 0.4839],
        [0.5087, 0.4913],
        [0.4784, 0.5216],
        [0.5034, 0.4966],
        [0.4600, 0.5400],
        [0.4881, 0.5119],
        [0.4832, 0.5168],
        [0.4860, 0.5140],
        [0.4714, 0.5286],
        [0.4579, 0.5421],
        [0.5048, 0.4952],
        [0.4723, 0.5277],
        [0.4622, 0.5378],
        [0.4959, 0.5041],
        [0.4838, 0.5162],
        [0.4817, 0.5183],
        [0.4631, 0.5369],
        [0.4558, 0.5442],
        [0.4998, 0.5002],
        [0.4917, 0.5083],
        [0.4540, 0.5460],
        [0.4714, 0.5286],
        [0.4669, 0.5331],
        [0.4916, 0.5084],
        [0.4385, 0.5615],
        [0.5177, 0.4823],
        [0.4922, 0.5078],
        [0.4810, 0.5190],
        [0.4870, 0.5130],
        [0.4734, 0.5266],
        [0.4579, 0.5421],
        [0.4519, 0.5481],
        [0.5109, 0.4891],
        [0.5044, 0.4956],
        [0.4954, 0.5046],
        [0.4644, 0.5356],
        [0.4751, 0.5249],
        [0.4950, 0.5050],
        [0.4706, 0.5294],
        [0.4818, 0.5182],
        [0.5176, 0.4824],
        [0.4819, 0.5181],
        [0.4720, 0.5280],
        [0.5178, 0.4822],
        [0.4516, 0.5484],
        [0.4713, 0.5287],
        [0.4951, 0.5049],
        [0.4684, 0.5316],
        [0.4796, 0.5204],
        [0.5136, 0.4864],
        [0.4399, 0.5601],
        [0.4780, 0.5220],
        [0.4914, 0.5086],
        [0.4590, 0.5410],
        [0.4807, 0.5193],
        [0.5098, 0.4902],
        [0.4637, 0.5363],
        [0.4965, 0.5035],
        [0.5008, 0.4992],
        [0.4833, 0.5167],
        [0.4982, 0.5018],
        [0.4547, 0.5453],
        [0.4667, 0.5333],
        [0.4818, 0.5182],
        [0.5093, 0.4907],
        [0.5026, 0.4974],
        [0.5075, 0.4925],
        [0.4919, 0.5081],
        [0.4782, 0.5218],
        [0.4649, 0.5351],
        [0.5047, 0.4953],
        [0.5006, 0.4994],
        [0.5076, 0.4924],
        [0.4873, 0.5127],
        [0.4839, 0.5161],
        [0.5037, 0.4963],
        [0.4669, 0.5331],
        [0.4842, 0.5158],
        [0.4624, 0.5376],
        [0.4868, 0.5132],
        [0.4835, 0.5165],
        [0.5001, 0.4999],
        [0.4771, 0.5229],
        [0.4997, 0.5003],
        [0.4778, 0.5222],
        [0.4603, 0.5397],
        [0.4788, 0.5212],
        [0.4962, 0.5038],
        [0.4808, 0.5192],
        [0.5000, 0.5000],
        [0.4845, 0.5155],
        [0.4450, 0.5550],
        [0.5090, 0.4910],
        [0.4803, 0.5197],
        [0.4523, 0.5477],
        [0.4973, 0.5027],
        [0.4922, 0.5078],
        [0.4663, 0.5337],
        [0.4634, 0.5366],
        [0.4785, 0.5215],
        [0.4905, 0.5095],
        [0.4819, 0.5181],
        [0.4587, 0.5413],
        [0.4738, 0.5262],
        [0.5013, 0.4987],
        [0.4937, 0.5063],
        [0.5013, 0.4987],
        [0.5040, 0.4960],
        [0.4896, 0.5104],
        [0.5321, 0.4679],
        [0.4864, 0.5136],
        [0.4906, 0.5094],
        [0.4915, 0.5085],
        [0.5043, 0.4957],
        [0.5071, 0.4929],
        [0.4718, 0.5282],
        [0.4847, 0.5153],
        [0.5077, 0.4923],
        [0.4918, 0.5082],
        [0.4689, 0.5311],
        [0.4881, 0.5119],
        [0.4800, 0.5200],
        [0.4878, 0.5122],
        [0.5123, 0.4877],
        [0.4800, 0.5200],
        [0.5152, 0.4848],
        [0.4750, 0.5250],
        [0.4643, 0.5357],
        [0.4814, 0.5186],
        [0.5007, 0.4993],
        [0.4858, 0.5142],
        [0.4983, 0.5017],
        [0.4655, 0.5345],
        [0.4762, 0.5238],
        [0.4819, 0.5181],
        [0.4547, 0.5453],
        [0.4837, 0.5163],
        [0.4644, 0.5356],
        [0.4539, 0.5461],
        [0.4980, 0.5020],
        [0.4758, 0.5242],
        [0.4750, 0.5250],
        [0.4876, 0.5124],
        [0.4680, 0.5320],
        [0.5061, 0.4939],
        [0.4959, 0.5041],
        [0.4831, 0.5169],
        [0.4994, 0.5006],
        [0.4409, 0.5591],
        [0.4744, 0.5256],
        [0.4873, 0.5127],
        [0.4901, 0.5099],
        [0.4664, 0.5336],
        [0.4906, 0.5094],
        [0.5012, 0.4988],
        [0.4470, 0.5530],
        [0.4610, 0.5390],
        [0.5001, 0.4999],
        [0.4497, 0.5503],
        [0.4479, 0.5521],
        [0.4951, 0.5049],
        [0.5226, 0.4774],
        [0.4661, 0.5339]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0002 loss: 0.6961 acc_train: 0.4338 time: 0.1186s
tensor([[0.5998, 0.4002],
        [0.6398, 0.3602],
        [0.6217, 0.3783],
        [0.6168, 0.3832],
        [0.6215, 0.3785],
        [0.6088, 0.3912],
        [0.6103, 0.3897],
        [0.6163, 0.3837],
        [0.5944, 0.4056],
        [0.6257, 0.3743],
        [0.6071, 0.3929],
        [0.6262, 0.3738],
        [0.5986, 0.4014],
        [0.6101, 0.3899],
        [0.6198, 0.3802],
        [0.6093, 0.3907],
        [0.6310, 0.3690],
        [0.6143, 0.3857],
        [0.6090, 0.3910],
        [0.6166, 0.3834],
        [0.6319, 0.3681],
        [0.5977, 0.4023],
        [0.6252, 0.3748],
        [0.6236, 0.3764],
        [0.6185, 0.3815],
        [0.6201, 0.3799],
        [0.6093, 0.3907],
        [0.6246, 0.3754],
        [0.6022, 0.3978],
        [0.6208, 0.3792],
        [0.5937, 0.4063],
        [0.6039, 0.3961],
        [0.5912, 0.4088],
        [0.6213, 0.3787],
        [0.6330, 0.3670],
        [0.6076, 0.3924],
        [0.6173, 0.3827],
        [0.6009, 0.3991],
        [0.6248, 0.3752],
        [0.6189, 0.3811],
        [0.6296, 0.3704],
        [0.6013, 0.3987],
        [0.5732, 0.4268],
        [0.6232, 0.3768],
        [0.6327, 0.3673],
        [0.6106, 0.3894],
        [0.6234, 0.3766],
        [0.6349, 0.3651],
        [0.6469, 0.3531],
        [0.5971, 0.4029],
        [0.6027, 0.3973],
        [0.5947, 0.4053],
        [0.6240, 0.3760],
        [0.6502, 0.3498],
        [0.6304, 0.3696],
        [0.5961, 0.4039],
        [0.6296, 0.3704],
        [0.5917, 0.4083],
        [0.6188, 0.3812],
        [0.6314, 0.3686],
        [0.6216, 0.3784],
        [0.6096, 0.3904],
        [0.6418, 0.3582],
        [0.6307, 0.3693],
        [0.6284, 0.3716],
        [0.5991, 0.4009],
        [0.6130, 0.3870],
        [0.6286, 0.3714],
        [0.5926, 0.4074],
        [0.6166, 0.3834],
        [0.6036, 0.3964],
        [0.6155, 0.3845],
        [0.6329, 0.3671],
        [0.6237, 0.3763],
        [0.6144, 0.3856],
        [0.6118, 0.3882],
        [0.6136, 0.3864],
        [0.6328, 0.3672],
        [0.6408, 0.3592],
        [0.6162, 0.3838],
        [0.5860, 0.4140],
        [0.5935, 0.4065],
        [0.5919, 0.4081],
        [0.5981, 0.4019],
        [0.6274, 0.3726],
        [0.6142, 0.3858],
        [0.6330, 0.3670],
        [0.6283, 0.3717],
        [0.6214, 0.3786],
        [0.6290, 0.3710],
        [0.6090, 0.3910],
        [0.6195, 0.3805],
        [0.6325, 0.3675],
        [0.5930, 0.4070],
        [0.6292, 0.3708],
        [0.6143, 0.3857],
        [0.6131, 0.3869],
        [0.6137, 0.3863],
        [0.6022, 0.3978],
        [0.5974, 0.4026],
        [0.6295, 0.3705],
        [0.6147, 0.3853],
        [0.6033, 0.3967],
        [0.5737, 0.4263],
        [0.6405, 0.3595],
        [0.6024, 0.3976],
        [0.6411, 0.3589],
        [0.5985, 0.4015],
        [0.6227, 0.3773],
        [0.6321, 0.3679],
        [0.6128, 0.3872],
        [0.6261, 0.3739],
        [0.6336, 0.3664],
        [0.6076, 0.3924],
        [0.6241, 0.3759],
        [0.6025, 0.3975],
        [0.6190, 0.3810],
        [0.6153, 0.3847],
        [0.5979, 0.4021],
        [0.6520, 0.3480],
        [0.5952, 0.4048],
        [0.6000, 0.4000],
        [0.6263, 0.3737],
        [0.6040, 0.3960],
        [0.6066, 0.3934],
        [0.5983, 0.4017],
        [0.5913, 0.4087],
        [0.6279, 0.3721],
        [0.6200, 0.3800],
        [0.5965, 0.4035],
        [0.6093, 0.3907],
        [0.5991, 0.4009],
        [0.6221, 0.3779],
        [0.6024, 0.3976],
        [0.6354, 0.3646],
        [0.6277, 0.3723],
        [0.6158, 0.3842],
        [0.6305, 0.3695],
        [0.6148, 0.3852],
        [0.5911, 0.4089],
        [0.5785, 0.4215],
        [0.6475, 0.3525],
        [0.6298, 0.3702],
        [0.6226, 0.3774],
        [0.5866, 0.4134],
        [0.6108, 0.3892],
        [0.6390, 0.3610],
        [0.5997, 0.4003],
        [0.6208, 0.3792],
        [0.6407, 0.3593],
        [0.6072, 0.3928],
        [0.6186, 0.3814],
        [0.6561, 0.3439],
        [0.6195, 0.3805],
        [0.6217, 0.3783],
        [0.6297, 0.3703],
        [0.6101, 0.3899],
        [0.6237, 0.3763],
        [0.6311, 0.3689],
        [0.5951, 0.4049],
        [0.6134, 0.3866],
        [0.6291, 0.3709],
        [0.5851, 0.4149],
        [0.6087, 0.3913],
        [0.6252, 0.3748],
        [0.5746, 0.4254],
        [0.6300, 0.3700],
        [0.6246, 0.3754],
        [0.6197, 0.3803],
        [0.6253, 0.3747],
        [0.5829, 0.4171],
        [0.6076, 0.3924],
        [0.6049, 0.3951],
        [0.6316, 0.3684],
        [0.6338, 0.3662],
        [0.6323, 0.3677],
        [0.6322, 0.3678],
        [0.6040, 0.3960],
        [0.5856, 0.4144],
        [0.6448, 0.3552],
        [0.6169, 0.3831],
        [0.6215, 0.3785],
        [0.6123, 0.3877],
        [0.6080, 0.3920],
        [0.6312, 0.3688],
        [0.6151, 0.3849],
        [0.5909, 0.4091],
        [0.6062, 0.3938],
        [0.6271, 0.3729],
        [0.6188, 0.3812],
        [0.6412, 0.3588],
        [0.6097, 0.3903],
        [0.6223, 0.3777],
        [0.6012, 0.3988],
        [0.5940, 0.4060],
        [0.6115, 0.3885],
        [0.6421, 0.3579],
        [0.6100, 0.3900],
        [0.6284, 0.3716],
        [0.6330, 0.3670],
        [0.5897, 0.4103],
        [0.6327, 0.3673],
        [0.6233, 0.3767],
        [0.5808, 0.4192],
        [0.6258, 0.3742],
        [0.6313, 0.3687],
        [0.6212, 0.3788],
        [0.6194, 0.3806],
        [0.6102, 0.3898],
        [0.6148, 0.3852],
        [0.6091, 0.3909],
        [0.5993, 0.4007],
        [0.6278, 0.3722],
        [0.6219, 0.3781],
        [0.6205, 0.3795],
        [0.6329, 0.3671],
        [0.6206, 0.3794],
        [0.6123, 0.3877],
        [0.6633, 0.3367],
        [0.6333, 0.3667],
        [0.6131, 0.3869],
        [0.6401, 0.3599],
        [0.6248, 0.3752],
        [0.6389, 0.3611],
        [0.6210, 0.3790],
        [0.6095, 0.3905],
        [0.6285, 0.3715],
        [0.6093, 0.3907],
        [0.6188, 0.3812],
        [0.6279, 0.3721],
        [0.6101, 0.3899],
        [0.6204, 0.3796],
        [0.6376, 0.3624],
        [0.6215, 0.3785],
        [0.6572, 0.3428],
        [0.6158, 0.3842],
        [0.6019, 0.3981],
        [0.6181, 0.3819],
        [0.6413, 0.3587],
        [0.6008, 0.3992],
        [0.6185, 0.3815],
        [0.6055, 0.3945],
        [0.6076, 0.3924],
        [0.6137, 0.3863],
        [0.6069, 0.3931],
        [0.6225, 0.3775],
        [0.6018, 0.3982],
        [0.6086, 0.3914],
        [0.6356, 0.3644],
        [0.6203, 0.3797],
        [0.6002, 0.3998],
        [0.6217, 0.3783],
        [0.6103, 0.3897],
        [0.6427, 0.3573],
        [0.6338, 0.3662],
        [0.6169, 0.3831],
        [0.6125, 0.3875],
        [0.5792, 0.4208],
        [0.6207, 0.3793],
        [0.6154, 0.3846],
        [0.6386, 0.3614],
        [0.6099, 0.3901],
        [0.6167, 0.3833],
        [0.6365, 0.3635],
        [0.5830, 0.4170],
        [0.5952, 0.4048],
        [0.6215, 0.3785],
        [0.5881, 0.4119],
        [0.5936, 0.4064],
        [0.6341, 0.3659],
        [0.6535, 0.3465],
        [0.5997, 0.4003]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0003 loss: 0.6699 acc_train: 0.6103 time: 0.1311s
tensor([[0.6632, 0.3368],
        [0.7057, 0.2943],
        [0.6782, 0.3218],
        [0.6691, 0.3309],
        [0.6858, 0.3142],
        [0.6697, 0.3303],
        [0.6523, 0.3477],
        [0.6763, 0.3237],
        [0.6638, 0.3362],
        [0.6656, 0.3344],
        [0.6612, 0.3388],
        [0.6740, 0.3260],
        [0.6571, 0.3429],
        [0.6531, 0.3469],
        [0.6796, 0.3204],
        [0.6637, 0.3363],
        [0.7074, 0.2926],
        [0.6662, 0.3338],
        [0.6771, 0.3229],
        [0.6633, 0.3367],
        [0.6945, 0.3055],
        [0.6589, 0.3411],
        [0.6904, 0.3096],
        [0.6898, 0.3102],
        [0.6720, 0.3280],
        [0.6647, 0.3353],
        [0.6678, 0.3322],
        [0.6795, 0.3205],
        [0.6548, 0.3452],
        [0.6673, 0.3327],
        [0.6536, 0.3464],
        [0.6531, 0.3469],
        [0.6451, 0.3549],
        [0.6641, 0.3359],
        [0.6946, 0.3054],
        [0.6458, 0.3542],
        [0.6634, 0.3366],
        [0.6555, 0.3445],
        [0.6855, 0.3145],
        [0.6655, 0.3345],
        [0.6815, 0.3185],
        [0.6567, 0.3433],
        [0.6231, 0.3769],
        [0.6773, 0.3227],
        [0.7023, 0.2977],
        [0.6663, 0.3337],
        [0.6898, 0.3102],
        [0.6974, 0.3026],
        [0.6934, 0.3066],
        [0.6463, 0.3537],
        [0.6532, 0.3468],
        [0.6604, 0.3396],
        [0.6662, 0.3338],
        [0.7061, 0.2939],
        [0.6856, 0.3144],
        [0.6654, 0.3346],
        [0.6950, 0.3050],
        [0.6511, 0.3489],
        [0.6724, 0.3276],
        [0.6747, 0.3253],
        [0.6517, 0.3483],
        [0.6673, 0.3327],
        [0.7001, 0.2999],
        [0.6837, 0.3163],
        [0.6809, 0.3191],
        [0.6679, 0.3321],
        [0.6707, 0.3293],
        [0.6837, 0.3163],
        [0.6572, 0.3428],
        [0.6720, 0.3280],
        [0.6543, 0.3457],
        [0.6533, 0.3467],
        [0.6852, 0.3148],
        [0.6889, 0.3111],
        [0.6705, 0.3295],
        [0.6642, 0.3358],
        [0.6725, 0.3275],
        [0.6807, 0.3193],
        [0.7061, 0.2939],
        [0.6603, 0.3397],
        [0.6305, 0.3695],
        [0.6502, 0.3498],
        [0.6434, 0.3566],
        [0.6491, 0.3509],
        [0.6772, 0.3228],
        [0.6654, 0.3346],
        [0.6920, 0.3080],
        [0.6826, 0.3174],
        [0.6762, 0.3238],
        [0.6689, 0.3311],
        [0.6659, 0.3341],
        [0.6711, 0.3289],
        [0.6813, 0.3187],
        [0.6301, 0.3699],
        [0.6828, 0.3172],
        [0.6875, 0.3125],
        [0.6680, 0.3320],
        [0.6724, 0.3276],
        [0.6827, 0.3173],
        [0.6538, 0.3462],
        [0.6893, 0.3107],
        [0.6678, 0.3322],
        [0.6599, 0.3401],
        [0.6317, 0.3683],
        [0.7052, 0.2948],
        [0.6616, 0.3384],
        [0.7006, 0.2994],
        [0.6681, 0.3319],
        [0.6611, 0.3389],
        [0.6877, 0.3123],
        [0.6350, 0.3650],
        [0.6933, 0.3067],
        [0.6932, 0.3068],
        [0.6800, 0.3200],
        [0.6760, 0.3240],
        [0.6557, 0.3443],
        [0.6731, 0.3269],
        [0.6822, 0.3178],
        [0.6691, 0.3309],
        [0.7078, 0.2922],
        [0.6422, 0.3578],
        [0.6592, 0.3408],
        [0.6732, 0.3268],
        [0.6522, 0.3478],
        [0.6558, 0.3442],
        [0.6593, 0.3407],
        [0.6448, 0.3552],
        [0.6771, 0.3229],
        [0.6623, 0.3377],
        [0.6537, 0.3463],
        [0.6640, 0.3360],
        [0.6574, 0.3426],
        [0.6778, 0.3222],
        [0.6671, 0.3329],
        [0.6898, 0.3102],
        [0.6823, 0.3177],
        [0.6693, 0.3307],
        [0.6895, 0.3105],
        [0.6719, 0.3281],
        [0.6442, 0.3558],
        [0.6352, 0.3648],
        [0.7011, 0.2989],
        [0.6768, 0.3232],
        [0.6727, 0.3273],
        [0.6287, 0.3713],
        [0.6687, 0.3313],
        [0.6918, 0.3082],
        [0.6555, 0.3445],
        [0.6850, 0.3150],
        [0.6897, 0.3103],
        [0.6505, 0.3495],
        [0.6846, 0.3154],
        [0.7102, 0.2898],
        [0.6973, 0.3027],
        [0.6970, 0.3030],
        [0.6874, 0.3126],
        [0.6727, 0.3273],
        [0.6878, 0.3122],
        [0.6794, 0.3206],
        [0.6726, 0.3274],
        [0.6715, 0.3285],
        [0.6868, 0.3132],
        [0.6447, 0.3553],
        [0.6642, 0.3358],
        [0.6629, 0.3371],
        [0.6258, 0.3742],
        [0.6786, 0.3214],
        [0.6698, 0.3302],
        [0.6756, 0.3244],
        [0.6686, 0.3314],
        [0.6265, 0.3735],
        [0.6603, 0.3397],
        [0.6598, 0.3402],
        [0.6770, 0.3230],
        [0.6887, 0.3113],
        [0.6828, 0.3172],
        [0.6895, 0.3105],
        [0.6588, 0.3412],
        [0.6330, 0.3670],
        [0.7034, 0.2966],
        [0.6642, 0.3358],
        [0.6623, 0.3377],
        [0.6574, 0.3426],
        [0.6512, 0.3488],
        [0.6862, 0.3138],
        [0.6753, 0.3247],
        [0.6289, 0.3711],
        [0.6697, 0.3303],
        [0.6705, 0.3295],
        [0.6683, 0.3317],
        [0.6992, 0.3008],
        [0.6576, 0.3424],
        [0.6684, 0.3316],
        [0.6453, 0.3547],
        [0.6643, 0.3357],
        [0.6745, 0.3255],
        [0.7021, 0.2979],
        [0.6480, 0.3520],
        [0.6845, 0.3155],
        [0.7059, 0.2941],
        [0.6615, 0.3385],
        [0.6856, 0.3144],
        [0.6844, 0.3156],
        [0.6305, 0.3695],
        [0.6804, 0.3196],
        [0.6848, 0.3152],
        [0.6925, 0.3075],
        [0.6871, 0.3129],
        [0.6578, 0.3422],
        [0.6665, 0.3335],
        [0.6648, 0.3352],
        [0.6603, 0.3397],
        [0.6991, 0.3009],
        [0.6667, 0.3333],
        [0.6785, 0.3215],
        [0.6890, 0.3110],
        [0.6627, 0.3373],
        [0.6616, 0.3384],
        [0.7108, 0.2892],
        [0.6858, 0.3142],
        [0.6641, 0.3359],
        [0.7070, 0.2930],
        [0.6742, 0.3258],
        [0.6921, 0.3079],
        [0.6836, 0.3164],
        [0.6626, 0.3374],
        [0.6712, 0.3288],
        [0.6652, 0.3348],
        [0.6743, 0.3257],
        [0.6883, 0.3117],
        [0.6700, 0.3300],
        [0.6790, 0.3210],
        [0.6908, 0.3092],
        [0.6792, 0.3208],
        [0.7111, 0.2889],
        [0.6833, 0.3167],
        [0.6551, 0.3449],
        [0.6742, 0.3258],
        [0.6976, 0.3024],
        [0.6422, 0.3578],
        [0.6719, 0.3281],
        [0.6718, 0.3282],
        [0.6649, 0.3351],
        [0.6621, 0.3379],
        [0.6727, 0.3273],
        [0.6917, 0.3083],
        [0.6678, 0.3322],
        [0.6812, 0.3188],
        [0.6959, 0.3041],
        [0.6770, 0.3230],
        [0.6530, 0.3470],
        [0.6805, 0.3195],
        [0.6604, 0.3396],
        [0.6956, 0.3044],
        [0.6965, 0.3035],
        [0.6698, 0.3302],
        [0.6629, 0.3371],
        [0.6505, 0.3495],
        [0.6812, 0.3188],
        [0.6728, 0.3272],
        [0.7064, 0.2936],
        [0.6773, 0.3227],
        [0.6738, 0.3262],
        [0.6951, 0.3049],
        [0.6425, 0.3575],
        [0.6549, 0.3451],
        [0.6778, 0.3222],
        [0.6482, 0.3518],
        [0.6646, 0.3354],
        [0.6904, 0.3096],
        [0.7053, 0.2947],
        [0.6648, 0.3352]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0004 loss: 0.6626 acc_train: 0.6103 time: 0.1190s
tensor([[0.6964, 0.3036],
        [0.7454, 0.2546],
        [0.7107, 0.2893],
        [0.6981, 0.3019],
        [0.7262, 0.2738],
        [0.6970, 0.3030],
        [0.6707, 0.3293],
        [0.7111, 0.2889],
        [0.7069, 0.2931],
        [0.6868, 0.3132],
        [0.6993, 0.3007],
        [0.6956, 0.3044],
        [0.6881, 0.3119],
        [0.6758, 0.3242],
        [0.7158, 0.2842],
        [0.6899, 0.3101],
        [0.7506, 0.2494],
        [0.6946, 0.3054],
        [0.7156, 0.2844],
        [0.6829, 0.3171],
        [0.7331, 0.2669],
        [0.6881, 0.3119],
        [0.7295, 0.2705],
        [0.7221, 0.2779],
        [0.7008, 0.2992],
        [0.6880, 0.3120],
        [0.7026, 0.2974],
        [0.7130, 0.2870],
        [0.6841, 0.3159],
        [0.6893, 0.3107],
        [0.6915, 0.3085],
        [0.6786, 0.3214],
        [0.6812, 0.3188],
        [0.6880, 0.3120],
        [0.7316, 0.2684],
        [0.6699, 0.3301],
        [0.6879, 0.3121],
        [0.6891, 0.3109],
        [0.7167, 0.2833],
        [0.6885, 0.3115],
        [0.7136, 0.2864],
        [0.6915, 0.3085],
        [0.6470, 0.3530],
        [0.7132, 0.2868],
        [0.7389, 0.2611],
        [0.6923, 0.3077],
        [0.7262, 0.2738],
        [0.7274, 0.2726],
        [0.7184, 0.2816],
        [0.6729, 0.3271],
        [0.6887, 0.3113],
        [0.6994, 0.3006],
        [0.6832, 0.3168],
        [0.7396, 0.2604],
        [0.7197, 0.2803],
        [0.7087, 0.2913],
        [0.7323, 0.2677],
        [0.6863, 0.3137],
        [0.7035, 0.2965],
        [0.6956, 0.3044],
        [0.6667, 0.3333],
        [0.6926, 0.3074],
        [0.7296, 0.2704],
        [0.7128, 0.2872],
        [0.7103, 0.2897],
        [0.7081, 0.2919],
        [0.6998, 0.3002],
        [0.7133, 0.2867],
        [0.6993, 0.3007],
        [0.7037, 0.2963],
        [0.6799, 0.3201],
        [0.6728, 0.3272],
        [0.7086, 0.2914],
        [0.7212, 0.2788],
        [0.6986, 0.3014],
        [0.6924, 0.3076],
        [0.7029, 0.2971],
        [0.7031, 0.2969],
        [0.7380, 0.2620],
        [0.6830, 0.3170],
        [0.6540, 0.3460],
        [0.6802, 0.3198],
        [0.6751, 0.3249],
        [0.6773, 0.3227],
        [0.7031, 0.2969],
        [0.6905, 0.3095],
        [0.7243, 0.2757],
        [0.7148, 0.2852],
        [0.7080, 0.2920],
        [0.6910, 0.3090],
        [0.6933, 0.3067],
        [0.6974, 0.3026],
        [0.7099, 0.2901],
        [0.6496, 0.3504],
        [0.7056, 0.2944],
        [0.7336, 0.2664],
        [0.7047, 0.2953],
        [0.7025, 0.2975],
        [0.7295, 0.2705],
        [0.6859, 0.3141],
        [0.7272, 0.2728],
        [0.6926, 0.3074],
        [0.6861, 0.3139],
        [0.6679, 0.3321],
        [0.7484, 0.2516],
        [0.6927, 0.3073],
        [0.7332, 0.2668],
        [0.7147, 0.2853],
        [0.6822, 0.3178],
        [0.7224, 0.2776],
        [0.6445, 0.3555],
        [0.7341, 0.2659],
        [0.7243, 0.2757],
        [0.7209, 0.2791],
        [0.7037, 0.2963],
        [0.6865, 0.3135],
        [0.7034, 0.2966],
        [0.7200, 0.2800],
        [0.7179, 0.2821],
        [0.7395, 0.2605],
        [0.6716, 0.3284],
        [0.6964, 0.3036],
        [0.6982, 0.3018],
        [0.6827, 0.3173],
        [0.6821, 0.3179],
        [0.6939, 0.3061],
        [0.6720, 0.3280],
        [0.7040, 0.2960],
        [0.6810, 0.3190],
        [0.6819, 0.3181],
        [0.6995, 0.3005],
        [0.6900, 0.3100],
        [0.7124, 0.2876],
        [0.6988, 0.3012],
        [0.7228, 0.2772],
        [0.7107, 0.2893],
        [0.6949, 0.3051],
        [0.7223, 0.2777],
        [0.7042, 0.2958],
        [0.6754, 0.3246],
        [0.6661, 0.3339],
        [0.7312, 0.2688],
        [0.7007, 0.2993],
        [0.6999, 0.3001],
        [0.6469, 0.3531],
        [0.7022, 0.2978],
        [0.7196, 0.2804],
        [0.6879, 0.3121],
        [0.7241, 0.2759],
        [0.7184, 0.2816],
        [0.6741, 0.3259],
        [0.7253, 0.2747],
        [0.7385, 0.2615],
        [0.7428, 0.2572],
        [0.7399, 0.2601],
        [0.7194, 0.2806],
        [0.7116, 0.2884],
        [0.7265, 0.2735],
        [0.7039, 0.2961],
        [0.7170, 0.2830],
        [0.7053, 0.2947],
        [0.7192, 0.2808],
        [0.6745, 0.3255],
        [0.6963, 0.3037],
        [0.6832, 0.3168],
        [0.6570, 0.3430],
        [0.7088, 0.2912],
        [0.6934, 0.3066],
        [0.7071, 0.2929],
        [0.6925, 0.3075],
        [0.6514, 0.3486],
        [0.6894, 0.3106],
        [0.6922, 0.3078],
        [0.7061, 0.2939],
        [0.7201, 0.2799],
        [0.7090, 0.2910],
        [0.7258, 0.2742],
        [0.6911, 0.3089],
        [0.6553, 0.3447],
        [0.7372, 0.2628],
        [0.6948, 0.3052],
        [0.6780, 0.3220],
        [0.6818, 0.3182],
        [0.6686, 0.3314],
        [0.7187, 0.2813],
        [0.7080, 0.2920],
        [0.6463, 0.3537],
        [0.7056, 0.2944],
        [0.6865, 0.3135],
        [0.6928, 0.3072],
        [0.7349, 0.2651],
        [0.6841, 0.3159],
        [0.6875, 0.3125],
        [0.6641, 0.3359],
        [0.7107, 0.2893],
        [0.7087, 0.2913],
        [0.7369, 0.2631],
        [0.6645, 0.3355],
        [0.7214, 0.2786],
        [0.7479, 0.2521],
        [0.7005, 0.2995],
        [0.7214, 0.2786],
        [0.7216, 0.2784],
        [0.6553, 0.3447],
        [0.7155, 0.2845],
        [0.7122, 0.2878],
        [0.7336, 0.2664],
        [0.7281, 0.2719],
        [0.6780, 0.3220],
        [0.6915, 0.3085],
        [0.7018, 0.2982],
        [0.6911, 0.3089],
        [0.7395, 0.2605],
        [0.6929, 0.3071],
        [0.7125, 0.2875],
        [0.7198, 0.2802],
        [0.6871, 0.3129],
        [0.6924, 0.3076],
        [0.7332, 0.2668],
        [0.7122, 0.2878],
        [0.6892, 0.3108],
        [0.7458, 0.2542],
        [0.6992, 0.3008],
        [0.7216, 0.2784],
        [0.7182, 0.2818],
        [0.7010, 0.2990],
        [0.6914, 0.3086],
        [0.6995, 0.3005],
        [0.7017, 0.2983],
        [0.7201, 0.2799],
        [0.7014, 0.2986],
        [0.7144, 0.2856],
        [0.7214, 0.2786],
        [0.7132, 0.2868],
        [0.7373, 0.2627],
        [0.7202, 0.2798],
        [0.6862, 0.3138],
        [0.7022, 0.2978],
        [0.7321, 0.2679],
        [0.6691, 0.3309],
        [0.7045, 0.2955],
        [0.7070, 0.2930],
        [0.6936, 0.3064],
        [0.6928, 0.3072],
        [0.7157, 0.2843],
        [0.7328, 0.2672],
        [0.7063, 0.2937],
        [0.7273, 0.2727],
        [0.7315, 0.2685],
        [0.7055, 0.2945],
        [0.6876, 0.3124],
        [0.7179, 0.2821],
        [0.6810, 0.3190],
        [0.7244, 0.2756],
        [0.7314, 0.2686],
        [0.6973, 0.3027],
        [0.6938, 0.3062],
        [0.6984, 0.3016],
        [0.7173, 0.2827],
        [0.7078, 0.2922],
        [0.7477, 0.2523],
        [0.7215, 0.2785],
        [0.7061, 0.2939],
        [0.7271, 0.2729],
        [0.6768, 0.3232],
        [0.6871, 0.3129],
        [0.7167, 0.2833],
        [0.6794, 0.3206],
        [0.7036, 0.2964],
        [0.7203, 0.2797],
        [0.7341, 0.2659],
        [0.7012, 0.2988]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0005 loss: 0.6591 acc_train: 0.6103 time: 0.1198s
tensor([[0.7050, 0.2950],
        [0.7597, 0.2403],
        [0.7216, 0.2784],
        [0.7079, 0.2921],
        [0.7409, 0.2591],
        [0.7053, 0.2947],
        [0.6677, 0.3323],
        [0.7243, 0.2757],
        [0.7245, 0.2755],
        [0.6878, 0.3122],
        [0.7175, 0.2825],
        [0.6966, 0.3034],
        [0.6961, 0.3039],
        [0.6770, 0.3230],
        [0.7292, 0.2708],
        [0.6942, 0.3058],
        [0.7668, 0.2332],
        [0.7014, 0.2986],
        [0.7298, 0.2702],
        [0.6811, 0.3189],
        [0.7483, 0.2517],
        [0.6932, 0.3068],
        [0.7457, 0.2543],
        [0.7305, 0.2695],
        [0.7110, 0.2890],
        [0.6915, 0.3085],
        [0.7145, 0.2855],
        [0.7258, 0.2742],
        [0.6905, 0.3095],
        [0.6915, 0.3085],
        [0.7062, 0.2938],
        [0.6833, 0.3167],
        [0.6949, 0.3051],
        [0.6920, 0.3080],
        [0.7457, 0.2543],
        [0.6809, 0.3191],
        [0.6926, 0.3074],
        [0.7003, 0.2997],
        [0.7223, 0.2777],
        [0.6907, 0.3093],
        [0.7241, 0.2759],
        [0.7024, 0.2976],
        [0.6535, 0.3465],
        [0.7275, 0.2725],
        [0.7504, 0.2496],
        [0.6950, 0.3050],
        [0.7377, 0.2623],
        [0.7356, 0.2644],
        [0.7234, 0.2766],
        [0.6800, 0.3200],
        [0.7050, 0.2950],
        [0.7156, 0.2844],
        [0.6826, 0.3174],
        [0.7524, 0.2476],
        [0.7314, 0.2686],
        [0.7265, 0.2735],
        [0.7432, 0.2568],
        [0.6973, 0.3027],
        [0.7115, 0.2885],
        [0.6959, 0.3041],
        [0.6658, 0.3342],
        [0.6941, 0.3059],
        [0.7370, 0.2630],
        [0.7211, 0.2789],
        [0.7178, 0.2822],
        [0.7226, 0.2774],
        [0.7099, 0.2901],
        [0.7186, 0.2814],
        [0.7154, 0.2846],
        [0.7124, 0.2876],
        [0.6836, 0.3164],
        [0.6712, 0.3288],
        [0.7092, 0.2908],
        [0.7311, 0.2689],
        [0.7035, 0.2965],
        [0.6976, 0.3024],
        [0.7119, 0.2881],
        [0.7047, 0.2953],
        [0.7453, 0.2547],
        [0.6859, 0.3141],
        [0.6573, 0.3427],
        [0.6877, 0.3123],
        [0.6839, 0.3161],
        [0.6851, 0.3149],
        [0.7068, 0.2932],
        [0.6942, 0.3058],
        [0.7360, 0.2640],
        [0.7242, 0.2758],
        [0.7175, 0.2825],
        [0.6938, 0.3062],
        [0.6984, 0.3016],
        [0.7045, 0.2955],
        [0.7180, 0.2820],
        [0.6539, 0.3461],
        [0.7089, 0.2911],
        [0.7542, 0.2458],
        [0.7208, 0.2792],
        [0.7072, 0.2928],
        [0.7490, 0.2510],
        [0.6964, 0.3036],
        [0.7437, 0.2563],
        [0.6956, 0.3044],
        [0.6895, 0.3105],
        [0.6809, 0.3191],
        [0.7666, 0.2334],
        [0.6990, 0.3010],
        [0.7434, 0.2566],
        [0.7371, 0.2629],
        [0.6827, 0.3173],
        [0.7338, 0.2662],
        [0.6477, 0.3523],
        [0.7525, 0.2475],
        [0.7336, 0.2664],
        [0.7368, 0.2632],
        [0.7090, 0.2910],
        [0.6970, 0.3030],
        [0.7110, 0.2890],
        [0.7314, 0.2686],
        [0.7395, 0.2605],
        [0.7501, 0.2499],
        [0.6789, 0.3211],
        [0.7117, 0.2883],
        [0.7042, 0.2958],
        [0.6916, 0.3084],
        [0.6868, 0.3132],
        [0.7028, 0.2972],
        [0.6767, 0.3233],
        [0.7097, 0.2903],
        [0.6806, 0.3194],
        [0.6857, 0.3143],
        [0.7134, 0.2866],
        [0.6980, 0.3020],
        [0.7255, 0.2745],
        [0.7060, 0.2940],
        [0.7351, 0.2649],
        [0.7164, 0.2836],
        [0.6970, 0.3030],
        [0.7339, 0.2661],
        [0.7187, 0.2813],
        [0.6854, 0.3146],
        [0.6746, 0.3254],
        [0.7398, 0.2602],
        [0.7037, 0.2963],
        [0.7056, 0.2944],
        [0.6438, 0.3562],
        [0.7117, 0.2883],
        [0.7273, 0.2727],
        [0.6965, 0.3035],
        [0.7408, 0.2592],
        [0.7274, 0.2726],
        [0.6792, 0.3208],
        [0.7387, 0.2613],
        [0.7463, 0.2537],
        [0.7622, 0.2378],
        [0.7583, 0.2417],
        [0.7276, 0.2724],
        [0.7283, 0.2717],
        [0.7413, 0.2587],
        [0.7072, 0.2928],
        [0.7319, 0.2681],
        [0.7162, 0.2838],
        [0.7301, 0.2699],
        [0.6821, 0.3179],
        [0.7080, 0.2920],
        [0.6878, 0.3122],
        [0.6689, 0.3311],
        [0.7213, 0.2787],
        [0.6990, 0.3010],
        [0.7169, 0.2831],
        [0.6963, 0.3037],
        [0.6641, 0.3359],
        [0.6934, 0.3066],
        [0.6995, 0.3005],
        [0.7162, 0.2838],
        [0.7294, 0.2706],
        [0.7143, 0.2857],
        [0.7397, 0.2603],
        [0.7001, 0.2999],
        [0.6578, 0.3422],
        [0.7478, 0.2522],
        [0.7041, 0.2959],
        [0.6744, 0.3256],
        [0.6882, 0.3118],
        [0.6669, 0.3331],
        [0.7307, 0.2693],
        [0.7218, 0.2782],
        [0.6446, 0.3554],
        [0.7175, 0.2825],
        [0.6825, 0.3175],
        [0.6978, 0.3022],
        [0.7481, 0.2519],
        [0.6914, 0.3086],
        [0.6874, 0.3126],
        [0.6622, 0.3378],
        [0.7318, 0.2682],
        [0.7159, 0.2841],
        [0.7506, 0.2494],
        [0.6655, 0.3345],
        [0.7351, 0.2649],
        [0.7649, 0.2351],
        [0.7111, 0.2889],
        [0.7356, 0.2644],
        [0.7354, 0.2646],
        [0.6597, 0.3403],
        [0.7288, 0.2712],
        [0.7196, 0.2804],
        [0.7499, 0.2501],
        [0.7454, 0.2546],
        [0.6780, 0.3220],
        [0.6926, 0.3074],
        [0.7150, 0.2850],
        [0.6974, 0.3026],
        [0.7565, 0.2435],
        [0.7008, 0.2992],
        [0.7230, 0.2770],
        [0.7295, 0.2705],
        [0.6904, 0.3096],
        [0.7058, 0.2942],
        [0.7396, 0.2604],
        [0.7182, 0.2818],
        [0.6917, 0.3083],
        [0.7621, 0.2379],
        [0.7034, 0.2966],
        [0.7298, 0.2702],
        [0.7340, 0.2660],
        [0.7164, 0.2836],
        [0.6951, 0.3049],
        [0.7092, 0.2908],
        [0.7076, 0.2924],
        [0.7294, 0.2706],
        [0.7111, 0.2889],
        [0.7276, 0.2724],
        [0.7309, 0.2691],
        [0.7232, 0.2768],
        [0.7443, 0.2557],
        [0.7316, 0.2684],
        [0.6956, 0.3044],
        [0.7070, 0.2930],
        [0.7459, 0.2541],
        [0.6791, 0.3209],
        [0.7182, 0.2818],
        [0.7169, 0.2831],
        [0.6971, 0.3029],
        [0.7018, 0.2982],
        [0.7357, 0.2643],
        [0.7483, 0.2517],
        [0.7229, 0.2771],
        [0.7470, 0.2530],
        [0.7444, 0.2556],
        [0.7145, 0.2855],
        [0.7005, 0.2995],
        [0.7345, 0.2655],
        [0.6820, 0.3180],
        [0.7334, 0.2666],
        [0.7436, 0.2564],
        [0.7038, 0.2962],
        [0.7031, 0.2969],
        [0.7197, 0.2803],
        [0.7306, 0.2694],
        [0.7198, 0.2802],
        [0.7642, 0.2358],
        [0.7402, 0.2598],
        [0.7172, 0.2828],
        [0.7369, 0.2631],
        [0.6877, 0.3123],
        [0.7016, 0.2984],
        [0.7344, 0.2656],
        [0.6853, 0.3147],
        [0.7159, 0.2841],
        [0.7289, 0.2711],
        [0.7445, 0.2555],
        [0.7137, 0.2863]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0006 loss: 0.6570 acc_train: 0.6103 time: 0.1213s
tensor([[0.6948, 0.3052],
        [0.7556, 0.2444],
        [0.7138, 0.2862],
        [0.7000, 0.3000],
        [0.7371, 0.2629],
        [0.6964, 0.3036],
        [0.6474, 0.3526],
        [0.7197, 0.2803],
        [0.7206, 0.2794],
        [0.6721, 0.3279],
        [0.7157, 0.2843],
        [0.6790, 0.3210],
        [0.6831, 0.3169],
        [0.6597, 0.3403],
        [0.7227, 0.2773],
        [0.6786, 0.3214],
        [0.7625, 0.2375],
        [0.6909, 0.3091],
        [0.7241, 0.2759],
        [0.6637, 0.3363],
        [0.7429, 0.2571],
        [0.6788, 0.3212],
        [0.7422, 0.2578],
        [0.7211, 0.2789],
        [0.7031, 0.2969],
        [0.6784, 0.3216],
        [0.7078, 0.2922],
        [0.7223, 0.2777],
        [0.6779, 0.3221],
        [0.6754, 0.3246],
        [0.7014, 0.2986],
        [0.6689, 0.3311],
        [0.6865, 0.3135],
        [0.6775, 0.3225],
        [0.7431, 0.2569],
        [0.6772, 0.3228],
        [0.6792, 0.3208],
        [0.6930, 0.3070],
        [0.7083, 0.2917],
        [0.6762, 0.3238],
        [0.7146, 0.2854],
        [0.6944, 0.3056],
        [0.6462, 0.3538],
        [0.7230, 0.2770],
        [0.7450, 0.2550],
        [0.6805, 0.3195],
        [0.7318, 0.2682],
        [0.7285, 0.2715],
        [0.7099, 0.2901],
        [0.6661, 0.3339],
        [0.7028, 0.2972],
        [0.7108, 0.2892],
        [0.6644, 0.3356],
        [0.7488, 0.2512],
        [0.7257, 0.2743],
        [0.7238, 0.2762],
        [0.7361, 0.2639],
        [0.6878, 0.3122],
        [0.6986, 0.3014],
        [0.6781, 0.3219],
        [0.6481, 0.3519],
        [0.6791, 0.3209],
        [0.7248, 0.2752],
        [0.7114, 0.2886],
        [0.7058, 0.2942],
        [0.7159, 0.2841],
        [0.7025, 0.2975],
        [0.7042, 0.2958],
        [0.7126, 0.2874],
        [0.7014, 0.2986],
        [0.6703, 0.3297],
        [0.6531, 0.3470],
        [0.6921, 0.3079],
        [0.7235, 0.2765],
        [0.6930, 0.3070],
        [0.6861, 0.3139],
        [0.7029, 0.2971],
        [0.6883, 0.3117],
        [0.7318, 0.2682],
        [0.6697, 0.3303],
        [0.6418, 0.3582],
        [0.6752, 0.3248],
        [0.6732, 0.3268],
        [0.6740, 0.3260],
        [0.6930, 0.3070],
        [0.6792, 0.3208],
        [0.7281, 0.2719],
        [0.7164, 0.2836],
        [0.7094, 0.2906],
        [0.6789, 0.3211],
        [0.6857, 0.3143],
        [0.6927, 0.3073],
        [0.7078, 0.2922],
        [0.6384, 0.3616],
        [0.6961, 0.3039],
        [0.7546, 0.2454],
        [0.7160, 0.2840],
        [0.6923, 0.3077],
        [0.7478, 0.2522],
        [0.6869, 0.3131],
        [0.7398, 0.2602],
        [0.6813, 0.3187],
        [0.6757, 0.3243],
        [0.6745, 0.3255],
        [0.7649, 0.2351],
        [0.6868, 0.3132],
        [0.7357, 0.2643],
        [0.7391, 0.2609],
        [0.6649, 0.3351],
        [0.7262, 0.2738],
        [0.6449, 0.3551],
        [0.7508, 0.2492],
        [0.7266, 0.2734],
        [0.7354, 0.2646],
        [0.6964, 0.3036],
        [0.6909, 0.3091],
        [0.7007, 0.2993],
        [0.7244, 0.2756],
        [0.7412, 0.2588],
        [0.7416, 0.2584],
        [0.6670, 0.3330],
        [0.7057, 0.2943],
        [0.6928, 0.3072],
        [0.6805, 0.3195],
        [0.6734, 0.3266],
        [0.6937, 0.3063],
        [0.6643, 0.3357],
        [0.6979, 0.3021],
        [0.6641, 0.3359],
        [0.6714, 0.3286],
        [0.7071, 0.2929],
        [0.6872, 0.3128],
        [0.7198, 0.2802],
        [0.6926, 0.3074],
        [0.7298, 0.2702],
        [0.7047, 0.2953],
        [0.6808, 0.3192],
        [0.7271, 0.2729],
        [0.7153, 0.2847],
        [0.6765, 0.3235],
        [0.6652, 0.3348],
        [0.7297, 0.2703],
        [0.6877, 0.3123],
        [0.6944, 0.3056],
        [0.6212, 0.3788],
        [0.7012, 0.2988],
        [0.7160, 0.2840],
        [0.6841, 0.3159],
        [0.7381, 0.2619],
        [0.7177, 0.2823],
        [0.6653, 0.3347],
        [0.7314, 0.2686],
        [0.7363, 0.2637],
        [0.7620, 0.2380],
        [0.7573, 0.2427],
        [0.7157, 0.2843],
        [0.7256, 0.2744],
        [0.7375, 0.2625],
        [0.6920, 0.3080],
        [0.7261, 0.2739],
        [0.7101, 0.2899],
        [0.7210, 0.2790],
        [0.6705, 0.3295],
        [0.6990, 0.3010],
        [0.6758, 0.3242],
        [0.6623, 0.3377],
        [0.7168, 0.2832],
        [0.6875, 0.3125],
        [0.7082, 0.2918],
        [0.6825, 0.3175],
        [0.6632, 0.3368],
        [0.6804, 0.3196],
        [0.6891, 0.3109],
        [0.7076, 0.2924],
        [0.7206, 0.2794],
        [0.7030, 0.2970],
        [0.7353, 0.2647],
        [0.6908, 0.3092],
        [0.6420, 0.3580],
        [0.7384, 0.2616],
        [0.6944, 0.3056],
        [0.6531, 0.3469],
        [0.6789, 0.3211],
        [0.6488, 0.3512],
        [0.7239, 0.2761],
        [0.7182, 0.2818],
        [0.6266, 0.3734],
        [0.7102, 0.2898],
        [0.6616, 0.3384],
        [0.6843, 0.3157],
        [0.7420, 0.2580],
        [0.6805, 0.3195],
        [0.6718, 0.3282],
        [0.6415, 0.3585],
        [0.7299, 0.2701],
        [0.7059, 0.2941],
        [0.7458, 0.2542],
        [0.6476, 0.3524],
        [0.7289, 0.2711],
        [0.7611, 0.2389],
        [0.7020, 0.2980],
        [0.7278, 0.2722],
        [0.7310, 0.2690],
        [0.6455, 0.3545],
        [0.7205, 0.2795],
        [0.7090, 0.2910],
        [0.7478, 0.2522],
        [0.7438, 0.2562],
        [0.6614, 0.3386],
        [0.6760, 0.3240],
        [0.7071, 0.2929],
        [0.6858, 0.3142],
        [0.7531, 0.2469],
        [0.6913, 0.3087],
        [0.7146, 0.2854],
        [0.7220, 0.2780],
        [0.6750, 0.3250],
        [0.6987, 0.3013],
        [0.7333, 0.2667],
        [0.7072, 0.2928],
        [0.6763, 0.3237],
        [0.7599, 0.2401],
        [0.6907, 0.3093],
        [0.7192, 0.2808],
        [0.7312, 0.2688],
        [0.7115, 0.2885],
        [0.6862, 0.3138],
        [0.7003, 0.2997],
        [0.6941, 0.3059],
        [0.7208, 0.2792],
        [0.7033, 0.2967],
        [0.7230, 0.2770],
        [0.7232, 0.2768],
        [0.7139, 0.2861],
        [0.7350, 0.2650],
        [0.7247, 0.2753],
        [0.6863, 0.3137],
        [0.6941, 0.3059],
        [0.7411, 0.2589],
        [0.6702, 0.3298],
        [0.7129, 0.2871],
        [0.7073, 0.2927],
        [0.6815, 0.3185],
        [0.6942, 0.3058],
        [0.7357, 0.2643],
        [0.7436, 0.2564],
        [0.7178, 0.2822],
        [0.7470, 0.2530],
        [0.7364, 0.2636],
        [0.7060, 0.2940],
        [0.6955, 0.3045],
        [0.7310, 0.2690],
        [0.6652, 0.3348],
        [0.7240, 0.2760],
        [0.7359, 0.2641],
        [0.6935, 0.3065],
        [0.6941, 0.3059],
        [0.7212, 0.2788],
        [0.7247, 0.2753],
        [0.7124, 0.2876],
        [0.7619, 0.2381],
        [0.7386, 0.2614],
        [0.7082, 0.2918],
        [0.7282, 0.2718],
        [0.6798, 0.3202],
        [0.6963, 0.3037],
        [0.7318, 0.2682],
        [0.6710, 0.3290],
        [0.7060, 0.2940],
        [0.7188, 0.2812],
        [0.7380, 0.2620],
        [0.7068, 0.2932]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0007 loss: 0.6552 acc_train: 0.6103 time: 0.1305s
tensor([[0.6768, 0.3232],
        [0.7414, 0.2586],
        [0.6958, 0.3042],
        [0.6840, 0.3160],
        [0.7248, 0.2752],
        [0.6774, 0.3226],
        [0.6192, 0.3808],
        [0.7066, 0.2934],
        [0.7056, 0.2944],
        [0.6473, 0.3527],
        [0.7034, 0.2966],
        [0.6523, 0.3477],
        [0.6599, 0.3401],
        [0.6348, 0.3652],
        [0.7076, 0.2924],
        [0.6554, 0.3446],
        [0.7483, 0.2517],
        [0.6739, 0.3261],
        [0.7099, 0.2901],
        [0.6389, 0.3611],
        [0.7285, 0.2715],
        [0.6560, 0.3440],
        [0.7299, 0.2701],
        [0.7039, 0.2961],
        [0.6895, 0.3105],
        [0.6559, 0.3441],
        [0.6924, 0.3076],
        [0.7102, 0.2898],
        [0.6563, 0.3437],
        [0.6519, 0.3481],
        [0.6876, 0.3124],
        [0.6483, 0.3517],
        [0.6688, 0.3312],
        [0.6550, 0.3450],
        [0.7322, 0.2678],
        [0.6652, 0.3348],
        [0.6593, 0.3407],
        [0.6778, 0.3222],
        [0.6870, 0.3130],
        [0.6543, 0.3457],
        [0.6972, 0.3028],
        [0.6785, 0.3215],
        [0.6311, 0.3689],
        [0.7097, 0.2903],
        [0.7342, 0.2658],
        [0.6606, 0.3394],
        [0.7190, 0.2810],
        [0.7154, 0.2846],
        [0.6903, 0.3097],
        [0.6457, 0.3543],
        [0.6918, 0.3082],
        [0.6954, 0.3046],
        [0.6398, 0.3602],
        [0.7369, 0.2631],
        [0.7119, 0.2881],
        [0.7106, 0.2894],
        [0.7216, 0.2784],
        [0.6704, 0.3296],
        [0.6772, 0.3228],
        [0.6518, 0.3482],
        [0.6226, 0.3774],
        [0.6574, 0.3426],
        [0.7050, 0.2950],
        [0.6946, 0.3054],
        [0.6849, 0.3151],
        [0.7009, 0.2991],
        [0.6848, 0.3152],
        [0.6805, 0.3195],
        [0.7005, 0.2995],
        [0.6811, 0.3189],
        [0.6488, 0.3512],
        [0.6267, 0.3733],
        [0.6701, 0.3299],
        [0.7071, 0.2929],
        [0.6754, 0.3246],
        [0.6670, 0.3330],
        [0.6850, 0.3150],
        [0.6646, 0.3354],
        [0.7112, 0.2888],
        [0.6472, 0.3528],
        [0.6152, 0.3848],
        [0.6515, 0.3485],
        [0.6517, 0.3483],
        [0.6541, 0.3459],
        [0.6728, 0.3272],
        [0.6556, 0.3444],
        [0.7115, 0.2885],
        [0.7005, 0.2995],
        [0.6952, 0.3048],
        [0.6551, 0.3449],
        [0.6663, 0.3337],
        [0.6727, 0.3273],
        [0.6903, 0.3097],
        [0.6147, 0.3853],
        [0.6773, 0.3227],
        [0.7437, 0.2563],
        [0.7017, 0.2983],
        [0.6675, 0.3325],
        [0.7383, 0.2617],
        [0.6682, 0.3318],
        [0.7261, 0.2739],
        [0.6596, 0.3404],
        [0.6521, 0.3479],
        [0.6585, 0.3415],
        [0.7536, 0.2464],
        [0.6667, 0.3333],
        [0.7197, 0.2803],
        [0.7326, 0.2674],
        [0.6405, 0.3595],
        [0.7096, 0.2904],
        [0.6384, 0.3616],
        [0.7399, 0.2601],
        [0.7133, 0.2867],
        [0.7258, 0.2742],
        [0.6755, 0.3245],
        [0.6759, 0.3241],
        [0.6813, 0.3187],
        [0.7103, 0.2897],
        [0.7341, 0.2659],
        [0.7262, 0.2738],
        [0.6473, 0.3527],
        [0.6871, 0.3129],
        [0.6724, 0.3276],
        [0.6625, 0.3375],
        [0.6527, 0.3473],
        [0.6765, 0.3235],
        [0.6426, 0.3574],
        [0.6772, 0.3228],
        [0.6424, 0.3576],
        [0.6515, 0.3485],
        [0.6916, 0.3084],
        [0.6690, 0.3310],
        [0.7041, 0.2959],
        [0.6718, 0.3282],
        [0.7166, 0.2834],
        [0.6845, 0.3155],
        [0.6580, 0.3420],
        [0.7121, 0.2879],
        [0.7031, 0.2969],
        [0.6603, 0.3397],
        [0.6470, 0.3530],
        [0.7100, 0.2900],
        [0.6633, 0.3367],
        [0.6764, 0.3236],
        [0.5924, 0.4076],
        [0.6799, 0.3201],
        [0.6975, 0.3025],
        [0.6622, 0.3378],
        [0.7266, 0.2734],
        [0.6993, 0.3007],
        [0.6428, 0.3572],
        [0.7140, 0.2860],
        [0.7177, 0.2823],
        [0.7523, 0.2477],
        [0.7477, 0.2523],
        [0.6942, 0.3058],
        [0.7136, 0.2864],
        [0.7238, 0.2762],
        [0.6678, 0.3322],
        [0.7120, 0.2880],
        [0.6966, 0.3034],
        [0.7036, 0.2964],
        [0.6514, 0.3486],
        [0.6783, 0.3217],
        [0.6594, 0.3406],
        [0.6473, 0.3527],
        [0.7024, 0.2976],
        [0.6688, 0.3312],
        [0.6898, 0.3102],
        [0.6589, 0.3411],
        [0.6552, 0.3448],
        [0.6627, 0.3373],
        [0.6717, 0.3283],
        [0.6876, 0.3124],
        [0.7050, 0.2950],
        [0.6830, 0.3170],
        [0.7224, 0.2776],
        [0.6730, 0.3270],
        [0.6187, 0.3813],
        [0.7218, 0.2782],
        [0.6770, 0.3230],
        [0.6256, 0.3744],
        [0.6622, 0.3378],
        [0.6241, 0.3759],
        [0.7081, 0.2919],
        [0.7060, 0.2940],
        [0.6021, 0.3979],
        [0.6958, 0.3042],
        [0.6347, 0.3653],
        [0.6645, 0.3355],
        [0.7262, 0.2738],
        [0.6621, 0.3379],
        [0.6524, 0.3476],
        [0.6129, 0.3871],
        [0.7174, 0.2826],
        [0.6880, 0.3120],
        [0.7315, 0.2685],
        [0.6222, 0.3778],
        [0.7155, 0.2845],
        [0.7459, 0.2541],
        [0.6840, 0.3160],
        [0.7116, 0.2884],
        [0.7195, 0.2805],
        [0.6243, 0.3757],
        [0.7013, 0.2987],
        [0.6910, 0.3090],
        [0.7357, 0.2643],
        [0.7327, 0.2673],
        [0.6374, 0.3626],
        [0.6521, 0.3479],
        [0.6891, 0.3109],
        [0.6685, 0.3315],
        [0.7407, 0.2593],
        [0.6740, 0.3260],
        [0.6975, 0.3025],
        [0.7071, 0.2929],
        [0.6524, 0.3476],
        [0.6814, 0.3186],
        [0.7222, 0.2778],
        [0.6909, 0.3091],
        [0.6530, 0.3470],
        [0.7499, 0.2501],
        [0.6713, 0.3287],
        [0.7008, 0.2992],
        [0.7199, 0.2801],
        [0.6997, 0.3003],
        [0.6703, 0.3297],
        [0.6837, 0.3163],
        [0.6708, 0.3292],
        [0.7021, 0.2979],
        [0.6886, 0.3114],
        [0.7098, 0.2902],
        [0.7074, 0.2926],
        [0.6965, 0.3035],
        [0.7178, 0.2822],
        [0.7103, 0.2897],
        [0.6695, 0.3305],
        [0.6734, 0.3266],
        [0.7279, 0.2721],
        [0.6525, 0.3475],
        [0.6981, 0.3019],
        [0.6895, 0.3105],
        [0.6588, 0.3412],
        [0.6775, 0.3225],
        [0.7250, 0.2750],
        [0.7309, 0.2691],
        [0.7015, 0.2985],
        [0.7355, 0.2645],
        [0.7195, 0.2805],
        [0.6903, 0.3097],
        [0.6814, 0.3186],
        [0.7174, 0.2826],
        [0.6444, 0.3556],
        [0.7056, 0.2944],
        [0.7208, 0.2792],
        [0.6777, 0.3223],
        [0.6777, 0.3223],
        [0.7124, 0.2876],
        [0.7090, 0.2910],
        [0.6980, 0.3020],
        [0.7516, 0.2484],
        [0.7270, 0.2730],
        [0.6891, 0.3109],
        [0.7102, 0.2898],
        [0.6628, 0.3372],
        [0.6811, 0.3189],
        [0.7183, 0.2817],
        [0.6511, 0.3489],
        [0.6862, 0.3138],
        [0.7005, 0.2995],
        [0.7251, 0.2749],
        [0.6915, 0.3085]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0008 loss: 0.6537 acc_train: 0.6103 time: 0.1332s
tensor([[0.6622, 0.3378],
        [0.7295, 0.2705],
        [0.6800, 0.3200],
        [0.6720, 0.3280],
        [0.7150, 0.2850],
        [0.6627, 0.3373],
        [0.5987, 0.4013],
        [0.6959, 0.3041],
        [0.6916, 0.3084],
        [0.6248, 0.3752],
        [0.6932, 0.3068],
        [0.6334, 0.3666],
        [0.6410, 0.3590],
        [0.6162, 0.3838],
        [0.6941, 0.3059],
        [0.6376, 0.3624],
        [0.7354, 0.2646],
        [0.6591, 0.3409],
        [0.6996, 0.3004],
        [0.6203, 0.3797],
        [0.7151, 0.2849],
        [0.6390, 0.3610],
        [0.7191, 0.2809],
        [0.6880, 0.3120],
        [0.6795, 0.3205],
        [0.6391, 0.3609],
        [0.6793, 0.3207],
        [0.6986, 0.3014],
        [0.6384, 0.3616],
        [0.6343, 0.3657],
        [0.6755, 0.3245],
        [0.6321, 0.3679],
        [0.6539, 0.3461],
        [0.6356, 0.3644],
        [0.7232, 0.2768],
        [0.6578, 0.3422],
        [0.6441, 0.3559],
        [0.6666, 0.3334],
        [0.6698, 0.3302],
        [0.6352, 0.3648],
        [0.6820, 0.3180],
        [0.6653, 0.3347],
        [0.6216, 0.3784],
        [0.7004, 0.2996],
        [0.7264, 0.2736],
        [0.6457, 0.3543],
        [0.7092, 0.2908],
        [0.7060, 0.2940],
        [0.6739, 0.3261],
        [0.6300, 0.3700],
        [0.6829, 0.3171],
        [0.6810, 0.3190],
        [0.6212, 0.3788],
        [0.7267, 0.2733],
        [0.7008, 0.2992],
        [0.6999, 0.3001],
        [0.7107, 0.2893],
        [0.6567, 0.3433],
        [0.6594, 0.3406],
        [0.6288, 0.3712],
        [0.6017, 0.3983],
        [0.6406, 0.3594],
        [0.6894, 0.3106],
        [0.6802, 0.3198],
        [0.6675, 0.3325],
        [0.6870, 0.3130],
        [0.6713, 0.3287],
        [0.6602, 0.3398],
        [0.6902, 0.3098],
        [0.6642, 0.3358],
        [0.6322, 0.3678],
        [0.6051, 0.3949],
        [0.6536, 0.3464],
        [0.6936, 0.3064],
        [0.6620, 0.3380],
        [0.6527, 0.3473],
        [0.6698, 0.3302],
        [0.6437, 0.3563],
        [0.6943, 0.3057],
        [0.6274, 0.3726],
        [0.5942, 0.4058],
        [0.6311, 0.3689],
        [0.6354, 0.3646],
        [0.6378, 0.3622],
        [0.6582, 0.3418],
        [0.6377, 0.3623],
        [0.6972, 0.3028],
        [0.6874, 0.3126],
        [0.6845, 0.3155],
        [0.6363, 0.3637],
        [0.6509, 0.3491],
        [0.6564, 0.3436],
        [0.6767, 0.3233],
        [0.5949, 0.4051],
        [0.6627, 0.3373],
        [0.7326, 0.2674],
        [0.6902, 0.3098],
        [0.6453, 0.3547],
        [0.7299, 0.2701],
        [0.6529, 0.3471],
        [0.7160, 0.2840],
        [0.6414, 0.3586],
        [0.6331, 0.3669],
        [0.6444, 0.3556],
        [0.7444, 0.2556],
        [0.6516, 0.3484],
        [0.7074, 0.2926],
        [0.7272, 0.2728],
        [0.6206, 0.3794],
        [0.6931, 0.3069],
        [0.6362, 0.3638],
        [0.7297, 0.2703],
        [0.7028, 0.2972],
        [0.7177, 0.2823],
        [0.6580, 0.3420],
        [0.6650, 0.3350],
        [0.6649, 0.3351],
        [0.6989, 0.3011],
        [0.7270, 0.2730],
        [0.7135, 0.2865],
        [0.6321, 0.3679],
        [0.6712, 0.3288],
        [0.6558, 0.3442],
        [0.6488, 0.3512],
        [0.6354, 0.3646],
        [0.6618, 0.3382],
        [0.6263, 0.3737],
        [0.6597, 0.3403],
        [0.6264, 0.3736],
        [0.6362, 0.3638],
        [0.6786, 0.3214],
        [0.6517, 0.3483],
        [0.6916, 0.3084],
        [0.6564, 0.3436],
        [0.7073, 0.2927],
        [0.6677, 0.3323],
        [0.6393, 0.3607],
        [0.7007, 0.2993],
        [0.6923, 0.3077],
        [0.6473, 0.3527],
        [0.6328, 0.3672],
        [0.6922, 0.3078],
        [0.6427, 0.3573],
        [0.6622, 0.3378],
        [0.5699, 0.4301],
        [0.6612, 0.3388],
        [0.6809, 0.3191],
        [0.6440, 0.3560],
        [0.7168, 0.2832],
        [0.6839, 0.3161],
        [0.6263, 0.3737],
        [0.7004, 0.2996],
        [0.7023, 0.2977],
        [0.7445, 0.2555],
        [0.7395, 0.2605],
        [0.6777, 0.3223],
        [0.7018, 0.2982],
        [0.7132, 0.2868],
        [0.6490, 0.3510],
        [0.7008, 0.2992],
        [0.6853, 0.3147],
        [0.6879, 0.3121],
        [0.6370, 0.3630],
        [0.6601, 0.3399],
        [0.6460, 0.3540],
        [0.6345, 0.3655],
        [0.6898, 0.3102],
        [0.6525, 0.3475],
        [0.6748, 0.3252],
        [0.6391, 0.3609],
        [0.6474, 0.3526],
        [0.6499, 0.3501],
        [0.6612, 0.3388],
        [0.6708, 0.3292],
        [0.6912, 0.3088],
        [0.6661, 0.3339],
        [0.7117, 0.2883],
        [0.6583, 0.3417],
        [0.5998, 0.4002],
        [0.7082, 0.2918],
        [0.6616, 0.3384],
        [0.6047, 0.3953],
        [0.6489, 0.3511],
        [0.6062, 0.3938],
        [0.6954, 0.3046],
        [0.6965, 0.3035],
        [0.5837, 0.4163],
        [0.6827, 0.3173],
        [0.6138, 0.3862],
        [0.6499, 0.3501],
        [0.7123, 0.2877],
        [0.6496, 0.3504],
        [0.6391, 0.3609],
        [0.5916, 0.4084],
        [0.7073, 0.2927],
        [0.6741, 0.3259],
        [0.7195, 0.2805],
        [0.6007, 0.3993],
        [0.7006, 0.2994],
        [0.7329, 0.2671],
        [0.6687, 0.3313],
        [0.6963, 0.3037],
        [0.7098, 0.2902],
        [0.6074, 0.3926],
        [0.6842, 0.3158],
        [0.6761, 0.3239],
        [0.7256, 0.2744],
        [0.7217, 0.2783],
        [0.6180, 0.3820],
        [0.6334, 0.3666],
        [0.6743, 0.3257],
        [0.6550, 0.3450],
        [0.7294, 0.2706],
        [0.6604, 0.3396],
        [0.6845, 0.3155],
        [0.6952, 0.3048],
        [0.6345, 0.3655],
        [0.6667, 0.3333],
        [0.7145, 0.2855],
        [0.6792, 0.3208],
        [0.6353, 0.3647],
        [0.7413, 0.2587],
        [0.6570, 0.3430],
        [0.6859, 0.3141],
        [0.7090, 0.2910],
        [0.6887, 0.3113],
        [0.6614, 0.3386],
        [0.6700, 0.3300],
        [0.6484, 0.3516],
        [0.6866, 0.3134],
        [0.6768, 0.3232],
        [0.6997, 0.3003],
        [0.6947, 0.3053],
        [0.6806, 0.3194],
        [0.7032, 0.2968],
        [0.6981, 0.3019],
        [0.6581, 0.3419],
        [0.6608, 0.3392],
        [0.7178, 0.2822],
        [0.6374, 0.3626],
        [0.6845, 0.3155],
        [0.6757, 0.3243],
        [0.6426, 0.3574],
        [0.6611, 0.3389],
        [0.7153, 0.2847],
        [0.7219, 0.2781],
        [0.6867, 0.3133],
        [0.7261, 0.2739],
        [0.7047, 0.2953],
        [0.6776, 0.3224],
        [0.6716, 0.3284],
        [0.7060, 0.2940],
        [0.6288, 0.3712],
        [0.6899, 0.3101],
        [0.7083, 0.2917],
        [0.6656, 0.3344],
        [0.6648, 0.3352],
        [0.7041, 0.2959],
        [0.6958, 0.3042],
        [0.6879, 0.3121],
        [0.7417, 0.2583],
        [0.7149, 0.2851],
        [0.6727, 0.3273],
        [0.6959, 0.3041],
        [0.6487, 0.3513],
        [0.6685, 0.3315],
        [0.7059, 0.2941],
        [0.6374, 0.3626],
        [0.6698, 0.3302],
        [0.6854, 0.3146],
        [0.7150, 0.2850],
        [0.6795, 0.3205]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0009 loss: 0.6529 acc_train: 0.6103 time: 0.1258s
tensor([[0.6564, 0.3436],
        [0.7247, 0.2753],
        [0.6723, 0.3277],
        [0.6687, 0.3313],
        [0.7112, 0.2888],
        [0.6572, 0.3428],
        [0.5921, 0.4079],
        [0.6927, 0.3073],
        [0.6845, 0.3155],
        [0.6151, 0.3849],
        [0.6890, 0.3110],
        [0.6272, 0.3728],
        [0.6330, 0.3670],
        [0.6081, 0.3919],
        [0.6889, 0.3111],
        [0.6304, 0.3696],
        [0.7311, 0.2689],
        [0.6538, 0.3462],
        [0.6978, 0.3022],
        [0.6127, 0.3873],
        [0.7080, 0.2920],
        [0.6334, 0.3666],
        [0.7166, 0.2834],
        [0.6813, 0.3187],
        [0.6767, 0.3233],
        [0.6324, 0.3676],
        [0.6741, 0.3259],
        [0.6924, 0.3076],
        [0.6313, 0.3687],
        [0.6278, 0.3722],
        [0.6715, 0.3285],
        [0.6252, 0.3748],
        [0.6470, 0.3530],
        [0.6270, 0.3730],
        [0.7198, 0.2802],
        [0.6567, 0.3433],
        [0.6381, 0.3619],
        [0.6644, 0.3356],
        [0.6647, 0.3353],
        [0.6275, 0.3725],
        [0.6769, 0.3231],
        [0.6601, 0.3399],
        [0.6218, 0.3782],
        [0.6991, 0.3009],
        [0.7247, 0.2753],
        [0.6414, 0.3586],
        [0.7075, 0.2925],
        [0.7040, 0.2960],
        [0.6669, 0.3331],
        [0.6246, 0.3754],
        [0.6808, 0.3192],
        [0.6737, 0.3263],
        [0.6145, 0.3855],
        [0.7239, 0.2761],
        [0.6973, 0.3027],
        [0.6966, 0.3034],
        [0.7083, 0.2917],
        [0.6520, 0.3480],
        [0.6526, 0.3474],
        [0.6193, 0.3807],
        [0.5923, 0.4077],
        [0.6336, 0.3664],
        [0.6839, 0.3161],
        [0.6753, 0.3247],
        [0.6592, 0.3408],
        [0.6818, 0.3182],
        [0.6678, 0.3322],
        [0.6515, 0.3485],
        [0.6885, 0.3115],
        [0.6561, 0.3439],
        [0.6271, 0.3729],
        [0.5965, 0.4035],
        [0.6465, 0.3535],
        [0.6892, 0.3108],
        [0.6587, 0.3413],
        [0.6482, 0.3518],
        [0.6651, 0.3349],
        [0.6343, 0.3657],
        [0.6871, 0.3129],
        [0.6196, 0.3804],
        [0.5851, 0.4149],
        [0.6233, 0.3767],
        [0.6280, 0.3720],
        [0.6324, 0.3676],
        [0.6541, 0.3459],
        [0.6306, 0.3694],
        [0.6909, 0.3091],
        [0.6835, 0.3165],
        [0.6826, 0.3174],
        [0.6297, 0.3703],
        [0.6462, 0.3538],
        [0.6492, 0.3508],
        [0.6728, 0.3272],
        [0.5865, 0.4135],
        [0.6590, 0.3410],
        [0.7265, 0.2735],
        [0.6866, 0.3134],
        [0.6345, 0.3655],
        [0.7278, 0.2722],
        [0.6467, 0.3533],
        [0.7136, 0.2864],
        [0.6341, 0.3659],
        [0.6261, 0.3739],
        [0.6386, 0.3614],
        [0.7412, 0.2588],
        [0.6463, 0.3537],
        [0.7012, 0.2988],
        [0.7274, 0.2726],
        [0.6127, 0.3873],
        [0.6845, 0.3155],
        [0.6413, 0.3587],
        [0.7251, 0.2749],
        [0.7013, 0.2987],
        [0.7162, 0.2838],
        [0.6521, 0.3479],
        [0.6623, 0.3377],
        [0.6570, 0.3430],
        [0.6960, 0.3040],
        [0.7251, 0.2749],
        [0.7089, 0.2911],
        [0.6285, 0.3715],
        [0.6639, 0.3361],
        [0.6501, 0.3499],
        [0.6457, 0.3543],
        [0.6282, 0.3718],
        [0.6579, 0.3421],
        [0.6212, 0.3788],
        [0.6513, 0.3487],
        [0.6224, 0.3776],
        [0.6321, 0.3679],
        [0.6732, 0.3268],
        [0.6449, 0.3551],
        [0.6875, 0.3125],
        [0.6510, 0.3490],
        [0.7054, 0.2946],
        [0.6613, 0.3387],
        [0.6316, 0.3684],
        [0.6982, 0.3018],
        [0.6883, 0.3117],
        [0.6444, 0.3556],
        [0.6288, 0.3712],
        [0.6823, 0.3177],
        [0.6335, 0.3665],
        [0.6575, 0.3425],
        [0.5602, 0.4398],
        [0.6530, 0.3470],
        [0.6722, 0.3278],
        [0.6367, 0.3633],
        [0.7126, 0.2874],
        [0.6774, 0.3226],
        [0.6204, 0.3796],
        [0.6960, 0.3040],
        [0.6964, 0.3036],
        [0.7426, 0.2574],
        [0.7369, 0.2631],
        [0.6698, 0.3302],
        [0.6969, 0.3031],
        [0.7100, 0.2900],
        [0.6405, 0.3595],
        [0.6975, 0.3025],
        [0.6825, 0.3175],
        [0.6806, 0.3194],
        [0.6312, 0.3688],
        [0.6526, 0.3474],
        [0.6428, 0.3572],
        [0.6294, 0.3706],
        [0.6855, 0.3145],
        [0.6458, 0.3542],
        [0.6693, 0.3307],
        [0.6295, 0.3705],
        [0.6452, 0.3548],
        [0.6476, 0.3524],
        [0.6614, 0.3386],
        [0.6620, 0.3380],
        [0.6867, 0.3133],
        [0.6585, 0.3415],
        [0.7094, 0.2906],
        [0.6535, 0.3465],
        [0.5921, 0.4079],
        [0.7026, 0.2974],
        [0.6543, 0.3457],
        [0.5980, 0.4020],
        [0.6433, 0.3567],
        [0.6013, 0.3987],
        [0.6913, 0.3087],
        [0.6946, 0.3054],
        [0.5787, 0.4213],
        [0.6788, 0.3212],
        [0.6063, 0.3937],
        [0.6468, 0.3532],
        [0.7060, 0.2940],
        [0.6475, 0.3525],
        [0.6349, 0.3651],
        [0.5844, 0.4156],
        [0.7042, 0.2958],
        [0.6700, 0.3300],
        [0.7155, 0.2845],
        [0.5903, 0.4097],
        [0.6936, 0.3064],
        [0.7270, 0.2730],
        [0.6619, 0.3381],
        [0.6892, 0.3108],
        [0.7067, 0.2933],
        [0.6023, 0.3977],
        [0.6756, 0.3244],
        [0.6689, 0.3311],
        [0.7218, 0.2782],
        [0.7176, 0.2824],
        [0.6111, 0.3889],
        [0.6272, 0.3728],
        [0.6678, 0.3322],
        [0.6511, 0.3489],
        [0.7247, 0.2753],
        [0.6554, 0.3446],
        [0.6802, 0.3198],
        [0.6923, 0.3077],
        [0.6299, 0.3701],
        [0.6603, 0.3397],
        [0.7133, 0.2867],
        [0.6760, 0.3240],
        [0.6297, 0.3703],
        [0.7398, 0.2602],
        [0.6523, 0.3477],
        [0.6796, 0.3204],
        [0.7044, 0.2956],
        [0.6828, 0.3172],
        [0.6610, 0.3390],
        [0.6654, 0.3346],
        [0.6374, 0.3626],
        [0.6807, 0.3193],
        [0.6733, 0.3267],
        [0.6978, 0.3022],
        [0.6906, 0.3094],
        [0.6743, 0.3257],
        [0.6974, 0.3026],
        [0.6941, 0.3059],
        [0.6560, 0.3440],
        [0.6578, 0.3422],
        [0.7152, 0.2848],
        [0.6303, 0.3697],
        [0.6788, 0.3212],
        [0.6710, 0.3290],
        [0.6384, 0.3616],
        [0.6536, 0.3464],
        [0.7122, 0.2878],
        [0.7200, 0.2800],
        [0.6803, 0.3197],
        [0.7236, 0.2764],
        [0.6986, 0.3014],
        [0.6739, 0.3261],
        [0.6691, 0.3309],
        [0.7030, 0.2970],
        [0.6228, 0.3772],
        [0.6830, 0.3170],
        [0.7044, 0.2956],
        [0.6625, 0.3375],
        [0.6609, 0.3391],
        [0.7015, 0.2985],
        [0.6913, 0.3087],
        [0.6862, 0.3138],
        [0.7381, 0.2619],
        [0.7096, 0.2904],
        [0.6643, 0.3357],
        [0.6899, 0.3101],
        [0.6444, 0.3556],
        [0.6658, 0.3342],
        [0.7014, 0.2986],
        [0.6330, 0.3670],
        [0.6635, 0.3365],
        [0.6784, 0.3216],
        [0.7134, 0.2866],
        [0.6758, 0.3242]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0010 loss: 0.6524 acc_train: 0.6103 time: 0.1202s
tensor([[0.6568, 0.3432],
        [0.7234, 0.2766],
        [0.6714, 0.3286],
        [0.6713, 0.3287],
        [0.7123, 0.2877],
        [0.6577, 0.3423],
        [0.5941, 0.4059],
        [0.6953, 0.3047],
        [0.6824, 0.3176],
        [0.6143, 0.3857],
        [0.6892, 0.3108],
        [0.6299, 0.3701],
        [0.6323, 0.3677],
        [0.6082, 0.3918],
        [0.6894, 0.3106],
        [0.6316, 0.3684],
        [0.7318, 0.2682],
        [0.6564, 0.3436],
        [0.7012, 0.2988],
        [0.6135, 0.3865],
        [0.7061, 0.2939],
        [0.6354, 0.3646],
        [0.7186, 0.2814],
        [0.6807, 0.3193],
        [0.6801, 0.3199],
        [0.6328, 0.3672],
        [0.6741, 0.3259],
        [0.6907, 0.3093],
        [0.6320, 0.3680],
        [0.6289, 0.3711],
        [0.6734, 0.3266],
        [0.6253, 0.3747],
        [0.6460, 0.3540],
        [0.6271, 0.3729],
        [0.7212, 0.2788],
        [0.6594, 0.3406],
        [0.6383, 0.3617],
        [0.6676, 0.3324],
        [0.6680, 0.3320],
        [0.6281, 0.3719],
        [0.6787, 0.3213],
        [0.6607, 0.3393],
        [0.6257, 0.3743],
        [0.7022, 0.2978],
        [0.7273, 0.2727],
        [0.6438, 0.3562],
        [0.7105, 0.2895],
        [0.7061, 0.2939],
        [0.6677, 0.3323],
        [0.6259, 0.3741],
        [0.6834, 0.3166],
        [0.6730, 0.3270],
        [0.6158, 0.3842],
        [0.7255, 0.2745],
        [0.6984, 0.3016],
        [0.6978, 0.3022],
        [0.7111, 0.2889],
        [0.6533, 0.3467],
        [0.6523, 0.3477],
        [0.6199, 0.3801],
        [0.5921, 0.4079],
        [0.6341, 0.3659],
        [0.6855, 0.3145],
        [0.6764, 0.3236],
        [0.6589, 0.3411],
        [0.6818, 0.3182],
        [0.6706, 0.3294],
        [0.6511, 0.3489],
        [0.6912, 0.3088],
        [0.6553, 0.3447],
        [0.6302, 0.3698],
        [0.5977, 0.4023],
        [0.6465, 0.3535],
        [0.6900, 0.3100],
        [0.6610, 0.3390],
        [0.6504, 0.3496],
        [0.6673, 0.3327],
        [0.6340, 0.3660],
        [0.6871, 0.3129],
        [0.6209, 0.3791],
        [0.5847, 0.4153],
        [0.6235, 0.3765],
        [0.6272, 0.3728],
        [0.6341, 0.3659],
        [0.6572, 0.3428],
        [0.6319, 0.3681],
        [0.6901, 0.3099],
        [0.6851, 0.3149],
        [0.6872, 0.3128],
        [0.6308, 0.3692],
        [0.6491, 0.3509],
        [0.6494, 0.3506],
        [0.6754, 0.3246],
        [0.5866, 0.4134],
        [0.6622, 0.3378],
        [0.7252, 0.2748],
        [0.6876, 0.3124],
        [0.6331, 0.3669],
        [0.7291, 0.2709],
        [0.6472, 0.3528],
        [0.7154, 0.2846],
        [0.6342, 0.3658],
        [0.6271, 0.3729],
        [0.6392, 0.3608],
        [0.7420, 0.2580],
        [0.6488, 0.3512],
        [0.7000, 0.3000],
        [0.7310, 0.2690],
        [0.6141, 0.3859],
        [0.6826, 0.3174],
        [0.6483, 0.3517],
        [0.7248, 0.2752],
        [0.7051, 0.2949],
        [0.7186, 0.2814],
        [0.6542, 0.3458],
        [0.6660, 0.3340],
        [0.6560, 0.3440],
        [0.6992, 0.3008],
        [0.7266, 0.2734],
        [0.7097, 0.2903],
        [0.6320, 0.3680],
        [0.6630, 0.3370],
        [0.6519, 0.3481],
        [0.6491, 0.3509],
        [0.6286, 0.3714],
        [0.6608, 0.3392],
        [0.6237, 0.3763],
        [0.6510, 0.3490],
        [0.6264, 0.3736],
        [0.6357, 0.3643],
        [0.6730, 0.3270],
        [0.6457, 0.3543],
        [0.6891, 0.3109],
        [0.6532, 0.3468],
        [0.7082, 0.2918],
        [0.6629, 0.3371],
        [0.6316, 0.3684],
        [0.7008, 0.2992],
        [0.6890, 0.3110],
        [0.6479, 0.3521],
        [0.6322, 0.3678],
        [0.6796, 0.3204],
        [0.6334, 0.3666],
        [0.6597, 0.3403],
        [0.5596, 0.4404],
        [0.6522, 0.3478],
        [0.6704, 0.3296],
        [0.6370, 0.3630],
        [0.7131, 0.2869],
        [0.6777, 0.3223],
        [0.6214, 0.3786],
        [0.6967, 0.3032],
        [0.6967, 0.3033],
        [0.7435, 0.2565],
        [0.7381, 0.2619],
        [0.6686, 0.3314],
        [0.6972, 0.3028],
        [0.7113, 0.2887],
        [0.6402, 0.3598],
        [0.6993, 0.3007],
        [0.6851, 0.3149],
        [0.6801, 0.3199],
        [0.6326, 0.3674],
        [0.6531, 0.3469],
        [0.6468, 0.3532],
        [0.6320, 0.3680],
        [0.6869, 0.3131],
        [0.6465, 0.3535],
        [0.6713, 0.3287],
        [0.6281, 0.3719],
        [0.6485, 0.3515],
        [0.6525, 0.3475],
        [0.6674, 0.3326],
        [0.6601, 0.3399],
        [0.6884, 0.3116],
        [0.6581, 0.3419],
        [0.7121, 0.2879],
        [0.6557, 0.3443],
        [0.5934, 0.4066],
        [0.7026, 0.2974],
        [0.6534, 0.3466],
        [0.6013, 0.3987],
        [0.6438, 0.3562],
        [0.6050, 0.3950],
        [0.6931, 0.3069],
        [0.6970, 0.3030],
        [0.5825, 0.4175],
        [0.6816, 0.3184],
        [0.6084, 0.3916],
        [0.6508, 0.3492],
        [0.7046, 0.2954],
        [0.6509, 0.3491],
        [0.6376, 0.3624],
        [0.5870, 0.4130],
        [0.7059, 0.2941],
        [0.6721, 0.3279],
        [0.7158, 0.2842],
        [0.5896, 0.4104],
        [0.6927, 0.3073],
        [0.7261, 0.2739],
        [0.6609, 0.3391],
        [0.6883, 0.3117],
        [0.7089, 0.2911],
        [0.6052, 0.3948],
        [0.6745, 0.3255],
        [0.6687, 0.3313],
        [0.7220, 0.2780],
        [0.7175, 0.2825],
        [0.6124, 0.3876],
        [0.6308, 0.3692],
        [0.6679, 0.3321],
        [0.6542, 0.3458],
        [0.7250, 0.2750],
        [0.6573, 0.3427],
        [0.6822, 0.3178],
        [0.6948, 0.3052],
        [0.6336, 0.3664],
        [0.6598, 0.3402],
        [0.7162, 0.2838],
        [0.6770, 0.3230],
        [0.6329, 0.3671],
        [0.7422, 0.2578],
        [0.6557, 0.3443],
        [0.6801, 0.3199],
        [0.7040, 0.2960],
        [0.6820, 0.3180],
        [0.6654, 0.3346],
        [0.6668, 0.3332],
        [0.6354, 0.3646],
        [0.6815, 0.3185],
        [0.6744, 0.3256],
        [0.7008, 0.2992],
        [0.6936, 0.3064],
        [0.6739, 0.3261],
        [0.6979, 0.3021],
        [0.6965, 0.3035],
        [0.6595, 0.3405],
        [0.6613, 0.3387],
        [0.7163, 0.2837],
        [0.6297, 0.3703],
        [0.6791, 0.3209],
        [0.6730, 0.3270],
        [0.6420, 0.3580],
        [0.6535, 0.3465],
        [0.7129, 0.2871],
        [0.7225, 0.2775],
        [0.6798, 0.3202],
        [0.7247, 0.2753],
        [0.6983, 0.3017],
        [0.6753, 0.3247],
        [0.6712, 0.3288],
        [0.7032, 0.2968],
        [0.6237, 0.3763],
        [0.6818, 0.3182],
        [0.7058, 0.2942],
        [0.6654, 0.3346],
        [0.6635, 0.3365],
        [0.7025, 0.2975],
        [0.6933, 0.3067],
        [0.6901, 0.3099],
        [0.7387, 0.2613],
        [0.7097, 0.2903],
        [0.6627, 0.3373],
        [0.6897, 0.3103],
        [0.6472, 0.3528],
        [0.6690, 0.3310],
        [0.7022, 0.2978],
        [0.6352, 0.3648],
        [0.6649, 0.3351],
        [0.6781, 0.3219],
        [0.7170, 0.2830],
        [0.6769, 0.3231]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0011 loss: 0.6523 acc_train: 0.6103 time: 0.1272s
tensor([[0.6596, 0.3404],
        [0.7227, 0.2773],
        [0.6727, 0.3273],
        [0.6751, 0.3249],
        [0.7143, 0.2857],
        [0.6608, 0.3392],
        [0.5995, 0.4005],
        [0.6986, 0.3014],
        [0.6828, 0.3172],
        [0.6175, 0.3825],
        [0.6902, 0.3098],
        [0.6359, 0.3641],
        [0.6348, 0.3652],
        [0.6119, 0.3881],
        [0.6918, 0.3082],
        [0.6360, 0.3640],
        [0.7326, 0.2674],
        [0.6610, 0.3390],
        [0.7048, 0.2952],
        [0.6180, 0.3820],
        [0.7056, 0.2944],
        [0.6394, 0.3606],
        [0.7208, 0.2792],
        [0.6817, 0.3183],
        [0.6829, 0.3171],
        [0.6363, 0.3637],
        [0.6759, 0.3241],
        [0.6902, 0.3098],
        [0.6356, 0.3644],
        [0.6330, 0.3670],
        [0.6773, 0.3227],
        [0.6281, 0.3719],
        [0.6470, 0.3530],
        [0.6310, 0.3690],
        [0.7229, 0.2771],
        [0.6625, 0.3375],
        [0.6409, 0.3591],
        [0.6721, 0.3279],
        [0.6739, 0.3261],
        [0.6319, 0.3681],
        [0.6827, 0.3173],
        [0.6632, 0.3368],
        [0.6310, 0.3690],
        [0.7055, 0.2945],
        [0.7298, 0.2702],
        [0.6486, 0.3514],
        [0.7136, 0.2864],
        [0.7080, 0.2920],
        [0.6715, 0.3285],
        [0.6288, 0.3712],
        [0.6861, 0.3139],
        [0.6742, 0.3258],
        [0.6200, 0.3800],
        [0.7271, 0.2729],
        [0.7003, 0.2997],
        [0.6993, 0.3007],
        [0.7146, 0.2854],
        [0.6562, 0.3438],
        [0.6550, 0.3450],
        [0.6252, 0.3748],
        [0.5964, 0.4036],
        [0.6381, 0.3619],
        [0.6886, 0.3114],
        [0.6785, 0.3215],
        [0.6617, 0.3383],
        [0.6831, 0.3169],
        [0.6743, 0.3257],
        [0.6544, 0.3456],
        [0.6935, 0.3065],
        [0.6573, 0.3427],
        [0.6359, 0.3641],
        [0.6033, 0.3967],
        [0.6496, 0.3504],
        [0.6920, 0.3080],
        [0.6650, 0.3350],
        [0.6542, 0.3458],
        [0.6709, 0.3291],
        [0.6382, 0.3618],
        [0.6892, 0.3108],
        [0.6257, 0.3743],
        [0.5896, 0.4104],
        [0.6273, 0.3727],
        [0.6297, 0.3703],
        [0.6384, 0.3616],
        [0.6626, 0.3374],
        [0.6368, 0.3632],
        [0.6912, 0.3088],
        [0.6878, 0.3122],
        [0.6922, 0.3078],
        [0.6349, 0.3651],
        [0.6539, 0.3461],
        [0.6526, 0.3474],
        [0.6789, 0.3211],
        [0.5905, 0.4095],
        [0.6680, 0.3320],
        [0.7239, 0.2761],
        [0.6895, 0.3105],
        [0.6363, 0.3637],
        [0.7300, 0.2700],
        [0.6501, 0.3499],
        [0.7168, 0.2832],
        [0.6376, 0.3624],
        [0.6310, 0.3690],
        [0.6421, 0.3579],
        [0.7432, 0.2568],
        [0.6542, 0.3458],
        [0.7002, 0.2998],
        [0.7332, 0.2668],
        [0.6184, 0.3816],
        [0.6834, 0.3166],
        [0.6545, 0.3455],
        [0.7256, 0.2744],
        [0.7094, 0.2906],
        [0.7207, 0.2793],
        [0.6589, 0.3411],
        [0.6703, 0.3297],
        [0.6577, 0.3423],
        [0.7031, 0.2969],
        [0.7282, 0.2718],
        [0.7112, 0.2888],
        [0.6371, 0.3629],
        [0.6643, 0.3357],
        [0.6561, 0.3439],
        [0.6537, 0.3463],
        [0.6322, 0.3678],
        [0.6652, 0.3348],
        [0.6288, 0.3712],
        [0.6538, 0.3462],
        [0.6331, 0.3669],
        [0.6415, 0.3585],
        [0.6747, 0.3253],
        [0.6492, 0.3508],
        [0.6921, 0.3079],
        [0.6575, 0.3425],
        [0.7110, 0.2890],
        [0.6669, 0.3331],
        [0.6343, 0.3657],
        [0.7040, 0.2960],
        [0.6901, 0.3099],
        [0.6525, 0.3475],
        [0.6379, 0.3621],
        [0.6797, 0.3203],
        [0.6366, 0.3634],
        [0.6636, 0.3364],
        [0.5634, 0.4366],
        [0.6547, 0.3453],
        [0.6712, 0.3288],
        [0.6398, 0.3602],
        [0.7144, 0.2856],
        [0.6802, 0.3198],
        [0.6252, 0.3748],
        [0.6989, 0.3011],
        [0.6981, 0.3019],
        [0.7438, 0.2562],
        [0.7389, 0.2611],
        [0.6702, 0.3298],
        [0.6987, 0.3013],
        [0.7133, 0.2867],
        [0.6431, 0.3569],
        [0.7020, 0.2980],
        [0.6880, 0.3120],
        [0.6820, 0.3180],
        [0.6371, 0.3629],
        [0.6572, 0.3428],
        [0.6527, 0.3473],
        [0.6369, 0.3631],
        [0.6902, 0.3098],
        [0.6505, 0.3495],
        [0.6752, 0.3248],
        [0.6304, 0.3696],
        [0.6536, 0.3464],
        [0.6583, 0.3417],
        [0.6734, 0.3266],
        [0.6607, 0.3393],
        [0.6919, 0.3081],
        [0.6605, 0.3395],
        [0.7154, 0.2846],
        [0.6615, 0.3385],
        [0.5984, 0.4016],
        [0.7035, 0.2965],
        [0.6549, 0.3451],
        [0.6078, 0.3922],
        [0.6472, 0.3528],
        [0.6107, 0.3893],
        [0.6957, 0.3043],
        [0.7001, 0.2999],
        [0.5900, 0.4100],
        [0.6849, 0.3151],
        [0.6146, 0.3854],
        [0.6567, 0.3433],
        [0.7051, 0.2949],
        [0.6553, 0.3447],
        [0.6422, 0.3578],
        [0.5932, 0.4068],
        [0.7078, 0.2922],
        [0.6756, 0.3244],
        [0.7174, 0.2826],
        [0.5934, 0.4066],
        [0.6933, 0.3067],
        [0.7263, 0.2737],
        [0.6620, 0.3380],
        [0.6888, 0.3112],
        [0.7114, 0.2886],
        [0.6110, 0.3890],
        [0.6750, 0.3250],
        [0.6711, 0.3289],
        [0.7233, 0.2767],
        [0.7178, 0.2822],
        [0.6174, 0.3826],
        [0.6370, 0.3630],
        [0.6701, 0.3299],
        [0.6587, 0.3413],
        [0.7261, 0.2739],
        [0.6617, 0.3383],
        [0.6861, 0.3139],
        [0.6981, 0.3019],
        [0.6389, 0.3611],
        [0.6616, 0.3384],
        [0.7192, 0.2808],
        [0.6789, 0.3211],
        [0.6389, 0.3611],
        [0.7441, 0.2559],
        [0.6617, 0.3383],
        [0.6819, 0.3181],
        [0.7049, 0.2951],
        [0.6824, 0.3176],
        [0.6694, 0.3306],
        [0.6694, 0.3306],
        [0.6377, 0.3623],
        [0.6837, 0.3163],
        [0.6771, 0.3229],
        [0.7042, 0.2958],
        [0.6979, 0.3021],
        [0.6755, 0.3245],
        [0.6993, 0.3007],
        [0.6995, 0.3005],
        [0.6638, 0.3362],
        [0.6660, 0.3340],
        [0.7174, 0.2826],
        [0.6316, 0.3684],
        [0.6808, 0.3192],
        [0.6764, 0.3236],
        [0.6482, 0.3518],
        [0.6561, 0.3439],
        [0.7140, 0.2860],
        [0.7242, 0.2758],
        [0.6815, 0.3185],
        [0.7258, 0.2742],
        [0.6995, 0.3005],
        [0.6781, 0.3219],
        [0.6738, 0.3262],
        [0.7036, 0.2964],
        [0.6283, 0.3717],
        [0.6830, 0.3170],
        [0.7086, 0.2914],
        [0.6691, 0.3309],
        [0.6672, 0.3328],
        [0.7030, 0.2970],
        [0.6969, 0.3031],
        [0.6942, 0.3058],
        [0.7394, 0.2606],
        [0.7107, 0.2893],
        [0.6643, 0.3357],
        [0.6913, 0.3087],
        [0.6516, 0.3484],
        [0.6739, 0.3261],
        [0.7040, 0.2960],
        [0.6394, 0.3606],
        [0.6691, 0.3309],
        [0.6798, 0.3202],
        [0.7207, 0.2793],
        [0.6794, 0.3206]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0012 loss: 0.6525 acc_train: 0.6103 time: 0.1253s
tensor([[0.6618, 0.3382],
        [0.7210, 0.2790],
        [0.6736, 0.3264],
        [0.6774, 0.3226],
        [0.7151, 0.2849],
        [0.6639, 0.3361],
        [0.6047, 0.3953],
        [0.7005, 0.2995],
        [0.6831, 0.3169],
        [0.6222, 0.3778],
        [0.6895, 0.3105],
        [0.6416, 0.3584],
        [0.6382, 0.3618],
        [0.6163, 0.3837],
        [0.6930, 0.3070],
        [0.6406, 0.3594],
        [0.7322, 0.2678],
        [0.6643, 0.3357],
        [0.7068, 0.2932],
        [0.6231, 0.3769],
        [0.7047, 0.2953],
        [0.6440, 0.3560],
        [0.7210, 0.2790],
        [0.6817, 0.3183],
        [0.6843, 0.3157],
        [0.6400, 0.3600],
        [0.6771, 0.3229],
        [0.6897, 0.3103],
        [0.6402, 0.3598],
        [0.6368, 0.3632],
        [0.6805, 0.3195],
        [0.6311, 0.3689],
        [0.6476, 0.3524],
        [0.6351, 0.3649],
        [0.7233, 0.2767],
        [0.6649, 0.3351],
        [0.6436, 0.3564],
        [0.6749, 0.3251],
        [0.6784, 0.3216],
        [0.6358, 0.3642],
        [0.6863, 0.3137],
        [0.6650, 0.3350],
        [0.6354, 0.3646],
        [0.7070, 0.2930],
        [0.7303, 0.2697],
        [0.6527, 0.3473],
        [0.7150, 0.2850],
        [0.7077, 0.2923],
        [0.6746, 0.3254],
        [0.6314, 0.3686],
        [0.6866, 0.3134],
        [0.6747, 0.3253],
        [0.6240, 0.3760],
        [0.7266, 0.2734],
        [0.7010, 0.2990],
        [0.6988, 0.3012],
        [0.7161, 0.2839],
        [0.6577, 0.3423],
        [0.6579, 0.3421],
        [0.6315, 0.3685],
        [0.6019, 0.3981],
        [0.6425, 0.3575],
        [0.6905, 0.3095],
        [0.6801, 0.3199],
        [0.6647, 0.3353],
        [0.6833, 0.3167],
        [0.6764, 0.3236],
        [0.6579, 0.3421],
        [0.6942, 0.3058],
        [0.6590, 0.3410],
        [0.6410, 0.3590],
        [0.6093, 0.3907],
        [0.6530, 0.3470],
        [0.6931, 0.3069],
        [0.6682, 0.3318],
        [0.6567, 0.3433],
        [0.6738, 0.3262],
        [0.6431, 0.3569],
        [0.6896, 0.3104],
        [0.6308, 0.3692],
        [0.5963, 0.4037],
        [0.6315, 0.3685],
        [0.6321, 0.3679],
        [0.6421, 0.3579],
        [0.6667, 0.3333],
        [0.6422, 0.3578],
        [0.6925, 0.3075],
        [0.6892, 0.3108],
        [0.6952, 0.3048],
        [0.6392, 0.3608],
        [0.6576, 0.3424],
        [0.6557, 0.3443],
        [0.6808, 0.3192],
        [0.5953, 0.4047],
        [0.6724, 0.3276],
        [0.7217, 0.2783],
        [0.6903, 0.3097],
        [0.6402, 0.3598],
        [0.7288, 0.2712],
        [0.6524, 0.3476],
        [0.7166, 0.2834],
        [0.6409, 0.3591],
        [0.6351, 0.3649],
        [0.6451, 0.3549],
        [0.7421, 0.2579],
        [0.6591, 0.3409],
        [0.7000, 0.3000],
        [0.7328, 0.2672],
        [0.6237, 0.3763],
        [0.6836, 0.3164],
        [0.6582, 0.3418],
        [0.7245, 0.2755],
        [0.7119, 0.2881],
        [0.7212, 0.2788],
        [0.6631, 0.3369],
        [0.6725, 0.3275],
        [0.6590, 0.3410],
        [0.7049, 0.2951],
        [0.7274, 0.2726],
        [0.7113, 0.2887],
        [0.6410, 0.3590],
        [0.6652, 0.3348],
        [0.6591, 0.3409],
        [0.6580, 0.3420],
        [0.6364, 0.3636],
        [0.6684, 0.3316],
        [0.6326, 0.3674],
        [0.6574, 0.3426],
        [0.6395, 0.3605],
        [0.6460, 0.3540],
        [0.6754, 0.3246],
        [0.6523, 0.3477],
        [0.6935, 0.3065],
        [0.6611, 0.3389],
        [0.7119, 0.2881],
        [0.6703, 0.3297],
        [0.6368, 0.3632],
        [0.7056, 0.2944],
        [0.6905, 0.3095],
        [0.6558, 0.3442],
        [0.6427, 0.3573],
        [0.6793, 0.3207],
        [0.6403, 0.3597],
        [0.6666, 0.3334],
        [0.5683, 0.4317],
        [0.6576, 0.3424],
        [0.6721, 0.3279],
        [0.6423, 0.3577],
        [0.7140, 0.2860],
        [0.6821, 0.3179],
        [0.6283, 0.3717],
        [0.6997, 0.3003],
        [0.6992, 0.3008],
        [0.7419, 0.2581],
        [0.7374, 0.2626],
        [0.6720, 0.3280],
        [0.6986, 0.3014],
        [0.7138, 0.2862],
        [0.6467, 0.3533],
        [0.7032, 0.2968],
        [0.6897, 0.3103],
        [0.6827, 0.3173],
        [0.6420, 0.3580],
        [0.6608, 0.3392],
        [0.6570, 0.3430],
        [0.6414, 0.3586],
        [0.6921, 0.3079],
        [0.6542, 0.3458],
        [0.6778, 0.3222],
        [0.6335, 0.3665],
        [0.6575, 0.3425],
        [0.6621, 0.3379],
        [0.6766, 0.3234],
        [0.6610, 0.3390],
        [0.6945, 0.3055],
        [0.6628, 0.3372],
        [0.7160, 0.2840],
        [0.6659, 0.3341],
        [0.6041, 0.3959],
        [0.7029, 0.2971],
        [0.6556, 0.3444],
        [0.6153, 0.3847],
        [0.6511, 0.3489],
        [0.6159, 0.3841],
        [0.6975, 0.3025],
        [0.7017, 0.2983],
        [0.5966, 0.4034],
        [0.6869, 0.3131],
        [0.6211, 0.3789],
        [0.6611, 0.3389],
        [0.7053, 0.2947],
        [0.6593, 0.3407],
        [0.6464, 0.3536],
        [0.6000, 0.4000],
        [0.7081, 0.2919],
        [0.6775, 0.3225],
        [0.7176, 0.2824],
        [0.5982, 0.4018],
        [0.6931, 0.3069],
        [0.7253, 0.2747],
        [0.6626, 0.3374],
        [0.6881, 0.3119],
        [0.7123, 0.2877],
        [0.6165, 0.3835],
        [0.6757, 0.3243],
        [0.6732, 0.3268],
        [0.7230, 0.2770],
        [0.7164, 0.2836],
        [0.6230, 0.3770],
        [0.6436, 0.3564],
        [0.6715, 0.3285],
        [0.6618, 0.3382],
        [0.7255, 0.2745],
        [0.6649, 0.3351],
        [0.6890, 0.3110],
        [0.6989, 0.3011],
        [0.6444, 0.3556],
        [0.6620, 0.3380],
        [0.7200, 0.2800],
        [0.6796, 0.3204],
        [0.6448, 0.3552],
        [0.7438, 0.2562],
        [0.6664, 0.3336],
        [0.6828, 0.3172],
        [0.7048, 0.2952],
        [0.6822, 0.3178],
        [0.6718, 0.3282],
        [0.6709, 0.3291],
        [0.6409, 0.3591],
        [0.6854, 0.3146],
        [0.6791, 0.3209],
        [0.7060, 0.2940],
        [0.7007, 0.2993],
        [0.6762, 0.3238],
        [0.6991, 0.3009],
        [0.7008, 0.2992],
        [0.6664, 0.3336],
        [0.6695, 0.3305],
        [0.7171, 0.2829],
        [0.6334, 0.3666],
        [0.6815, 0.3185],
        [0.6789, 0.3211],
        [0.6536, 0.3464],
        [0.6580, 0.3420],
        [0.7127, 0.2873],
        [0.7236, 0.2764],
        [0.6825, 0.3175],
        [0.7247, 0.2753],
        [0.7002, 0.2998],
        [0.6796, 0.3204],
        [0.6750, 0.3250],
        [0.7027, 0.2973],
        [0.6325, 0.3675],
        [0.6838, 0.3162],
        [0.7095, 0.2905],
        [0.6707, 0.3293],
        [0.6696, 0.3304],
        [0.7019, 0.2981],
        [0.6990, 0.3010],
        [0.6960, 0.3040],
        [0.7379, 0.2621],
        [0.7101, 0.2899],
        [0.6663, 0.3337],
        [0.6920, 0.3080],
        [0.6554, 0.3446],
        [0.6771, 0.3229],
        [0.7047, 0.2953],
        [0.6431, 0.3569],
        [0.6729, 0.3271],
        [0.6818, 0.3182],
        [0.7220, 0.2780],
        [0.6808, 0.3192]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0013 loss: 0.6532 acc_train: 0.6103 time: 0.1219s
tensor([[0.6612, 0.3388],
        [0.7170, 0.2830],
        [0.6722, 0.3278],
        [0.6769, 0.3231],
        [0.7123, 0.2877],
        [0.6650, 0.3350],
        [0.6079, 0.3921],
        [0.6990, 0.3010],
        [0.6813, 0.3187],
        [0.6258, 0.3742],
        [0.6859, 0.3141],
        [0.6456, 0.3544],
        [0.6401, 0.3599],
        [0.6184, 0.3816],
        [0.6910, 0.3090],
        [0.6430, 0.3570],
        [0.7287, 0.2713],
        [0.6647, 0.3353],
        [0.7050, 0.2950],
        [0.6261, 0.3739],
        [0.7018, 0.2982],
        [0.6463, 0.3537],
        [0.7181, 0.2819],
        [0.6798, 0.3202],
        [0.6827, 0.3173],
        [0.6417, 0.3583],
        [0.6758, 0.3242],
        [0.6873, 0.3127],
        [0.6430, 0.3570],
        [0.6392, 0.3608],
        [0.6803, 0.3197],
        [0.6326, 0.3674],
        [0.6458, 0.3542],
        [0.6376, 0.3624],
        [0.7203, 0.2797],
        [0.6651, 0.3349],
        [0.6444, 0.3556],
        [0.6746, 0.3254],
        [0.6795, 0.3205],
        [0.6380, 0.3620],
        [0.6871, 0.3129],
        [0.6646, 0.3354],
        [0.6369, 0.3631],
        [0.7054, 0.2946],
        [0.7274, 0.2726],
        [0.6540, 0.3460],
        [0.7126, 0.2874],
        [0.7039, 0.2961],
        [0.6753, 0.3247],
        [0.6320, 0.3680],
        [0.6833, 0.3167],
        [0.6732, 0.3268],
        [0.6260, 0.3740],
        [0.7223, 0.2777],
        [0.6984, 0.3016],
        [0.6961, 0.3039],
        [0.7136, 0.2864],
        [0.6573, 0.3427],
        [0.6581, 0.3419],
        [0.6357, 0.3643],
        [0.6065, 0.3935],
        [0.6442, 0.3558],
        [0.6898, 0.3102],
        [0.6802, 0.3198],
        [0.6656, 0.3344],
        [0.6809, 0.3191],
        [0.6751, 0.3249],
        [0.6594, 0.3406],
        [0.6916, 0.3084],
        [0.6591, 0.3409],
        [0.6443, 0.3557],
        [0.6135, 0.3865],
        [0.6547, 0.3453],
        [0.6914, 0.3086],
        [0.6678, 0.3322],
        [0.6567, 0.3433],
        [0.6734, 0.3266],
        [0.6460, 0.3540],
        [0.6872, 0.3128],
        [0.6340, 0.3660],
        [0.6026, 0.3974],
        [0.6342, 0.3658],
        [0.6328, 0.3672],
        [0.6432, 0.3568],
        [0.6679, 0.3321],
        [0.6458, 0.3542],
        [0.6909, 0.3091],
        [0.6878, 0.3122],
        [0.6943, 0.3057],
        [0.6417, 0.3583],
        [0.6577, 0.3423],
        [0.6569, 0.3431],
        [0.6797, 0.3203],
        [0.5995, 0.4005],
        [0.6737, 0.3263],
        [0.7173, 0.2827],
        [0.6884, 0.3116],
        [0.6427, 0.3573],
        [0.7244, 0.2756],
        [0.6520, 0.3480],
        [0.7128, 0.2872],
        [0.6427, 0.3573],
        [0.6371, 0.3629],
        [0.6461, 0.3539],
        [0.7379, 0.2621],
        [0.6613, 0.3387],
        [0.6972, 0.3028],
        [0.7285, 0.2715],
        [0.6273, 0.3727],
        [0.6821, 0.3179],
        [0.6586, 0.3414],
        [0.7202, 0.2798],
        [0.7106, 0.2894],
        [0.7185, 0.2815],
        [0.6643, 0.3357],
        [0.6715, 0.3285],
        [0.6584, 0.3416],
        [0.7032, 0.2968],
        [0.7231, 0.2769],
        [0.7082, 0.2918],
        [0.6421, 0.3579],
        [0.6641, 0.3359],
        [0.6589, 0.3411],
        [0.6592, 0.3408],
        [0.6382, 0.3618],
        [0.6688, 0.3312],
        [0.6338, 0.3662],
        [0.6593, 0.3407],
        [0.6437, 0.3563],
        [0.6472, 0.3528],
        [0.6738, 0.3262],
        [0.6530, 0.3470],
        [0.6920, 0.3080],
        [0.6620, 0.3380],
        [0.7093, 0.2907],
        [0.6712, 0.3288],
        [0.6378, 0.3622],
        [0.7037, 0.2963],
        [0.6881, 0.3119],
        [0.6561, 0.3439],
        [0.6439, 0.3561],
        [0.6774, 0.3226],
        [0.6430, 0.3570],
        [0.6664, 0.3336],
        [0.5727, 0.4273],
        [0.6588, 0.3412],
        [0.6720, 0.3280],
        [0.6430, 0.3570],
        [0.7100, 0.2900],
        [0.6817, 0.3183],
        [0.6301, 0.3699],
        [0.6976, 0.3024],
        [0.6978, 0.3022],
        [0.7365, 0.2635],
        [0.7321, 0.2679],
        [0.6723, 0.3277],
        [0.6954, 0.3046],
        [0.7113, 0.2887],
        [0.6488, 0.3512],
        [0.7012, 0.2988],
        [0.6880, 0.3120],
        [0.6813, 0.3187],
        [0.6444, 0.3556],
        [0.6617, 0.3383],
        [0.6582, 0.3418],
        [0.6425, 0.3575],
        [0.6910, 0.3090],
        [0.6556, 0.3444],
        [0.6778, 0.3222],
        [0.6350, 0.3650],
        [0.6585, 0.3415],
        [0.6625, 0.3375],
        [0.6760, 0.3240],
        [0.6601, 0.3399],
        [0.6940, 0.3060],
        [0.6629, 0.3371],
        [0.7129, 0.2871],
        [0.6677, 0.3323],
        [0.6083, 0.3917],
        [0.7004, 0.2996],
        [0.6543, 0.3457],
        [0.6209, 0.3791],
        [0.6532, 0.3468],
        [0.6183, 0.3817],
        [0.6954, 0.3046],
        [0.7000, 0.3000],
        [0.6011, 0.3989],
        [0.6857, 0.3143],
        [0.6253, 0.3747],
        [0.6628, 0.3372],
        [0.7033, 0.2967],
        [0.6605, 0.3395],
        [0.6479, 0.3521],
        [0.6051, 0.3949],
        [0.7048, 0.2952],
        [0.6767, 0.3233],
        [0.7148, 0.2852],
        [0.6016, 0.3984],
        [0.6904, 0.3096],
        [0.7219, 0.2781],
        [0.6606, 0.3394],
        [0.6854, 0.3146],
        [0.7098, 0.2902],
        [0.6198, 0.3802],
        [0.6747, 0.3253],
        [0.6726, 0.3274],
        [0.7199, 0.2801],
        [0.7121, 0.2879],
        [0.6268, 0.3732],
        [0.6474, 0.3526],
        [0.6708, 0.3292],
        [0.6621, 0.3379],
        [0.7217, 0.2783],
        [0.6648, 0.3352],
        [0.6891, 0.3109],
        [0.6959, 0.3041],
        [0.6473, 0.3527],
        [0.6603, 0.3397],
        [0.7172, 0.2828],
        [0.6780, 0.3220],
        [0.6477, 0.3523],
        [0.7398, 0.2602],
        [0.6684, 0.3316],
        [0.6815, 0.3185],
        [0.7022, 0.2978],
        [0.6800, 0.3200],
        [0.6708, 0.3292],
        [0.6698, 0.3302],
        [0.6428, 0.3572],
        [0.6849, 0.3151],
        [0.6782, 0.3218],
        [0.7045, 0.2955],
        [0.7004, 0.2996],
        [0.6750, 0.3250],
        [0.6966, 0.3034],
        [0.6994, 0.3006],
        [0.6654, 0.3346],
        [0.6702, 0.3298],
        [0.7139, 0.2861],
        [0.6338, 0.3662],
        [0.6799, 0.3201],
        [0.6781, 0.3219],
        [0.6559, 0.3441],
        [0.6575, 0.3425],
        [0.7085, 0.2915],
        [0.7199, 0.2801],
        [0.6811, 0.3189],
        [0.7204, 0.2796],
        [0.6986, 0.3014],
        [0.6789, 0.3211],
        [0.6734, 0.3266],
        [0.6991, 0.3009],
        [0.6348, 0.3652],
        [0.6819, 0.3181],
        [0.7073, 0.2927],
        [0.6692, 0.3308],
        [0.6693, 0.3307],
        [0.6980, 0.3020],
        [0.6977, 0.3023],
        [0.6941, 0.3059],
        [0.7332, 0.2668],
        [0.7062, 0.2938],
        [0.6666, 0.3334],
        [0.6908, 0.3092],
        [0.6561, 0.3439],
        [0.6767, 0.3233],
        [0.7029, 0.2971],
        [0.6445, 0.3555],
        [0.6735, 0.3265],
        [0.6818, 0.3182],
        [0.7191, 0.2809],
        [0.6797, 0.3203]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0014 loss: 0.6543 acc_train: 0.6103 time: 0.1231s
tensor([[0.6590, 0.3410],
        [0.7113, 0.2887],
        [0.6693, 0.3307],
        [0.6742, 0.3258],
        [0.7069, 0.2931],
        [0.6641, 0.3359],
        [0.6104, 0.3896],
        [0.6948, 0.3052],
        [0.6784, 0.3216],
        [0.6285, 0.3715],
        [0.6806, 0.3194],
        [0.6480, 0.3520],
        [0.6407, 0.3593],
        [0.6191, 0.3809],
        [0.6867, 0.3133],
        [0.6432, 0.3568],
        [0.7231, 0.2769],
        [0.6632, 0.3368],
        [0.7004, 0.2996],
        [0.6281, 0.3719],
        [0.6970, 0.3030],
        [0.6466, 0.3534],
        [0.7127, 0.2873],
        [0.6773, 0.3227],
        [0.6790, 0.3210],
        [0.6424, 0.3576],
        [0.6726, 0.3274],
        [0.6837, 0.3163],
        [0.6440, 0.3560],
        [0.6398, 0.3602],
        [0.6780, 0.3220],
        [0.6328, 0.3672],
        [0.6427, 0.3573],
        [0.6387, 0.3613],
        [0.7143, 0.2857],
        [0.6636, 0.3364],
        [0.6440, 0.3560],
        [0.6716, 0.3284],
        [0.6781, 0.3219],
        [0.6388, 0.3612],
        [0.6858, 0.3142],
        [0.6623, 0.3377],
        [0.6360, 0.3640],
        [0.7010, 0.2990],
        [0.7219, 0.2781],
        [0.6531, 0.3469],
        [0.7077, 0.2923],
        [0.6978, 0.3022],
        [0.6737, 0.3263],
        [0.6307, 0.3693],
        [0.6774, 0.3226],
        [0.6704, 0.3296],
        [0.6269, 0.3731],
        [0.7156, 0.2844],
        [0.6938, 0.3062],
        [0.6916, 0.3084],
        [0.7081, 0.2919],
        [0.6551, 0.3449],
        [0.6563, 0.3437],
        [0.6382, 0.3618],
        [0.6106, 0.3894],
        [0.6440, 0.3560],
        [0.6867, 0.3133],
        [0.6785, 0.3215],
        [0.6651, 0.3349],
        [0.6771, 0.3229],
        [0.6721, 0.3279],
        [0.6595, 0.3405],
        [0.6865, 0.3135],
        [0.6580, 0.3420],
        [0.6458, 0.3542],
        [0.6156, 0.3844],
        [0.6546, 0.3454],
        [0.6875, 0.3125],
        [0.6656, 0.3344],
        [0.6551, 0.3449],
        [0.6709, 0.3291],
        [0.6469, 0.3531],
        [0.6830, 0.3170],
        [0.6355, 0.3645],
        [0.6079, 0.3921],
        [0.6354, 0.3646],
        [0.6323, 0.3677],
        [0.6432, 0.3568],
        [0.6668, 0.3332],
        [0.6475, 0.3525],
        [0.6873, 0.3127],
        [0.6838, 0.3162],
        [0.6909, 0.3091],
        [0.6424, 0.3576],
        [0.6556, 0.3444],
        [0.6563, 0.3437],
        [0.6765, 0.3235],
        [0.6035, 0.3965],
        [0.6722, 0.3278],
        [0.7114, 0.2886],
        [0.6844, 0.3156],
        [0.6435, 0.3565],
        [0.7178, 0.2822],
        [0.6501, 0.3499],
        [0.7067, 0.2933],
        [0.6430, 0.3570],
        [0.6372, 0.3628],
        [0.6451, 0.3549],
        [0.7313, 0.2687],
        [0.6612, 0.3388],
        [0.6922, 0.3078],
        [0.7212, 0.2788],
        [0.6291, 0.3709],
        [0.6794, 0.3206],
        [0.6566, 0.3434],
        [0.7138, 0.2862],
        [0.7064, 0.2936],
        [0.7133, 0.2867],
        [0.6630, 0.3370],
        [0.6684, 0.3316],
        [0.6565, 0.3435],
        [0.6988, 0.3012],
        [0.7159, 0.2841],
        [0.7023, 0.2977],
        [0.6413, 0.3587],
        [0.6616, 0.3384],
        [0.6567, 0.3433],
        [0.6581, 0.3419],
        [0.6384, 0.3616],
        [0.6670, 0.3330],
        [0.6329, 0.3671],
        [0.6595, 0.3405],
        [0.6461, 0.3539],
        [0.6457, 0.3543],
        [0.6707, 0.3293],
        [0.6518, 0.3482],
        [0.6884, 0.3116],
        [0.6610, 0.3390],
        [0.7042, 0.2958],
        [0.6701, 0.3299],
        [0.6380, 0.3620],
        [0.6993, 0.3007],
        [0.6839, 0.3161],
        [0.6544, 0.3456],
        [0.6436, 0.3564],
        [0.6749, 0.3251],
        [0.6444, 0.3556],
        [0.6641, 0.3359],
        [0.5773, 0.4227],
        [0.6590, 0.3410],
        [0.6703, 0.3297],
        [0.6430, 0.3570],
        [0.7041, 0.2959],
        [0.6795, 0.3205],
        [0.6307, 0.3693],
        [0.6934, 0.3066],
        [0.6948, 0.3052],
        [0.7285, 0.2715],
        [0.7242, 0.2758],
        [0.6715, 0.3285],
        [0.6905, 0.3095],
        [0.7060, 0.2940],
        [0.6495, 0.3505],
        [0.6969, 0.3031],
        [0.6843, 0.3157],
        [0.6787, 0.3213],
        [0.6453, 0.3547],
        [0.6603, 0.3397],
        [0.6573, 0.3427],
        [0.6414, 0.3586],
        [0.6874, 0.3126],
        [0.6553, 0.3447],
        [0.6760, 0.3240],
        [0.6354, 0.3646],
        [0.6566, 0.3434],
        [0.6608, 0.3392],
        [0.6725, 0.3275],
        [0.6584, 0.3416],
        [0.6911, 0.3089],
        [0.6612, 0.3388],
        [0.7072, 0.2928],
        [0.6675, 0.3325],
        [0.6111, 0.3889],
        [0.6965, 0.3035],
        [0.6518, 0.3482],
        [0.6241, 0.3759],
        [0.6535, 0.3465],
        [0.6193, 0.3807],
        [0.6910, 0.3090],
        [0.6955, 0.3045],
        [0.6038, 0.3962],
        [0.6816, 0.3184],
        [0.6275, 0.3725],
        [0.6620, 0.3380],
        [0.6993, 0.3007],
        [0.6591, 0.3409],
        [0.6483, 0.3517],
        [0.6086, 0.3914],
        [0.6985, 0.3015],
        [0.6735, 0.3265],
        [0.7095, 0.2905],
        [0.6042, 0.3958],
        [0.6857, 0.3143],
        [0.7169, 0.2831],
        [0.6571, 0.3429],
        [0.6812, 0.3188],
        [0.7041, 0.2959],
        [0.6213, 0.3787],
        [0.6725, 0.3275],
        [0.6697, 0.3303],
        [0.7149, 0.2851],
        [0.7057, 0.2943],
        [0.6289, 0.3711],
        [0.6491, 0.3509],
        [0.6686, 0.3314],
        [0.6604, 0.3396],
        [0.7155, 0.2845],
        [0.6622, 0.3378],
        [0.6872, 0.3128],
        [0.6907, 0.3093],
        [0.6482, 0.3518],
        [0.6573, 0.3427],
        [0.7125, 0.2875],
        [0.6746, 0.3254],
        [0.6489, 0.3511],
        [0.7329, 0.2671],
        [0.6679, 0.3321],
        [0.6787, 0.3213],
        [0.6971, 0.3029],
        [0.6762, 0.3238],
        [0.6669, 0.3331],
        [0.6671, 0.3329],
        [0.6433, 0.3567],
        [0.6824, 0.3176],
        [0.6753, 0.3247],
        [0.7004, 0.2996],
        [0.6973, 0.3027],
        [0.6721, 0.3279],
        [0.6922, 0.3078],
        [0.6959, 0.3041],
        [0.6620, 0.3380],
        [0.6684, 0.3316],
        [0.7086, 0.2914],
        [0.6333, 0.3667],
        [0.6763, 0.3237],
        [0.6743, 0.3257],
        [0.6560, 0.3440],
        [0.6553, 0.3447],
        [0.7018, 0.2982],
        [0.7140, 0.2860],
        [0.6780, 0.3220],
        [0.7135, 0.2865],
        [0.6952, 0.3048],
        [0.6762, 0.3238],
        [0.6696, 0.3304],
        [0.6932, 0.3068],
        [0.6354, 0.3646],
        [0.6784, 0.3216],
        [0.7028, 0.2972],
        [0.6658, 0.3342],
        [0.6671, 0.3329],
        [0.6923, 0.3077],
        [0.6937, 0.3063],
        [0.6898, 0.3102],
        [0.7257, 0.2743],
        [0.6998, 0.3002],
        [0.6652, 0.3348],
        [0.6884, 0.3116],
        [0.6548, 0.3452],
        [0.6737, 0.3263],
        [0.6991, 0.3009],
        [0.6440, 0.3560],
        [0.6714, 0.3286],
        [0.6805, 0.3195],
        [0.7133, 0.2867],
        [0.6765, 0.3235]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0015 loss: 0.6556 acc_train: 0.6103 time: 0.1225s
tensor([[0.6566, 0.3434],
        [0.7050, 0.2950],
        [0.6660, 0.3340],
        [0.6708, 0.3292],
        [0.7005, 0.2995],
        [0.6627, 0.3373],
        [0.6134, 0.3866],
        [0.6894, 0.3106],
        [0.6752, 0.3248],
        [0.6309, 0.3691],
        [0.6746, 0.3254],
        [0.6494, 0.3506],
        [0.6410, 0.3590],
        [0.6205, 0.3795],
        [0.6819, 0.3181],
        [0.6427, 0.3573],
        [0.7157, 0.2843],
        [0.6614, 0.3386],
        [0.6942, 0.3058],
        [0.6302, 0.3698],
        [0.6919, 0.3081],
        [0.6461, 0.3539],
        [0.7063, 0.2937],
        [0.6743, 0.3257],
        [0.6750, 0.3250],
        [0.6428, 0.3572],
        [0.6686, 0.3314],
        [0.6802, 0.3198],
        [0.6441, 0.3559],
        [0.6399, 0.3601],
        [0.6745, 0.3255],
        [0.6336, 0.3664],
        [0.6401, 0.3599],
        [0.6399, 0.3601],
        [0.7072, 0.2928],
        [0.6616, 0.3384],
        [0.6436, 0.3564],
        [0.6675, 0.3325],
        [0.6754, 0.3246],
        [0.6391, 0.3609],
        [0.6834, 0.3166],
        [0.6593, 0.3407],
        [0.6345, 0.3655],
        [0.6951, 0.3049],
        [0.7155, 0.2845],
        [0.6515, 0.3485],
        [0.7017, 0.2983],
        [0.6910, 0.3090],
        [0.6714, 0.3286],
        [0.6295, 0.3705],
        [0.6711, 0.3289],
        [0.6672, 0.3328],
        [0.6277, 0.3723],
        [0.7084, 0.2916],
        [0.6883, 0.3117],
        [0.6863, 0.3137],
        [0.7012, 0.2988],
        [0.6526, 0.3474],
        [0.6544, 0.3456],
        [0.6400, 0.3600],
        [0.6153, 0.3847],
        [0.6435, 0.3565],
        [0.6830, 0.3170],
        [0.6755, 0.3245],
        [0.6640, 0.3360],
        [0.6727, 0.3273],
        [0.6686, 0.3314],
        [0.6590, 0.3410],
        [0.6807, 0.3193],
        [0.6566, 0.3434],
        [0.6463, 0.3537],
        [0.6178, 0.3822],
        [0.6540, 0.3460],
        [0.6831, 0.3169],
        [0.6625, 0.3375],
        [0.6530, 0.3470],
        [0.6671, 0.3329],
        [0.6471, 0.3529],
        [0.6786, 0.3214],
        [0.6361, 0.3639],
        [0.6125, 0.3875],
        [0.6367, 0.3633],
        [0.6326, 0.3674],
        [0.6426, 0.3574],
        [0.6646, 0.3354],
        [0.6480, 0.3520],
        [0.6831, 0.3169],
        [0.6792, 0.3208],
        [0.6864, 0.3136],
        [0.6429, 0.3571],
        [0.6533, 0.3467],
        [0.6550, 0.3450],
        [0.6723, 0.3277],
        [0.6078, 0.3922],
        [0.6699, 0.3301],
        [0.7046, 0.2954],
        [0.6794, 0.3206],
        [0.6441, 0.3559],
        [0.7104, 0.2896],
        [0.6482, 0.3518],
        [0.6998, 0.3002],
        [0.6428, 0.3572],
        [0.6373, 0.3627],
        [0.6441, 0.3559],
        [0.7237, 0.2763],
        [0.6599, 0.3401],
        [0.6868, 0.3132],
        [0.7124, 0.2876],
        [0.6306, 0.3694],
        [0.6766, 0.3234],
        [0.6536, 0.3464],
        [0.7066, 0.2934],
        [0.7006, 0.2994],
        [0.7065, 0.2935],
        [0.6606, 0.3394],
        [0.6643, 0.3357],
        [0.6544, 0.3456],
        [0.6932, 0.3068],
        [0.7075, 0.2925],
        [0.6958, 0.3042],
        [0.6397, 0.3603],
        [0.6588, 0.3412],
        [0.6543, 0.3457],
        [0.6555, 0.3445],
        [0.6382, 0.3618],
        [0.6640, 0.3360],
        [0.6317, 0.3683],
        [0.6588, 0.3412],
        [0.6472, 0.3528],
        [0.6434, 0.3566],
        [0.6670, 0.3330],
        [0.6503, 0.3497],
        [0.6838, 0.3162],
        [0.6589, 0.3411],
        [0.6978, 0.3022],
        [0.6682, 0.3318],
        [0.6383, 0.3617],
        [0.6935, 0.3065],
        [0.6792, 0.3208],
        [0.6521, 0.3479],
        [0.6434, 0.3566],
        [0.6719, 0.3281],
        [0.6453, 0.3547],
        [0.6615, 0.3385],
        [0.5832, 0.4168],
        [0.6585, 0.3415],
        [0.6685, 0.3315],
        [0.6430, 0.3570],
        [0.6974, 0.3026],
        [0.6766, 0.3234],
        [0.6317, 0.3683],
        [0.6884, 0.3116],
        [0.6911, 0.3089],
        [0.7193, 0.2807],
        [0.7152, 0.2848],
        [0.6702, 0.3298],
        [0.6852, 0.3148],
        [0.6994, 0.3006],
        [0.6500, 0.3500],
        [0.6910, 0.3090],
        [0.6798, 0.3202],
        [0.6758, 0.3242],
        [0.6459, 0.3541],
        [0.6582, 0.3418],
        [0.6556, 0.3444],
        [0.6399, 0.3601],
        [0.6830, 0.3170],
        [0.6543, 0.3457],
        [0.6733, 0.3267],
        [0.6360, 0.3640],
        [0.6540, 0.3460],
        [0.6580, 0.3420],
        [0.6682, 0.3318],
        [0.6564, 0.3436],
        [0.6868, 0.3132],
        [0.6592, 0.3408],
        [0.7003, 0.2997],
        [0.6662, 0.3338],
        [0.6138, 0.3862],
        [0.6917, 0.3083],
        [0.6495, 0.3505],
        [0.6271, 0.3729],
        [0.6529, 0.3471],
        [0.6203, 0.3797],
        [0.6859, 0.3141],
        [0.6903, 0.3097],
        [0.6064, 0.3936],
        [0.6762, 0.3238],
        [0.6290, 0.3710],
        [0.6605, 0.3395],
        [0.6948, 0.3052],
        [0.6569, 0.3431],
        [0.6479, 0.3521],
        [0.6119, 0.3881],
        [0.6913, 0.3087],
        [0.6700, 0.3300],
        [0.7033, 0.2967],
        [0.6070, 0.3930],
        [0.6804, 0.3196],
        [0.7107, 0.2893],
        [0.6540, 0.3460],
        [0.6769, 0.3231],
        [0.6976, 0.3024],
        [0.6226, 0.3774],
        [0.6694, 0.3306],
        [0.6666, 0.3334],
        [0.7086, 0.2914],
        [0.6988, 0.3012],
        [0.6310, 0.3690],
        [0.6500, 0.3500],
        [0.6658, 0.3342],
        [0.6576, 0.3424],
        [0.7083, 0.2917],
        [0.6588, 0.3412],
        [0.6841, 0.3159],
        [0.6847, 0.3153],
        [0.6480, 0.3520],
        [0.6544, 0.3456],
        [0.7066, 0.2934],
        [0.6711, 0.3289],
        [0.6491, 0.3509],
        [0.7242, 0.2758],
        [0.6660, 0.3340],
        [0.6754, 0.3246],
        [0.6912, 0.3088],
        [0.6718, 0.3282],
        [0.6620, 0.3380],
        [0.6640, 0.3360],
        [0.6435, 0.3565],
        [0.6795, 0.3205],
        [0.6718, 0.3282],
        [0.6945, 0.3055],
        [0.6927, 0.3073],
        [0.6689, 0.3311],
        [0.6869, 0.3131],
        [0.6911, 0.3089],
        [0.6579, 0.3421],
        [0.6658, 0.3342],
        [0.7025, 0.2975],
        [0.6330, 0.3670],
        [0.6722, 0.3278],
        [0.6698, 0.3302],
        [0.6550, 0.3450],
        [0.6527, 0.3473],
        [0.6943, 0.3057],
        [0.7071, 0.2929],
        [0.6750, 0.3250],
        [0.7056, 0.2944],
        [0.6913, 0.3087],
        [0.6726, 0.3274],
        [0.6650, 0.3350],
        [0.6867, 0.3133],
        [0.6359, 0.3641],
        [0.6751, 0.3249],
        [0.6973, 0.3027],
        [0.6622, 0.3378],
        [0.6644, 0.3356],
        [0.6859, 0.3141],
        [0.6889, 0.3111],
        [0.6843, 0.3157],
        [0.7171, 0.2829],
        [0.6927, 0.3073],
        [0.6632, 0.3368],
        [0.6853, 0.3147],
        [0.6529, 0.3471],
        [0.6699, 0.3301],
        [0.6943, 0.3057],
        [0.6433, 0.3567],
        [0.6689, 0.3311],
        [0.6786, 0.3214],
        [0.7061, 0.2939],
        [0.6725, 0.3275]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0016 loss: 0.6571 acc_train: 0.6103 time: 0.1487s
tensor([[0.6541, 0.3459],
        [0.6982, 0.3018],
        [0.6629, 0.3371],
        [0.6668, 0.3332],
        [0.6933, 0.3067],
        [0.6602, 0.3398],
        [0.6162, 0.3838],
        [0.6831, 0.3169],
        [0.6715, 0.3285],
        [0.6326, 0.3674],
        [0.6685, 0.3315],
        [0.6499, 0.3501],
        [0.6411, 0.3589],
        [0.6221, 0.3779],
        [0.6764, 0.3236],
        [0.6417, 0.3583],
        [0.7072, 0.2928],
        [0.6590, 0.3410],
        [0.6869, 0.3131],
        [0.6322, 0.3678],
        [0.6865, 0.3135],
        [0.6451, 0.3549],
        [0.6991, 0.3009],
        [0.6710, 0.3290],
        [0.6704, 0.3296],
        [0.6430, 0.3570],
        [0.6649, 0.3351],
        [0.6767, 0.3233],
        [0.6436, 0.3564],
        [0.6398, 0.3602],
        [0.6702, 0.3298],
        [0.6342, 0.3658],
        [0.6384, 0.3616],
        [0.6407, 0.3593],
        [0.6996, 0.3004],
        [0.6589, 0.3411],
        [0.6433, 0.3567],
        [0.6631, 0.3369],
        [0.6722, 0.3278],
        [0.6387, 0.3613],
        [0.6802, 0.3198],
        [0.6560, 0.3440],
        [0.6330, 0.3670],
        [0.6881, 0.3119],
        [0.7078, 0.2922],
        [0.6498, 0.3502],
        [0.6946, 0.3054],
        [0.6843, 0.3157],
        [0.6687, 0.3313],
        [0.6287, 0.3713],
        [0.6647, 0.3353],
        [0.6635, 0.3365],
        [0.6290, 0.3710],
        [0.7009, 0.2991],
        [0.6821, 0.3179],
        [0.6805, 0.3195],
        [0.6939, 0.3061],
        [0.6501, 0.3499],
        [0.6525, 0.3475],
        [0.6410, 0.3590],
        [0.6195, 0.3805],
        [0.6427, 0.3573],
        [0.6791, 0.3209],
        [0.6715, 0.3285],
        [0.6621, 0.3379],
        [0.6681, 0.3319],
        [0.6648, 0.3352],
        [0.6576, 0.3424],
        [0.6742, 0.3258],
        [0.6548, 0.3452],
        [0.6458, 0.3542],
        [0.6198, 0.3802],
        [0.6532, 0.3468],
        [0.6784, 0.3216],
        [0.6591, 0.3409],
        [0.6507, 0.3493],
        [0.6624, 0.3376],
        [0.6469, 0.3531],
        [0.6742, 0.3258],
        [0.6364, 0.3636],
        [0.6165, 0.3835],
        [0.6372, 0.3628],
        [0.6330, 0.3670],
        [0.6414, 0.3586],
        [0.6614, 0.3386],
        [0.6478, 0.3522],
        [0.6783, 0.3217],
        [0.6741, 0.3259],
        [0.6808, 0.3192],
        [0.6429, 0.3571],
        [0.6510, 0.3490],
        [0.6531, 0.3469],
        [0.6679, 0.3321],
        [0.6118, 0.3882],
        [0.6664, 0.3336],
        [0.6969, 0.3031],
        [0.6739, 0.3261],
        [0.6441, 0.3559],
        [0.7024, 0.2976],
        [0.6463, 0.3537],
        [0.6926, 0.3074],
        [0.6421, 0.3579],
        [0.6372, 0.3628],
        [0.6429, 0.3571],
        [0.7152, 0.2848],
        [0.6568, 0.3432],
        [0.6818, 0.3182],
        [0.7026, 0.2974],
        [0.6320, 0.3680],
        [0.6735, 0.3265],
        [0.6498, 0.3502],
        [0.6987, 0.3013],
        [0.6936, 0.3064],
        [0.6986, 0.3014],
        [0.6580, 0.3420],
        [0.6594, 0.3406],
        [0.6521, 0.3479],
        [0.6870, 0.3130],
        [0.6987, 0.3013],
        [0.6892, 0.3108],
        [0.6381, 0.3619],
        [0.6563, 0.3437],
        [0.6521, 0.3479],
        [0.6526, 0.3474],
        [0.6380, 0.3620],
        [0.6601, 0.3398],
        [0.6308, 0.3692],
        [0.6574, 0.3426],
        [0.6469, 0.3531],
        [0.6412, 0.3588],
        [0.6629, 0.3371],
        [0.6487, 0.3513],
        [0.6785, 0.3215],
        [0.6558, 0.3442],
        [0.6903, 0.3097],
        [0.6655, 0.3345],
        [0.6385, 0.3615],
        [0.6873, 0.3127],
        [0.6738, 0.3262],
        [0.6495, 0.3505],
        [0.6424, 0.3576],
        [0.6688, 0.3312],
        [0.6459, 0.3541],
        [0.6579, 0.3421],
        [0.5894, 0.4106],
        [0.6573, 0.3427],
        [0.6665, 0.3335],
        [0.6427, 0.3573],
        [0.6903, 0.3097],
        [0.6733, 0.3267],
        [0.6324, 0.3676],
        [0.6826, 0.3174],
        [0.6864, 0.3136],
        [0.7098, 0.2902],
        [0.7053, 0.2947],
        [0.6681, 0.3319],
        [0.6796, 0.3204],
        [0.6922, 0.3078],
        [0.6500, 0.3500],
        [0.6844, 0.3156],
        [0.6745, 0.3255],
        [0.6723, 0.3277],
        [0.6453, 0.3547],
        [0.6557, 0.3443],
        [0.6530, 0.3470],
        [0.6383, 0.3617],
        [0.6780, 0.3220],
        [0.6531, 0.3469],
        [0.6692, 0.3308],
        [0.6365, 0.3635],
        [0.6508, 0.3492],
        [0.6548, 0.3452],
        [0.6637, 0.3363],
        [0.6544, 0.3456],
        [0.6813, 0.3187],
        [0.6572, 0.3428],
        [0.6932, 0.3068],
        [0.6637, 0.3363],
        [0.6164, 0.3836],
        [0.6864, 0.3136],
        [0.6476, 0.3524],
        [0.6293, 0.3707],
        [0.6516, 0.3484],
        [0.6214, 0.3786],
        [0.6806, 0.3194],
        [0.6842, 0.3158],
        [0.6090, 0.3910],
        [0.6707, 0.3293],
        [0.6308, 0.3692],
        [0.6579, 0.3421],
        [0.6896, 0.3104],
        [0.6541, 0.3459],
        [0.6471, 0.3529],
        [0.6150, 0.3850],
        [0.6838, 0.3162],
        [0.6663, 0.3337],
        [0.6962, 0.3038],
        [0.6100, 0.3900],
        [0.6751, 0.3249],
        [0.7037, 0.2963],
        [0.6511, 0.3489],
        [0.6729, 0.3271],
        [0.6902, 0.3098],
        [0.6233, 0.3767],
        [0.6662, 0.3338],
        [0.6629, 0.3371],
        [0.7011, 0.2989],
        [0.6920, 0.3080],
        [0.6323, 0.3677],
        [0.6495, 0.3505],
        [0.6629, 0.3371],
        [0.6544, 0.3456],
        [0.7005, 0.2995],
        [0.6552, 0.3448],
        [0.6798, 0.3202],
        [0.6786, 0.3214],
        [0.6468, 0.3532],
        [0.6514, 0.3486],
        [0.6994, 0.3006],
        [0.6676, 0.3324],
        [0.6483, 0.3517],
        [0.7143, 0.2857],
        [0.6634, 0.3366],
        [0.6717, 0.3283],
        [0.6850, 0.3150],
        [0.6672, 0.3328],
        [0.6561, 0.3439],
        [0.6608, 0.3392],
        [0.6436, 0.3564],
        [0.6758, 0.3242],
        [0.6678, 0.3322],
        [0.6880, 0.3120],
        [0.6873, 0.3127],
        [0.6656, 0.3344],
        [0.6814, 0.3186],
        [0.6852, 0.3148],
        [0.6542, 0.3458],
        [0.6630, 0.3370],
        [0.6957, 0.3043],
        [0.6329, 0.3671],
        [0.6678, 0.3322],
        [0.6654, 0.3346],
        [0.6534, 0.3466],
        [0.6503, 0.3497],
        [0.6865, 0.3135],
        [0.6995, 0.3005],
        [0.6714, 0.3286],
        [0.6974, 0.3026],
        [0.6870, 0.3130],
        [0.6683, 0.3317],
        [0.6603, 0.3397],
        [0.6804, 0.3196],
        [0.6358, 0.3642],
        [0.6718, 0.3282],
        [0.6912, 0.3088],
        [0.6582, 0.3418],
        [0.6611, 0.3389],
        [0.6796, 0.3204],
        [0.6831, 0.3169],
        [0.6783, 0.3217],
        [0.7085, 0.2915],
        [0.6853, 0.3147],
        [0.6606, 0.3394],
        [0.6813, 0.3187],
        [0.6503, 0.3497],
        [0.6654, 0.3346],
        [0.6885, 0.3115],
        [0.6426, 0.3574],
        [0.6656, 0.3344],
        [0.6759, 0.3241],
        [0.6982, 0.3018],
        [0.6681, 0.3319]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0017 loss: 0.6588 acc_train: 0.6103 time: 0.1199s
tensor([[0.6533, 0.3467],
        [0.6928, 0.3072],
        [0.6616, 0.3384],
        [0.6642, 0.3358],
        [0.6876, 0.3124],
        [0.6587, 0.3413],
        [0.6206, 0.3794],
        [0.6780, 0.3220],
        [0.6694, 0.3306],
        [0.6356, 0.3644],
        [0.6646, 0.3354],
        [0.6513, 0.3487],
        [0.6426, 0.3574],
        [0.6256, 0.3744],
        [0.6724, 0.3276],
        [0.6424, 0.3576],
        [0.7000, 0.3000],
        [0.6581, 0.3419],
        [0.6810, 0.3190],
        [0.6355, 0.3645],
        [0.6829, 0.3171],
        [0.6455, 0.3545],
        [0.6930, 0.3070],
        [0.6690, 0.3310],
        [0.6675, 0.3325],
        [0.6446, 0.3554],
        [0.6630, 0.3370],
        [0.6746, 0.3254],
        [0.6446, 0.3554],
        [0.6413, 0.3587],
        [0.6672, 0.3328],
        [0.6366, 0.3634],
        [0.6390, 0.3610],
        [0.6428, 0.3572],
        [0.6933, 0.3067],
        [0.6573, 0.3427],
        [0.6445, 0.3555],
        [0.6601, 0.3399],
        [0.6703, 0.3297],
        [0.6399, 0.3601],
        [0.6780, 0.3220],
        [0.6546, 0.3454],
        [0.6333, 0.3667],
        [0.6825, 0.3175],
        [0.7009, 0.2991],
        [0.6497, 0.3503],
        [0.6887, 0.3113],
        [0.6792, 0.3208],
        [0.6673, 0.3327],
        [0.6302, 0.3698],
        [0.6606, 0.3394],
        [0.6614, 0.3386],
        [0.6318, 0.3682],
        [0.6950, 0.3050],
        [0.6774, 0.3226],
        [0.6763, 0.3237],
        [0.6880, 0.3120],
        [0.6491, 0.3509],
        [0.6523, 0.3477],
        [0.6433, 0.3567],
        [0.6249, 0.3751],
        [0.6436, 0.3564],
        [0.6767, 0.3233],
        [0.6688, 0.3312],
        [0.6614, 0.3386],
        [0.6654, 0.3346],
        [0.6627, 0.3373],
        [0.6570, 0.3430],
        [0.6693, 0.3307],
        [0.6546, 0.3454],
        [0.6465, 0.3535],
        [0.6234, 0.3766],
        [0.6535, 0.3465],
        [0.6750, 0.3250],
        [0.6576, 0.3424],
        [0.6500, 0.3500],
        [0.6594, 0.3406],
        [0.6481, 0.3519],
        [0.6715, 0.3285],
        [0.6379, 0.3621],
        [0.6215, 0.3785],
        [0.6390, 0.3610],
        [0.6352, 0.3648],
        [0.6419, 0.3581],
        [0.6592, 0.3408],
        [0.6488, 0.3512],
        [0.6750, 0.3250],
        [0.6709, 0.3291],
        [0.6764, 0.3236],
        [0.6444, 0.3556],
        [0.6506, 0.3494],
        [0.6526, 0.3474],
        [0.6652, 0.3348],
        [0.6173, 0.3827],
        [0.6641, 0.3359],
        [0.6907, 0.3093],
        [0.6700, 0.3300],
        [0.6455, 0.3545],
        [0.6958, 0.3042],
        [0.6461, 0.3539],
        [0.6870, 0.3130],
        [0.6429, 0.3571],
        [0.6389, 0.3611],
        [0.6434, 0.3566],
        [0.7075, 0.2925],
        [0.6549, 0.3451],
        [0.6783, 0.3217],
        [0.6940, 0.3060],
        [0.6347, 0.3653],
        [0.6717, 0.3283],
        [0.6474, 0.3526],
        [0.6923, 0.3077],
        [0.6876, 0.3124],
        [0.6918, 0.3082],
        [0.6567, 0.3433],
        [0.6554, 0.3446],
        [0.6515, 0.3485],
        [0.6821, 0.3179],
        [0.6917, 0.3083],
        [0.6847, 0.3153],
        [0.6384, 0.3616],
        [0.6555, 0.3445],
        [0.6517, 0.3483],
        [0.6512, 0.3488],
        [0.6396, 0.3604],
        [0.6579, 0.3421],
        [0.6321, 0.3679],
        [0.6572, 0.3428],
        [0.6475, 0.3525],
        [0.6411, 0.3589],
        [0.6603, 0.3397],
        [0.6486, 0.3514],
        [0.6744, 0.3256],
        [0.6539, 0.3461],
        [0.6841, 0.3159],
        [0.6641, 0.3359],
        [0.6405, 0.3595],
        [0.6823, 0.3177],
        [0.6700, 0.3300],
        [0.6486, 0.3514],
        [0.6428, 0.3572],
        [0.6673, 0.3327],
        [0.6480, 0.3520],
        [0.6560, 0.3440],
        [0.5973, 0.4027],
        [0.6574, 0.3426],
        [0.6661, 0.3339],
        [0.6440, 0.3560],
        [0.6847, 0.3153],
        [0.6714, 0.3286],
        [0.6344, 0.3656],
        [0.6782, 0.3218],
        [0.6831, 0.3169],
        [0.7018, 0.2982],
        [0.6971, 0.3029],
        [0.6672, 0.3328],
        [0.6758, 0.3242],
        [0.6863, 0.3137],
        [0.6512, 0.3488],
        [0.6793, 0.3207],
        [0.6708, 0.3292],
        [0.6700, 0.3300],
        [0.6459, 0.3541],
        [0.6547, 0.3453],
        [0.6515, 0.3485],
        [0.6385, 0.3615],
        [0.6743, 0.3257],
        [0.6533, 0.3467],
        [0.6666, 0.3334],
        [0.6385, 0.3615],
        [0.6486, 0.3514],
        [0.6536, 0.3464],
        [0.6608, 0.3392],
        [0.6543, 0.3457],
        [0.6769, 0.3231],
        [0.6567, 0.3433],
        [0.6876, 0.3124],
        [0.6620, 0.3380],
        [0.6204, 0.3796],
        [0.6825, 0.3175],
        [0.6478, 0.3522],
        [0.6325, 0.3675],
        [0.6515, 0.3485],
        [0.6244, 0.3756],
        [0.6769, 0.3231],
        [0.6792, 0.3208],
        [0.6132, 0.3868],
        [0.6670, 0.3330],
        [0.6340, 0.3660],
        [0.6564, 0.3436],
        [0.6856, 0.3144],
        [0.6528, 0.3472],
        [0.6477, 0.3523],
        [0.6194, 0.3806],
        [0.6782, 0.3218],
        [0.6644, 0.3356],
        [0.6905, 0.3095],
        [0.6150, 0.3850],
        [0.6719, 0.3281],
        [0.6977, 0.3023],
        [0.6504, 0.3496],
        [0.6709, 0.3291],
        [0.6843, 0.3157],
        [0.6257, 0.3743],
        [0.6648, 0.3352],
        [0.6609, 0.3391],
        [0.6949, 0.3051],
        [0.6869, 0.3131],
        [0.6349, 0.3651],
        [0.6499, 0.3501],
        [0.6617, 0.3383],
        [0.6530, 0.3470],
        [0.6941, 0.3059],
        [0.6537, 0.3463],
        [0.6766, 0.3234],
        [0.6743, 0.3257],
        [0.6470, 0.3530],
        [0.6504, 0.3496],
        [0.6932, 0.3068],
        [0.6656, 0.3344],
        [0.6488, 0.3512],
        [0.7057, 0.2943],
        [0.6618, 0.3382],
        [0.6695, 0.3305],
        [0.6802, 0.3198],
        [0.6646, 0.3354],
        [0.6519, 0.3481],
        [0.6593, 0.3407],
        [0.6453, 0.3547],
        [0.6730, 0.3270],
        [0.6651, 0.3349],
        [0.6827, 0.3173],
        [0.6831, 0.3169],
        [0.6638, 0.3362],
        [0.6778, 0.3222],
        [0.6804, 0.3196],
        [0.6526, 0.3474],
        [0.6617, 0.3383],
        [0.6902, 0.3098],
        [0.6344, 0.3656],
        [0.6650, 0.3350],
        [0.6625, 0.3375],
        [0.6531, 0.3469],
        [0.6502, 0.3498],
        [0.6804, 0.3196],
        [0.6934, 0.3066],
        [0.6692, 0.3308],
        [0.6904, 0.3096],
        [0.6841, 0.3159],
        [0.6654, 0.3346],
        [0.6576, 0.3424],
        [0.6765, 0.3234],
        [0.6369, 0.3631],
        [0.6704, 0.3296],
        [0.6865, 0.3135],
        [0.6561, 0.3439],
        [0.6594, 0.3406],
        [0.6749, 0.3251],
        [0.6786, 0.3214],
        [0.6740, 0.3260],
        [0.7012, 0.2988],
        [0.6797, 0.3203],
        [0.6594, 0.3406],
        [0.6783, 0.3217],
        [0.6491, 0.3509],
        [0.6624, 0.3376],
        [0.6840, 0.3160],
        [0.6434, 0.3566],
        [0.6638, 0.3362],
        [0.6743, 0.3257],
        [0.6918, 0.3082],
        [0.6652, 0.3348]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0018 loss: 0.6604 acc_train: 0.6103 time: 0.1313s
tensor([[0.6538, 0.3462],
        [0.6885, 0.3115],
        [0.6613, 0.3387],
        [0.6626, 0.3374],
        [0.6833, 0.3167],
        [0.6577, 0.3423],
        [0.6259, 0.3741],
        [0.6741, 0.3259],
        [0.6682, 0.3318],
        [0.6393, 0.3607],
        [0.6625, 0.3375],
        [0.6531, 0.3469],
        [0.6450, 0.3550],
        [0.6304, 0.3696],
        [0.6697, 0.3303],
        [0.6440, 0.3560],
        [0.6940, 0.3060],
        [0.6581, 0.3419],
        [0.6765, 0.3235],
        [0.6394, 0.3606],
        [0.6805, 0.3195],
        [0.6468, 0.3532],
        [0.6880, 0.3120],
        [0.6681, 0.3319],
        [0.6658, 0.3342],
        [0.6472, 0.3528],
        [0.6624, 0.3376],
        [0.6734, 0.3266],
        [0.6465, 0.3535],
        [0.6439, 0.3561],
        [0.6654, 0.3346],
        [0.6399, 0.3601],
        [0.6412, 0.3588],
        [0.6456, 0.3544],
        [0.6879, 0.3121],
        [0.6563, 0.3437],
        [0.6468, 0.3532],
        [0.6582, 0.3418],
        [0.6691, 0.3309],
        [0.6419, 0.3581],
        [0.6767, 0.3233],
        [0.6544, 0.3456],
        [0.6347, 0.3653],
        [0.6781, 0.3219],
        [0.6948, 0.3052],
        [0.6506, 0.3494],
        [0.6838, 0.3162],
        [0.6756, 0.3244],
        [0.6666, 0.3334],
        [0.6335, 0.3665],
        [0.6584, 0.3416],
        [0.6602, 0.3398],
        [0.6357, 0.3643],
        [0.6903, 0.3097],
        [0.6739, 0.3261],
        [0.6731, 0.3269],
        [0.6835, 0.3165],
        [0.6491, 0.3509],
        [0.6533, 0.3467],
        [0.6463, 0.3537],
        [0.6307, 0.3693],
        [0.6456, 0.3544],
        [0.6749, 0.3251],
        [0.6669, 0.3331],
        [0.6614, 0.3386],
        [0.6640, 0.3360],
        [0.6617, 0.3383],
        [0.6572, 0.3428],
        [0.6659, 0.3341],
        [0.6557, 0.3443],
        [0.6478, 0.3522],
        [0.6278, 0.3722],
        [0.6548, 0.3452],
        [0.6726, 0.3274],
        [0.6574, 0.3426],
        [0.6505, 0.3495],
        [0.6580, 0.3420],
        [0.6501, 0.3499],
        [0.6700, 0.3300],
        [0.6400, 0.3600],
        [0.6271, 0.3729],
        [0.6415, 0.3585],
        [0.6384, 0.3616],
        [0.6437, 0.3563],
        [0.6581, 0.3419],
        [0.6506, 0.3494],
        [0.6729, 0.3271],
        [0.6687, 0.3313],
        [0.6729, 0.3271],
        [0.6468, 0.3532],
        [0.6514, 0.3486],
        [0.6532, 0.3468],
        [0.6640, 0.3360],
        [0.6235, 0.3765],
        [0.6626, 0.3374],
        [0.6857, 0.3143],
        [0.6677, 0.3323],
        [0.6475, 0.3525],
        [0.6904, 0.3096],
        [0.6472, 0.3528],
        [0.6828, 0.3172],
        [0.6448, 0.3552],
        [0.6416, 0.3584],
        [0.6451, 0.3549],
        [0.7006, 0.2994],
        [0.6540, 0.3460],
        [0.6760, 0.3240],
        [0.6869, 0.3131],
        [0.6384, 0.3616],
        [0.6707, 0.3293],
        [0.6460, 0.3540],
        [0.6870, 0.3130],
        [0.6826, 0.3174],
        [0.6860, 0.3140],
        [0.6565, 0.3435],
        [0.6526, 0.3474],
        [0.6521, 0.3479],
        [0.6785, 0.3215],
        [0.6859, 0.3141],
        [0.6817, 0.3183],
        [0.6403, 0.3597],
        [0.6559, 0.3441],
        [0.6527, 0.3473],
        [0.6510, 0.3490],
        [0.6422, 0.3578],
        [0.6571, 0.3429],
        [0.6349, 0.3651],
        [0.6581, 0.3419],
        [0.6485, 0.3515],
        [0.6426, 0.3574],
        [0.6588, 0.3412],
        [0.6498, 0.3502],
        [0.6714, 0.3286],
        [0.6534, 0.3466],
        [0.6788, 0.3212],
        [0.6637, 0.3363],
        [0.6438, 0.3562],
        [0.6784, 0.3216],
        [0.6675, 0.3325],
        [0.6490, 0.3510],
        [0.6442, 0.3558],
        [0.6669, 0.3331],
        [0.6506, 0.3494],
        [0.6555, 0.3445],
        [0.6059, 0.3941],
        [0.6584, 0.3416],
        [0.6666, 0.3334],
        [0.6464, 0.3536],
        [0.6803, 0.3197],
        [0.6704, 0.3296],
        [0.6373, 0.3627],
        [0.6750, 0.3250],
        [0.6810, 0.3190],
        [0.6954, 0.3046],
        [0.6903, 0.3097],
        [0.6671, 0.3329],
        [0.6734, 0.3266],
        [0.6816, 0.3184],
        [0.6529, 0.3471],
        [0.6754, 0.3246],
        [0.6683, 0.3317],
        [0.6686, 0.3314],
        [0.6471, 0.3529],
        [0.6550, 0.3450],
        [0.6506, 0.3494],
        [0.6401, 0.3599],
        [0.6718, 0.3282],
        [0.6543, 0.3457],
        [0.6652, 0.3348],
        [0.6415, 0.3585],
        [0.6471, 0.3529],
        [0.6538, 0.3462],
        [0.6592, 0.3408],
        [0.6554, 0.3446],
        [0.6737, 0.3263],
        [0.6572, 0.3428],
        [0.6833, 0.3167],
        [0.6608, 0.3392],
        [0.6255, 0.3745],
        [0.6798, 0.3202],
        [0.6494, 0.3506],
        [0.6365, 0.3635],
        [0.6520, 0.3480],
        [0.6286, 0.3714],
        [0.6746, 0.3254],
        [0.6752, 0.3248],
        [0.6186, 0.3814],
        [0.6651, 0.3349],
        [0.6380, 0.3620],
        [0.6561, 0.3439],
        [0.6825, 0.3175],
        [0.6526, 0.3474],
        [0.6494, 0.3506],
        [0.6245, 0.3755],
        [0.6741, 0.3259],
        [0.6637, 0.3363],
        [0.6858, 0.3142],
        [0.6210, 0.3790],
        [0.6701, 0.3299],
        [0.6926, 0.3074],
        [0.6511, 0.3489],
        [0.6702, 0.3298],
        [0.6796, 0.3204],
        [0.6291, 0.3709],
        [0.6646, 0.3354],
        [0.6599, 0.3401],
        [0.6896, 0.3104],
        [0.6831, 0.3169],
        [0.6382, 0.3618],
        [0.6510, 0.3490],
        [0.6616, 0.3384],
        [0.6529, 0.3471],
        [0.6890, 0.3110],
        [0.6536, 0.3464],
        [0.6743, 0.3257],
        [0.6715, 0.3285],
        [0.6481, 0.3519],
        [0.6512, 0.3488],
        [0.6880, 0.3120],
        [0.6647, 0.3353],
        [0.6502, 0.3498],
        [0.6983, 0.3017],
        [0.6609, 0.3391],
        [0.6683, 0.3317],
        [0.6765, 0.3235],
        [0.6634, 0.3366],
        [0.6490, 0.3510],
        [0.6590, 0.3410],
        [0.6482, 0.3518],
        [0.6712, 0.3288],
        [0.6636, 0.3364],
        [0.6786, 0.3214],
        [0.6796, 0.3204],
        [0.6630, 0.3370],
        [0.6758, 0.3242],
        [0.6766, 0.3234],
        [0.6524, 0.3476],
        [0.6614, 0.3386],
        [0.6856, 0.3144],
        [0.6370, 0.3630],
        [0.6637, 0.3363],
        [0.6611, 0.3389],
        [0.6537, 0.3463],
        [0.6515, 0.3485],
        [0.6761, 0.3239],
        [0.6885, 0.3115],
        [0.6681, 0.3319],
        [0.6847, 0.3153],
        [0.6819, 0.3181],
        [0.6637, 0.3363],
        [0.6567, 0.3433],
        [0.6745, 0.3255],
        [0.6390, 0.3610],
        [0.6701, 0.3299],
        [0.6830, 0.3170],
        [0.6554, 0.3446],
        [0.6590, 0.3410],
        [0.6716, 0.3284],
        [0.6752, 0.3248],
        [0.6712, 0.3288],
        [0.6951, 0.3049],
        [0.6754, 0.3246],
        [0.6590, 0.3410],
        [0.6760, 0.3240],
        [0.6491, 0.3509],
        [0.6604, 0.3396],
        [0.6806, 0.3194],
        [0.6454, 0.3546],
        [0.6633, 0.3367],
        [0.6733, 0.3267],
        [0.6866, 0.3134],
        [0.6638, 0.3362]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0019 loss: 0.6619 acc_train: 0.6103 time: 0.1220s
tensor([[0.6545, 0.3455],
        [0.6846, 0.3154],
        [0.6614, 0.3386],
        [0.6614, 0.3386],
        [0.6794, 0.3206],
        [0.6569, 0.3431],
        [0.6310, 0.3690],
        [0.6705, 0.3295],
        [0.6668, 0.3332],
        [0.6430, 0.3570],
        [0.6614, 0.3386],
        [0.6546, 0.3454],
        [0.6472, 0.3528],
        [0.6353, 0.3647],
        [0.6675, 0.3325],
        [0.6459, 0.3541],
        [0.6886, 0.3114],
        [0.6581, 0.3419],
        [0.6728, 0.3272],
        [0.6431, 0.3569],
        [0.6783, 0.3217],
        [0.6484, 0.3516],
        [0.6835, 0.3165],
        [0.6673, 0.3327],
        [0.6647, 0.3353],
        [0.6497, 0.3503],
        [0.6621, 0.3379],
        [0.6719, 0.3281],
        [0.6483, 0.3517],
        [0.6467, 0.3533],
        [0.6639, 0.3361],
        [0.6432, 0.3568],
        [0.6439, 0.3561],
        [0.6482, 0.3518],
        [0.6829, 0.3171],
        [0.6552, 0.3448],
        [0.6490, 0.3510],
        [0.6569, 0.3431],
        [0.6680, 0.3320],
        [0.6439, 0.3561],
        [0.6752, 0.3248],
        [0.6547, 0.3453],
        [0.6364, 0.3636],
        [0.6743, 0.3257],
        [0.6892, 0.3108],
        [0.6520, 0.3480],
        [0.6796, 0.3204],
        [0.6726, 0.3274],
        [0.6659, 0.3341],
        [0.6372, 0.3628],
        [0.6572, 0.3428],
        [0.6593, 0.3407],
        [0.6399, 0.3601],
        [0.6859, 0.3141],
        [0.6713, 0.3287],
        [0.6705, 0.3295],
        [0.6795, 0.3205],
        [0.6498, 0.3502],
        [0.6544, 0.3456],
        [0.6490, 0.3510],
        [0.6360, 0.3640],
        [0.6478, 0.3522],
        [0.6731, 0.3269],
        [0.6651, 0.3349],
        [0.6613, 0.3387],
        [0.6630, 0.3370],
        [0.6610, 0.3390],
        [0.6572, 0.3428],
        [0.6630, 0.3370],
        [0.6570, 0.3430],
        [0.6488, 0.3512],
        [0.6322, 0.3678],
        [0.6561, 0.3439],
        [0.6704, 0.3296],
        [0.6576, 0.3424],
        [0.6516, 0.3484],
        [0.6574, 0.3426],
        [0.6520, 0.3480],
        [0.6689, 0.3311],
        [0.6419, 0.3581],
        [0.6323, 0.3677],
        [0.6440, 0.3560],
        [0.6419, 0.3581],
        [0.6457, 0.3543],
        [0.6575, 0.3425],
        [0.6524, 0.3476],
        [0.6713, 0.3287],
        [0.6667, 0.3333],
        [0.6700, 0.3300],
        [0.6490, 0.3510],
        [0.6527, 0.3473],
        [0.6539, 0.3461],
        [0.6631, 0.3369],
        [0.6293, 0.3707],
        [0.6614, 0.3386],
        [0.6815, 0.3185],
        [0.6664, 0.3336],
        [0.6495, 0.3505],
        [0.6853, 0.3147],
        [0.6488, 0.3512],
        [0.6788, 0.3212],
        [0.6468, 0.3532],
        [0.6445, 0.3555],
        [0.6470, 0.3530],
        [0.6941, 0.3059],
        [0.6534, 0.3466],
        [0.6741, 0.3259],
        [0.6809, 0.3191],
        [0.6420, 0.3580],
        [0.6698, 0.3302],
        [0.6448, 0.3552],
        [0.6824, 0.3176],
        [0.6782, 0.3218],
        [0.6808, 0.3192],
        [0.6566, 0.3434],
        [0.6505, 0.3495],
        [0.6531, 0.3469],
        [0.6749, 0.3251],
        [0.6805, 0.3195],
        [0.6792, 0.3208],
        [0.6430, 0.3570],
        [0.6566, 0.3434],
        [0.6540, 0.3460],
        [0.6513, 0.3487],
        [0.6449, 0.3551],
        [0.6567, 0.3433],
        [0.6381, 0.3619],
        [0.6590, 0.3410],
        [0.6495, 0.3505],
        [0.6447, 0.3553],
        [0.6580, 0.3420],
        [0.6510, 0.3490],
        [0.6687, 0.3313],
        [0.6536, 0.3464],
        [0.6744, 0.3256],
        [0.6631, 0.3369],
        [0.6470, 0.3530],
        [0.6751, 0.3249],
        [0.6653, 0.3347],
        [0.6498, 0.3502],
        [0.6461, 0.3539],
        [0.6668, 0.3332],
        [0.6529, 0.3471],
        [0.6553, 0.3447],
        [0.6141, 0.3859],
        [0.6595, 0.3405],
        [0.6669, 0.3331],
        [0.6488, 0.3512],
        [0.6766, 0.3234],
        [0.6694, 0.3306],
        [0.6402, 0.3598],
        [0.6725, 0.3275],
        [0.6790, 0.3210],
        [0.6900, 0.3100],
        [0.6845, 0.3155],
        [0.6666, 0.3334],
        [0.6713, 0.3287],
        [0.6771, 0.3229],
        [0.6545, 0.3455],
        [0.6720, 0.3280],
        [0.6663, 0.3337],
        [0.6674, 0.3326],
        [0.6485, 0.3515],
        [0.6555, 0.3445],
        [0.6499, 0.3501],
        [0.6421, 0.3579],
        [0.6697, 0.3303],
        [0.6553, 0.3447],
        [0.6641, 0.3359],
        [0.6444, 0.3556],
        [0.6457, 0.3543],
        [0.6544, 0.3456],
        [0.6581, 0.3419],
        [0.6567, 0.3433],
        [0.6708, 0.3292],
        [0.6579, 0.3421],
        [0.6794, 0.3206],
        [0.6597, 0.3403],
        [0.6306, 0.3694],
        [0.6777, 0.3223],
        [0.6514, 0.3486],
        [0.6403, 0.3597],
        [0.6524, 0.3476],
        [0.6330, 0.3670],
        [0.6727, 0.3273],
        [0.6717, 0.3283],
        [0.6241, 0.3759],
        [0.6638, 0.3362],
        [0.6419, 0.3581],
        [0.6561, 0.3439],
        [0.6797, 0.3203],
        [0.6529, 0.3471],
        [0.6510, 0.3490],
        [0.6295, 0.3705],
        [0.6708, 0.3292],
        [0.6633, 0.3367],
        [0.6814, 0.3186],
        [0.6271, 0.3729],
        [0.6688, 0.3312],
        [0.6877, 0.3123],
        [0.6519, 0.3481],
        [0.6699, 0.3301],
        [0.6753, 0.3247],
        [0.6328, 0.3672],
        [0.6648, 0.3352],
        [0.6593, 0.3407],
        [0.6848, 0.3152],
        [0.6797, 0.3203],
        [0.6414, 0.3586],
        [0.6518, 0.3482],
        [0.6617, 0.3383],
        [0.6531, 0.3469],
        [0.6845, 0.3155],
        [0.6540, 0.3460],
        [0.6720, 0.3280],
        [0.6694, 0.3306],
        [0.6494, 0.3506],
        [0.6526, 0.3474],
        [0.6834, 0.3166],
        [0.6642, 0.3358],
        [0.6516, 0.3484],
        [0.6917, 0.3083],
        [0.6600, 0.3400],
        [0.6672, 0.3328],
        [0.6732, 0.3268],
        [0.6627, 0.3373],
        [0.6470, 0.3530],
        [0.6592, 0.3408],
        [0.6511, 0.3489],
        [0.6695, 0.3305],
        [0.6623, 0.3377],
        [0.6753, 0.3247],
        [0.6762, 0.3238],
        [0.6624, 0.3376],
        [0.6742, 0.3258],
        [0.6732, 0.3268],
        [0.6528, 0.3472],
        [0.6610, 0.3390],
        [0.6814, 0.3186],
        [0.6400, 0.3600],
        [0.6629, 0.3371],
        [0.6602, 0.3398],
        [0.6543, 0.3457],
        [0.6531, 0.3469],
        [0.6726, 0.3274],
        [0.6841, 0.3159],
        [0.6670, 0.3330],
        [0.6800, 0.3200],
        [0.6796, 0.3204],
        [0.6623, 0.3377],
        [0.6564, 0.3436],
        [0.6732, 0.3268],
        [0.6412, 0.3588],
        [0.6699, 0.3301],
        [0.6798, 0.3202],
        [0.6552, 0.3448],
        [0.6590, 0.3410],
        [0.6689, 0.3311],
        [0.6721, 0.3279],
        [0.6691, 0.3309],
        [0.6893, 0.3107],
        [0.6719, 0.3281],
        [0.6588, 0.3412],
        [0.6737, 0.3263],
        [0.6499, 0.3501],
        [0.6590, 0.3410],
        [0.6777, 0.3223],
        [0.6475, 0.3525],
        [0.6629, 0.3371],
        [0.6720, 0.3280],
        [0.6821, 0.3179],
        [0.6628, 0.3372]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0020 loss: 0.6633 acc_train: 0.6103 time: 0.1252s
tensor([[0.6547, 0.3453],
        [0.6802, 0.3198],
        [0.6610, 0.3390],
        [0.6598, 0.3402],
        [0.6752, 0.3248],
        [0.6559, 0.3441],
        [0.6352, 0.3648],
        [0.6669, 0.3331],
        [0.6649, 0.3351],
        [0.6455, 0.3545],
        [0.6603, 0.3397],
        [0.6550, 0.3450],
        [0.6484, 0.3516],
        [0.6392, 0.3608],
        [0.6651, 0.3349],
        [0.6470, 0.3530],
        [0.6833, 0.3167],
        [0.6573, 0.3427],
        [0.6692, 0.3308],
        [0.6456, 0.3544],
        [0.6757, 0.3243],
        [0.6494, 0.3506],
        [0.6788, 0.3212],
        [0.6660, 0.3340],
        [0.6630, 0.3370],
        [0.6512, 0.3488],
        [0.6613, 0.3387],
        [0.6697, 0.3303],
        [0.6492, 0.3508],
        [0.6486, 0.3514],
        [0.6620, 0.3380],
        [0.6456, 0.3544],
        [0.6461, 0.3539],
        [0.6497, 0.3503],
        [0.6778, 0.3222],
        [0.6532, 0.3468],
        [0.6503, 0.3497],
        [0.6555, 0.3445],
        [0.6661, 0.3339],
        [0.6449, 0.3551],
        [0.6728, 0.3272],
        [0.6545, 0.3455],
        [0.6373, 0.3627],
        [0.6706, 0.3294],
        [0.6830, 0.3170],
        [0.6527, 0.3473],
        [0.6751, 0.3249],
        [0.6696, 0.3304],
        [0.6644, 0.3356],
        [0.6404, 0.3596],
        [0.6558, 0.3442],
        [0.6578, 0.3422],
        [0.6435, 0.3565],
        [0.6811, 0.3189],
        [0.6683, 0.3317],
        [0.6678, 0.3322],
        [0.6752, 0.3248],
        [0.6502, 0.3498],
        [0.6548, 0.3452],
        [0.6505, 0.3495],
        [0.6399, 0.3601],
        [0.6492, 0.3508],
        [0.6705, 0.3295],
        [0.6630, 0.3370],
        [0.6605, 0.3395],
        [0.6616, 0.3384],
        [0.6598, 0.3402],
        [0.6565, 0.3435],
        [0.6602, 0.3398],
        [0.6577, 0.3423],
        [0.6489, 0.3511],
        [0.6357, 0.3643],
        [0.6566, 0.3434],
        [0.6678, 0.3322],
        [0.6571, 0.3429],
        [0.6521, 0.3479],
        [0.6567, 0.3433],
        [0.6528, 0.3472],
        [0.6671, 0.3329],
        [0.6432, 0.3568],
        [0.6365, 0.3635],
        [0.6457, 0.3543],
        [0.6446, 0.3554],
        [0.6470, 0.3530],
        [0.6566, 0.3434],
        [0.6532, 0.3468],
        [0.6693, 0.3307],
        [0.6643, 0.3357],
        [0.6671, 0.3329],
        [0.6502, 0.3498],
        [0.6536, 0.3464],
        [0.6539, 0.3461],
        [0.6617, 0.3383],
        [0.6337, 0.3663],
        [0.6599, 0.3401],
        [0.6773, 0.3227],
        [0.6650, 0.3350],
        [0.6505, 0.3495],
        [0.6799, 0.3201],
        [0.6500, 0.3500],
        [0.6743, 0.3257],
        [0.6481, 0.3519],
        [0.6466, 0.3534],
        [0.6480, 0.3520],
        [0.6873, 0.3127],
        [0.6524, 0.3476],
        [0.6717, 0.3283],
        [0.6752, 0.3248],
        [0.6446, 0.3554],
        [0.6683, 0.3317],
        [0.6432, 0.3568],
        [0.6777, 0.3223],
        [0.6737, 0.3263],
        [0.6756, 0.3244],
        [0.6561, 0.3439],
        [0.6485, 0.3515],
        [0.6535, 0.3465],
        [0.6712, 0.3288],
        [0.6753, 0.3247],
        [0.6764, 0.3236],
        [0.6451, 0.3549],
        [0.6566, 0.3434],
        [0.6546, 0.3454],
        [0.6513, 0.3487],
        [0.6466, 0.3534],
        [0.6561, 0.3439],
        [0.6407, 0.3593],
        [0.6592, 0.3408],
        [0.6497, 0.3503],
        [0.6464, 0.3536],
        [0.6568, 0.3432],
        [0.6515, 0.3485],
        [0.6658, 0.3342],
        [0.6534, 0.3466],
        [0.6702, 0.3298],
        [0.6619, 0.3381],
        [0.6492, 0.3508],
        [0.6715, 0.3285],
        [0.6629, 0.3371],
        [0.6501, 0.3499],
        [0.6472, 0.3528],
        [0.6661, 0.3339],
        [0.6539, 0.3461],
        [0.6548, 0.3452],
        [0.6208, 0.3792],
        [0.6598, 0.3402],
        [0.6663, 0.3337],
        [0.6504, 0.3496],
        [0.6730, 0.3270],
        [0.6677, 0.3323],
        [0.6423, 0.3577],
        [0.6697, 0.3303],
        [0.6763, 0.3237],
        [0.6846, 0.3154],
        [0.6791, 0.3209],
        [0.6652, 0.3348],
        [0.6689, 0.3311],
        [0.6726, 0.3274],
        [0.6551, 0.3449],
        [0.6682, 0.3318],
        [0.6640, 0.3360],
        [0.6657, 0.3343],
        [0.6492, 0.3508],
        [0.6555, 0.3445],
        [0.6486, 0.3514],
        [0.6437, 0.3563],
        [0.6672, 0.3328],
        [0.6556, 0.3444],
        [0.6626, 0.3374],
        [0.6465, 0.3535],
        [0.6437, 0.3563],
        [0.6546, 0.3454],
        [0.6568, 0.3432],
        [0.6573, 0.3427],
        [0.6676, 0.3324],
        [0.6579, 0.3421],
        [0.6753, 0.3247],
        [0.6579, 0.3421],
        [0.6347, 0.3653],
        [0.6753, 0.3247],
        [0.6529, 0.3471],
        [0.6430, 0.3570],
        [0.6520, 0.3480],
        [0.6366, 0.3634],
        [0.6703, 0.3297],
        [0.6682, 0.3318],
        [0.6289, 0.3711],
        [0.6622, 0.3378],
        [0.6445, 0.3555],
        [0.6556, 0.3444],
        [0.6763, 0.3237],
        [0.6529, 0.3471],
        [0.6517, 0.3483],
        [0.6335, 0.3665],
        [0.6675, 0.3325],
        [0.6622, 0.3378],
        [0.6769, 0.3231],
        [0.6323, 0.3677],
        [0.6671, 0.3329],
        [0.6824, 0.3176],
        [0.6523, 0.3477],
        [0.6688, 0.3312],
        [0.6711, 0.3289],
        [0.6358, 0.3642],
        [0.6642, 0.3358],
        [0.6582, 0.3418],
        [0.6797, 0.3203],
        [0.6760, 0.3240],
        [0.6435, 0.3565],
        [0.6518, 0.3482],
        [0.6612, 0.3388],
        [0.6530, 0.3470],
        [0.6801, 0.3199],
        [0.6540, 0.3460],
        [0.6691, 0.3309],
        [0.6671, 0.3329],
        [0.6502, 0.3498],
        [0.6536, 0.3464],
        [0.6785, 0.3215],
        [0.6632, 0.3368],
        [0.6521, 0.3479],
        [0.6853, 0.3147],
        [0.6587, 0.3413],
        [0.6655, 0.3345],
        [0.6697, 0.3303],
        [0.6616, 0.3384],
        [0.6451, 0.3549],
        [0.6589, 0.3411],
        [0.6529, 0.3471],
        [0.6673, 0.3327],
        [0.6606, 0.3394],
        [0.6718, 0.3282],
        [0.6724, 0.3276],
        [0.6612, 0.3388],
        [0.6722, 0.3278],
        [0.6694, 0.3306],
        [0.6530, 0.3470],
        [0.6597, 0.3403],
        [0.6772, 0.3228],
        [0.6425, 0.3575],
        [0.6616, 0.3384],
        [0.6586, 0.3414],
        [0.6542, 0.3458],
        [0.6541, 0.3459],
        [0.6693, 0.3307],
        [0.6794, 0.3206],
        [0.6654, 0.3346],
        [0.6756, 0.3244],
        [0.6765, 0.3235],
        [0.6606, 0.3394],
        [0.6557, 0.3443],
        [0.6712, 0.3288],
        [0.6427, 0.3573],
        [0.6689, 0.3311],
        [0.6761, 0.3239],
        [0.6547, 0.3453],
        [0.6586, 0.3414],
        [0.6660, 0.3340],
        [0.6688, 0.3312],
        [0.6667, 0.3333],
        [0.6837, 0.3163],
        [0.6689, 0.3311],
        [0.6580, 0.3420],
        [0.6707, 0.3293],
        [0.6503, 0.3497],
        [0.6574, 0.3426],
        [0.6746, 0.3254],
        [0.6489, 0.3511],
        [0.6619, 0.3381],
        [0.6697, 0.3303],
        [0.6774, 0.3226],
        [0.6613, 0.3387]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0021 loss: 0.6646 acc_train: 0.6103 time: 3.6143s
tensor([[0.6546, 0.3454],
        [0.6762, 0.3238],
        [0.6604, 0.3396],
        [0.6584, 0.3416],
        [0.6714, 0.3286],
        [0.6547, 0.3453],
        [0.6388, 0.3612],
        [0.6639, 0.3361],
        [0.6630, 0.3370],
        [0.6476, 0.3524],
        [0.6593, 0.3407],
        [0.6549, 0.3451],
        [0.6494, 0.3506],
        [0.6425, 0.3575],
        [0.6631, 0.3369],
        [0.6477, 0.3523],
        [0.6785, 0.3215],
        [0.6562, 0.3438],
        [0.6661, 0.3339],
        [0.6475, 0.3525],
        [0.6731, 0.3269],
        [0.6503, 0.3497],
        [0.6744, 0.3256],
        [0.6647, 0.3353],
        [0.6616, 0.3384],
        [0.6522, 0.3478],
        [0.6606, 0.3394],
        [0.6673, 0.3327],
        [0.6499, 0.3501],
        [0.6502, 0.3498],
        [0.6601, 0.3399],
        [0.6475, 0.3525],
        [0.6482, 0.3518],
        [0.6508, 0.3492],
        [0.6733, 0.3267],
        [0.6511, 0.3489],
        [0.6512, 0.3488],
        [0.6546, 0.3454],
        [0.6640, 0.3360],
        [0.6457, 0.3543],
        [0.6702, 0.3298],
        [0.6543, 0.3457],
        [0.6379, 0.3621],
        [0.6674, 0.3326],
        [0.6772, 0.3228],
        [0.6530, 0.3470],
        [0.6712, 0.3288],
        [0.6670, 0.3330],
        [0.6628, 0.3372],
        [0.6434, 0.3566],
        [0.6550, 0.3450],
        [0.6566, 0.3434],
        [0.6465, 0.3535],
        [0.6766, 0.3234],
        [0.6656, 0.3344],
        [0.6653, 0.3347],
        [0.6715, 0.3285],
        [0.6509, 0.3491],
        [0.6549, 0.3451],
        [0.6514, 0.3486],
        [0.6427, 0.3573],
        [0.6502, 0.3498],
        [0.6678, 0.3322],
        [0.6610, 0.3390],
        [0.6597, 0.3403],
        [0.6604, 0.3396],
        [0.6588, 0.3412],
        [0.6559, 0.3441],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6489, 0.3511],
        [0.6388, 0.3612],
        [0.6568, 0.3432],
        [0.6652, 0.3348],
        [0.6565, 0.3435],
        [0.6525, 0.3475],
        [0.6563, 0.3437],
        [0.6533, 0.3467],
        [0.6654, 0.3346],
        [0.6443, 0.3557],
        [0.6398, 0.3602],
        [0.6472, 0.3528],
        [0.6468, 0.3532],
        [0.6482, 0.3518],
        [0.6556, 0.3444],
        [0.6536, 0.3464],
        [0.6674, 0.3326],
        [0.6623, 0.3377],
        [0.6643, 0.3357],
        [0.6511, 0.3489],
        [0.6544, 0.3456],
        [0.6537, 0.3463],
        [0.6603, 0.3397],
        [0.6373, 0.3627],
        [0.6586, 0.3414],
        [0.6735, 0.3265],
        [0.6637, 0.3363],
        [0.6515, 0.3485],
        [0.6751, 0.3249],
        [0.6510, 0.3490],
        [0.6703, 0.3297],
        [0.6492, 0.3508],
        [0.6483, 0.3517],
        [0.6490, 0.3510],
        [0.6812, 0.3188],
        [0.6519, 0.3481],
        [0.6694, 0.3306],
        [0.6705, 0.3295],
        [0.6466, 0.3534],
        [0.6666, 0.3334],
        [0.6419, 0.3581],
        [0.6734, 0.3266],
        [0.6698, 0.3302],
        [0.6712, 0.3288],
        [0.6554, 0.3446],
        [0.6469, 0.3531],
        [0.6540, 0.3460],
        [0.6679, 0.3321],
        [0.6707, 0.3293],
        [0.6738, 0.3262],
        [0.6470, 0.3530],
        [0.6566, 0.3434],
        [0.6551, 0.3449],
        [0.6515, 0.3485],
        [0.6479, 0.3521],
        [0.6556, 0.3444],
        [0.6431, 0.3569],
        [0.6590, 0.3410],
        [0.6498, 0.3502],
        [0.6479, 0.3521],
        [0.6556, 0.3444],
        [0.6515, 0.3485],
        [0.6631, 0.3369],
        [0.6532, 0.3468],
        [0.6668, 0.3332],
        [0.6608, 0.3392],
        [0.6508, 0.3492],
        [0.6684, 0.3316],
        [0.6609, 0.3391],
        [0.6507, 0.3493],
        [0.6481, 0.3519],
        [0.6653, 0.3347],
        [0.6543, 0.3457],
        [0.6544, 0.3456],
        [0.6264, 0.3736],
        [0.6598, 0.3402],
        [0.6651, 0.3349],
        [0.6515, 0.3485],
        [0.6697, 0.3303],
        [0.6658, 0.3342],
        [0.6440, 0.3560],
        [0.6672, 0.3328],
        [0.6734, 0.3266],
        [0.6798, 0.3202],
        [0.6745, 0.3255],
        [0.6637, 0.3363],
        [0.6667, 0.3333],
        [0.6688, 0.3312],
        [0.6553, 0.3447],
        [0.6650, 0.3350],
        [0.6621, 0.3379],
        [0.6639, 0.3361],
        [0.6495, 0.3505],
        [0.6553, 0.3447],
        [0.6471, 0.3529],
        [0.6452, 0.3548],
        [0.6649, 0.3351],
        [0.6555, 0.3445],
        [0.6613, 0.3387],
        [0.6480, 0.3520],
        [0.6420, 0.3580],
        [0.6546, 0.3454],
        [0.6555, 0.3445],
        [0.6576, 0.3424],
        [0.6648, 0.3352],
        [0.6577, 0.3423],
        [0.6715, 0.3285],
        [0.6563, 0.3437],
        [0.6385, 0.3615],
        [0.6727, 0.3273],
        [0.6541, 0.3459],
        [0.6451, 0.3549],
        [0.6514, 0.3486],
        [0.6398, 0.3602],
        [0.6680, 0.3320],
        [0.6650, 0.3350],
        [0.6332, 0.3668],
        [0.6608, 0.3392],
        [0.6467, 0.3533],
        [0.6551, 0.3449],
        [0.6733, 0.3267],
        [0.6530, 0.3470],
        [0.6524, 0.3476],
        [0.6372, 0.3628],
        [0.6649, 0.3351],
        [0.6611, 0.3389],
        [0.6727, 0.3273],
        [0.6367, 0.3633],
        [0.6653, 0.3347],
        [0.6776, 0.3224],
        [0.6528, 0.3472],
        [0.6675, 0.3325],
        [0.6677, 0.3323],
        [0.6387, 0.3613],
        [0.6634, 0.3366],
        [0.6574, 0.3426],
        [0.6751, 0.3249],
        [0.6725, 0.3275],
        [0.6454, 0.3546],
        [0.6519, 0.3481],
        [0.6605, 0.3395],
        [0.6531, 0.3469],
        [0.6759, 0.3241],
        [0.6542, 0.3458],
        [0.6664, 0.3336],
        [0.6650, 0.3350],
        [0.6508, 0.3492],
        [0.6545, 0.3455],
        [0.6737, 0.3263],
        [0.6620, 0.3380],
        [0.6523, 0.3477],
        [0.6795, 0.3205],
        [0.6576, 0.3424],
        [0.6636, 0.3364],
        [0.6668, 0.3332],
        [0.6605, 0.3395],
        [0.6438, 0.3562],
        [0.6584, 0.3416],
        [0.6539, 0.3461],
        [0.6647, 0.3353],
        [0.6590, 0.3410],
        [0.6687, 0.3313],
        [0.6686, 0.3314],
        [0.6602, 0.3398],
        [0.6701, 0.3299],
        [0.6662, 0.3338],
        [0.6533, 0.3467],
        [0.6585, 0.3415],
        [0.6733, 0.3267],
        [0.6447, 0.3553],
        [0.6607, 0.3393],
        [0.6574, 0.3426],
        [0.6541, 0.3459],
        [0.6548, 0.3452],
        [0.6665, 0.3335],
        [0.6752, 0.3248],
        [0.6639, 0.3361],
        [0.6718, 0.3282],
        [0.6733, 0.3267],
        [0.6590, 0.3410],
        [0.6552, 0.3448],
        [0.6690, 0.3310],
        [0.6443, 0.3557],
        [0.6675, 0.3325],
        [0.6727, 0.3273],
        [0.6543, 0.3457],
        [0.6580, 0.3420],
        [0.6633, 0.3367],
        [0.6659, 0.3341],
        [0.6644, 0.3356],
        [0.6785, 0.3215],
        [0.6662, 0.3338],
        [0.6571, 0.3429],
        [0.6677, 0.3323],
        [0.6505, 0.3495],
        [0.6560, 0.3440],
        [0.6716, 0.3284],
        [0.6497, 0.3503],
        [0.6610, 0.3390],
        [0.6671, 0.3329],
        [0.6732, 0.3268],
        [0.6600, 0.3400]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0022 loss: 0.6658 acc_train: 0.6103 time: 0.1364s
tensor([[0.6548, 0.3452],
        [0.6729, 0.3271],
        [0.6601, 0.3399],
        [0.6575, 0.3425],
        [0.6686, 0.3314],
        [0.6542, 0.3458],
        [0.6421, 0.3579],
        [0.6618, 0.3382],
        [0.6618, 0.3382],
        [0.6494, 0.3506],
        [0.6589, 0.3411],
        [0.6551, 0.3449],
        [0.6506, 0.3494],
        [0.6456, 0.3544],
        [0.6619, 0.3381],
        [0.6486, 0.3514],
        [0.6747, 0.3253],
        [0.6558, 0.3442],
        [0.6637, 0.3363],
        [0.6492, 0.3508],
        [0.6707, 0.3293],
        [0.6513, 0.3487],
        [0.6709, 0.3291],
        [0.6639, 0.3361],
        [0.6602, 0.3398],
        [0.6534, 0.3466],
        [0.6605, 0.3395],
        [0.6653, 0.3347],
        [0.6509, 0.3491],
        [0.6519, 0.3481],
        [0.6587, 0.3413],
        [0.6495, 0.3505],
        [0.6503, 0.3497],
        [0.6519, 0.3481],
        [0.6699, 0.3301],
        [0.6496, 0.3504],
        [0.6521, 0.3479],
        [0.6543, 0.3457],
        [0.6622, 0.3378],
        [0.6469, 0.3531],
        [0.6677, 0.3323],
        [0.6547, 0.3453],
        [0.6389, 0.3611],
        [0.6651, 0.3349],
        [0.6724, 0.3276],
        [0.6534, 0.3466],
        [0.6682, 0.3318],
        [0.6648, 0.3352],
        [0.6617, 0.3383],
        [0.6464, 0.3536],
        [0.6550, 0.3450],
        [0.6560, 0.3440],
        [0.6494, 0.3506],
        [0.6729, 0.3271],
        [0.6634, 0.3366],
        [0.6635, 0.3365],
        [0.6688, 0.3312],
        [0.6522, 0.3478],
        [0.6553, 0.3447],
        [0.6524, 0.3476],
        [0.6449, 0.3551],
        [0.6514, 0.3486],
        [0.6659, 0.3341],
        [0.6594, 0.3406],
        [0.6593, 0.3407],
        [0.6598, 0.3402],
        [0.6584, 0.3416],
        [0.6558, 0.3442],
        [0.6569, 0.3431],
        [0.6587, 0.3413],
        [0.6493, 0.3507],
        [0.6419, 0.3581],
        [0.6572, 0.3428],
        [0.6633, 0.3367],
        [0.6561, 0.3439],
        [0.6532, 0.3468],
        [0.6564, 0.3436],
        [0.6539, 0.3461],
        [0.6644, 0.3356],
        [0.6457, 0.3543],
        [0.6429, 0.3571],
        [0.6489, 0.3511],
        [0.6490, 0.3510],
        [0.6496, 0.3504],
        [0.6551, 0.3449],
        [0.6541, 0.3459],
        [0.6661, 0.3339],
        [0.6610, 0.3390],
        [0.6622, 0.3378],
        [0.6521, 0.3479],
        [0.6554, 0.3446],
        [0.6538, 0.3462],
        [0.6595, 0.3405],
        [0.6406, 0.3594],
        [0.6578, 0.3422],
        [0.6705, 0.3295],
        [0.6628, 0.3372],
        [0.6527, 0.3473],
        [0.6714, 0.3286],
        [0.6522, 0.3478],
        [0.6671, 0.3329],
        [0.6505, 0.3495],
        [0.6501, 0.3499],
        [0.6502, 0.3498],
        [0.6762, 0.3238],
        [0.6518, 0.3482],
        [0.6676, 0.3324],
        [0.6671, 0.3329],
        [0.6486, 0.3514],
        [0.6655, 0.3345],
        [0.6415, 0.3585],
        [0.6699, 0.3301],
        [0.6669, 0.3331],
        [0.6679, 0.3321],
        [0.6552, 0.3448],
        [0.6465, 0.3535],
        [0.6548, 0.3452],
        [0.6656, 0.3344],
        [0.6675, 0.3325],
        [0.6717, 0.3283],
        [0.6491, 0.3509],
        [0.6571, 0.3429],
        [0.6557, 0.3443],
        [0.6522, 0.3478],
        [0.6492, 0.3508],
        [0.6557, 0.3443],
        [0.6456, 0.3544],
        [0.6589, 0.3411],
        [0.6503, 0.3497],
        [0.6498, 0.3502],
        [0.6551, 0.3449],
        [0.6518, 0.3482],
        [0.6612, 0.3388],
        [0.6535, 0.3465],
        [0.6645, 0.3355],
        [0.6603, 0.3397],
        [0.6522, 0.3478],
        [0.6660, 0.3340],
        [0.6596, 0.3404],
        [0.6517, 0.3483],
        [0.6492, 0.3508],
        [0.6648, 0.3352],
        [0.6547, 0.3453],
        [0.6543, 0.3457],
        [0.6314, 0.3686],
        [0.6599, 0.3401],
        [0.6640, 0.3360],
        [0.6528, 0.3472],
        [0.6672, 0.3328],
        [0.6643, 0.3357],
        [0.6461, 0.3539],
        [0.6654, 0.3346],
        [0.6708, 0.3292],
        [0.6756, 0.3244],
        [0.6708, 0.3292],
        [0.6626, 0.3374],
        [0.6652, 0.3348],
        [0.6660, 0.3340],
        [0.6555, 0.3445],
        [0.6627, 0.3373],
        [0.6610, 0.3390],
        [0.6626, 0.3374],
        [0.6500, 0.3500],
        [0.6554, 0.3446],
        [0.6461, 0.3539],
        [0.6468, 0.3532],
        [0.6631, 0.3369],
        [0.6557, 0.3443],
        [0.6605, 0.3395],
        [0.6495, 0.3505],
        [0.6412, 0.3588],
        [0.6548, 0.3452],
        [0.6547, 0.3453],
        [0.6580, 0.3420],
        [0.6628, 0.3372],
        [0.6578, 0.3422],
        [0.6684, 0.3316],
        [0.6555, 0.3445],
        [0.6420, 0.3580],
        [0.6707, 0.3293],
        [0.6553, 0.3447],
        [0.6471, 0.3529],
        [0.6514, 0.3486],
        [0.6429, 0.3571],
        [0.6662, 0.3338],
        [0.6626, 0.3374],
        [0.6374, 0.3626],
        [0.6600, 0.3400],
        [0.6489, 0.3511],
        [0.6550, 0.3450],
        [0.6709, 0.3291],
        [0.6537, 0.3463],
        [0.6533, 0.3467],
        [0.6409, 0.3591],
        [0.6634, 0.3366],
        [0.6605, 0.3395],
        [0.6694, 0.3306],
        [0.6407, 0.3593],
        [0.6642, 0.3358],
        [0.6736, 0.3264],
        [0.6538, 0.3462],
        [0.6662, 0.3338],
        [0.6654, 0.3346],
        [0.6416, 0.3584],
        [0.6626, 0.3374],
        [0.6571, 0.3429],
        [0.6713, 0.3287],
        [0.6697, 0.3303],
        [0.6473, 0.3527],
        [0.6526, 0.3474],
        [0.6601, 0.3399],
        [0.6535, 0.3465],
        [0.6725, 0.3275],
        [0.6547, 0.3453],
        [0.6643, 0.3357],
        [0.6635, 0.3365],
        [0.6517, 0.3483],
        [0.6556, 0.3444],
        [0.6698, 0.3302],
        [0.6611, 0.3389],
        [0.6528, 0.3472],
        [0.6750, 0.3250],
        [0.6571, 0.3429],
        [0.6622, 0.3378],
        [0.6647, 0.3353],
        [0.6597, 0.3403],
        [0.6436, 0.3564],
        [0.6582, 0.3418],
        [0.6548, 0.3452],
        [0.6626, 0.3374],
        [0.6579, 0.3421],
        [0.6663, 0.3337],
        [0.6655, 0.3345],
        [0.6597, 0.3403],
        [0.6684, 0.3316],
        [0.6641, 0.3359],
        [0.6541, 0.3459],
        [0.6576, 0.3424],
        [0.6704, 0.3296],
        [0.6471, 0.3529],
        [0.6605, 0.3395],
        [0.6568, 0.3432],
        [0.6545, 0.3455],
        [0.6555, 0.3445],
        [0.6647, 0.3353],
        [0.6717, 0.3283],
        [0.6627, 0.3373],
        [0.6689, 0.3311],
        [0.6704, 0.3296],
        [0.6580, 0.3420],
        [0.6552, 0.3448],
        [0.6671, 0.3329],
        [0.6463, 0.3537],
        [0.6662, 0.3338],
        [0.6698, 0.3302],
        [0.6542, 0.3458],
        [0.6577, 0.3423],
        [0.6613, 0.3387],
        [0.6639, 0.3361],
        [0.6628, 0.3372],
        [0.6744, 0.3256],
        [0.6641, 0.3359],
        [0.6566, 0.3434],
        [0.6653, 0.3347],
        [0.6511, 0.3489],
        [0.6552, 0.3448],
        [0.6692, 0.3308],
        [0.6507, 0.3493],
        [0.6607, 0.3393],
        [0.6647, 0.3353],
        [0.6698, 0.3302],
        [0.6590, 0.3410]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0023 loss: 0.6668 acc_train: 0.6103 time: 0.1160s
tensor([[0.6551, 0.3449],
        [0.6700, 0.3300],
        [0.6601, 0.3399],
        [0.6569, 0.3431],
        [0.6666, 0.3334],
        [0.6539, 0.3461],
        [0.6449, 0.3551],
        [0.6603, 0.3397],
        [0.6609, 0.3391],
        [0.6509, 0.3491],
        [0.6587, 0.3413],
        [0.6553, 0.3447],
        [0.6517, 0.3483],
        [0.6482, 0.3518],
        [0.6611, 0.3389],
        [0.6497, 0.3503],
        [0.6717, 0.3283],
        [0.6556, 0.3444],
        [0.6620, 0.3380],
        [0.6505, 0.3495],
        [0.6687, 0.3313],
        [0.6524, 0.3476],
        [0.6681, 0.3319],
        [0.6632, 0.3368],
        [0.6591, 0.3409],
        [0.6544, 0.3456],
        [0.6605, 0.3395],
        [0.6636, 0.3364],
        [0.6519, 0.3481],
        [0.6532, 0.3468],
        [0.6576, 0.3424],
        [0.6513, 0.3487],
        [0.6524, 0.3476],
        [0.6529, 0.3471],
        [0.6673, 0.3327],
        [0.6484, 0.3516],
        [0.6528, 0.3472],
        [0.6541, 0.3459],
        [0.6607, 0.3393],
        [0.6482, 0.3518],
        [0.6655, 0.3345],
        [0.6553, 0.3447],
        [0.6400, 0.3600],
        [0.6634, 0.3366],
        [0.6686, 0.3314],
        [0.6537, 0.3463],
        [0.6659, 0.3341],
        [0.6630, 0.3370],
        [0.6610, 0.3390],
        [0.6491, 0.3509],
        [0.6551, 0.3449],
        [0.6559, 0.3441],
        [0.6518, 0.3482],
        [0.6697, 0.3303],
        [0.6617, 0.3383],
        [0.6620, 0.3380],
        [0.6668, 0.3332],
        [0.6536, 0.3464],
        [0.6559, 0.3441],
        [0.6533, 0.3467],
        [0.6468, 0.3532],
        [0.6525, 0.3475],
        [0.6644, 0.3356],
        [0.6585, 0.3415],
        [0.6590, 0.3410],
        [0.6594, 0.3406],
        [0.6582, 0.3418],
        [0.6560, 0.3440],
        [0.6563, 0.3437],
        [0.6591, 0.3409],
        [0.6500, 0.3500],
        [0.6448, 0.3552],
        [0.6577, 0.3423],
        [0.6617, 0.3383],
        [0.6558, 0.3442],
        [0.6539, 0.3461],
        [0.6567, 0.3433],
        [0.6546, 0.3454],
        [0.6638, 0.3362],
        [0.6473, 0.3527],
        [0.6454, 0.3546],
        [0.6507, 0.3494],
        [0.6508, 0.3492],
        [0.6510, 0.3490],
        [0.6550, 0.3450],
        [0.6546, 0.3454],
        [0.6651, 0.3349],
        [0.6599, 0.3401],
        [0.6606, 0.3394],
        [0.6531, 0.3469],
        [0.6564, 0.3436],
        [0.6539, 0.3461],
        [0.6588, 0.3412],
        [0.6434, 0.3566],
        [0.6574, 0.3426],
        [0.6682, 0.3318],
        [0.6623, 0.3377],
        [0.6540, 0.3460],
        [0.6683, 0.3317],
        [0.6533, 0.3467],
        [0.6644, 0.3356],
        [0.6518, 0.3482],
        [0.6517, 0.3483],
        [0.6511, 0.3489],
        [0.6721, 0.3279],
        [0.6521, 0.3479],
        [0.6661, 0.3339],
        [0.6647, 0.3353],
        [0.6503, 0.3497],
        [0.6646, 0.3354],
        [0.6416, 0.3584],
        [0.6673, 0.3327],
        [0.6647, 0.3353],
        [0.6653, 0.3347],
        [0.6552, 0.3448],
        [0.6468, 0.3532],
        [0.6556, 0.3444],
        [0.6639, 0.3361],
        [0.6653, 0.3347],
        [0.6699, 0.3301],
        [0.6508, 0.3492],
        [0.6576, 0.3424],
        [0.6564, 0.3436],
        [0.6531, 0.3469],
        [0.6503, 0.3497],
        [0.6560, 0.3440],
        [0.6480, 0.3520],
        [0.6589, 0.3411],
        [0.6511, 0.3489],
        [0.6517, 0.3483],
        [0.6550, 0.3450],
        [0.6522, 0.3478],
        [0.6599, 0.3401],
        [0.6539, 0.3461],
        [0.6630, 0.3370],
        [0.6600, 0.3400],
        [0.6535, 0.3465],
        [0.6643, 0.3357],
        [0.6585, 0.3415],
        [0.6527, 0.3473],
        [0.6503, 0.3497],
        [0.6641, 0.3359],
        [0.6550, 0.3450],
        [0.6544, 0.3456],
        [0.6360, 0.3640],
        [0.6600, 0.3400],
        [0.6628, 0.3372],
        [0.6539, 0.3461],
        [0.6651, 0.3349],
        [0.6632, 0.3368],
        [0.6481, 0.3519],
        [0.6639, 0.3361],
        [0.6685, 0.3315],
        [0.6722, 0.3278],
        [0.6680, 0.3320],
        [0.6619, 0.3381],
        [0.6641, 0.3359],
        [0.6640, 0.3360],
        [0.6557, 0.3443],
        [0.6610, 0.3390],
        [0.6603, 0.3397],
        [0.6618, 0.3382],
        [0.6507, 0.3493],
        [0.6556, 0.3444],
        [0.6456, 0.3544],
        [0.6484, 0.3516],
        [0.6619, 0.3381],
        [0.6560, 0.3440],
        [0.6601, 0.3399],
        [0.6511, 0.3489],
        [0.6410, 0.3590],
        [0.6550, 0.3450],
        [0.6541, 0.3459],
        [0.6582, 0.3418],
        [0.6613, 0.3387],
        [0.6580, 0.3420],
        [0.6658, 0.3342],
        [0.6550, 0.3450],
        [0.6453, 0.3547],
        [0.6688, 0.3312],
        [0.6562, 0.3438],
        [0.6488, 0.3512],
        [0.6516, 0.3484],
        [0.6458, 0.3542],
        [0.6649, 0.3351],
        [0.6609, 0.3391],
        [0.6411, 0.3589],
        [0.6595, 0.3405],
        [0.6509, 0.3491],
        [0.6551, 0.3449],
        [0.6690, 0.3310],
        [0.6543, 0.3457],
        [0.6541, 0.3459],
        [0.6443, 0.3557],
        [0.6623, 0.3377],
        [0.6602, 0.3398],
        [0.6668, 0.3332],
        [0.6441, 0.3559],
        [0.6633, 0.3367],
        [0.6704, 0.3296],
        [0.6548, 0.3452],
        [0.6651, 0.3349],
        [0.6640, 0.3360],
        [0.6444, 0.3556],
        [0.6619, 0.3381],
        [0.6572, 0.3428],
        [0.6683, 0.3317],
        [0.6674, 0.3326],
        [0.6490, 0.3510],
        [0.6533, 0.3467],
        [0.6598, 0.3402],
        [0.6540, 0.3460],
        [0.6697, 0.3303],
        [0.6552, 0.3448],
        [0.6625, 0.3375],
        [0.6624, 0.3376],
        [0.6526, 0.3474],
        [0.6566, 0.3434],
        [0.6668, 0.3332],
        [0.6605, 0.3395],
        [0.6534, 0.3466],
        [0.6714, 0.3286],
        [0.6566, 0.3434],
        [0.6612, 0.3388],
        [0.6631, 0.3369],
        [0.6593, 0.3407],
        [0.6440, 0.3560],
        [0.6582, 0.3418],
        [0.6554, 0.3446],
        [0.6608, 0.3392],
        [0.6574, 0.3426],
        [0.6644, 0.3356],
        [0.6631, 0.3369],
        [0.6595, 0.3405],
        [0.6669, 0.3331],
        [0.6625, 0.3375],
        [0.6549, 0.3451],
        [0.6572, 0.3428],
        [0.6680, 0.3320],
        [0.6494, 0.3506],
        [0.6606, 0.3394],
        [0.6566, 0.3434],
        [0.6549, 0.3451],
        [0.6561, 0.3439],
        [0.6634, 0.3366],
        [0.6687, 0.3313],
        [0.6620, 0.3380],
        [0.6665, 0.3335],
        [0.6678, 0.3322],
        [0.6574, 0.3426],
        [0.6554, 0.3446],
        [0.6655, 0.3345],
        [0.6481, 0.3519],
        [0.6650, 0.3350],
        [0.6676, 0.3324],
        [0.6543, 0.3457],
        [0.6574, 0.3426],
        [0.6599, 0.3401],
        [0.6623, 0.3377],
        [0.6614, 0.3386],
        [0.6709, 0.3291],
        [0.6625, 0.3375],
        [0.6562, 0.3438],
        [0.6634, 0.3366],
        [0.6518, 0.3482],
        [0.6549, 0.3451],
        [0.6673, 0.3327],
        [0.6514, 0.3486],
        [0.6605, 0.3395],
        [0.6627, 0.3373],
        [0.6668, 0.3332],
        [0.6583, 0.3417]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0024 loss: 0.6676 acc_train: 0.6103 time: 0.1205s
tensor([[0.6550, 0.3450],
        [0.6674, 0.3326],
        [0.6599, 0.3401],
        [0.6564, 0.3436],
        [0.6649, 0.3351],
        [0.6537, 0.3463],
        [0.6469, 0.3531],
        [0.6591, 0.3409],
        [0.6601, 0.3399],
        [0.6518, 0.3482],
        [0.6582, 0.3418],
        [0.6551, 0.3449],
        [0.6525, 0.3475],
        [0.6500, 0.3500],
        [0.6605, 0.3395],
        [0.6506, 0.3494],
        [0.6691, 0.3309],
        [0.6553, 0.3447],
        [0.6606, 0.3394],
        [0.6514, 0.3486],
        [0.6666, 0.3334],
        [0.6529, 0.3471],
        [0.6656, 0.3344],
        [0.6624, 0.3376],
        [0.6581, 0.3419],
        [0.6549, 0.3451],
        [0.6602, 0.3398],
        [0.6618, 0.3382],
        [0.6526, 0.3474],
        [0.6538, 0.3462],
        [0.6567, 0.3433],
        [0.6526, 0.3474],
        [0.6538, 0.3462],
        [0.6534, 0.3466],
        [0.6650, 0.3350],
        [0.6472, 0.3528],
        [0.6531, 0.3469],
        [0.6538, 0.3462],
        [0.6593, 0.3407],
        [0.6491, 0.3509],
        [0.6633, 0.3367],
        [0.6558, 0.3442],
        [0.6409, 0.3591],
        [0.6620, 0.3380],
        [0.6655, 0.3345],
        [0.6538, 0.3462],
        [0.6639, 0.3361],
        [0.6614, 0.3386],
        [0.6602, 0.3398],
        [0.6510, 0.3490],
        [0.6551, 0.3449],
        [0.6559, 0.3441],
        [0.6533, 0.3467],
        [0.6669, 0.3331],
        [0.6601, 0.3399],
        [0.6607, 0.3393],
        [0.6653, 0.3347],
        [0.6548, 0.3452],
        [0.6562, 0.3438],
        [0.6538, 0.3462],
        [0.6479, 0.3521],
        [0.6531, 0.3469],
        [0.6631, 0.3369],
        [0.6577, 0.3423],
        [0.6586, 0.3414],
        [0.6590, 0.3410],
        [0.6579, 0.3421],
        [0.6562, 0.3438],
        [0.6560, 0.3440],
        [0.6591, 0.3409],
        [0.6506, 0.3494],
        [0.6470, 0.3530],
        [0.6578, 0.3422],
        [0.6602, 0.3398],
        [0.6555, 0.3445],
        [0.6543, 0.3457],
        [0.6569, 0.3431],
        [0.6551, 0.3449],
        [0.6634, 0.3366],
        [0.6487, 0.3513],
        [0.6471, 0.3529],
        [0.6519, 0.3481],
        [0.6520, 0.3480],
        [0.6521, 0.3479],
        [0.6547, 0.3453],
        [0.6547, 0.3453],
        [0.6639, 0.3361],
        [0.6589, 0.3411],
        [0.6591, 0.3409],
        [0.6537, 0.3463],
        [0.6569, 0.3431],
        [0.6537, 0.3463],
        [0.6581, 0.3419],
        [0.6454, 0.3546],
        [0.6569, 0.3431],
        [0.6662, 0.3338],
        [0.6616, 0.3384],
        [0.6548, 0.3452],
        [0.6656, 0.3344],
        [0.6540, 0.3460],
        [0.6623, 0.3377],
        [0.6528, 0.3472],
        [0.6526, 0.3474],
        [0.6517, 0.3483],
        [0.6687, 0.3313],
        [0.6523, 0.3477],
        [0.6647, 0.3353],
        [0.6627, 0.3373],
        [0.6514, 0.3486],
        [0.6636, 0.3364],
        [0.6420, 0.3580],
        [0.6652, 0.3348],
        [0.6627, 0.3373],
        [0.6631, 0.3369],
        [0.6552, 0.3448],
        [0.6473, 0.3527],
        [0.6560, 0.3440],
        [0.6624, 0.3376],
        [0.6636, 0.3364],
        [0.6681, 0.3319],
        [0.6517, 0.3483],
        [0.6578, 0.3422],
        [0.6568, 0.3432],
        [0.6537, 0.3463],
        [0.6510, 0.3490],
        [0.6562, 0.3438],
        [0.6497, 0.3503],
        [0.6584, 0.3416],
        [0.6517, 0.3483],
        [0.6529, 0.3471],
        [0.6550, 0.3450],
        [0.6525, 0.3475],
        [0.6589, 0.3411],
        [0.6541, 0.3459],
        [0.6616, 0.3384],
        [0.6595, 0.3405],
        [0.6542, 0.3458],
        [0.6629, 0.3371],
        [0.6576, 0.3424],
        [0.6533, 0.3467],
        [0.6510, 0.3490],
        [0.6632, 0.3368],
        [0.6550, 0.3450],
        [0.6544, 0.3456],
        [0.6395, 0.3605],
        [0.6595, 0.3405],
        [0.6614, 0.3386],
        [0.6545, 0.3455],
        [0.6634, 0.3366],
        [0.6622, 0.3378],
        [0.6496, 0.3504],
        [0.6626, 0.3374],
        [0.6662, 0.3338],
        [0.6693, 0.3307],
        [0.6658, 0.3342],
        [0.6610, 0.3390],
        [0.6631, 0.3369],
        [0.6622, 0.3378],
        [0.6558, 0.3442],
        [0.6597, 0.3403],
        [0.6596, 0.3404],
        [0.6611, 0.3389],
        [0.6512, 0.3488],
        [0.6555, 0.3445],
        [0.6453, 0.3547],
        [0.6497, 0.3503],
        [0.6608, 0.3392],
        [0.6559, 0.3441],
        [0.6595, 0.3405],
        [0.6522, 0.3478],
        [0.6411, 0.3589],
        [0.6549, 0.3451],
        [0.6534, 0.3466],
        [0.6579, 0.3421],
        [0.6601, 0.3399],
        [0.6577, 0.3423],
        [0.6636, 0.3364],
        [0.6547, 0.3453],
        [0.6477, 0.3523],
        [0.6668, 0.3332],
        [0.6565, 0.3435],
        [0.6499, 0.3501],
        [0.6518, 0.3482],
        [0.6479, 0.3521],
        [0.6637, 0.3363],
        [0.6596, 0.3404],
        [0.6439, 0.3561],
        [0.6589, 0.3411],
        [0.6524, 0.3476],
        [0.6551, 0.3449],
        [0.6671, 0.3329],
        [0.6547, 0.3453],
        [0.6545, 0.3455],
        [0.6470, 0.3530],
        [0.6614, 0.3386],
        [0.6597, 0.3403],
        [0.6645, 0.3355],
        [0.6467, 0.3533],
        [0.6623, 0.3377],
        [0.6677, 0.3323],
        [0.6554, 0.3446],
        [0.6637, 0.3363],
        [0.6629, 0.3371],
        [0.6464, 0.3536],
        [0.6609, 0.3391],
        [0.6571, 0.3429],
        [0.6657, 0.3343],
        [0.6653, 0.3347],
        [0.6503, 0.3497],
        [0.6538, 0.3462],
        [0.6595, 0.3405],
        [0.6542, 0.3458],
        [0.6672, 0.3328],
        [0.6554, 0.3446],
        [0.6609, 0.3391],
        [0.6613, 0.3387],
        [0.6533, 0.3467],
        [0.6570, 0.3430],
        [0.6641, 0.3359],
        [0.6595, 0.3405],
        [0.6537, 0.3463],
        [0.6683, 0.3317],
        [0.6562, 0.3438],
        [0.6601, 0.3399],
        [0.6617, 0.3383],
        [0.6588, 0.3412],
        [0.6443, 0.3557],
        [0.6579, 0.3421],
        [0.6554, 0.3446],
        [0.6592, 0.3408],
        [0.6569, 0.3431],
        [0.6626, 0.3374],
        [0.6612, 0.3388],
        [0.6594, 0.3406],
        [0.6652, 0.3348],
        [0.6612, 0.3388],
        [0.6554, 0.3446],
        [0.6569, 0.3431],
        [0.6659, 0.3341],
        [0.6511, 0.3489],
        [0.6605, 0.3395],
        [0.6564, 0.3436],
        [0.6551, 0.3449],
        [0.6560, 0.3440],
        [0.6623, 0.3377],
        [0.6660, 0.3340],
        [0.6613, 0.3387],
        [0.6643, 0.3357],
        [0.6653, 0.3347],
        [0.6568, 0.3432],
        [0.6556, 0.3444],
        [0.6638, 0.3362],
        [0.6495, 0.3505],
        [0.6635, 0.3365],
        [0.6657, 0.3343],
        [0.6542, 0.3458],
        [0.6568, 0.3432],
        [0.6586, 0.3414],
        [0.6610, 0.3390],
        [0.6601, 0.3399],
        [0.6679, 0.3321],
        [0.6610, 0.3390],
        [0.6557, 0.3443],
        [0.6616, 0.3384],
        [0.6520, 0.3480],
        [0.6546, 0.3454],
        [0.6653, 0.3347],
        [0.6518, 0.3482],
        [0.6599, 0.3401],
        [0.6609, 0.3391],
        [0.6644, 0.3356],
        [0.6576, 0.3424]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0025 loss: 0.6683 acc_train: 0.6103 time: 0.1383s
tensor([[0.6547, 0.3453],
        [0.6652, 0.3348],
        [0.6593, 0.3407],
        [0.6558, 0.3442],
        [0.6634, 0.3366],
        [0.6532, 0.3468],
        [0.6482, 0.3518],
        [0.6580, 0.3420],
        [0.6593, 0.3407],
        [0.6521, 0.3479],
        [0.6573, 0.3427],
        [0.6545, 0.3455],
        [0.6528, 0.3472],
        [0.6509, 0.3491],
        [0.6599, 0.3401],
        [0.6511, 0.3489],
        [0.6669, 0.3331],
        [0.6550, 0.3450],
        [0.6594, 0.3406],
        [0.6516, 0.3484],
        [0.6644, 0.3356],
        [0.6528, 0.3472],
        [0.6633, 0.3367],
        [0.6612, 0.3388],
        [0.6569, 0.3431],
        [0.6549, 0.3451],
        [0.6596, 0.3404],
        [0.6599, 0.3401],
        [0.6528, 0.3472],
        [0.6538, 0.3462],
        [0.6556, 0.3444],
        [0.6532, 0.3468],
        [0.6546, 0.3454],
        [0.6534, 0.3466],
        [0.6631, 0.3369],
        [0.6461, 0.3539],
        [0.6530, 0.3470],
        [0.6535, 0.3465],
        [0.6579, 0.3421],
        [0.6498, 0.3502],
        [0.6612, 0.3388],
        [0.6559, 0.3441],
        [0.6415, 0.3585],
        [0.6606, 0.3394],
        [0.6631, 0.3369],
        [0.6536, 0.3464],
        [0.6621, 0.3379],
        [0.6599, 0.3401],
        [0.6593, 0.3407],
        [0.6521, 0.3479],
        [0.6547, 0.3453],
        [0.6558, 0.3442],
        [0.6539, 0.3461],
        [0.6644, 0.3356],
        [0.6586, 0.3414],
        [0.6593, 0.3407],
        [0.6639, 0.3361],
        [0.6554, 0.3446],
        [0.6561, 0.3439],
        [0.6537, 0.3463],
        [0.6484, 0.3516],
        [0.6532, 0.3468],
        [0.6617, 0.3383],
        [0.6568, 0.3432],
        [0.6580, 0.3420],
        [0.6583, 0.3417],
        [0.6574, 0.3426],
        [0.6562, 0.3438],
        [0.6557, 0.3443],
        [0.6586, 0.3414],
        [0.6510, 0.3490],
        [0.6484, 0.3516],
        [0.6575, 0.3425],
        [0.6588, 0.3412],
        [0.6548, 0.3452],
        [0.6543, 0.3457],
        [0.6566, 0.3434],
        [0.6551, 0.3449],
        [0.6628, 0.3372],
        [0.6495, 0.3505],
        [0.6480, 0.3520],
        [0.6526, 0.3474],
        [0.6523, 0.3477],
        [0.6526, 0.3474],
        [0.6542, 0.3458],
        [0.6544, 0.3456],
        [0.6625, 0.3375],
        [0.6578, 0.3422],
        [0.6577, 0.3423],
        [0.6538, 0.3462],
        [0.6568, 0.3432],
        [0.6532, 0.3468],
        [0.6571, 0.3429],
        [0.6465, 0.3535],
        [0.6563, 0.3437],
        [0.6643, 0.3357],
        [0.6606, 0.3394],
        [0.6549, 0.3451],
        [0.6634, 0.3366],
        [0.6540, 0.3460],
        [0.6605, 0.3395],
        [0.6531, 0.3469],
        [0.6528, 0.3472],
        [0.6518, 0.3482],
        [0.6661, 0.3339],
        [0.6522, 0.3478],
        [0.6633, 0.3367],
        [0.6610, 0.3390],
        [0.6518, 0.3482],
        [0.6623, 0.3377],
        [0.6423, 0.3577],
        [0.6634, 0.3366],
        [0.6610, 0.3390],
        [0.6612, 0.3388],
        [0.6548, 0.3452],
        [0.6477, 0.3523],
        [0.6559, 0.3441],
        [0.6610, 0.3390],
        [0.6622, 0.3378],
        [0.6661, 0.3339],
        [0.6520, 0.3480],
        [0.6574, 0.3426],
        [0.6567, 0.3433],
        [0.6539, 0.3461],
        [0.6513, 0.3487],
        [0.6560, 0.3440],
        [0.6507, 0.3493],
        [0.6576, 0.3424],
        [0.6520, 0.3480],
        [0.6536, 0.3464],
        [0.6549, 0.3451],
        [0.6524, 0.3476],
        [0.6579, 0.3421],
        [0.6539, 0.3461],
        [0.6601, 0.3399],
        [0.6588, 0.3412],
        [0.6542, 0.3458],
        [0.6616, 0.3384],
        [0.6568, 0.3432],
        [0.6534, 0.3466],
        [0.6512, 0.3488],
        [0.6620, 0.3380],
        [0.6546, 0.3454],
        [0.6542, 0.3458],
        [0.6420, 0.3580],
        [0.6587, 0.3413],
        [0.6596, 0.3404],
        [0.6545, 0.3455],
        [0.6617, 0.3383],
        [0.6610, 0.3390],
        [0.6504, 0.3496],
        [0.6612, 0.3388],
        [0.6640, 0.3360],
        [0.6666, 0.3334],
        [0.6640, 0.3360],
        [0.6599, 0.3401],
        [0.6620, 0.3380],
        [0.6607, 0.3393],
        [0.6554, 0.3446],
        [0.6585, 0.3415],
        [0.6587, 0.3413],
        [0.6601, 0.3399],
        [0.6512, 0.3488],
        [0.6549, 0.3451],
        [0.6451, 0.3549],
        [0.6505, 0.3495],
        [0.6595, 0.3405],
        [0.6556, 0.3444],
        [0.6588, 0.3412],
        [0.6528, 0.3472],
        [0.6415, 0.3585],
        [0.6544, 0.3456],
        [0.6527, 0.3473],
        [0.6571, 0.3429],
        [0.6589, 0.3411],
        [0.6571, 0.3429],
        [0.6616, 0.3384],
        [0.6545, 0.3455],
        [0.6494, 0.3506],
        [0.6647, 0.3353],
        [0.6564, 0.3436],
        [0.6502, 0.3498],
        [0.6517, 0.3483],
        [0.6492, 0.3508],
        [0.6623, 0.3377],
        [0.6584, 0.3416],
        [0.6456, 0.3544],
        [0.6583, 0.3417],
        [0.6532, 0.3468],
        [0.6546, 0.3454],
        [0.6653, 0.3347],
        [0.6547, 0.3453],
        [0.6542, 0.3458],
        [0.6488, 0.3512],
        [0.6605, 0.3395],
        [0.6589, 0.3411],
        [0.6624, 0.3376],
        [0.6482, 0.3518],
        [0.6609, 0.3391],
        [0.6654, 0.3346],
        [0.6555, 0.3445],
        [0.6620, 0.3380],
        [0.6619, 0.3381],
        [0.6476, 0.3524],
        [0.6597, 0.3403],
        [0.6569, 0.3431],
        [0.6634, 0.3366],
        [0.6634, 0.3366],
        [0.6510, 0.3490],
        [0.6540, 0.3460],
        [0.6588, 0.3412],
        [0.6541, 0.3459],
        [0.6649, 0.3351],
        [0.6551, 0.3449],
        [0.6592, 0.3408],
        [0.6602, 0.3398],
        [0.6536, 0.3464],
        [0.6569, 0.3431],
        [0.6617, 0.3383],
        [0.6582, 0.3418],
        [0.6537, 0.3463],
        [0.6656, 0.3344],
        [0.6557, 0.3443],
        [0.6590, 0.3410],
        [0.6603, 0.3397],
        [0.6581, 0.3419],
        [0.6447, 0.3553],
        [0.6571, 0.3429],
        [0.6549, 0.3451],
        [0.6577, 0.3423],
        [0.6564, 0.3436],
        [0.6608, 0.3392],
        [0.6595, 0.3405],
        [0.6590, 0.3410],
        [0.6632, 0.3368],
        [0.6600, 0.3400],
        [0.6554, 0.3446],
        [0.6564, 0.3436],
        [0.6641, 0.3359],
        [0.6521, 0.3479],
        [0.6601, 0.3399],
        [0.6562, 0.3438],
        [0.6549, 0.3451],
        [0.6554, 0.3446],
        [0.6611, 0.3389],
        [0.6636, 0.3364],
        [0.6603, 0.3397],
        [0.6624, 0.3376],
        [0.6629, 0.3371],
        [0.6562, 0.3438],
        [0.6555, 0.3445],
        [0.6619, 0.3381],
        [0.6503, 0.3497],
        [0.6618, 0.3382],
        [0.6638, 0.3362],
        [0.6540, 0.3460],
        [0.6560, 0.3440],
        [0.6575, 0.3425],
        [0.6600, 0.3400],
        [0.6588, 0.3412],
        [0.6652, 0.3348],
        [0.6594, 0.3406],
        [0.6549, 0.3451],
        [0.6601, 0.3399],
        [0.6520, 0.3480],
        [0.6543, 0.3457],
        [0.6632, 0.3368],
        [0.6518, 0.3482],
        [0.6588, 0.3412],
        [0.6592, 0.3408],
        [0.6623, 0.3377],
        [0.6567, 0.3433]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0026 loss: 0.6688 acc_train: 0.6103 time: 0.1377s
tensor([[0.6546, 0.3454],
        [0.6637, 0.3363],
        [0.6590, 0.3410],
        [0.6557, 0.3443],
        [0.6626, 0.3374],
        [0.6530, 0.3470],
        [0.6493, 0.3507],
        [0.6575, 0.3425],
        [0.6589, 0.3411],
        [0.6523, 0.3477],
        [0.6568, 0.3432],
        [0.6542, 0.3458],
        [0.6533, 0.3467],
        [0.6517, 0.3483],
        [0.6596, 0.3404],
        [0.6518, 0.3482],
        [0.6654, 0.3346],
        [0.6551, 0.3449],
        [0.6587, 0.3413],
        [0.6519, 0.3481],
        [0.6629, 0.3371],
        [0.6528, 0.3472],
        [0.6618, 0.3382],
        [0.6603, 0.3397],
        [0.6563, 0.3437],
        [0.6550, 0.3450],
        [0.6592, 0.3408],
        [0.6587, 0.3413],
        [0.6533, 0.3467],
        [0.6539, 0.3461],
        [0.6549, 0.3451],
        [0.6537, 0.3463],
        [0.6552, 0.3448],
        [0.6534, 0.3466],
        [0.6618, 0.3382],
        [0.6458, 0.3542],
        [0.6532, 0.3468],
        [0.6537, 0.3463],
        [0.6572, 0.3428],
        [0.6506, 0.3494],
        [0.6598, 0.3402],
        [0.6562, 0.3438],
        [0.6424, 0.3576],
        [0.6599, 0.3401],
        [0.6617, 0.3383],
        [0.6537, 0.3463],
        [0.6610, 0.3390],
        [0.6591, 0.3409],
        [0.6589, 0.3411],
        [0.6530, 0.3470],
        [0.6546, 0.3454],
        [0.6560, 0.3440],
        [0.6542, 0.3458],
        [0.6625, 0.3375],
        [0.6578, 0.3422],
        [0.6586, 0.3414],
        [0.6631, 0.3369],
        [0.6560, 0.3440],
        [0.6563, 0.3437],
        [0.6537, 0.3463],
        [0.6490, 0.3510],
        [0.6533, 0.3467],
        [0.6608, 0.3392],
        [0.6565, 0.3435],
        [0.6577, 0.3423],
        [0.6580, 0.3420],
        [0.6572, 0.3428],
        [0.6566, 0.3434],
        [0.6559, 0.3441],
        [0.6581, 0.3419],
        [0.6516, 0.3484],
        [0.6497, 0.3503],
        [0.6574, 0.3426],
        [0.6580, 0.3420],
        [0.6547, 0.3453],
        [0.6545, 0.3455],
        [0.6565, 0.3435],
        [0.6552, 0.3448],
        [0.6624, 0.3376],
        [0.6504, 0.3496],
        [0.6488, 0.3512],
        [0.6532, 0.3468],
        [0.6526, 0.3474],
        [0.6532, 0.3468],
        [0.6542, 0.3458],
        [0.6544, 0.3456],
        [0.6615, 0.3385],
        [0.6571, 0.3429],
        [0.6571, 0.3429],
        [0.6540, 0.3460],
        [0.6567, 0.3433],
        [0.6530, 0.3470],
        [0.6567, 0.3433],
        [0.6477, 0.3523],
        [0.6559, 0.3441],
        [0.6630, 0.3370],
        [0.6599, 0.3401],
        [0.6550, 0.3450],
        [0.6619, 0.3381],
        [0.6539, 0.3461],
        [0.6594, 0.3406],
        [0.6535, 0.3465],
        [0.6530, 0.3470],
        [0.6522, 0.3478],
        [0.6644, 0.3356],
        [0.6524, 0.3476],
        [0.6624, 0.3376],
        [0.6601, 0.3399],
        [0.6523, 0.3477],
        [0.6615, 0.3385],
        [0.6430, 0.3570],
        [0.6622, 0.3378],
        [0.6599, 0.3401],
        [0.6602, 0.3398],
        [0.6547, 0.3453],
        [0.6484, 0.3516],
        [0.6560, 0.3440],
        [0.6602, 0.3398],
        [0.6615, 0.3385],
        [0.6647, 0.3353],
        [0.6522, 0.3478],
        [0.6571, 0.3429],
        [0.6568, 0.3432],
        [0.6541, 0.3459],
        [0.6517, 0.3483],
        [0.6560, 0.3440],
        [0.6516, 0.3484],
        [0.6571, 0.3429],
        [0.6524, 0.3476],
        [0.6543, 0.3457],
        [0.6550, 0.3450],
        [0.6524, 0.3476],
        [0.6575, 0.3425],
        [0.6539, 0.3461],
        [0.6592, 0.3408],
        [0.6583, 0.3417],
        [0.6543, 0.3457],
        [0.6608, 0.3392],
        [0.6566, 0.3434],
        [0.6536, 0.3464],
        [0.6516, 0.3484],
        [0.6610, 0.3390],
        [0.6545, 0.3455],
        [0.6544, 0.3456],
        [0.6441, 0.3559],
        [0.6581, 0.3419],
        [0.6583, 0.3417],
        [0.6545, 0.3455],
        [0.6607, 0.3393],
        [0.6604, 0.3396],
        [0.6512, 0.3488],
        [0.6604, 0.3396],
        [0.6623, 0.3377],
        [0.6648, 0.3352],
        [0.6629, 0.3371],
        [0.6592, 0.3408],
        [0.6613, 0.3387],
        [0.6599, 0.3401],
        [0.6552, 0.3448],
        [0.6579, 0.3421],
        [0.6584, 0.3416],
        [0.6595, 0.3405],
        [0.6515, 0.3485],
        [0.6544, 0.3456],
        [0.6456, 0.3544],
        [0.6514, 0.3486],
        [0.6588, 0.3412],
        [0.6554, 0.3446],
        [0.6584, 0.3416],
        [0.6534, 0.3466],
        [0.6424, 0.3576],
        [0.6543, 0.3457],
        [0.6524, 0.3476],
        [0.6564, 0.3436],
        [0.6584, 0.3416],
        [0.6567, 0.3433],
        [0.6604, 0.3396],
        [0.6546, 0.3454],
        [0.6508, 0.3492],
        [0.6631, 0.3369],
        [0.6564, 0.3436],
        [0.6507, 0.3493],
        [0.6518, 0.3482],
        [0.6502, 0.3498],
        [0.6612, 0.3388],
        [0.6578, 0.3422],
        [0.6471, 0.3529],
        [0.6581, 0.3419],
        [0.6539, 0.3461],
        [0.6545, 0.3455],
        [0.6640, 0.3360],
        [0.6549, 0.3451],
        [0.6542, 0.3458],
        [0.6501, 0.3499],
        [0.6600, 0.3400],
        [0.6583, 0.3417],
        [0.6612, 0.3388],
        [0.6495, 0.3505],
        [0.6599, 0.3401],
        [0.6638, 0.3362],
        [0.6558, 0.3442],
        [0.6608, 0.3392],
        [0.6614, 0.3386],
        [0.6488, 0.3512],
        [0.6589, 0.3411],
        [0.6569, 0.3431],
        [0.6617, 0.3383],
        [0.6622, 0.3378],
        [0.6518, 0.3482],
        [0.6543, 0.3457],
        [0.6584, 0.3416],
        [0.6542, 0.3458],
        [0.6633, 0.3367],
        [0.6549, 0.3451],
        [0.6582, 0.3418],
        [0.6595, 0.3405],
        [0.6540, 0.3460],
        [0.6568, 0.3432],
        [0.6600, 0.3400],
        [0.6574, 0.3426],
        [0.6540, 0.3460],
        [0.6639, 0.3361],
        [0.6554, 0.3446],
        [0.6584, 0.3416],
        [0.6596, 0.3404],
        [0.6579, 0.3421],
        [0.6456, 0.3544],
        [0.6566, 0.3434],
        [0.6546, 0.3454],
        [0.6570, 0.3430],
        [0.6563, 0.3437],
        [0.6597, 0.3403],
        [0.6585, 0.3415],
        [0.6589, 0.3411],
        [0.6617, 0.3383],
        [0.6594, 0.3406],
        [0.6557, 0.3443],
        [0.6564, 0.3436],
        [0.6629, 0.3371],
        [0.6529, 0.3471],
        [0.6599, 0.3401],
        [0.6563, 0.3437],
        [0.6549, 0.3451],
        [0.6548, 0.3452],
        [0.6604, 0.3396],
        [0.6620, 0.3380],
        [0.6597, 0.3403],
        [0.6611, 0.3389],
        [0.6612, 0.3388],
        [0.6560, 0.3440],
        [0.6557, 0.3443],
        [0.6606, 0.3394],
        [0.6508, 0.3492],
        [0.6606, 0.3394],
        [0.6625, 0.3375],
        [0.6540, 0.3460],
        [0.6556, 0.3444],
        [0.6569, 0.3431],
        [0.6596, 0.3404],
        [0.6581, 0.3419],
        [0.6635, 0.3365],
        [0.6583, 0.3417],
        [0.6545, 0.3455],
        [0.6592, 0.3408],
        [0.6523, 0.3477],
        [0.6543, 0.3457],
        [0.6618, 0.3382],
        [0.6520, 0.3480],
        [0.6580, 0.3420],
        [0.6582, 0.3418],
        [0.6611, 0.3389],
        [0.6563, 0.3437]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0027 loss: 0.6692 acc_train: 0.6103 time: 0.1194s
tensor([[0.6547, 0.3453],
        [0.6626, 0.3374],
        [0.6587, 0.3413],
        [0.6559, 0.3441],
        [0.6622, 0.3378],
        [0.6529, 0.3471],
        [0.6501, 0.3499],
        [0.6574, 0.3426],
        [0.6588, 0.3412],
        [0.6525, 0.3475],
        [0.6565, 0.3435],
        [0.6542, 0.3458],
        [0.6536, 0.3464],
        [0.6522, 0.3478],
        [0.6595, 0.3405],
        [0.6524, 0.3476],
        [0.6645, 0.3355],
        [0.6554, 0.3446],
        [0.6583, 0.3417],
        [0.6521, 0.3479],
        [0.6618, 0.3382],
        [0.6526, 0.3474],
        [0.6608, 0.3392],
        [0.6597, 0.3403],
        [0.6559, 0.3441],
        [0.6551, 0.3449],
        [0.6587, 0.3413],
        [0.6581, 0.3419],
        [0.6538, 0.3462],
        [0.6540, 0.3460],
        [0.6546, 0.3454],
        [0.6541, 0.3459],
        [0.6557, 0.3443],
        [0.6536, 0.3464],
        [0.6612, 0.3388],
        [0.6460, 0.3540],
        [0.6534, 0.3466],
        [0.6542, 0.3458],
        [0.6570, 0.3430],
        [0.6516, 0.3484],
        [0.6591, 0.3409],
        [0.6564, 0.3436],
        [0.6433, 0.3567],
        [0.6595, 0.3405],
        [0.6610, 0.3390],
        [0.6539, 0.3461],
        [0.6604, 0.3396],
        [0.6587, 0.3413],
        [0.6586, 0.3414],
        [0.6537, 0.3463],
        [0.6547, 0.3453],
        [0.6563, 0.3437],
        [0.6542, 0.3458],
        [0.6612, 0.3388],
        [0.6573, 0.3427],
        [0.6583, 0.3417],
        [0.6627, 0.3373],
        [0.6564, 0.3436],
        [0.6565, 0.3435],
        [0.6537, 0.3463],
        [0.6497, 0.3503],
        [0.6534, 0.3466],
        [0.6602, 0.3398],
        [0.6565, 0.3435],
        [0.6576, 0.3424],
        [0.6579, 0.3421],
        [0.6571, 0.3429],
        [0.6568, 0.3432],
        [0.6562, 0.3438],
        [0.6578, 0.3422],
        [0.6524, 0.3476],
        [0.6507, 0.3493],
        [0.6574, 0.3426],
        [0.6575, 0.3425],
        [0.6548, 0.3452],
        [0.6547, 0.3453],
        [0.6565, 0.3435],
        [0.6555, 0.3445],
        [0.6621, 0.3379],
        [0.6512, 0.3488],
        [0.6495, 0.3505],
        [0.6535, 0.3465],
        [0.6528, 0.3472],
        [0.6538, 0.3462],
        [0.6542, 0.3458],
        [0.6545, 0.3455],
        [0.6605, 0.3395],
        [0.6568, 0.3432],
        [0.6569, 0.3431],
        [0.6541, 0.3459],
        [0.6565, 0.3435],
        [0.6530, 0.3470],
        [0.6565, 0.3435],
        [0.6487, 0.3513],
        [0.6556, 0.3444],
        [0.6620, 0.3380],
        [0.6593, 0.3407],
        [0.6551, 0.3449],
        [0.6611, 0.3389],
        [0.6537, 0.3463],
        [0.6589, 0.3411],
        [0.6538, 0.3462],
        [0.6532, 0.3468],
        [0.6526, 0.3474],
        [0.6635, 0.3365],
        [0.6528, 0.3472],
        [0.6617, 0.3383],
        [0.6595, 0.3405],
        [0.6527, 0.3473],
        [0.6609, 0.3391],
        [0.6438, 0.3562],
        [0.6615, 0.3385],
        [0.6594, 0.3406],
        [0.6598, 0.3402],
        [0.6546, 0.3454],
        [0.6491, 0.3509],
        [0.6559, 0.3441],
        [0.6597, 0.3403],
        [0.6611, 0.3389],
        [0.6637, 0.3363],
        [0.6522, 0.3478],
        [0.6569, 0.3431],
        [0.6569, 0.3431],
        [0.6545, 0.3455],
        [0.6522, 0.3478],
        [0.6561, 0.3439],
        [0.6523, 0.3477],
        [0.6568, 0.3432],
        [0.6528, 0.3472],
        [0.6548, 0.3452],
        [0.6553, 0.3447],
        [0.6525, 0.3475],
        [0.6574, 0.3426],
        [0.6540, 0.3460],
        [0.6586, 0.3414],
        [0.6580, 0.3420],
        [0.6543, 0.3457],
        [0.6603, 0.3397],
        [0.6566, 0.3434],
        [0.6536, 0.3464],
        [0.6520, 0.3480],
        [0.6603, 0.3397],
        [0.6548, 0.3452],
        [0.6546, 0.3454],
        [0.6459, 0.3541],
        [0.6576, 0.3424],
        [0.6574, 0.3426],
        [0.6545, 0.3455],
        [0.6601, 0.3399],
        [0.6599, 0.3401],
        [0.6518, 0.3482],
        [0.6598, 0.3402],
        [0.6613, 0.3387],
        [0.6636, 0.3364],
        [0.6623, 0.3377],
        [0.6589, 0.3411],
        [0.6609, 0.3391],
        [0.6596, 0.3404],
        [0.6551, 0.3449],
        [0.6577, 0.3423],
        [0.6583, 0.3417],
        [0.6591, 0.3409],
        [0.6518, 0.3482],
        [0.6541, 0.3459],
        [0.6463, 0.3537],
        [0.6523, 0.3477],
        [0.6584, 0.3416],
        [0.6553, 0.3447],
        [0.6582, 0.3418],
        [0.6540, 0.3460],
        [0.6435, 0.3565],
        [0.6544, 0.3456],
        [0.6525, 0.3475],
        [0.6559, 0.3441],
        [0.6582, 0.3418],
        [0.6564, 0.3436],
        [0.6597, 0.3403],
        [0.6547, 0.3453],
        [0.6519, 0.3481],
        [0.6620, 0.3380],
        [0.6561, 0.3439],
        [0.6511, 0.3489],
        [0.6520, 0.3480],
        [0.6510, 0.3490],
        [0.6605, 0.3395],
        [0.6576, 0.3424],
        [0.6482, 0.3518],
        [0.6580, 0.3420],
        [0.6543, 0.3457],
        [0.6545, 0.3455],
        [0.6630, 0.3370],
        [0.6550, 0.3450],
        [0.6541, 0.3459],
        [0.6510, 0.3490],
        [0.6598, 0.3402],
        [0.6578, 0.3422],
        [0.6605, 0.3395],
        [0.6504, 0.3496],
        [0.6594, 0.3406],
        [0.6627, 0.3373],
        [0.6561, 0.3439],
        [0.6599, 0.3401],
        [0.6611, 0.3389],
        [0.6497, 0.3503],
        [0.6585, 0.3415],
        [0.6569, 0.3431],
        [0.6605, 0.3395],
        [0.6615, 0.3385],
        [0.6525, 0.3475],
        [0.6546, 0.3454],
        [0.6582, 0.3418],
        [0.6545, 0.3455],
        [0.6622, 0.3378],
        [0.6547, 0.3453],
        [0.6576, 0.3424],
        [0.6592, 0.3408],
        [0.6544, 0.3456],
        [0.6566, 0.3434],
        [0.6588, 0.3412],
        [0.6568, 0.3432],
        [0.6543, 0.3457],
        [0.6629, 0.3371],
        [0.6553, 0.3447],
        [0.6582, 0.3418],
        [0.6590, 0.3410],
        [0.6579, 0.3421],
        [0.6466, 0.3534],
        [0.6564, 0.3436],
        [0.6544, 0.3456],
        [0.6567, 0.3433],
        [0.6564, 0.3436],
        [0.6591, 0.3409],
        [0.6581, 0.3419],
        [0.6589, 0.3411],
        [0.6605, 0.3395],
        [0.6591, 0.3409],
        [0.6560, 0.3440],
        [0.6566, 0.3434],
        [0.6622, 0.3378],
        [0.6533, 0.3467],
        [0.6598, 0.3402],
        [0.6567, 0.3433],
        [0.6549, 0.3451],
        [0.6543, 0.3457],
        [0.6600, 0.3400],
        [0.6609, 0.3391],
        [0.6592, 0.3408],
        [0.6603, 0.3397],
        [0.6601, 0.3399],
        [0.6558, 0.3442],
        [0.6559, 0.3441],
        [0.6598, 0.3402],
        [0.6513, 0.3487],
        [0.6597, 0.3403],
        [0.6617, 0.3383],
        [0.6541, 0.3459],
        [0.6555, 0.3445],
        [0.6567, 0.3433],
        [0.6594, 0.3406],
        [0.6578, 0.3422],
        [0.6625, 0.3375],
        [0.6577, 0.3423],
        [0.6543, 0.3457],
        [0.6586, 0.3414],
        [0.6527, 0.3473],
        [0.6547, 0.3453],
        [0.6608, 0.3392],
        [0.6524, 0.3476],
        [0.6574, 0.3426],
        [0.6577, 0.3423],
        [0.6604, 0.3396],
        [0.6563, 0.3437]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0028 loss: 0.6695 acc_train: 0.6103 time: 0.1252s
tensor([[0.6551, 0.3449],
        [0.6622, 0.3378],
        [0.6587, 0.3413],
        [0.6564, 0.3436],
        [0.6622, 0.3378],
        [0.6532, 0.3468],
        [0.6509, 0.3491],
        [0.6577, 0.3423],
        [0.6591, 0.3409],
        [0.6529, 0.3471],
        [0.6565, 0.3435],
        [0.6545, 0.3455],
        [0.6542, 0.3458],
        [0.6527, 0.3473],
        [0.6597, 0.3403],
        [0.6531, 0.3469],
        [0.6640, 0.3360],
        [0.6559, 0.3441],
        [0.6582, 0.3418],
        [0.6524, 0.3476],
        [0.6613, 0.3387],
        [0.6526, 0.3474],
        [0.6604, 0.3396],
        [0.6594, 0.3406],
        [0.6561, 0.3439],
        [0.6552, 0.3448],
        [0.6585, 0.3415],
        [0.6581, 0.3419],
        [0.6545, 0.3455],
        [0.6543, 0.3457],
        [0.6548, 0.3452],
        [0.6544, 0.3456],
        [0.6561, 0.3439],
        [0.6541, 0.3459],
        [0.6611, 0.3389],
        [0.6466, 0.3534],
        [0.6538, 0.3462],
        [0.6550, 0.3450],
        [0.6573, 0.3427],
        [0.6527, 0.3473],
        [0.6590, 0.3410],
        [0.6567, 0.3433],
        [0.6443, 0.3557],
        [0.6595, 0.3405],
        [0.6606, 0.3394],
        [0.6543, 0.3457],
        [0.6602, 0.3398],
        [0.6588, 0.3412],
        [0.6586, 0.3414],
        [0.6544, 0.3456],
        [0.6551, 0.3449],
        [0.6569, 0.3431],
        [0.6542, 0.3458],
        [0.6605, 0.3395],
        [0.6574, 0.3426],
        [0.6584, 0.3416],
        [0.6626, 0.3374],
        [0.6568, 0.3432],
        [0.6569, 0.3431],
        [0.6540, 0.3460],
        [0.6505, 0.3495],
        [0.6537, 0.3463],
        [0.6601, 0.3399],
        [0.6568, 0.3432],
        [0.6578, 0.3422],
        [0.6581, 0.3419],
        [0.6572, 0.3428],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6577, 0.3423],
        [0.6532, 0.3468],
        [0.6517, 0.3483],
        [0.6575, 0.3425],
        [0.6574, 0.3426],
        [0.6552, 0.3448],
        [0.6549, 0.3451],
        [0.6565, 0.3435],
        [0.6559, 0.3441],
        [0.6619, 0.3381],
        [0.6520, 0.3480],
        [0.6503, 0.3497],
        [0.6539, 0.3461],
        [0.6532, 0.3468],
        [0.6545, 0.3455],
        [0.6545, 0.3455],
        [0.6548, 0.3452],
        [0.6599, 0.3401],
        [0.6569, 0.3431],
        [0.6573, 0.3427],
        [0.6545, 0.3455],
        [0.6565, 0.3435],
        [0.6534, 0.3466],
        [0.6568, 0.3432],
        [0.6499, 0.3501],
        [0.6557, 0.3443],
        [0.6616, 0.3384],
        [0.6591, 0.3409],
        [0.6553, 0.3447],
        [0.6609, 0.3391],
        [0.6537, 0.3463],
        [0.6589, 0.3411],
        [0.6542, 0.3458],
        [0.6534, 0.3466],
        [0.6533, 0.3467],
        [0.6632, 0.3368],
        [0.6535, 0.3465],
        [0.6615, 0.3385],
        [0.6595, 0.3405],
        [0.6531, 0.3469],
        [0.6608, 0.3392],
        [0.6447, 0.3553],
        [0.6614, 0.3386],
        [0.6594, 0.3406],
        [0.6600, 0.3400],
        [0.6548, 0.3452],
        [0.6500, 0.3500],
        [0.6559, 0.3441],
        [0.6597, 0.3403],
        [0.6613, 0.3387],
        [0.6632, 0.3368],
        [0.6524, 0.3476],
        [0.6567, 0.3433],
        [0.6570, 0.3430],
        [0.6549, 0.3451],
        [0.6529, 0.3471],
        [0.6562, 0.3438],
        [0.6529, 0.3471],
        [0.6569, 0.3431],
        [0.6533, 0.3467],
        [0.6553, 0.3447],
        [0.6558, 0.3442],
        [0.6529, 0.3471],
        [0.6578, 0.3422],
        [0.6543, 0.3457],
        [0.6585, 0.3415],
        [0.6581, 0.3419],
        [0.6546, 0.3454],
        [0.6601, 0.3399],
        [0.6571, 0.3429],
        [0.6539, 0.3461],
        [0.6525, 0.3475],
        [0.6599, 0.3401],
        [0.6554, 0.3446],
        [0.6551, 0.3449],
        [0.6474, 0.3526],
        [0.6574, 0.3426],
        [0.6571, 0.3429],
        [0.6547, 0.3453],
        [0.6599, 0.3401],
        [0.6598, 0.3402],
        [0.6525, 0.3475],
        [0.6596, 0.3404],
        [0.6608, 0.3392],
        [0.6631, 0.3369],
        [0.6622, 0.3378],
        [0.6589, 0.3411],
        [0.6609, 0.3391],
        [0.6598, 0.3402],
        [0.6554, 0.3446],
        [0.6580, 0.3420],
        [0.6584, 0.3416],
        [0.6591, 0.3409],
        [0.6524, 0.3476],
        [0.6542, 0.3458],
        [0.6474, 0.3526],
        [0.6533, 0.3467],
        [0.6584, 0.3416],
        [0.6553, 0.3447],
        [0.6581, 0.3419],
        [0.6547, 0.3453],
        [0.6449, 0.3551],
        [0.6547, 0.3453],
        [0.6531, 0.3469],
        [0.6556, 0.3444],
        [0.6585, 0.3415],
        [0.6564, 0.3436],
        [0.6596, 0.3404],
        [0.6551, 0.3449],
        [0.6528, 0.3472],
        [0.6613, 0.3387],
        [0.6562, 0.3438],
        [0.6517, 0.3483],
        [0.6525, 0.3475],
        [0.6516, 0.3484],
        [0.6603, 0.3397],
        [0.6577, 0.3423],
        [0.6491, 0.3509],
        [0.6582, 0.3418],
        [0.6547, 0.3453],
        [0.6547, 0.3453],
        [0.6625, 0.3375],
        [0.6552, 0.3448],
        [0.6542, 0.3458],
        [0.6518, 0.3482],
        [0.6599, 0.3401],
        [0.6577, 0.3423],
        [0.6604, 0.3396],
        [0.6512, 0.3488],
        [0.6592, 0.3408],
        [0.6623, 0.3377],
        [0.6564, 0.3436],
        [0.6595, 0.3405],
        [0.6612, 0.3388],
        [0.6507, 0.3493],
        [0.6585, 0.3415],
        [0.6571, 0.3429],
        [0.6599, 0.3401],
        [0.6614, 0.3386],
        [0.6533, 0.3467],
        [0.6550, 0.3450],
        [0.6583, 0.3417],
        [0.6549, 0.3451],
        [0.6617, 0.3383],
        [0.6547, 0.3453],
        [0.6576, 0.3424],
        [0.6593, 0.3407],
        [0.6548, 0.3452],
        [0.6566, 0.3434],
        [0.6582, 0.3418],
        [0.6567, 0.3433],
        [0.6548, 0.3452],
        [0.6625, 0.3375],
        [0.6554, 0.3446],
        [0.6582, 0.3418],
        [0.6589, 0.3411],
        [0.6583, 0.3417],
        [0.6478, 0.3522],
        [0.6565, 0.3435],
        [0.6545, 0.3455],
        [0.6568, 0.3432],
        [0.6570, 0.3430],
        [0.6591, 0.3409],
        [0.6582, 0.3418],
        [0.6590, 0.3410],
        [0.6598, 0.3402],
        [0.6592, 0.3408],
        [0.6565, 0.3435],
        [0.6570, 0.3430],
        [0.6620, 0.3380],
        [0.6537, 0.3463],
        [0.6599, 0.3401],
        [0.6574, 0.3426],
        [0.6550, 0.3450],
        [0.6541, 0.3459],
        [0.6600, 0.3400],
        [0.6604, 0.3396],
        [0.6592, 0.3408],
        [0.6600, 0.3400],
        [0.6598, 0.3402],
        [0.6560, 0.3440],
        [0.6563, 0.3437],
        [0.6594, 0.3406],
        [0.6518, 0.3482],
        [0.6593, 0.3407],
        [0.6615, 0.3385],
        [0.6546, 0.3454],
        [0.6557, 0.3443],
        [0.6570, 0.3430],
        [0.6595, 0.3405],
        [0.6579, 0.3421],
        [0.6622, 0.3378],
        [0.6578, 0.3422],
        [0.6546, 0.3454],
        [0.6585, 0.3415],
        [0.6533, 0.3467],
        [0.6553, 0.3447],
        [0.6605, 0.3395],
        [0.6529, 0.3471],
        [0.6569, 0.3431],
        [0.6577, 0.3423],
        [0.6602, 0.3398],
        [0.6566, 0.3434]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0029 loss: 0.6696 acc_train: 0.6103 time: 0.1225s
tensor([[0.6559, 0.3441],
        [0.6623, 0.3377],
        [0.6590, 0.3410],
        [0.6572, 0.3428],
        [0.6627, 0.3373],
        [0.6538, 0.3462],
        [0.6518, 0.3482],
        [0.6583, 0.3417],
        [0.6597, 0.3403],
        [0.6536, 0.3464],
        [0.6570, 0.3430],
        [0.6552, 0.3448],
        [0.6549, 0.3451],
        [0.6533, 0.3467],
        [0.6602, 0.3398],
        [0.6540, 0.3460],
        [0.6640, 0.3360],
        [0.6567, 0.3433],
        [0.6586, 0.3414],
        [0.6529, 0.3471],
        [0.6615, 0.3385],
        [0.6530, 0.3470],
        [0.6606, 0.3394],
        [0.6596, 0.3404],
        [0.6567, 0.3433],
        [0.6556, 0.3444],
        [0.6585, 0.3415],
        [0.6587, 0.3413],
        [0.6554, 0.3446],
        [0.6549, 0.3451],
        [0.6555, 0.3445],
        [0.6548, 0.3452],
        [0.6568, 0.3432],
        [0.6548, 0.3452],
        [0.6614, 0.3386],
        [0.6477, 0.3523],
        [0.6546, 0.3454],
        [0.6559, 0.3441],
        [0.6580, 0.3420],
        [0.6540, 0.3460],
        [0.6595, 0.3405],
        [0.6572, 0.3428],
        [0.6456, 0.3544],
        [0.6599, 0.3401],
        [0.6607, 0.3393],
        [0.6549, 0.3451],
        [0.6606, 0.3394],
        [0.6593, 0.3407],
        [0.6590, 0.3410],
        [0.6551, 0.3449],
        [0.6559, 0.3441],
        [0.6576, 0.3424],
        [0.6544, 0.3456],
        [0.6604, 0.3396],
        [0.6579, 0.3421],
        [0.6589, 0.3411],
        [0.6629, 0.3371],
        [0.6573, 0.3427],
        [0.6575, 0.3425],
        [0.6548, 0.3452],
        [0.6516, 0.3484],
        [0.6544, 0.3456],
        [0.6604, 0.3396],
        [0.6575, 0.3425],
        [0.6583, 0.3417],
        [0.6586, 0.3414],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6578, 0.3422],
        [0.6580, 0.3420],
        [0.6543, 0.3457],
        [0.6529, 0.3471],
        [0.6578, 0.3422],
        [0.6579, 0.3421],
        [0.6559, 0.3441],
        [0.6555, 0.3445],
        [0.6568, 0.3432],
        [0.6567, 0.3433],
        [0.6619, 0.3381],
        [0.6528, 0.3472],
        [0.6513, 0.3487],
        [0.6546, 0.3454],
        [0.6539, 0.3461],
        [0.6553, 0.3447],
        [0.6552, 0.3448],
        [0.6554, 0.3446],
        [0.6598, 0.3402],
        [0.6573, 0.3427],
        [0.6580, 0.3420],
        [0.6552, 0.3448],
        [0.6567, 0.3433],
        [0.6542, 0.3458],
        [0.6575, 0.3425],
        [0.6511, 0.3489],
        [0.6562, 0.3438],
        [0.6616, 0.3384],
        [0.6593, 0.3407],
        [0.6557, 0.3443],
        [0.6612, 0.3388],
        [0.6540, 0.3460],
        [0.6595, 0.3405],
        [0.6547, 0.3453],
        [0.6539, 0.3461],
        [0.6542, 0.3458],
        [0.6635, 0.3365],
        [0.6544, 0.3456],
        [0.6617, 0.3383],
        [0.6599, 0.3401],
        [0.6539, 0.3461],
        [0.6612, 0.3388],
        [0.6460, 0.3540],
        [0.6617, 0.3383],
        [0.6599, 0.3401],
        [0.6606, 0.3394],
        [0.6553, 0.3447],
        [0.6510, 0.3490],
        [0.6563, 0.3437],
        [0.6600, 0.3400],
        [0.6618, 0.3382],
        [0.6633, 0.3367],
        [0.6529, 0.3471],
        [0.6569, 0.3431],
        [0.6574, 0.3426],
        [0.6557, 0.3443],
        [0.6538, 0.3462],
        [0.6566, 0.3434],
        [0.6537, 0.3463],
        [0.6573, 0.3427],
        [0.6541, 0.3459],
        [0.6559, 0.3441],
        [0.6567, 0.3433],
        [0.6535, 0.3465],
        [0.6586, 0.3414],
        [0.6549, 0.3451],
        [0.6589, 0.3411],
        [0.6584, 0.3416],
        [0.6552, 0.3448],
        [0.6604, 0.3396],
        [0.6578, 0.3422],
        [0.6544, 0.3456],
        [0.6533, 0.3467],
        [0.6598, 0.3402],
        [0.6563, 0.3437],
        [0.6559, 0.3441],
        [0.6489, 0.3511],
        [0.6576, 0.3424],
        [0.6575, 0.3425],
        [0.6553, 0.3447],
        [0.6602, 0.3398],
        [0.6602, 0.3398],
        [0.6533, 0.3467],
        [0.6598, 0.3402],
        [0.6610, 0.3390],
        [0.6632, 0.3368],
        [0.6624, 0.3376],
        [0.6593, 0.3407],
        [0.6613, 0.3387],
        [0.6603, 0.3397],
        [0.6559, 0.3441],
        [0.6586, 0.3414],
        [0.6591, 0.3409],
        [0.6595, 0.3405],
        [0.6531, 0.3469],
        [0.6547, 0.3453],
        [0.6489, 0.3511],
        [0.6543, 0.3457],
        [0.6590, 0.3410],
        [0.6558, 0.3442],
        [0.6583, 0.3417],
        [0.6554, 0.3446],
        [0.6464, 0.3536],
        [0.6553, 0.3447],
        [0.6541, 0.3459],
        [0.6558, 0.3442],
        [0.6592, 0.3408],
        [0.6567, 0.3433],
        [0.6601, 0.3399],
        [0.6558, 0.3442],
        [0.6538, 0.3462],
        [0.6611, 0.3389],
        [0.6566, 0.3434],
        [0.6525, 0.3475],
        [0.6534, 0.3466],
        [0.6523, 0.3477],
        [0.6606, 0.3394],
        [0.6582, 0.3418],
        [0.6501, 0.3499],
        [0.6586, 0.3414],
        [0.6551, 0.3449],
        [0.6552, 0.3448],
        [0.6623, 0.3377],
        [0.6556, 0.3444],
        [0.6546, 0.3454],
        [0.6526, 0.3474],
        [0.6602, 0.3398],
        [0.6580, 0.3420],
        [0.6611, 0.3389],
        [0.6521, 0.3479],
        [0.6596, 0.3404],
        [0.6624, 0.3376],
        [0.6569, 0.3431],
        [0.6598, 0.3402],
        [0.6617, 0.3383],
        [0.6517, 0.3483],
        [0.6591, 0.3409],
        [0.6575, 0.3425],
        [0.6599, 0.3401],
        [0.6619, 0.3381],
        [0.6542, 0.3458],
        [0.6557, 0.3443],
        [0.6588, 0.3412],
        [0.6555, 0.3445],
        [0.6617, 0.3383],
        [0.6550, 0.3450],
        [0.6581, 0.3419],
        [0.6597, 0.3403],
        [0.6555, 0.3445],
        [0.6568, 0.3432],
        [0.6580, 0.3420],
        [0.6572, 0.3428],
        [0.6555, 0.3445],
        [0.6627, 0.3373],
        [0.6558, 0.3442],
        [0.6587, 0.3413],
        [0.6592, 0.3408],
        [0.6590, 0.3410],
        [0.6492, 0.3508],
        [0.6569, 0.3431],
        [0.6549, 0.3451],
        [0.6572, 0.3428],
        [0.6578, 0.3422],
        [0.6596, 0.3404],
        [0.6589, 0.3411],
        [0.6593, 0.3407],
        [0.6596, 0.3404],
        [0.6598, 0.3402],
        [0.6572, 0.3428],
        [0.6576, 0.3424],
        [0.6622, 0.3378],
        [0.6543, 0.3457],
        [0.6603, 0.3397],
        [0.6583, 0.3417],
        [0.6554, 0.3446],
        [0.6544, 0.3456],
        [0.6604, 0.3396],
        [0.6605, 0.3395],
        [0.6595, 0.3405],
        [0.6603, 0.3397],
        [0.6601, 0.3399],
        [0.6565, 0.3435],
        [0.6570, 0.3430],
        [0.6597, 0.3403],
        [0.6526, 0.3474],
        [0.6596, 0.3404],
        [0.6617, 0.3383],
        [0.6554, 0.3446],
        [0.6563, 0.3437],
        [0.6577, 0.3423],
        [0.6600, 0.3400],
        [0.6584, 0.3416],
        [0.6625, 0.3375],
        [0.6585, 0.3415],
        [0.6554, 0.3446],
        [0.6589, 0.3411],
        [0.6542, 0.3458],
        [0.6562, 0.3438],
        [0.6608, 0.3392],
        [0.6537, 0.3463],
        [0.6569, 0.3431],
        [0.6582, 0.3418],
        [0.6605, 0.3395],
        [0.6573, 0.3427]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0030 loss: 0.6696 acc_train: 0.6103 time: 0.1304s
tensor([[0.6571, 0.3429],
        [0.6628, 0.3372],
        [0.6596, 0.3404],
        [0.6583, 0.3417],
        [0.6634, 0.3366],
        [0.6547, 0.3453],
        [0.6528, 0.3472],
        [0.6592, 0.3408],
        [0.6606, 0.3394],
        [0.6547, 0.3453],
        [0.6580, 0.3420],
        [0.6563, 0.3437],
        [0.6558, 0.3442],
        [0.6540, 0.3460],
        [0.6610, 0.3390],
        [0.6551, 0.3449],
        [0.6643, 0.3357],
        [0.6578, 0.3422],
        [0.6593, 0.3407],
        [0.6537, 0.3463],
        [0.6621, 0.3379],
        [0.6537, 0.3463],
        [0.6613, 0.3387],
        [0.6602, 0.3398],
        [0.6575, 0.3425],
        [0.6562, 0.3438],
        [0.6589, 0.3411],
        [0.6597, 0.3403],
        [0.6565, 0.3435],
        [0.6558, 0.3442],
        [0.6566, 0.3434],
        [0.6554, 0.3446],
        [0.6577, 0.3423],
        [0.6559, 0.3441],
        [0.6621, 0.3379],
        [0.6491, 0.3509],
        [0.6557, 0.3443],
        [0.6570, 0.3430],
        [0.6590, 0.3410],
        [0.6554, 0.3446],
        [0.6605, 0.3395],
        [0.6580, 0.3420],
        [0.6471, 0.3529],
        [0.6606, 0.3394],
        [0.6611, 0.3389],
        [0.6558, 0.3442],
        [0.6614, 0.3386],
        [0.6603, 0.3397],
        [0.6598, 0.3402],
        [0.6559, 0.3441],
        [0.6569, 0.3431],
        [0.6586, 0.3414],
        [0.6549, 0.3451],
        [0.6609, 0.3391],
        [0.6588, 0.3412],
        [0.6598, 0.3402],
        [0.6634, 0.3366],
        [0.6579, 0.3421],
        [0.6583, 0.3417],
        [0.6557, 0.3443],
        [0.6528, 0.3472],
        [0.6553, 0.3447],
        [0.6610, 0.3390],
        [0.6585, 0.3415],
        [0.6591, 0.3409],
        [0.6595, 0.3405],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6588, 0.3412],
        [0.6586, 0.3414],
        [0.6554, 0.3446],
        [0.6542, 0.3458],
        [0.6584, 0.3416],
        [0.6586, 0.3414],
        [0.6569, 0.3431],
        [0.6563, 0.3437],
        [0.6572, 0.3428],
        [0.6577, 0.3423],
        [0.6622, 0.3378],
        [0.6538, 0.3462],
        [0.6525, 0.3475],
        [0.6555, 0.3445],
        [0.6548, 0.3452],
        [0.6563, 0.3437],
        [0.6561, 0.3439],
        [0.6563, 0.3437],
        [0.6601, 0.3399],
        [0.6581, 0.3419],
        [0.6591, 0.3409],
        [0.6561, 0.3439],
        [0.6572, 0.3428],
        [0.6555, 0.3445],
        [0.6584, 0.3416],
        [0.6526, 0.3474],
        [0.6571, 0.3429],
        [0.6620, 0.3380],
        [0.6599, 0.3401],
        [0.6563, 0.3437],
        [0.6619, 0.3381],
        [0.6546, 0.3454],
        [0.6604, 0.3396],
        [0.6556, 0.3444],
        [0.6546, 0.3454],
        [0.6554, 0.3446],
        [0.6643, 0.3357],
        [0.6555, 0.3445],
        [0.6621, 0.3379],
        [0.6608, 0.3392],
        [0.6549, 0.3451],
        [0.6619, 0.3381],
        [0.6474, 0.3526],
        [0.6625, 0.3375],
        [0.6607, 0.3393],
        [0.6615, 0.3385],
        [0.6561, 0.3439],
        [0.6522, 0.3478],
        [0.6571, 0.3429],
        [0.6607, 0.3393],
        [0.6628, 0.3372],
        [0.6640, 0.3360],
        [0.6536, 0.3464],
        [0.6574, 0.3426],
        [0.6580, 0.3420],
        [0.6567, 0.3433],
        [0.6549, 0.3451],
        [0.6571, 0.3429],
        [0.6546, 0.3454],
        [0.6581, 0.3419],
        [0.6551, 0.3449],
        [0.6567, 0.3433],
        [0.6577, 0.3423],
        [0.6542, 0.3458],
        [0.6595, 0.3405],
        [0.6558, 0.3442],
        [0.6596, 0.3404],
        [0.6591, 0.3409],
        [0.6561, 0.3439],
        [0.6610, 0.3390],
        [0.6588, 0.3412],
        [0.6552, 0.3448],
        [0.6543, 0.3457],
        [0.6601, 0.3399],
        [0.6575, 0.3425],
        [0.6570, 0.3430],
        [0.6505, 0.3495],
        [0.6581, 0.3419],
        [0.6584, 0.3416],
        [0.6562, 0.3438],
        [0.6609, 0.3391],
        [0.6611, 0.3389],
        [0.6543, 0.3457],
        [0.6604, 0.3396],
        [0.6617, 0.3383],
        [0.6638, 0.3362],
        [0.6630, 0.3370],
        [0.6600, 0.3400],
        [0.6620, 0.3380],
        [0.6612, 0.3388],
        [0.6566, 0.3434],
        [0.6594, 0.3406],
        [0.6600, 0.3400],
        [0.6602, 0.3398],
        [0.6541, 0.3459],
        [0.6556, 0.3444],
        [0.6505, 0.3495],
        [0.6555, 0.3445],
        [0.6599, 0.3401],
        [0.6566, 0.3434],
        [0.6589, 0.3411],
        [0.6563, 0.3437],
        [0.6482, 0.3518],
        [0.6562, 0.3438],
        [0.6554, 0.3446],
        [0.6564, 0.3436],
        [0.6601, 0.3399],
        [0.6575, 0.3425],
        [0.6611, 0.3389],
        [0.6567, 0.3433],
        [0.6546, 0.3454],
        [0.6613, 0.3387],
        [0.6573, 0.3427],
        [0.6534, 0.3466],
        [0.6546, 0.3454],
        [0.6530, 0.3470],
        [0.6614, 0.3386],
        [0.6591, 0.3409],
        [0.6513, 0.3487],
        [0.6595, 0.3405],
        [0.6556, 0.3444],
        [0.6561, 0.3439],
        [0.6626, 0.3374],
        [0.6562, 0.3438],
        [0.6553, 0.3447],
        [0.6534, 0.3466],
        [0.6608, 0.3392],
        [0.6587, 0.3413],
        [0.6621, 0.3379],
        [0.6531, 0.3469],
        [0.6603, 0.3397],
        [0.6630, 0.3370],
        [0.6576, 0.3424],
        [0.6604, 0.3396],
        [0.6624, 0.3376],
        [0.6528, 0.3472],
        [0.6600, 0.3400],
        [0.6583, 0.3417],
        [0.6604, 0.3396],
        [0.6627, 0.3373],
        [0.6552, 0.3448],
        [0.6567, 0.3433],
        [0.6596, 0.3404],
        [0.6564, 0.3436],
        [0.6622, 0.3378],
        [0.6558, 0.3442],
        [0.6590, 0.3410],
        [0.6604, 0.3396],
        [0.6563, 0.3437],
        [0.6574, 0.3426],
        [0.6583, 0.3417],
        [0.6582, 0.3418],
        [0.6563, 0.3437],
        [0.6634, 0.3366],
        [0.6564, 0.3436],
        [0.6595, 0.3405],
        [0.6600, 0.3400],
        [0.6600, 0.3400],
        [0.6508, 0.3492],
        [0.6578, 0.3422],
        [0.6556, 0.3444],
        [0.6580, 0.3420],
        [0.6589, 0.3411],
        [0.6606, 0.3394],
        [0.6598, 0.3402],
        [0.6599, 0.3401],
        [0.6600, 0.3400],
        [0.6608, 0.3392],
        [0.6581, 0.3419],
        [0.6584, 0.3416],
        [0.6627, 0.3373],
        [0.6550, 0.3450],
        [0.6609, 0.3391],
        [0.6594, 0.3406],
        [0.6559, 0.3441],
        [0.6551, 0.3449],
        [0.6612, 0.3388],
        [0.6611, 0.3389],
        [0.6601, 0.3399],
        [0.6610, 0.3390],
        [0.6609, 0.3391],
        [0.6573, 0.3427],
        [0.6581, 0.3419],
        [0.6603, 0.3397],
        [0.6536, 0.3464],
        [0.6603, 0.3397],
        [0.6623, 0.3377],
        [0.6566, 0.3434],
        [0.6571, 0.3429],
        [0.6588, 0.3412],
        [0.6608, 0.3392],
        [0.6594, 0.3406],
        [0.6634, 0.3366],
        [0.6596, 0.3404],
        [0.6565, 0.3435],
        [0.6597, 0.3403],
        [0.6554, 0.3446],
        [0.6573, 0.3427],
        [0.6615, 0.3385],
        [0.6547, 0.3453],
        [0.6572, 0.3428],
        [0.6590, 0.3410],
        [0.6612, 0.3388],
        [0.6584, 0.3416]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0031 loss: 0.6696 acc_train: 0.6103 time: 0.1353s
tensor([[0.6584, 0.3416],
        [0.6636, 0.3364],
        [0.6606, 0.3394],
        [0.6594, 0.3406],
        [0.6643, 0.3357],
        [0.6558, 0.3442],
        [0.6538, 0.3462],
        [0.6603, 0.3397],
        [0.6616, 0.3384],
        [0.6560, 0.3440],
        [0.6591, 0.3409],
        [0.6575, 0.3425],
        [0.6568, 0.3432],
        [0.6549, 0.3451],
        [0.6619, 0.3381],
        [0.6563, 0.3437],
        [0.6650, 0.3350],
        [0.6589, 0.3411],
        [0.6602, 0.3398],
        [0.6546, 0.3454],
        [0.6630, 0.3370],
        [0.6549, 0.3451],
        [0.6624, 0.3376],
        [0.6612, 0.3388],
        [0.6585, 0.3415],
        [0.6569, 0.3431],
        [0.6595, 0.3405],
        [0.6610, 0.3390],
        [0.6576, 0.3424],
        [0.6568, 0.3432],
        [0.6581, 0.3419],
        [0.6562, 0.3438],
        [0.6586, 0.3414],
        [0.6571, 0.3429],
        [0.6631, 0.3369],
        [0.6507, 0.3493],
        [0.6569, 0.3431],
        [0.6582, 0.3418],
        [0.6601, 0.3399],
        [0.6568, 0.3432],
        [0.6617, 0.3383],
        [0.6590, 0.3410],
        [0.6489, 0.3511],
        [0.6615, 0.3385],
        [0.6618, 0.3382],
        [0.6569, 0.3431],
        [0.6625, 0.3375],
        [0.6615, 0.3385],
        [0.6607, 0.3393],
        [0.6569, 0.3431],
        [0.6581, 0.3419],
        [0.6597, 0.3403],
        [0.6557, 0.3443],
        [0.6618, 0.3382],
        [0.6599, 0.3401],
        [0.6609, 0.3391],
        [0.6641, 0.3359],
        [0.6587, 0.3413],
        [0.6592, 0.3408],
        [0.6569, 0.3431],
        [0.6541, 0.3459],
        [0.6565, 0.3435],
        [0.6619, 0.3381],
        [0.6597, 0.3403],
        [0.6600, 0.3400],
        [0.6604, 0.3396],
        [0.6596, 0.3404],
        [0.6593, 0.3407],
        [0.6599, 0.3401],
        [0.6594, 0.3406],
        [0.6567, 0.3433],
        [0.6555, 0.3445],
        [0.6591, 0.3409],
        [0.6597, 0.3403],
        [0.6582, 0.3418],
        [0.6573, 0.3427],
        [0.6579, 0.3421],
        [0.6588, 0.3412],
        [0.6626, 0.3374],
        [0.6548, 0.3452],
        [0.6538, 0.3462],
        [0.6565, 0.3435],
        [0.6558, 0.3442],
        [0.6574, 0.3426],
        [0.6572, 0.3428],
        [0.6574, 0.3426],
        [0.6607, 0.3393],
        [0.6591, 0.3409],
        [0.6604, 0.3396],
        [0.6572, 0.3428],
        [0.6579, 0.3421],
        [0.6570, 0.3430],
        [0.6596, 0.3404],
        [0.6541, 0.3459],
        [0.6582, 0.3418],
        [0.6628, 0.3372],
        [0.6608, 0.3392],
        [0.6572, 0.3428],
        [0.6629, 0.3371],
        [0.6556, 0.3444],
        [0.6617, 0.3383],
        [0.6566, 0.3434],
        [0.6555, 0.3445],
        [0.6568, 0.3432],
        [0.6655, 0.3345],
        [0.6567, 0.3433],
        [0.6628, 0.3372],
        [0.6620, 0.3380],
        [0.6560, 0.3440],
        [0.6629, 0.3371],
        [0.6489, 0.3511],
        [0.6635, 0.3365],
        [0.6618, 0.3382],
        [0.6626, 0.3374],
        [0.6571, 0.3429],
        [0.6535, 0.3465],
        [0.6581, 0.3419],
        [0.6616, 0.3384],
        [0.6639, 0.3361],
        [0.6649, 0.3351],
        [0.6546, 0.3454],
        [0.6580, 0.3420],
        [0.6588, 0.3412],
        [0.6578, 0.3422],
        [0.6563, 0.3437],
        [0.6578, 0.3422],
        [0.6557, 0.3443],
        [0.6591, 0.3409],
        [0.6561, 0.3439],
        [0.6577, 0.3423],
        [0.6590, 0.3410],
        [0.6549, 0.3451],
        [0.6606, 0.3394],
        [0.6570, 0.3430],
        [0.6606, 0.3394],
        [0.6600, 0.3400],
        [0.6572, 0.3428],
        [0.6619, 0.3381],
        [0.6599, 0.3401],
        [0.6561, 0.3439],
        [0.6554, 0.3446],
        [0.6608, 0.3392],
        [0.6587, 0.3413],
        [0.6582, 0.3418],
        [0.6520, 0.3480],
        [0.6589, 0.3411],
        [0.6597, 0.3403],
        [0.6572, 0.3428],
        [0.6620, 0.3380],
        [0.6622, 0.3378],
        [0.6554, 0.3446],
        [0.6612, 0.3388],
        [0.6627, 0.3373],
        [0.6647, 0.3353],
        [0.6639, 0.3361],
        [0.6608, 0.3392],
        [0.6630, 0.3370],
        [0.6623, 0.3377],
        [0.6575, 0.3425],
        [0.6603, 0.3397],
        [0.6612, 0.3388],
        [0.6610, 0.3390],
        [0.6553, 0.3447],
        [0.6567, 0.3433],
        [0.6524, 0.3476],
        [0.6568, 0.3432],
        [0.6611, 0.3389],
        [0.6577, 0.3423],
        [0.6597, 0.3403],
        [0.6573, 0.3427],
        [0.6500, 0.3500],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6612, 0.3388],
        [0.6585, 0.3415],
        [0.6623, 0.3377],
        [0.6577, 0.3423],
        [0.6555, 0.3445],
        [0.6618, 0.3382],
        [0.6583, 0.3417],
        [0.6546, 0.3454],
        [0.6559, 0.3441],
        [0.6538, 0.3462],
        [0.6624, 0.3376],
        [0.6603, 0.3397],
        [0.6526, 0.3474],
        [0.6606, 0.3394],
        [0.6562, 0.3438],
        [0.6571, 0.3429],
        [0.6632, 0.3368],
        [0.6571, 0.3429],
        [0.6562, 0.3438],
        [0.6543, 0.3457],
        [0.6618, 0.3382],
        [0.6597, 0.3403],
        [0.6634, 0.3366],
        [0.6542, 0.3458],
        [0.6613, 0.3387],
        [0.6639, 0.3361],
        [0.6583, 0.3417],
        [0.6614, 0.3386],
        [0.6633, 0.3367],
        [0.6540, 0.3460],
        [0.6612, 0.3388],
        [0.6592, 0.3408],
        [0.6613, 0.3387],
        [0.6637, 0.3363],
        [0.6563, 0.3437],
        [0.6578, 0.3422],
        [0.6607, 0.3393],
        [0.6574, 0.3426],
        [0.6631, 0.3369],
        [0.6569, 0.3431],
        [0.6602, 0.3398],
        [0.6613, 0.3387],
        [0.6572, 0.3428],
        [0.6582, 0.3418],
        [0.6589, 0.3411],
        [0.6595, 0.3405],
        [0.6574, 0.3426],
        [0.6644, 0.3356],
        [0.6573, 0.3427],
        [0.6605, 0.3395],
        [0.6611, 0.3389],
        [0.6611, 0.3389],
        [0.6522, 0.3478],
        [0.6589, 0.3411],
        [0.6566, 0.3434],
        [0.6591, 0.3409],
        [0.6600, 0.3400],
        [0.6618, 0.3382],
        [0.6610, 0.3390],
        [0.6606, 0.3394],
        [0.6607, 0.3393],
        [0.6620, 0.3380],
        [0.6591, 0.3409],
        [0.6594, 0.3406],
        [0.6635, 0.3365],
        [0.6559, 0.3441],
        [0.6617, 0.3383],
        [0.6606, 0.3394],
        [0.6567, 0.3433],
        [0.6560, 0.3440],
        [0.6623, 0.3377],
        [0.6621, 0.3379],
        [0.6610, 0.3390],
        [0.6620, 0.3380],
        [0.6619, 0.3381],
        [0.6584, 0.3416],
        [0.6592, 0.3408],
        [0.6613, 0.3387],
        [0.6547, 0.3453],
        [0.6613, 0.3387],
        [0.6632, 0.3368],
        [0.6579, 0.3421],
        [0.6582, 0.3418],
        [0.6600, 0.3400],
        [0.6617, 0.3383],
        [0.6606, 0.3394],
        [0.6645, 0.3355],
        [0.6610, 0.3390],
        [0.6579, 0.3421],
        [0.6606, 0.3394],
        [0.6567, 0.3433],
        [0.6587, 0.3413],
        [0.6627, 0.3373],
        [0.6560, 0.3440],
        [0.6578, 0.3422],
        [0.6602, 0.3398],
        [0.6622, 0.3378],
        [0.6597, 0.3403]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0032 loss: 0.6696 acc_train: 0.6103 time: 0.1199s
tensor([[0.6597, 0.3403],
        [0.6644, 0.3356],
        [0.6616, 0.3384],
        [0.6606, 0.3394],
        [0.6653, 0.3347],
        [0.6568, 0.3432],
        [0.6549, 0.3451],
        [0.6615, 0.3385],
        [0.6628, 0.3372],
        [0.6573, 0.3427],
        [0.6605, 0.3395],
        [0.6588, 0.3412],
        [0.6578, 0.3422],
        [0.6559, 0.3441],
        [0.6628, 0.3372],
        [0.6575, 0.3425],
        [0.6659, 0.3341],
        [0.6601, 0.3399],
        [0.6613, 0.3387],
        [0.6557, 0.3443],
        [0.6641, 0.3359],
        [0.6561, 0.3439],
        [0.6636, 0.3364],
        [0.6623, 0.3377],
        [0.6596, 0.3404],
        [0.6578, 0.3422],
        [0.6601, 0.3399],
        [0.6623, 0.3377],
        [0.6587, 0.3413],
        [0.6577, 0.3423],
        [0.6595, 0.3405],
        [0.6570, 0.3430],
        [0.6596, 0.3404],
        [0.6583, 0.3417],
        [0.6642, 0.3358],
        [0.6525, 0.3475],
        [0.6582, 0.3418],
        [0.6594, 0.3406],
        [0.6613, 0.3387],
        [0.6580, 0.3420],
        [0.6630, 0.3370],
        [0.6603, 0.3397],
        [0.6507, 0.3493],
        [0.6625, 0.3375],
        [0.6627, 0.3373],
        [0.6580, 0.3420],
        [0.6637, 0.3363],
        [0.6628, 0.3372],
        [0.6616, 0.3384],
        [0.6579, 0.3421],
        [0.6594, 0.3406],
        [0.6608, 0.3392],
        [0.6567, 0.3433],
        [0.6629, 0.3371],
        [0.6612, 0.3388],
        [0.6621, 0.3379],
        [0.6649, 0.3351],
        [0.6595, 0.3405],
        [0.6601, 0.3399],
        [0.6580, 0.3420],
        [0.6553, 0.3447],
        [0.6577, 0.3423],
        [0.6628, 0.3372],
        [0.6610, 0.3390],
        [0.6610, 0.3390],
        [0.6614, 0.3386],
        [0.6607, 0.3393],
        [0.6603, 0.3397],
        [0.6611, 0.3389],
        [0.6604, 0.3396],
        [0.6579, 0.3421],
        [0.6569, 0.3431],
        [0.6599, 0.3401],
        [0.6608, 0.3392],
        [0.6594, 0.3406],
        [0.6586, 0.3414],
        [0.6588, 0.3412],
        [0.6599, 0.3401],
        [0.6632, 0.3368],
        [0.6559, 0.3441],
        [0.6551, 0.3449],
        [0.6576, 0.3424],
        [0.6568, 0.3432],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6584, 0.3416],
        [0.6616, 0.3384],
        [0.6601, 0.3399],
        [0.6617, 0.3383],
        [0.6584, 0.3416],
        [0.6586, 0.3414],
        [0.6585, 0.3415],
        [0.6607, 0.3393],
        [0.6556, 0.3444],
        [0.6594, 0.3406],
        [0.6638, 0.3362],
        [0.6620, 0.3380],
        [0.6581, 0.3419],
        [0.6641, 0.3359],
        [0.6567, 0.3433],
        [0.6631, 0.3369],
        [0.6577, 0.3423],
        [0.6565, 0.3435],
        [0.6581, 0.3419],
        [0.6667, 0.3333],
        [0.6578, 0.3422],
        [0.6635, 0.3365],
        [0.6633, 0.3367],
        [0.6573, 0.3427],
        [0.6640, 0.3360],
        [0.6505, 0.3495],
        [0.6647, 0.3353],
        [0.6630, 0.3370],
        [0.6637, 0.3363],
        [0.6581, 0.3419],
        [0.6547, 0.3453],
        [0.6592, 0.3408],
        [0.6626, 0.3374],
        [0.6652, 0.3348],
        [0.6659, 0.3341],
        [0.6557, 0.3443],
        [0.6588, 0.3412],
        [0.6597, 0.3403],
        [0.6591, 0.3409],
        [0.6576, 0.3424],
        [0.6587, 0.3413],
        [0.6568, 0.3432],
        [0.6601, 0.3399],
        [0.6572, 0.3428],
        [0.6587, 0.3413],
        [0.6602, 0.3398],
        [0.6558, 0.3442],
        [0.6618, 0.3382],
        [0.6582, 0.3418],
        [0.6618, 0.3382],
        [0.6610, 0.3390],
        [0.6583, 0.3417],
        [0.6629, 0.3371],
        [0.6610, 0.3390],
        [0.6572, 0.3428],
        [0.6567, 0.3433],
        [0.6616, 0.3384],
        [0.6599, 0.3401],
        [0.6594, 0.3406],
        [0.6535, 0.3465],
        [0.6599, 0.3401],
        [0.6611, 0.3389],
        [0.6583, 0.3417],
        [0.6632, 0.3368],
        [0.6634, 0.3366],
        [0.6565, 0.3435],
        [0.6621, 0.3379],
        [0.6637, 0.3363],
        [0.6658, 0.3342],
        [0.6650, 0.3350],
        [0.6616, 0.3384],
        [0.6641, 0.3359],
        [0.6634, 0.3366],
        [0.6585, 0.3415],
        [0.6613, 0.3387],
        [0.6625, 0.3375],
        [0.6621, 0.3379],
        [0.6565, 0.3435],
        [0.6579, 0.3421],
        [0.6541, 0.3459],
        [0.6580, 0.3420],
        [0.6624, 0.3376],
        [0.6590, 0.3410],
        [0.6606, 0.3394],
        [0.6583, 0.3417],
        [0.6518, 0.3482],
        [0.6582, 0.3418],
        [0.6583, 0.3417],
        [0.6581, 0.3419],
        [0.6623, 0.3377],
        [0.6597, 0.3403],
        [0.6636, 0.3364],
        [0.6587, 0.3413],
        [0.6563, 0.3437],
        [0.6626, 0.3374],
        [0.6595, 0.3405],
        [0.6558, 0.3442],
        [0.6573, 0.3427],
        [0.6548, 0.3452],
        [0.6635, 0.3365],
        [0.6615, 0.3385],
        [0.6539, 0.3461],
        [0.6617, 0.3383],
        [0.6569, 0.3431],
        [0.6583, 0.3417],
        [0.6640, 0.3360],
        [0.6581, 0.3419],
        [0.6572, 0.3428],
        [0.6552, 0.3448],
        [0.6628, 0.3372],
        [0.6609, 0.3391],
        [0.6648, 0.3352],
        [0.6553, 0.3447],
        [0.6625, 0.3375],
        [0.6649, 0.3351],
        [0.6591, 0.3409],
        [0.6626, 0.3374],
        [0.6643, 0.3357],
        [0.6552, 0.3448],
        [0.6624, 0.3376],
        [0.6603, 0.3397],
        [0.6624, 0.3376],
        [0.6649, 0.3351],
        [0.6575, 0.3425],
        [0.6588, 0.3412],
        [0.6619, 0.3381],
        [0.6585, 0.3415],
        [0.6641, 0.3359],
        [0.6582, 0.3418],
        [0.6614, 0.3386],
        [0.6623, 0.3377],
        [0.6581, 0.3419],
        [0.6592, 0.3408],
        [0.6598, 0.3402],
        [0.6610, 0.3390],
        [0.6584, 0.3416],
        [0.6655, 0.3345],
        [0.6583, 0.3417],
        [0.6616, 0.3384],
        [0.6624, 0.3376],
        [0.6624, 0.3376],
        [0.6536, 0.3464],
        [0.6602, 0.3398],
        [0.6577, 0.3423],
        [0.6603, 0.3397],
        [0.6611, 0.3389],
        [0.6631, 0.3369],
        [0.6621, 0.3379],
        [0.6613, 0.3387],
        [0.6617, 0.3383],
        [0.6634, 0.3366],
        [0.6603, 0.3397],
        [0.6605, 0.3395],
        [0.6643, 0.3357],
        [0.6570, 0.3430],
        [0.6625, 0.3375],
        [0.6618, 0.3382],
        [0.6576, 0.3424],
        [0.6570, 0.3430],
        [0.6635, 0.3365],
        [0.6632, 0.3368],
        [0.6619, 0.3381],
        [0.6631, 0.3369],
        [0.6631, 0.3369],
        [0.6595, 0.3405],
        [0.6605, 0.3395],
        [0.6623, 0.3377],
        [0.6559, 0.3441],
        [0.6624, 0.3376],
        [0.6641, 0.3359],
        [0.6592, 0.3408],
        [0.6595, 0.3405],
        [0.6614, 0.3386],
        [0.6627, 0.3373],
        [0.6619, 0.3381],
        [0.6658, 0.3342],
        [0.6624, 0.3376],
        [0.6594, 0.3406],
        [0.6617, 0.3383],
        [0.6581, 0.3419],
        [0.6600, 0.3400],
        [0.6639, 0.3361],
        [0.6574, 0.3426],
        [0.6587, 0.3413],
        [0.6613, 0.3387],
        [0.6633, 0.3367],
        [0.6612, 0.3388]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0033 loss: 0.6695 acc_train: 0.6103 time: 0.1306s
tensor([[0.6609, 0.3391],
        [0.6652, 0.3348],
        [0.6628, 0.3372],
        [0.6617, 0.3383],
        [0.6662, 0.3338],
        [0.6578, 0.3422],
        [0.6559, 0.3441],
        [0.6626, 0.3374],
        [0.6639, 0.3361],
        [0.6585, 0.3415],
        [0.6618, 0.3382],
        [0.6600, 0.3400],
        [0.6587, 0.3413],
        [0.6570, 0.3430],
        [0.6637, 0.3363],
        [0.6586, 0.3414],
        [0.6668, 0.3332],
        [0.6613, 0.3387],
        [0.6625, 0.3375],
        [0.6568, 0.3432],
        [0.6651, 0.3349],
        [0.6574, 0.3426],
        [0.6648, 0.3352],
        [0.6634, 0.3366],
        [0.6607, 0.3393],
        [0.6588, 0.3412],
        [0.6608, 0.3392],
        [0.6636, 0.3364],
        [0.6597, 0.3403],
        [0.6587, 0.3413],
        [0.6609, 0.3391],
        [0.6579, 0.3421],
        [0.6605, 0.3395],
        [0.6596, 0.3404],
        [0.6654, 0.3346],
        [0.6542, 0.3458],
        [0.6594, 0.3406],
        [0.6604, 0.3396],
        [0.6625, 0.3375],
        [0.6591, 0.3409],
        [0.6641, 0.3359],
        [0.6615, 0.3385],
        [0.6526, 0.3474],
        [0.6636, 0.3364],
        [0.6637, 0.3363],
        [0.6591, 0.3409],
        [0.6651, 0.3349],
        [0.6642, 0.3358],
        [0.6626, 0.3374],
        [0.6589, 0.3411],
        [0.6607, 0.3393],
        [0.6619, 0.3381],
        [0.6578, 0.3422],
        [0.6640, 0.3360],
        [0.6625, 0.3375],
        [0.6633, 0.3367],
        [0.6658, 0.3342],
        [0.6604, 0.3396],
        [0.6611, 0.3389],
        [0.6591, 0.3409],
        [0.6563, 0.3437],
        [0.6588, 0.3412],
        [0.6638, 0.3362],
        [0.6622, 0.3378],
        [0.6620, 0.3380],
        [0.6623, 0.3377],
        [0.6619, 0.3381],
        [0.6613, 0.3387],
        [0.6621, 0.3379],
        [0.6614, 0.3386],
        [0.6590, 0.3410],
        [0.6581, 0.3419],
        [0.6608, 0.3392],
        [0.6620, 0.3380],
        [0.6606, 0.3394],
        [0.6599, 0.3401],
        [0.6599, 0.3401],
        [0.6609, 0.3391],
        [0.6638, 0.3362],
        [0.6570, 0.3430],
        [0.6563, 0.3437],
        [0.6585, 0.3415],
        [0.6578, 0.3422],
        [0.6596, 0.3404],
        [0.6596, 0.3404],
        [0.6594, 0.3406],
        [0.6626, 0.3374],
        [0.6611, 0.3389],
        [0.6630, 0.3370],
        [0.6596, 0.3404],
        [0.6595, 0.3405],
        [0.6600, 0.3400],
        [0.6619, 0.3381],
        [0.6568, 0.3432],
        [0.6606, 0.3394],
        [0.6649, 0.3351],
        [0.6633, 0.3367],
        [0.6590, 0.3410],
        [0.6653, 0.3347],
        [0.6579, 0.3421],
        [0.6644, 0.3356],
        [0.6588, 0.3412],
        [0.6576, 0.3424],
        [0.6593, 0.3407],
        [0.6679, 0.3321],
        [0.6587, 0.3413],
        [0.6643, 0.3357],
        [0.6646, 0.3354],
        [0.6585, 0.3415],
        [0.6651, 0.3349],
        [0.6519, 0.3481],
        [0.6657, 0.3343],
        [0.6641, 0.3359],
        [0.6647, 0.3353],
        [0.6592, 0.3408],
        [0.6558, 0.3442],
        [0.6603, 0.3397],
        [0.6636, 0.3364],
        [0.6665, 0.3335],
        [0.6670, 0.3330],
        [0.6569, 0.3431],
        [0.6596, 0.3404],
        [0.6606, 0.3394],
        [0.6603, 0.3397],
        [0.6588, 0.3412],
        [0.6597, 0.3403],
        [0.6579, 0.3421],
        [0.6611, 0.3389],
        [0.6583, 0.3417],
        [0.6597, 0.3403],
        [0.6612, 0.3388],
        [0.6566, 0.3434],
        [0.6629, 0.3371],
        [0.6594, 0.3406],
        [0.6630, 0.3370],
        [0.6620, 0.3380],
        [0.6595, 0.3405],
        [0.6640, 0.3360],
        [0.6620, 0.3380],
        [0.6582, 0.3418],
        [0.6579, 0.3421],
        [0.6626, 0.3374],
        [0.6609, 0.3391],
        [0.6606, 0.3394],
        [0.6548, 0.3452],
        [0.6610, 0.3390],
        [0.6626, 0.3374],
        [0.6593, 0.3407],
        [0.6644, 0.3356],
        [0.6647, 0.3353],
        [0.6576, 0.3424],
        [0.6631, 0.3369],
        [0.6647, 0.3353],
        [0.6670, 0.3330],
        [0.6662, 0.3338],
        [0.6623, 0.3377],
        [0.6652, 0.3348],
        [0.6645, 0.3355],
        [0.6595, 0.3405],
        [0.6622, 0.3378],
        [0.6637, 0.3363],
        [0.6631, 0.3369],
        [0.6577, 0.3423],
        [0.6590, 0.3410],
        [0.6556, 0.3444],
        [0.6590, 0.3410],
        [0.6637, 0.3363],
        [0.6603, 0.3397],
        [0.6615, 0.3385],
        [0.6593, 0.3407],
        [0.6535, 0.3465],
        [0.6593, 0.3407],
        [0.6597, 0.3403],
        [0.6590, 0.3410],
        [0.6634, 0.3366],
        [0.6608, 0.3392],
        [0.6649, 0.3351],
        [0.6597, 0.3403],
        [0.6571, 0.3429],
        [0.6635, 0.3365],
        [0.6608, 0.3392],
        [0.6570, 0.3430],
        [0.6587, 0.3413],
        [0.6558, 0.3442],
        [0.6646, 0.3354],
        [0.6627, 0.3373],
        [0.6551, 0.3449],
        [0.6629, 0.3371],
        [0.6576, 0.3424],
        [0.6595, 0.3405],
        [0.6649, 0.3351],
        [0.6591, 0.3409],
        [0.6582, 0.3418],
        [0.6560, 0.3440],
        [0.6638, 0.3362],
        [0.6622, 0.3378],
        [0.6661, 0.3339],
        [0.6563, 0.3437],
        [0.6636, 0.3364],
        [0.6658, 0.3342],
        [0.6600, 0.3400],
        [0.6637, 0.3363],
        [0.6652, 0.3348],
        [0.6563, 0.3437],
        [0.6636, 0.3364],
        [0.6614, 0.3386],
        [0.6635, 0.3365],
        [0.6660, 0.3340],
        [0.6586, 0.3414],
        [0.6598, 0.3402],
        [0.6631, 0.3369],
        [0.6597, 0.3403],
        [0.6652, 0.3348],
        [0.6596, 0.3404],
        [0.6625, 0.3375],
        [0.6633, 0.3367],
        [0.6590, 0.3410],
        [0.6603, 0.3397],
        [0.6607, 0.3393],
        [0.6625, 0.3375],
        [0.6595, 0.3405],
        [0.6666, 0.3334],
        [0.6593, 0.3407],
        [0.6627, 0.3373],
        [0.6637, 0.3363],
        [0.6637, 0.3363],
        [0.6549, 0.3451],
        [0.6614, 0.3386],
        [0.6588, 0.3412],
        [0.6616, 0.3384],
        [0.6621, 0.3379],
        [0.6645, 0.3355],
        [0.6633, 0.3367],
        [0.6621, 0.3379],
        [0.6628, 0.3372],
        [0.6647, 0.3353],
        [0.6615, 0.3385],
        [0.6615, 0.3385],
        [0.6652, 0.3348],
        [0.6582, 0.3418],
        [0.6634, 0.3366],
        [0.6629, 0.3371],
        [0.6586, 0.3414],
        [0.6580, 0.3420],
        [0.6647, 0.3353],
        [0.6645, 0.3355],
        [0.6629, 0.3371],
        [0.6643, 0.3357],
        [0.6642, 0.3358],
        [0.6606, 0.3394],
        [0.6619, 0.3381],
        [0.6634, 0.3366],
        [0.6571, 0.3429],
        [0.6635, 0.3365],
        [0.6651, 0.3349],
        [0.6606, 0.3394],
        [0.6608, 0.3392],
        [0.6627, 0.3373],
        [0.6637, 0.3363],
        [0.6633, 0.3367],
        [0.6671, 0.3329],
        [0.6638, 0.3362],
        [0.6608, 0.3392],
        [0.6627, 0.3373],
        [0.6594, 0.3406],
        [0.6612, 0.3388],
        [0.6651, 0.3349],
        [0.6588, 0.3412],
        [0.6595, 0.3405],
        [0.6625, 0.3375],
        [0.6645, 0.3355],
        [0.6626, 0.3374]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0034 loss: 0.6694 acc_train: 0.6103 time: 0.1236s
tensor([[0.6620, 0.3380],
        [0.6660, 0.3340],
        [0.6639, 0.3361],
        [0.6627, 0.3373],
        [0.6670, 0.3330],
        [0.6586, 0.3414],
        [0.6569, 0.3431],
        [0.6637, 0.3363],
        [0.6649, 0.3351],
        [0.6595, 0.3405],
        [0.6631, 0.3369],
        [0.6611, 0.3389],
        [0.6595, 0.3405],
        [0.6580, 0.3420],
        [0.6645, 0.3355],
        [0.6595, 0.3405],
        [0.6677, 0.3323],
        [0.6624, 0.3376],
        [0.6636, 0.3364],
        [0.6578, 0.3422],
        [0.6661, 0.3339],
        [0.6585, 0.3415],
        [0.6659, 0.3341],
        [0.6645, 0.3355],
        [0.6617, 0.3383],
        [0.6598, 0.3402],
        [0.6615, 0.3385],
        [0.6648, 0.3352],
        [0.6605, 0.3395],
        [0.6596, 0.3404],
        [0.6622, 0.3378],
        [0.6587, 0.3413],
        [0.6614, 0.3386],
        [0.6607, 0.3393],
        [0.6664, 0.3336],
        [0.6558, 0.3442],
        [0.6605, 0.3395],
        [0.6613, 0.3387],
        [0.6636, 0.3364],
        [0.6600, 0.3400],
        [0.6651, 0.3349],
        [0.6627, 0.3373],
        [0.6543, 0.3457],
        [0.6646, 0.3354],
        [0.6645, 0.3355],
        [0.6602, 0.3398],
        [0.6664, 0.3336],
        [0.6654, 0.3346],
        [0.6635, 0.3365],
        [0.6598, 0.3402],
        [0.6618, 0.3382],
        [0.6628, 0.3372],
        [0.6590, 0.3410],
        [0.6652, 0.3348],
        [0.6637, 0.3363],
        [0.6645, 0.3355],
        [0.6667, 0.3333],
        [0.6612, 0.3388],
        [0.6619, 0.3381],
        [0.6600, 0.3400],
        [0.6572, 0.3428],
        [0.6597, 0.3403],
        [0.6647, 0.3353],
        [0.6634, 0.3366],
        [0.6628, 0.3372],
        [0.6630, 0.3370],
        [0.6630, 0.3370],
        [0.6622, 0.3378],
        [0.6631, 0.3369],
        [0.6623, 0.3377],
        [0.6599, 0.3401],
        [0.6592, 0.3408],
        [0.6617, 0.3383],
        [0.6631, 0.3369],
        [0.6616, 0.3384],
        [0.6612, 0.3388],
        [0.6610, 0.3390],
        [0.6617, 0.3383],
        [0.6644, 0.3356],
        [0.6581, 0.3419],
        [0.6572, 0.3428],
        [0.6593, 0.3407],
        [0.6586, 0.3414],
        [0.6606, 0.3394],
        [0.6607, 0.3393],
        [0.6603, 0.3397],
        [0.6637, 0.3363],
        [0.6621, 0.3379],
        [0.6642, 0.3358],
        [0.6606, 0.3394],
        [0.6603, 0.3397],
        [0.6614, 0.3386],
        [0.6630, 0.3370],
        [0.6579, 0.3421],
        [0.6616, 0.3384],
        [0.6659, 0.3341],
        [0.6646, 0.3354],
        [0.6599, 0.3401],
        [0.6665, 0.3335],
        [0.6591, 0.3409],
        [0.6655, 0.3345],
        [0.6598, 0.3402],
        [0.6586, 0.3414],
        [0.6605, 0.3395],
        [0.6689, 0.3311],
        [0.6595, 0.3405],
        [0.6651, 0.3349],
        [0.6658, 0.3342],
        [0.6596, 0.3404],
        [0.6661, 0.3339],
        [0.6534, 0.3466],
        [0.6667, 0.3333],
        [0.6651, 0.3349],
        [0.6657, 0.3343],
        [0.6602, 0.3398],
        [0.6569, 0.3431],
        [0.6614, 0.3386],
        [0.6646, 0.3354],
        [0.6677, 0.3323],
        [0.6679, 0.3321],
        [0.6582, 0.3418],
        [0.6603, 0.3397],
        [0.6615, 0.3385],
        [0.6615, 0.3385],
        [0.6599, 0.3401],
        [0.6607, 0.3393],
        [0.6590, 0.3410],
        [0.6620, 0.3380],
        [0.6594, 0.3406],
        [0.6607, 0.3393],
        [0.6621, 0.3379],
        [0.6574, 0.3426],
        [0.6638, 0.3362],
        [0.6604, 0.3396],
        [0.6641, 0.3359],
        [0.6628, 0.3372],
        [0.6606, 0.3394],
        [0.6652, 0.3348],
        [0.6630, 0.3370],
        [0.6592, 0.3408],
        [0.6591, 0.3409],
        [0.6635, 0.3365],
        [0.6617, 0.3383],
        [0.6616, 0.3384],
        [0.6558, 0.3442],
        [0.6620, 0.3380],
        [0.6639, 0.3361],
        [0.6601, 0.3399],
        [0.6656, 0.3344],
        [0.6658, 0.3342],
        [0.6585, 0.3415],
        [0.6641, 0.3359],
        [0.6657, 0.3343],
        [0.6681, 0.3319],
        [0.6673, 0.3327],
        [0.6629, 0.3371],
        [0.6663, 0.3337],
        [0.6655, 0.3345],
        [0.6605, 0.3395],
        [0.6630, 0.3370],
        [0.6648, 0.3352],
        [0.6641, 0.3359],
        [0.6588, 0.3412],
        [0.6600, 0.3400],
        [0.6570, 0.3430],
        [0.6599, 0.3401],
        [0.6650, 0.3350],
        [0.6615, 0.3385],
        [0.6624, 0.3376],
        [0.6601, 0.3399],
        [0.6550, 0.3450],
        [0.6603, 0.3397],
        [0.6608, 0.3392],
        [0.6600, 0.3400],
        [0.6643, 0.3357],
        [0.6619, 0.3381],
        [0.6661, 0.3339],
        [0.6607, 0.3393],
        [0.6579, 0.3421],
        [0.6646, 0.3354],
        [0.6621, 0.3379],
        [0.6581, 0.3419],
        [0.6599, 0.3401],
        [0.6569, 0.3431],
        [0.6655, 0.3345],
        [0.6639, 0.3361],
        [0.6563, 0.3437],
        [0.6639, 0.3361],
        [0.6583, 0.3417],
        [0.6606, 0.3394],
        [0.6659, 0.3341],
        [0.6600, 0.3400],
        [0.6591, 0.3409],
        [0.6567, 0.3433],
        [0.6648, 0.3352],
        [0.6635, 0.3365],
        [0.6673, 0.3327],
        [0.6572, 0.3428],
        [0.6647, 0.3353],
        [0.6666, 0.3334],
        [0.6608, 0.3392],
        [0.6648, 0.3352],
        [0.6661, 0.3339],
        [0.6574, 0.3426],
        [0.6646, 0.3354],
        [0.6624, 0.3376],
        [0.6647, 0.3353],
        [0.6671, 0.3329],
        [0.6597, 0.3403],
        [0.6607, 0.3393],
        [0.6641, 0.3359],
        [0.6607, 0.3393],
        [0.6663, 0.3337],
        [0.6610, 0.3390],
        [0.6635, 0.3365],
        [0.6643, 0.3357],
        [0.6598, 0.3402],
        [0.6615, 0.3385],
        [0.6616, 0.3384],
        [0.6640, 0.3360],
        [0.6604, 0.3396],
        [0.6676, 0.3324],
        [0.6602, 0.3398],
        [0.6637, 0.3363],
        [0.6650, 0.3350],
        [0.6648, 0.3352],
        [0.6559, 0.3441],
        [0.6626, 0.3374],
        [0.6598, 0.3402],
        [0.6628, 0.3372],
        [0.6630, 0.3370],
        [0.6658, 0.3342],
        [0.6644, 0.3356],
        [0.6628, 0.3372],
        [0.6639, 0.3361],
        [0.6659, 0.3341],
        [0.6627, 0.3373],
        [0.6625, 0.3375],
        [0.6661, 0.3339],
        [0.6592, 0.3408],
        [0.6642, 0.3358],
        [0.6638, 0.3362],
        [0.6595, 0.3405],
        [0.6591, 0.3409],
        [0.6658, 0.3342],
        [0.6656, 0.3344],
        [0.6638, 0.3362],
        [0.6653, 0.3347],
        [0.6652, 0.3348],
        [0.6617, 0.3383],
        [0.6632, 0.3368],
        [0.6645, 0.3355],
        [0.6582, 0.3418],
        [0.6644, 0.3356],
        [0.6660, 0.3340],
        [0.6619, 0.3381],
        [0.6620, 0.3380],
        [0.6639, 0.3361],
        [0.6646, 0.3354],
        [0.6646, 0.3354],
        [0.6683, 0.3317],
        [0.6650, 0.3350],
        [0.6620, 0.3380],
        [0.6637, 0.3363],
        [0.6605, 0.3395],
        [0.6622, 0.3378],
        [0.6662, 0.3338],
        [0.6601, 0.3399],
        [0.6603, 0.3397],
        [0.6636, 0.3364],
        [0.6656, 0.3344],
        [0.6639, 0.3361]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0035 loss: 0.6693 acc_train: 0.6103 time: 0.1280s
tensor([[0.6629, 0.3371],
        [0.6667, 0.3333],
        [0.6649, 0.3351],
        [0.6634, 0.3366],
        [0.6677, 0.3323],
        [0.6593, 0.3407],
        [0.6577, 0.3423],
        [0.6645, 0.3355],
        [0.6658, 0.3342],
        [0.6603, 0.3397],
        [0.6642, 0.3358],
        [0.6621, 0.3379],
        [0.6601, 0.3399],
        [0.6590, 0.3410],
        [0.6651, 0.3349],
        [0.6602, 0.3398],
        [0.6685, 0.3315],
        [0.6632, 0.3368],
        [0.6646, 0.3354],
        [0.6588, 0.3412],
        [0.6669, 0.3331],
        [0.6595, 0.3405],
        [0.6668, 0.3332],
        [0.6655, 0.3345],
        [0.6624, 0.3376],
        [0.6607, 0.3393],
        [0.6622, 0.3378],
        [0.6657, 0.3343],
        [0.6612, 0.3388],
        [0.6603, 0.3397],
        [0.6634, 0.3366],
        [0.6593, 0.3407],
        [0.6621, 0.3379],
        [0.6616, 0.3384],
        [0.6672, 0.3328],
        [0.6573, 0.3427],
        [0.6613, 0.3387],
        [0.6620, 0.3380],
        [0.6646, 0.3354],
        [0.6607, 0.3393],
        [0.6658, 0.3342],
        [0.6637, 0.3363],
        [0.6557, 0.3443],
        [0.6655, 0.3345],
        [0.6652, 0.3348],
        [0.6612, 0.3388],
        [0.6676, 0.3324],
        [0.6665, 0.3335],
        [0.6643, 0.3357],
        [0.6607, 0.3393],
        [0.6628, 0.3372],
        [0.6636, 0.3364],
        [0.6601, 0.3399],
        [0.6662, 0.3338],
        [0.6647, 0.3353],
        [0.6656, 0.3344],
        [0.6676, 0.3324],
        [0.6620, 0.3380],
        [0.6626, 0.3374],
        [0.6607, 0.3393],
        [0.6580, 0.3420],
        [0.6605, 0.3395],
        [0.6654, 0.3346],
        [0.6643, 0.3357],
        [0.6635, 0.3365],
        [0.6635, 0.3365],
        [0.6640, 0.3360],
        [0.6630, 0.3370],
        [0.6639, 0.3361],
        [0.6631, 0.3369],
        [0.6607, 0.3393],
        [0.6600, 0.3400],
        [0.6625, 0.3375],
        [0.6641, 0.3359],
        [0.6625, 0.3375],
        [0.6623, 0.3377],
        [0.6620, 0.3380],
        [0.6624, 0.3376],
        [0.6650, 0.3350],
        [0.6591, 0.3409],
        [0.6580, 0.3420],
        [0.6600, 0.3400],
        [0.6593, 0.3407],
        [0.6615, 0.3385],
        [0.6617, 0.3383],
        [0.6609, 0.3391],
        [0.6647, 0.3353],
        [0.6629, 0.3371],
        [0.6651, 0.3349],
        [0.6614, 0.3386],
        [0.6610, 0.3390],
        [0.6624, 0.3376],
        [0.6639, 0.3361],
        [0.6588, 0.3412],
        [0.6625, 0.3375],
        [0.6668, 0.3332],
        [0.6657, 0.3343],
        [0.6607, 0.3393],
        [0.6675, 0.3325],
        [0.6602, 0.3398],
        [0.6664, 0.3336],
        [0.6607, 0.3393],
        [0.6595, 0.3405],
        [0.6614, 0.3386],
        [0.6698, 0.3302],
        [0.6602, 0.3398],
        [0.6658, 0.3342],
        [0.6668, 0.3332],
        [0.6605, 0.3395],
        [0.6668, 0.3332],
        [0.6547, 0.3453],
        [0.6675, 0.3325],
        [0.6660, 0.3340],
        [0.6666, 0.3334],
        [0.6611, 0.3389],
        [0.6578, 0.3422],
        [0.6624, 0.3376],
        [0.6654, 0.3346],
        [0.6688, 0.3312],
        [0.6687, 0.3313],
        [0.6592, 0.3408],
        [0.6609, 0.3391],
        [0.6623, 0.3377],
        [0.6625, 0.3375],
        [0.6607, 0.3393],
        [0.6617, 0.3383],
        [0.6600, 0.3400],
        [0.6628, 0.3372],
        [0.6603, 0.3397],
        [0.6615, 0.3385],
        [0.6629, 0.3371],
        [0.6582, 0.3418],
        [0.6646, 0.3354],
        [0.6613, 0.3387],
        [0.6652, 0.3348],
        [0.6635, 0.3365],
        [0.6615, 0.3385],
        [0.6663, 0.3337],
        [0.6637, 0.3363],
        [0.6600, 0.3400],
        [0.6602, 0.3398],
        [0.6643, 0.3357],
        [0.6623, 0.3377],
        [0.6624, 0.3376],
        [0.6567, 0.3433],
        [0.6630, 0.3370],
        [0.6650, 0.3350],
        [0.6609, 0.3391],
        [0.6666, 0.3334],
        [0.6668, 0.3332],
        [0.6594, 0.3406],
        [0.6651, 0.3349],
        [0.6665, 0.3335],
        [0.6692, 0.3308],
        [0.6683, 0.3317],
        [0.6634, 0.3366],
        [0.6672, 0.3328],
        [0.6663, 0.3337],
        [0.6613, 0.3387],
        [0.6637, 0.3363],
        [0.6658, 0.3342],
        [0.6650, 0.3350],
        [0.6597, 0.3403],
        [0.6607, 0.3393],
        [0.6582, 0.3418],
        [0.6606, 0.3394],
        [0.6661, 0.3339],
        [0.6624, 0.3376],
        [0.6632, 0.3368],
        [0.6608, 0.3392],
        [0.6563, 0.3437],
        [0.6611, 0.3389],
        [0.6617, 0.3383],
        [0.6608, 0.3392],
        [0.6651, 0.3349],
        [0.6628, 0.3372],
        [0.6671, 0.3329],
        [0.6615, 0.3385],
        [0.6587, 0.3413],
        [0.6657, 0.3343],
        [0.6632, 0.3368],
        [0.6591, 0.3409],
        [0.6609, 0.3391],
        [0.6579, 0.3421],
        [0.6664, 0.3336],
        [0.6649, 0.3351],
        [0.6573, 0.3427],
        [0.6647, 0.3353],
        [0.6590, 0.3410],
        [0.6616, 0.3384],
        [0.6668, 0.3332],
        [0.6608, 0.3392],
        [0.6599, 0.3401],
        [0.6574, 0.3426],
        [0.6656, 0.3344],
        [0.6646, 0.3354],
        [0.6683, 0.3317],
        [0.6580, 0.3420],
        [0.6657, 0.3343],
        [0.6673, 0.3327],
        [0.6614, 0.3386],
        [0.6657, 0.3343],
        [0.6669, 0.3331],
        [0.6583, 0.3417],
        [0.6654, 0.3346],
        [0.6632, 0.3368],
        [0.6658, 0.3342],
        [0.6680, 0.3320],
        [0.6606, 0.3394],
        [0.6614, 0.3386],
        [0.6650, 0.3350],
        [0.6616, 0.3384],
        [0.6673, 0.3327],
        [0.6623, 0.3377],
        [0.6644, 0.3356],
        [0.6651, 0.3349],
        [0.6605, 0.3395],
        [0.6625, 0.3375],
        [0.6625, 0.3375],
        [0.6654, 0.3346],
        [0.6612, 0.3388],
        [0.6685, 0.3315],
        [0.6611, 0.3389],
        [0.6646, 0.3354],
        [0.6662, 0.3338],
        [0.6659, 0.3341],
        [0.6568, 0.3432],
        [0.6636, 0.3364],
        [0.6606, 0.3394],
        [0.6638, 0.3362],
        [0.6638, 0.3362],
        [0.6669, 0.3331],
        [0.6653, 0.3347],
        [0.6635, 0.3365],
        [0.6650, 0.3350],
        [0.6669, 0.3331],
        [0.6637, 0.3363],
        [0.6633, 0.3367],
        [0.6670, 0.3330],
        [0.6602, 0.3398],
        [0.6650, 0.3350],
        [0.6645, 0.3355],
        [0.6604, 0.3396],
        [0.6600, 0.3400],
        [0.6668, 0.3332],
        [0.6665, 0.3335],
        [0.6647, 0.3353],
        [0.6662, 0.3338],
        [0.6660, 0.3340],
        [0.6627, 0.3373],
        [0.6644, 0.3356],
        [0.6654, 0.3346],
        [0.6591, 0.3409],
        [0.6652, 0.3348],
        [0.6669, 0.3331],
        [0.6629, 0.3371],
        [0.6631, 0.3369],
        [0.6649, 0.3351],
        [0.6654, 0.3346],
        [0.6658, 0.3342],
        [0.6694, 0.3306],
        [0.6660, 0.3340],
        [0.6631, 0.3369],
        [0.6646, 0.3354],
        [0.6615, 0.3385],
        [0.6630, 0.3370],
        [0.6671, 0.3329],
        [0.6612, 0.3388],
        [0.6610, 0.3390],
        [0.6645, 0.3355],
        [0.6666, 0.3334],
        [0.6650, 0.3350]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0036 loss: 0.6692 acc_train: 0.6103 time: 0.1204s
tensor([[0.6637, 0.3363],
        [0.6674, 0.3326],
        [0.6658, 0.3342],
        [0.6640, 0.3360],
        [0.6683, 0.3317],
        [0.6599, 0.3401],
        [0.6583, 0.3417],
        [0.6652, 0.3348],
        [0.6666, 0.3334],
        [0.6608, 0.3392],
        [0.6651, 0.3349],
        [0.6627, 0.3373],
        [0.6605, 0.3395],
        [0.6598, 0.3402],
        [0.6657, 0.3343],
        [0.6608, 0.3392],
        [0.6692, 0.3308],
        [0.6638, 0.3362],
        [0.6655, 0.3345],
        [0.6595, 0.3405],
        [0.6677, 0.3323],
        [0.6602, 0.3398],
        [0.6675, 0.3325],
        [0.6663, 0.3337],
        [0.6630, 0.3370],
        [0.6615, 0.3385],
        [0.6627, 0.3373],
        [0.6663, 0.3337],
        [0.6617, 0.3383],
        [0.6610, 0.3390],
        [0.6643, 0.3357],
        [0.6599, 0.3401],
        [0.6627, 0.3373],
        [0.6623, 0.3377],
        [0.6679, 0.3321],
        [0.6586, 0.3414],
        [0.6620, 0.3380],
        [0.6625, 0.3375],
        [0.6654, 0.3346],
        [0.6612, 0.3388],
        [0.6664, 0.3336],
        [0.6645, 0.3355],
        [0.6569, 0.3431],
        [0.6663, 0.3337],
        [0.6657, 0.3343],
        [0.6619, 0.3381],
        [0.6685, 0.3315],
        [0.6674, 0.3326],
        [0.6650, 0.3350],
        [0.6614, 0.3386],
        [0.6636, 0.3364],
        [0.6642, 0.3358],
        [0.6612, 0.3388],
        [0.6671, 0.3329],
        [0.6656, 0.3344],
        [0.6665, 0.3335],
        [0.6683, 0.3317],
        [0.6628, 0.3372],
        [0.6632, 0.3368],
        [0.6612, 0.3388],
        [0.6585, 0.3415],
        [0.6611, 0.3389],
        [0.6661, 0.3339],
        [0.6651, 0.3349],
        [0.6641, 0.3359],
        [0.6638, 0.3362],
        [0.6648, 0.3352],
        [0.6637, 0.3363],
        [0.6645, 0.3355],
        [0.6639, 0.3361],
        [0.6613, 0.3387],
        [0.6606, 0.3394],
        [0.6633, 0.3367],
        [0.6650, 0.3350],
        [0.6631, 0.3369],
        [0.6632, 0.3368],
        [0.6630, 0.3370],
        [0.6629, 0.3371],
        [0.6654, 0.3346],
        [0.6599, 0.3401],
        [0.6585, 0.3415],
        [0.6605, 0.3395],
        [0.6598, 0.3402],
        [0.6622, 0.3378],
        [0.6625, 0.3375],
        [0.6614, 0.3386],
        [0.6656, 0.3344],
        [0.6635, 0.3365],
        [0.6659, 0.3341],
        [0.6620, 0.3380],
        [0.6616, 0.3384],
        [0.6632, 0.3368],
        [0.6646, 0.3354],
        [0.6594, 0.3406],
        [0.6632, 0.3368],
        [0.6676, 0.3324],
        [0.6667, 0.3333],
        [0.6613, 0.3387],
        [0.6684, 0.3316],
        [0.6612, 0.3388],
        [0.6670, 0.3330],
        [0.6615, 0.3385],
        [0.6602, 0.3398],
        [0.6621, 0.3379],
        [0.6705, 0.3295],
        [0.6606, 0.3394],
        [0.6665, 0.3335],
        [0.6676, 0.3324],
        [0.6612, 0.3388],
        [0.6674, 0.3326],
        [0.6559, 0.3441],
        [0.6681, 0.3319],
        [0.6667, 0.3333],
        [0.6673, 0.3327],
        [0.6618, 0.3382],
        [0.6587, 0.3413],
        [0.6631, 0.3369],
        [0.6661, 0.3339],
        [0.6696, 0.3304],
        [0.6694, 0.3306],
        [0.6601, 0.3399],
        [0.6614, 0.3386],
        [0.6629, 0.3371],
        [0.6633, 0.3367],
        [0.6614, 0.3386],
        [0.6626, 0.3374],
        [0.6608, 0.3392],
        [0.6635, 0.3365],
        [0.6611, 0.3389],
        [0.6622, 0.3378],
        [0.6634, 0.3366],
        [0.6588, 0.3412],
        [0.6652, 0.3348],
        [0.6619, 0.3381],
        [0.6660, 0.3340],
        [0.6640, 0.3360],
        [0.6622, 0.3378],
        [0.6673, 0.3327],
        [0.6643, 0.3357],
        [0.6606, 0.3394],
        [0.6611, 0.3389],
        [0.6650, 0.3350],
        [0.6627, 0.3373],
        [0.6631, 0.3369],
        [0.6573, 0.3427],
        [0.6638, 0.3362],
        [0.6659, 0.3341],
        [0.6616, 0.3384],
        [0.6676, 0.3324],
        [0.6675, 0.3325],
        [0.6601, 0.3399],
        [0.6660, 0.3340],
        [0.6672, 0.3328],
        [0.6701, 0.3299],
        [0.6691, 0.3309],
        [0.6638, 0.3362],
        [0.6680, 0.3320],
        [0.6669, 0.3331],
        [0.6619, 0.3381],
        [0.6643, 0.3357],
        [0.6667, 0.3333],
        [0.6658, 0.3342],
        [0.6604, 0.3396],
        [0.6613, 0.3387],
        [0.6591, 0.3409],
        [0.6611, 0.3389],
        [0.6671, 0.3329],
        [0.6632, 0.3368],
        [0.6638, 0.3362],
        [0.6614, 0.3386],
        [0.6574, 0.3426],
        [0.6617, 0.3383],
        [0.6624, 0.3376],
        [0.6614, 0.3386],
        [0.6657, 0.3343],
        [0.6637, 0.3363],
        [0.6679, 0.3321],
        [0.6621, 0.3379],
        [0.6593, 0.3407],
        [0.6668, 0.3332],
        [0.6642, 0.3358],
        [0.6599, 0.3401],
        [0.6616, 0.3384],
        [0.6588, 0.3412],
        [0.6671, 0.3329],
        [0.6657, 0.3343],
        [0.6581, 0.3419],
        [0.6653, 0.3347],
        [0.6596, 0.3404],
        [0.6624, 0.3376],
        [0.6676, 0.3324],
        [0.6614, 0.3386],
        [0.6606, 0.3394],
        [0.6580, 0.3420],
        [0.6663, 0.3337],
        [0.6656, 0.3344],
        [0.6690, 0.3310],
        [0.6586, 0.3414],
        [0.6665, 0.3335],
        [0.6679, 0.3321],
        [0.6619, 0.3381],
        [0.6664, 0.3336],
        [0.6675, 0.3325],
        [0.6590, 0.3410],
        [0.6660, 0.3340],
        [0.6640, 0.3360],
        [0.6668, 0.3332],
        [0.6686, 0.3314],
        [0.6613, 0.3387],
        [0.6619, 0.3381],
        [0.6656, 0.3344],
        [0.6622, 0.3378],
        [0.6681, 0.3319],
        [0.6633, 0.3367],
        [0.6650, 0.3350],
        [0.6659, 0.3341],
        [0.6610, 0.3390],
        [0.6634, 0.3366],
        [0.6632, 0.3368],
        [0.6664, 0.3336],
        [0.6619, 0.3381],
        [0.6693, 0.3307],
        [0.6617, 0.3383],
        [0.6653, 0.3347],
        [0.6671, 0.3329],
        [0.6667, 0.3333],
        [0.6576, 0.3424],
        [0.6644, 0.3356],
        [0.6613, 0.3387],
        [0.6647, 0.3353],
        [0.6644, 0.3356],
        [0.6678, 0.3322],
        [0.6661, 0.3339],
        [0.6641, 0.3359],
        [0.6660, 0.3340],
        [0.6677, 0.3323],
        [0.6646, 0.3354],
        [0.6639, 0.3361],
        [0.6677, 0.3323],
        [0.6609, 0.3391],
        [0.6657, 0.3343],
        [0.6651, 0.3349],
        [0.6612, 0.3388],
        [0.6607, 0.3393],
        [0.6676, 0.3324],
        [0.6673, 0.3327],
        [0.6655, 0.3345],
        [0.6669, 0.3331],
        [0.6667, 0.3333],
        [0.6635, 0.3365],
        [0.6653, 0.3347],
        [0.6662, 0.3338],
        [0.6598, 0.3402],
        [0.6659, 0.3341],
        [0.6676, 0.3324],
        [0.6638, 0.3362],
        [0.6640, 0.3360],
        [0.6657, 0.3343],
        [0.6661, 0.3339],
        [0.6668, 0.3332],
        [0.6702, 0.3298],
        [0.6668, 0.3332],
        [0.6639, 0.3361],
        [0.6654, 0.3346],
        [0.6623, 0.3377],
        [0.6636, 0.3364],
        [0.6679, 0.3321],
        [0.6621, 0.3379],
        [0.6616, 0.3384],
        [0.6653, 0.3347],
        [0.6676, 0.3324],
        [0.6659, 0.3341]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0037 loss: 0.6692 acc_train: 0.6103 time: 0.1207s
tensor([[0.6642, 0.3358],
        [0.6679, 0.3321],
        [0.6664, 0.3336],
        [0.6644, 0.3356],
        [0.6687, 0.3313],
        [0.6603, 0.3397],
        [0.6587, 0.3413],
        [0.6657, 0.3343],
        [0.6671, 0.3329],
        [0.6611, 0.3389],
        [0.6657, 0.3343],
        [0.6632, 0.3368],
        [0.6608, 0.3392],
        [0.6604, 0.3396],
        [0.6661, 0.3339],
        [0.6612, 0.3388],
        [0.6697, 0.3303],
        [0.6640, 0.3360],
        [0.6662, 0.3338],
        [0.6600, 0.3400],
        [0.6683, 0.3317],
        [0.6607, 0.3393],
        [0.6680, 0.3320],
        [0.6668, 0.3332],
        [0.6633, 0.3367],
        [0.6620, 0.3380],
        [0.6630, 0.3370],
        [0.6667, 0.3333],
        [0.6620, 0.3380],
        [0.6614, 0.3386],
        [0.6650, 0.3350],
        [0.6602, 0.3398],
        [0.6631, 0.3369],
        [0.6628, 0.3372],
        [0.6684, 0.3316],
        [0.6598, 0.3402],
        [0.6623, 0.3377],
        [0.6628, 0.3372],
        [0.6659, 0.3341],
        [0.6615, 0.3385],
        [0.6667, 0.3333],
        [0.6651, 0.3349],
        [0.6577, 0.3423],
        [0.6669, 0.3331],
        [0.6660, 0.3340],
        [0.6625, 0.3375],
        [0.6691, 0.3309],
        [0.6680, 0.3320],
        [0.6655, 0.3345],
        [0.6621, 0.3379],
        [0.6642, 0.3358],
        [0.6648, 0.3352],
        [0.6620, 0.3380],
        [0.6677, 0.3323],
        [0.6662, 0.3338],
        [0.6671, 0.3329],
        [0.6689, 0.3311],
        [0.6634, 0.3366],
        [0.6636, 0.3364],
        [0.6614, 0.3386],
        [0.6589, 0.3411],
        [0.6615, 0.3385],
        [0.6665, 0.3335],
        [0.6656, 0.3344],
        [0.6645, 0.3355],
        [0.6639, 0.3361],
        [0.6654, 0.3346],
        [0.6641, 0.3359],
        [0.6650, 0.3350],
        [0.6644, 0.3356],
        [0.6617, 0.3383],
        [0.6610, 0.3390],
        [0.6639, 0.3361],
        [0.6656, 0.3344],
        [0.6636, 0.3364],
        [0.6638, 0.3362],
        [0.6637, 0.3363],
        [0.6632, 0.3368],
        [0.6657, 0.3343],
        [0.6604, 0.3396],
        [0.6588, 0.3412],
        [0.6608, 0.3392],
        [0.6602, 0.3398],
        [0.6628, 0.3372],
        [0.6630, 0.3370],
        [0.6618, 0.3382],
        [0.6664, 0.3336],
        [0.6639, 0.3361],
        [0.6663, 0.3337],
        [0.6624, 0.3376],
        [0.6620, 0.3380],
        [0.6637, 0.3363],
        [0.6650, 0.3350],
        [0.6597, 0.3403],
        [0.6636, 0.3364],
        [0.6682, 0.3318],
        [0.6674, 0.3326],
        [0.6617, 0.3383],
        [0.6690, 0.3310],
        [0.6620, 0.3380],
        [0.6674, 0.3326],
        [0.6620, 0.3380],
        [0.6608, 0.3392],
        [0.6626, 0.3374],
        [0.6710, 0.3290],
        [0.6609, 0.3391],
        [0.6672, 0.3328],
        [0.6682, 0.3318],
        [0.6616, 0.3384],
        [0.6678, 0.3322],
        [0.6570, 0.3430],
        [0.6686, 0.3314],
        [0.6672, 0.3328],
        [0.6678, 0.3322],
        [0.6623, 0.3377],
        [0.6594, 0.3406],
        [0.6637, 0.3363],
        [0.6665, 0.3335],
        [0.6702, 0.3298],
        [0.6698, 0.3302],
        [0.6606, 0.3394],
        [0.6617, 0.3383],
        [0.6633, 0.3367],
        [0.6639, 0.3361],
        [0.6618, 0.3382],
        [0.6633, 0.3367],
        [0.6614, 0.3386],
        [0.6641, 0.3359],
        [0.6616, 0.3384],
        [0.6627, 0.3373],
        [0.6638, 0.3362],
        [0.6593, 0.3407],
        [0.6657, 0.3343],
        [0.6623, 0.3377],
        [0.6667, 0.3333],
        [0.6643, 0.3357],
        [0.6627, 0.3373],
        [0.6680, 0.3320],
        [0.6648, 0.3352],
        [0.6610, 0.3390],
        [0.6617, 0.3383],
        [0.6655, 0.3345],
        [0.6629, 0.3371],
        [0.6635, 0.3365],
        [0.6577, 0.3423],
        [0.6644, 0.3356],
        [0.6665, 0.3335],
        [0.6621, 0.3379],
        [0.6683, 0.3317],
        [0.6681, 0.3319],
        [0.6608, 0.3392],
        [0.6667, 0.3333],
        [0.6677, 0.3323],
        [0.6708, 0.3292],
        [0.6696, 0.3304],
        [0.6641, 0.3359],
        [0.6685, 0.3315],
        [0.6674, 0.3326],
        [0.6624, 0.3376],
        [0.6646, 0.3354],
        [0.6673, 0.3327],
        [0.6664, 0.3336],
        [0.6609, 0.3391],
        [0.6617, 0.3383],
        [0.6598, 0.3402],
        [0.6615, 0.3385],
        [0.6678, 0.3322],
        [0.6637, 0.3363],
        [0.6642, 0.3358],
        [0.6618, 0.3382],
        [0.6582, 0.3418],
        [0.6621, 0.3379],
        [0.6628, 0.3372],
        [0.6618, 0.3382],
        [0.6661, 0.3339],
        [0.6643, 0.3357],
        [0.6685, 0.3315],
        [0.6625, 0.3375],
        [0.6598, 0.3402],
        [0.6676, 0.3324],
        [0.6649, 0.3351],
        [0.6604, 0.3396],
        [0.6621, 0.3379],
        [0.6595, 0.3405],
        [0.6677, 0.3323],
        [0.6663, 0.3337],
        [0.6586, 0.3414],
        [0.6656, 0.3344],
        [0.6600, 0.3400],
        [0.6629, 0.3371],
        [0.6682, 0.3318],
        [0.6618, 0.3382],
        [0.6611, 0.3389],
        [0.6584, 0.3416],
        [0.6668, 0.3332],
        [0.6663, 0.3337],
        [0.6696, 0.3304],
        [0.6590, 0.3410],
        [0.6671, 0.3329],
        [0.6683, 0.3317],
        [0.6623, 0.3377],
        [0.6669, 0.3331],
        [0.6679, 0.3321],
        [0.6595, 0.3405],
        [0.6663, 0.3337],
        [0.6645, 0.3355],
        [0.6675, 0.3325],
        [0.6691, 0.3309],
        [0.6617, 0.3383],
        [0.6622, 0.3378],
        [0.6660, 0.3340],
        [0.6626, 0.3374],
        [0.6687, 0.3313],
        [0.6641, 0.3359],
        [0.6654, 0.3346],
        [0.6664, 0.3336],
        [0.6613, 0.3387],
        [0.6641, 0.3359],
        [0.6638, 0.3362],
        [0.6672, 0.3328],
        [0.6623, 0.3377],
        [0.6698, 0.3302],
        [0.6622, 0.3378],
        [0.6659, 0.3341],
        [0.6679, 0.3321],
        [0.6672, 0.3328],
        [0.6582, 0.3418],
        [0.6649, 0.3351],
        [0.6617, 0.3383],
        [0.6653, 0.3347],
        [0.6649, 0.3351],
        [0.6683, 0.3317],
        [0.6666, 0.3334],
        [0.6646, 0.3354],
        [0.6667, 0.3333],
        [0.6682, 0.3318],
        [0.6653, 0.3347],
        [0.6642, 0.3358],
        [0.6684, 0.3316],
        [0.6615, 0.3385],
        [0.6662, 0.3338],
        [0.6654, 0.3346],
        [0.6617, 0.3383],
        [0.6612, 0.3388],
        [0.6682, 0.3318],
        [0.6678, 0.3322],
        [0.6661, 0.3339],
        [0.6675, 0.3325],
        [0.6672, 0.3328],
        [0.6642, 0.3358],
        [0.6660, 0.3340],
        [0.6668, 0.3332],
        [0.6602, 0.3398],
        [0.6664, 0.3336],
        [0.6683, 0.3317],
        [0.6643, 0.3357],
        [0.6647, 0.3353],
        [0.6663, 0.3337],
        [0.6666, 0.3334],
        [0.6676, 0.3324],
        [0.6708, 0.3292],
        [0.6672, 0.3328],
        [0.6644, 0.3356],
        [0.6660, 0.3340],
        [0.6628, 0.3372],
        [0.6641, 0.3359],
        [0.6685, 0.3315],
        [0.6628, 0.3372],
        [0.6620, 0.3380],
        [0.6659, 0.3341],
        [0.6683, 0.3317],
        [0.6664, 0.3336]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0038 loss: 0.6691 acc_train: 0.6103 time: 0.1248s
tensor([[0.6646, 0.3354],
        [0.6685, 0.3315],
        [0.6669, 0.3331],
        [0.6646, 0.3354],
        [0.6689, 0.3311],
        [0.6605, 0.3395],
        [0.6590, 0.3410],
        [0.6661, 0.3339],
        [0.6675, 0.3325],
        [0.6612, 0.3388],
        [0.6661, 0.3339],
        [0.6634, 0.3366],
        [0.6610, 0.3390],
        [0.6608, 0.3392],
        [0.6664, 0.3336],
        [0.6615, 0.3385],
        [0.6701, 0.3299],
        [0.6641, 0.3359],
        [0.6667, 0.3333],
        [0.6604, 0.3396],
        [0.6688, 0.3312],
        [0.6610, 0.3390],
        [0.6683, 0.3317],
        [0.6672, 0.3328],
        [0.6636, 0.3364],
        [0.6624, 0.3376],
        [0.6633, 0.3367],
        [0.6669, 0.3331],
        [0.6622, 0.3378],
        [0.6618, 0.3382],
        [0.6654, 0.3346],
        [0.6605, 0.3395],
        [0.6635, 0.3365],
        [0.6632, 0.3368],
        [0.6686, 0.3314],
        [0.6607, 0.3393],
        [0.6626, 0.3374],
        [0.6630, 0.3370],
        [0.6664, 0.3336],
        [0.6617, 0.3383],
        [0.6669, 0.3331],
        [0.6654, 0.3346],
        [0.6583, 0.3417],
        [0.6674, 0.3326],
        [0.6661, 0.3339],
        [0.6628, 0.3372],
        [0.6695, 0.3305],
        [0.6685, 0.3315],
        [0.6659, 0.3341],
        [0.6625, 0.3375],
        [0.6647, 0.3353],
        [0.6652, 0.3348],
        [0.6626, 0.3374],
        [0.6681, 0.3319],
        [0.6666, 0.3334],
        [0.6676, 0.3324],
        [0.6694, 0.3306],
        [0.6639, 0.3361],
        [0.6639, 0.3361],
        [0.6615, 0.3385],
        [0.6592, 0.3408],
        [0.6618, 0.3382],
        [0.6667, 0.3333],
        [0.6659, 0.3341],
        [0.6648, 0.3352],
        [0.6640, 0.3360],
        [0.6659, 0.3341],
        [0.6645, 0.3355],
        [0.6654, 0.3346],
        [0.6649, 0.3351],
        [0.6619, 0.3381],
        [0.6612, 0.3388],
        [0.6644, 0.3356],
        [0.6660, 0.3340],
        [0.6639, 0.3361],
        [0.6642, 0.3358],
        [0.6642, 0.3358],
        [0.6635, 0.3365],
        [0.6659, 0.3341],
        [0.6607, 0.3393],
        [0.6589, 0.3411],
        [0.6610, 0.3390],
        [0.6605, 0.3395],
        [0.6632, 0.3368],
        [0.6634, 0.3366],
        [0.6620, 0.3380],
        [0.6670, 0.3330],
        [0.6642, 0.3358],
        [0.6666, 0.3334],
        [0.6626, 0.3374],
        [0.6623, 0.3377],
        [0.6639, 0.3361],
        [0.6653, 0.3347],
        [0.6599, 0.3401],
        [0.6638, 0.3362],
        [0.6686, 0.3314],
        [0.6678, 0.3322],
        [0.6620, 0.3380],
        [0.6694, 0.3306],
        [0.6626, 0.3374],
        [0.6677, 0.3323],
        [0.6623, 0.3377],
        [0.6611, 0.3389],
        [0.6630, 0.3370],
        [0.6712, 0.3288],
        [0.6611, 0.3389],
        [0.6677, 0.3323],
        [0.6685, 0.3315],
        [0.6618, 0.3382],
        [0.6681, 0.3319],
        [0.6579, 0.3421],
        [0.6689, 0.3311],
        [0.6674, 0.3326],
        [0.6681, 0.3319],
        [0.6625, 0.3375],
        [0.6600, 0.3400],
        [0.6641, 0.3359],
        [0.6669, 0.3331],
        [0.6705, 0.3295],
        [0.6700, 0.3300],
        [0.6608, 0.3392],
        [0.6619, 0.3381],
        [0.6636, 0.3364],
        [0.6642, 0.3358],
        [0.6621, 0.3379],
        [0.6638, 0.3362],
        [0.6618, 0.3382],
        [0.6647, 0.3353],
        [0.6620, 0.3380],
        [0.6630, 0.3370],
        [0.6640, 0.3360],
        [0.6596, 0.3404],
        [0.6659, 0.3341],
        [0.6624, 0.3376],
        [0.6671, 0.3329],
        [0.6644, 0.3356],
        [0.6630, 0.3370],
        [0.6685, 0.3315],
        [0.6652, 0.3348],
        [0.6613, 0.3387],
        [0.6622, 0.3378],
        [0.6658, 0.3342],
        [0.6631, 0.3369],
        [0.6638, 0.3362],
        [0.6579, 0.3421],
        [0.6648, 0.3352],
        [0.6669, 0.3331],
        [0.6625, 0.3375],
        [0.6688, 0.3312],
        [0.6684, 0.3316],
        [0.6613, 0.3387],
        [0.6672, 0.3328],
        [0.6682, 0.3318],
        [0.6713, 0.3287],
        [0.6700, 0.3300],
        [0.6643, 0.3357],
        [0.6689, 0.3311],
        [0.6677, 0.3323],
        [0.6627, 0.3373],
        [0.6647, 0.3353],
        [0.6678, 0.3322],
        [0.6669, 0.3331],
        [0.6613, 0.3387],
        [0.6620, 0.3380],
        [0.6603, 0.3397],
        [0.6618, 0.3382],
        [0.6683, 0.3317],
        [0.6640, 0.3360],
        [0.6645, 0.3355],
        [0.6620, 0.3380],
        [0.6588, 0.3412],
        [0.6624, 0.3376],
        [0.6629, 0.3371],
        [0.6621, 0.3379],
        [0.6664, 0.3336],
        [0.6648, 0.3352],
        [0.6688, 0.3312],
        [0.6628, 0.3372],
        [0.6602, 0.3398],
        [0.6683, 0.3317],
        [0.6655, 0.3345],
        [0.6607, 0.3393],
        [0.6624, 0.3376],
        [0.6601, 0.3399],
        [0.6682, 0.3318],
        [0.6667, 0.3333],
        [0.6589, 0.3411],
        [0.6657, 0.3343],
        [0.6603, 0.3397],
        [0.6634, 0.3366],
        [0.6688, 0.3312],
        [0.6621, 0.3379],
        [0.6615, 0.3385],
        [0.6588, 0.3412],
        [0.6672, 0.3328],
        [0.6669, 0.3331],
        [0.6699, 0.3301],
        [0.6594, 0.3406],
        [0.6675, 0.3325],
        [0.6686, 0.3314],
        [0.6625, 0.3375],
        [0.6674, 0.3326],
        [0.6682, 0.3318],
        [0.6598, 0.3402],
        [0.6666, 0.3334],
        [0.6648, 0.3352],
        [0.6681, 0.3319],
        [0.6693, 0.3307],
        [0.6619, 0.3381],
        [0.6624, 0.3376],
        [0.6662, 0.3338],
        [0.6628, 0.3372],
        [0.6691, 0.3309],
        [0.6647, 0.3353],
        [0.6657, 0.3343],
        [0.6668, 0.3332],
        [0.6614, 0.3386],
        [0.6647, 0.3353],
        [0.6642, 0.3358],
        [0.6676, 0.3324],
        [0.6627, 0.3373],
        [0.6702, 0.3298],
        [0.6625, 0.3375],
        [0.6663, 0.3337],
        [0.6684, 0.3316],
        [0.6676, 0.3324],
        [0.6588, 0.3412],
        [0.6654, 0.3346],
        [0.6619, 0.3381],
        [0.6656, 0.3344],
        [0.6653, 0.3347],
        [0.6686, 0.3314],
        [0.6670, 0.3330],
        [0.6649, 0.3351],
        [0.6673, 0.3327],
        [0.6685, 0.3315],
        [0.6657, 0.3343],
        [0.6645, 0.3355],
        [0.6689, 0.3311],
        [0.6618, 0.3382],
        [0.6667, 0.3333],
        [0.6655, 0.3345],
        [0.6621, 0.3379],
        [0.6615, 0.3385],
        [0.6686, 0.3314],
        [0.6682, 0.3318],
        [0.6665, 0.3335],
        [0.6678, 0.3322],
        [0.6677, 0.3323],
        [0.6646, 0.3354],
        [0.6665, 0.3335],
        [0.6672, 0.3328],
        [0.6605, 0.3395],
        [0.6668, 0.3332],
        [0.6687, 0.3313],
        [0.6647, 0.3353],
        [0.6652, 0.3348],
        [0.6668, 0.3332],
        [0.6669, 0.3331],
        [0.6681, 0.3319],
        [0.6712, 0.3288],
        [0.6674, 0.3326],
        [0.6647, 0.3353],
        [0.6664, 0.3336],
        [0.6631, 0.3369],
        [0.6645, 0.3355],
        [0.6689, 0.3311],
        [0.6631, 0.3369],
        [0.6623, 0.3377],
        [0.6662, 0.3338],
        [0.6689, 0.3311],
        [0.6667, 0.3333]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0039 loss: 0.6691 acc_train: 0.6103 time: 0.1234s
tensor([[0.6649, 0.3351],
        [0.6689, 0.3311],
        [0.6671, 0.3329],
        [0.6647, 0.3353],
        [0.6691, 0.3309],
        [0.6607, 0.3393],
        [0.6592, 0.3408],
        [0.6663, 0.3337],
        [0.6677, 0.3323],
        [0.6611, 0.3389],
        [0.6663, 0.3337],
        [0.6635, 0.3365],
        [0.6611, 0.3389],
        [0.6611, 0.3389],
        [0.6666, 0.3334],
        [0.6617, 0.3383],
        [0.6703, 0.3297],
        [0.6641, 0.3359],
        [0.6671, 0.3329],
        [0.6606, 0.3394],
        [0.6691, 0.3309],
        [0.6610, 0.3390],
        [0.6684, 0.3316],
        [0.6675, 0.3325],
        [0.6637, 0.3363],
        [0.6627, 0.3373],
        [0.6635, 0.3365],
        [0.6670, 0.3330],
        [0.6623, 0.3377],
        [0.6621, 0.3379],
        [0.6657, 0.3343],
        [0.6607, 0.3393],
        [0.6638, 0.3362],
        [0.6634, 0.3366],
        [0.6687, 0.3313],
        [0.6614, 0.3386],
        [0.6627, 0.3373],
        [0.6631, 0.3369],
        [0.6666, 0.3334],
        [0.6617, 0.3383],
        [0.6671, 0.3329],
        [0.6656, 0.3344],
        [0.6585, 0.3415],
        [0.6677, 0.3323],
        [0.6661, 0.3339],
        [0.6629, 0.3371],
        [0.6697, 0.3303],
        [0.6688, 0.3312],
        [0.6661, 0.3339],
        [0.6629, 0.3371],
        [0.6650, 0.3350],
        [0.6655, 0.3345],
        [0.6631, 0.3369],
        [0.6683, 0.3317],
        [0.6668, 0.3332],
        [0.6678, 0.3322],
        [0.6697, 0.3303],
        [0.6642, 0.3358],
        [0.6642, 0.3358],
        [0.6615, 0.3385],
        [0.6594, 0.3406],
        [0.6619, 0.3381],
        [0.6668, 0.3332],
        [0.6661, 0.3339],
        [0.6650, 0.3350],
        [0.6640, 0.3360],
        [0.6661, 0.3339],
        [0.6647, 0.3353],
        [0.6656, 0.3344],
        [0.6652, 0.3348],
        [0.6620, 0.3380],
        [0.6612, 0.3388],
        [0.6648, 0.3352],
        [0.6662, 0.3338],
        [0.6641, 0.3359],
        [0.6643, 0.3357],
        [0.6646, 0.3354],
        [0.6637, 0.3363],
        [0.6660, 0.3340],
        [0.6608, 0.3392],
        [0.6590, 0.3410],
        [0.6611, 0.3389],
        [0.6607, 0.3393],
        [0.6634, 0.3366],
        [0.6635, 0.3365],
        [0.6622, 0.3378],
        [0.6675, 0.3325],
        [0.6643, 0.3357],
        [0.6666, 0.3334],
        [0.6628, 0.3372],
        [0.6625, 0.3375],
        [0.6640, 0.3360],
        [0.6654, 0.3346],
        [0.6600, 0.3400],
        [0.6638, 0.3362],
        [0.6689, 0.3311],
        [0.6681, 0.3319],
        [0.6622, 0.3378],
        [0.6696, 0.3304],
        [0.6630, 0.3370],
        [0.6677, 0.3323],
        [0.6625, 0.3375],
        [0.6613, 0.3387],
        [0.6632, 0.3368],
        [0.6713, 0.3287],
        [0.6611, 0.3389],
        [0.6681, 0.3319],
        [0.6686, 0.3314],
        [0.6619, 0.3381],
        [0.6684, 0.3316],
        [0.6587, 0.3413],
        [0.6691, 0.3309],
        [0.6676, 0.3324],
        [0.6683, 0.3317],
        [0.6626, 0.3374],
        [0.6606, 0.3394],
        [0.6644, 0.3356],
        [0.6671, 0.3329],
        [0.6707, 0.3293],
        [0.6700, 0.3300],
        [0.6609, 0.3391],
        [0.6620, 0.3380],
        [0.6637, 0.3363],
        [0.6644, 0.3356],
        [0.6623, 0.3377],
        [0.6642, 0.3358],
        [0.6620, 0.3380],
        [0.6651, 0.3349],
        [0.6623, 0.3377],
        [0.6632, 0.3368],
        [0.6642, 0.3358],
        [0.6599, 0.3401],
        [0.6661, 0.3339],
        [0.6623, 0.3377],
        [0.6673, 0.3327],
        [0.6645, 0.3355],
        [0.6631, 0.3369],
        [0.6687, 0.3313],
        [0.6654, 0.3346],
        [0.6614, 0.3386],
        [0.6626, 0.3374],
        [0.6661, 0.3339],
        [0.6631, 0.3369],
        [0.6639, 0.3361],
        [0.6581, 0.3419],
        [0.6651, 0.3349],
        [0.6671, 0.3329],
        [0.6628, 0.3372],
        [0.6691, 0.3309],
        [0.6687, 0.3313],
        [0.6617, 0.3383],
        [0.6676, 0.3324],
        [0.6685, 0.3315],
        [0.6716, 0.3284],
        [0.6701, 0.3299],
        [0.6644, 0.3356],
        [0.6690, 0.3310],
        [0.6678, 0.3322],
        [0.6630, 0.3370],
        [0.6648, 0.3352],
        [0.6681, 0.3319],
        [0.6673, 0.3327],
        [0.6615, 0.3385],
        [0.6622, 0.3378],
        [0.6607, 0.3393],
        [0.6620, 0.3380],
        [0.6686, 0.3314],
        [0.6641, 0.3359],
        [0.6647, 0.3353],
        [0.6620, 0.3380],
        [0.6593, 0.3407],
        [0.6626, 0.3374],
        [0.6627, 0.3373],
        [0.6623, 0.3377],
        [0.6665, 0.3335],
        [0.6652, 0.3348],
        [0.6690, 0.3310],
        [0.6629, 0.3371],
        [0.6604, 0.3396],
        [0.6688, 0.3312],
        [0.6659, 0.3341],
        [0.6609, 0.3391],
        [0.6625, 0.3375],
        [0.6604, 0.3396],
        [0.6686, 0.3314],
        [0.6669, 0.3331],
        [0.6591, 0.3409],
        [0.6657, 0.3343],
        [0.6605, 0.3395],
        [0.6636, 0.3364],
        [0.6691, 0.3309],
        [0.6621, 0.3379],
        [0.6618, 0.3382],
        [0.6590, 0.3410],
        [0.6675, 0.3325],
        [0.6672, 0.3328],
        [0.6700, 0.3300],
        [0.6596, 0.3404],
        [0.6678, 0.3322],
        [0.6689, 0.3311],
        [0.6626, 0.3374],
        [0.6677, 0.3323],
        [0.6684, 0.3316],
        [0.6600, 0.3400],
        [0.6667, 0.3333],
        [0.6651, 0.3349],
        [0.6685, 0.3315],
        [0.6695, 0.3305],
        [0.6619, 0.3381],
        [0.6624, 0.3376],
        [0.6663, 0.3337],
        [0.6628, 0.3372],
        [0.6693, 0.3307],
        [0.6650, 0.3350],
        [0.6658, 0.3342],
        [0.6671, 0.3329],
        [0.6615, 0.3385],
        [0.6651, 0.3349],
        [0.6644, 0.3356],
        [0.6678, 0.3322],
        [0.6629, 0.3371],
        [0.6705, 0.3295],
        [0.6627, 0.3373],
        [0.6666, 0.3334],
        [0.6687, 0.3313],
        [0.6678, 0.3322],
        [0.6593, 0.3407],
        [0.6657, 0.3343],
        [0.6619, 0.3381],
        [0.6658, 0.3342],
        [0.6656, 0.3344],
        [0.6687, 0.3313],
        [0.6672, 0.3328],
        [0.6651, 0.3349],
        [0.6678, 0.3322],
        [0.6686, 0.3314],
        [0.6660, 0.3340],
        [0.6646, 0.3354],
        [0.6693, 0.3307],
        [0.6620, 0.3380],
        [0.6670, 0.3330],
        [0.6655, 0.3345],
        [0.6624, 0.3376],
        [0.6616, 0.3384],
        [0.6689, 0.3311],
        [0.6684, 0.3316],
        [0.6669, 0.3331],
        [0.6679, 0.3321],
        [0.6680, 0.3320],
        [0.6649, 0.3351],
        [0.6667, 0.3333],
        [0.6676, 0.3324],
        [0.6607, 0.3393],
        [0.6671, 0.3329],
        [0.6691, 0.3309],
        [0.6649, 0.3351],
        [0.6655, 0.3345],
        [0.6671, 0.3329],
        [0.6670, 0.3330],
        [0.6684, 0.3316],
        [0.6713, 0.3287],
        [0.6675, 0.3325],
        [0.6649, 0.3351],
        [0.6668, 0.3332],
        [0.6634, 0.3366],
        [0.6646, 0.3354],
        [0.6693, 0.3307],
        [0.6633, 0.3367],
        [0.6625, 0.3375],
        [0.6665, 0.3335],
        [0.6693, 0.3307],
        [0.6669, 0.3331]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0040 loss: 0.6690 acc_train: 0.6103 time: 0.1484s
tensor([[0.6650, 0.3350],
        [0.6692, 0.3308],
        [0.6672, 0.3328],
        [0.6647, 0.3353],
        [0.6692, 0.3308],
        [0.6607, 0.3393],
        [0.6592, 0.3408],
        [0.6663, 0.3337],
        [0.6678, 0.3322],
        [0.6609, 0.3391],
        [0.6663, 0.3337],
        [0.6636, 0.3364],
        [0.6613, 0.3387],
        [0.6613, 0.3387],
        [0.6666, 0.3334],
        [0.6618, 0.3382],
        [0.6704, 0.3296],
        [0.6639, 0.3361],
        [0.6673, 0.3327],
        [0.6607, 0.3393],
        [0.6693, 0.3307],
        [0.6610, 0.3390],
        [0.6684, 0.3316],
        [0.6676, 0.3324],
        [0.6637, 0.3363],
        [0.6628, 0.3372],
        [0.6636, 0.3364],
        [0.6670, 0.3330],
        [0.6623, 0.3377],
        [0.6622, 0.3378],
        [0.6657, 0.3343],
        [0.6608, 0.3392],
        [0.6640, 0.3360],
        [0.6635, 0.3365],
        [0.6687, 0.3313],
        [0.6619, 0.3381],
        [0.6627, 0.3373],
        [0.6632, 0.3368],
        [0.6667, 0.3333],
        [0.6617, 0.3383],
        [0.6672, 0.3328],
        [0.6657, 0.3343],
        [0.6586, 0.3414],
        [0.6678, 0.3322],
        [0.6659, 0.3341],
        [0.6630, 0.3370],
        [0.6698, 0.3302],
        [0.6689, 0.3311],
        [0.6662, 0.3338],
        [0.6631, 0.3369],
        [0.6651, 0.3349],
        [0.6657, 0.3343],
        [0.6632, 0.3368],
        [0.6683, 0.3317],
        [0.6669, 0.3331],
        [0.6679, 0.3321],
        [0.6699, 0.3301],
        [0.6645, 0.3355],
        [0.6643, 0.3357],
        [0.6614, 0.3386],
        [0.6596, 0.3404],
        [0.6619, 0.3381],
        [0.6668, 0.3332],
        [0.6662, 0.3338],
        [0.6651, 0.3349],
        [0.6639, 0.3361],
        [0.6663, 0.3337],
        [0.6648, 0.3352],
        [0.6657, 0.3343],
        [0.6654, 0.3346],
        [0.6620, 0.3380],
        [0.6611, 0.3389],
        [0.6651, 0.3349],
        [0.6661, 0.3339],
        [0.6642, 0.3358],
        [0.6643, 0.3357],
        [0.6647, 0.3353],
        [0.6638, 0.3362],
        [0.6661, 0.3339],
        [0.6609, 0.3391],
        [0.6591, 0.3409],
        [0.6611, 0.3389],
        [0.6609, 0.3391],
        [0.6635, 0.3365],
        [0.6635, 0.3365],
        [0.6623, 0.3377],
        [0.6678, 0.3322],
        [0.6643, 0.3357],
        [0.6666, 0.3334],
        [0.6629, 0.3371],
        [0.6626, 0.3374],
        [0.6639, 0.3361],
        [0.6654, 0.3346],
        [0.6600, 0.3400],
        [0.6637, 0.3363],
        [0.6689, 0.3311],
        [0.6682, 0.3318],
        [0.6622, 0.3378],
        [0.6697, 0.3303],
        [0.6632, 0.3368],
        [0.6676, 0.3324],
        [0.6626, 0.3374],
        [0.6614, 0.3386],
        [0.6632, 0.3368],
        [0.6712, 0.3288],
        [0.6612, 0.3388],
        [0.6684, 0.3316],
        [0.6685, 0.3315],
        [0.6618, 0.3382],
        [0.6685, 0.3315],
        [0.6592, 0.3408],
        [0.6692, 0.3308],
        [0.6676, 0.3324],
        [0.6683, 0.3317],
        [0.6625, 0.3375],
        [0.6610, 0.3390],
        [0.6646, 0.3354],
        [0.6671, 0.3329],
        [0.6706, 0.3294],
        [0.6698, 0.3302],
        [0.6606, 0.3394],
        [0.6621, 0.3379],
        [0.6638, 0.3362],
        [0.6644, 0.3356],
        [0.6624, 0.3376],
        [0.6644, 0.3356],
        [0.6621, 0.3379],
        [0.6655, 0.3345],
        [0.6623, 0.3377],
        [0.6633, 0.3367],
        [0.6643, 0.3357],
        [0.6600, 0.3400],
        [0.6661, 0.3339],
        [0.6621, 0.3379],
        [0.6673, 0.3327],
        [0.6644, 0.3356],
        [0.6631, 0.3369],
        [0.6688, 0.3312],
        [0.6655, 0.3345],
        [0.6615, 0.3385],
        [0.6627, 0.3373],
        [0.6662, 0.3338],
        [0.6631, 0.3369],
        [0.6638, 0.3362],
        [0.6581, 0.3419],
        [0.6653, 0.3347],
        [0.6671, 0.3329],
        [0.6629, 0.3371],
        [0.6692, 0.3308],
        [0.6687, 0.3313],
        [0.6619, 0.3381],
        [0.6678, 0.3322],
        [0.6687, 0.3313],
        [0.6718, 0.3282],
        [0.6702, 0.3298],
        [0.6645, 0.3355],
        [0.6690, 0.3310],
        [0.6679, 0.3321],
        [0.6631, 0.3369],
        [0.6647, 0.3353],
        [0.6683, 0.3317],
        [0.6675, 0.3325],
        [0.6617, 0.3383],
        [0.6622, 0.3378],
        [0.6609, 0.3391],
        [0.6621, 0.3379],
        [0.6686, 0.3314],
        [0.6640, 0.3360],
        [0.6647, 0.3353],
        [0.6620, 0.3380],
        [0.6595, 0.3405],
        [0.6626, 0.3374],
        [0.6625, 0.3375],
        [0.6624, 0.3376],
        [0.6666, 0.3334],
        [0.6653, 0.3347],
        [0.6690, 0.3310],
        [0.6629, 0.3371],
        [0.6606, 0.3394],
        [0.6691, 0.3309],
        [0.6661, 0.3339],
        [0.6609, 0.3391],
        [0.6624, 0.3376],
        [0.6606, 0.3394],
        [0.6688, 0.3312],
        [0.6669, 0.3331],
        [0.6592, 0.3408],
        [0.6655, 0.3345],
        [0.6606, 0.3394],
        [0.6637, 0.3363],
        [0.6693, 0.3307],
        [0.6621, 0.3379],
        [0.6620, 0.3380],
        [0.6591, 0.3409],
        [0.6677, 0.3323],
        [0.6674, 0.3326],
        [0.6699, 0.3301],
        [0.6596, 0.3404],
        [0.6679, 0.3321],
        [0.6690, 0.3310],
        [0.6627, 0.3373],
        [0.6679, 0.3321],
        [0.6685, 0.3315],
        [0.6601, 0.3399],
        [0.6668, 0.3332],
        [0.6652, 0.3348],
        [0.6686, 0.3314],
        [0.6695, 0.3305],
        [0.6618, 0.3382],
        [0.6623, 0.3377],
        [0.6664, 0.3336],
        [0.6627, 0.3373],
        [0.6692, 0.3308],
        [0.6650, 0.3350],
        [0.6658, 0.3342],
        [0.6672, 0.3328],
        [0.6614, 0.3386],
        [0.6653, 0.3347],
        [0.6645, 0.3355],
        [0.6678, 0.3322],
        [0.6630, 0.3370],
        [0.6706, 0.3294],
        [0.6627, 0.3373],
        [0.6668, 0.3332],
        [0.6689, 0.3311],
        [0.6678, 0.3322],
        [0.6597, 0.3403],
        [0.6658, 0.3342],
        [0.6619, 0.3381],
        [0.6657, 0.3343],
        [0.6658, 0.3342],
        [0.6686, 0.3314],
        [0.6673, 0.3327],
        [0.6652, 0.3348],
        [0.6680, 0.3320],
        [0.6685, 0.3315],
        [0.6661, 0.3339],
        [0.6646, 0.3354],
        [0.6694, 0.3306],
        [0.6621, 0.3379],
        [0.6672, 0.3328],
        [0.6655, 0.3345],
        [0.6625, 0.3375],
        [0.6616, 0.3384],
        [0.6690, 0.3310],
        [0.6685, 0.3315],
        [0.6670, 0.3330],
        [0.6679, 0.3321],
        [0.6682, 0.3318],
        [0.6651, 0.3349],
        [0.6667, 0.3333],
        [0.6678, 0.3322],
        [0.6607, 0.3393],
        [0.6673, 0.3327],
        [0.6693, 0.3307],
        [0.6649, 0.3351],
        [0.6657, 0.3343],
        [0.6672, 0.3328],
        [0.6670, 0.3330],
        [0.6685, 0.3315],
        [0.6713, 0.3287],
        [0.6674, 0.3326],
        [0.6649, 0.3351],
        [0.6670, 0.3330],
        [0.6634, 0.3366],
        [0.6647, 0.3353],
        [0.6694, 0.3306],
        [0.6633, 0.3367],
        [0.6627, 0.3373],
        [0.6666, 0.3334],
        [0.6695, 0.3305],
        [0.6668, 0.3332]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0041 loss: 0.6690 acc_train: 0.6103 time: 0.1270s
tensor([[0.6649, 0.3351],
        [0.6693, 0.3307],
        [0.6670, 0.3330],
        [0.6646, 0.3354],
        [0.6691, 0.3309],
        [0.6606, 0.3394],
        [0.6592, 0.3408],
        [0.6662, 0.3338],
        [0.6677, 0.3323],
        [0.6607, 0.3393],
        [0.6662, 0.3338],
        [0.6635, 0.3365],
        [0.6614, 0.3386],
        [0.6613, 0.3387],
        [0.6666, 0.3334],
        [0.6617, 0.3383],
        [0.6704, 0.3296],
        [0.6636, 0.3364],
        [0.6673, 0.3327],
        [0.6606, 0.3394],
        [0.6694, 0.3306],
        [0.6608, 0.3392],
        [0.6682, 0.3318],
        [0.6676, 0.3324],
        [0.6635, 0.3365],
        [0.6628, 0.3372],
        [0.6636, 0.3364],
        [0.6669, 0.3331],
        [0.6622, 0.3378],
        [0.6623, 0.3377],
        [0.6656, 0.3344],
        [0.6608, 0.3392],
        [0.6642, 0.3358],
        [0.6635, 0.3365],
        [0.6686, 0.3314],
        [0.6621, 0.3379],
        [0.6627, 0.3373],
        [0.6633, 0.3367],
        [0.6667, 0.3333],
        [0.6615, 0.3385],
        [0.6673, 0.3327],
        [0.6656, 0.3344],
        [0.6585, 0.3415],
        [0.6678, 0.3322],
        [0.6656, 0.3344],
        [0.6629, 0.3371],
        [0.6697, 0.3303],
        [0.6688, 0.3312],
        [0.6661, 0.3339],
        [0.6631, 0.3369],
        [0.6651, 0.3349],
        [0.6658, 0.3342],
        [0.6633, 0.3367],
        [0.6681, 0.3319],
        [0.6668, 0.3332],
        [0.6678, 0.3322],
        [0.6699, 0.3301],
        [0.6646, 0.3354],
        [0.6643, 0.3357],
        [0.6612, 0.3388],
        [0.6596, 0.3404],
        [0.6617, 0.3383],
        [0.6666, 0.3334],
        [0.6661, 0.3339],
        [0.6651, 0.3349],
        [0.6637, 0.3363],
        [0.6662, 0.3338],
        [0.6649, 0.3351],
        [0.6657, 0.3343],
        [0.6654, 0.3346],
        [0.6619, 0.3381],
        [0.6610, 0.3390],
        [0.6651, 0.3349],
        [0.6660, 0.3340],
        [0.6642, 0.3358],
        [0.6642, 0.3358],
        [0.6646, 0.3354],
        [0.6638, 0.3362],
        [0.6662, 0.3338],
        [0.6608, 0.3392],
        [0.6590, 0.3410],
        [0.6610, 0.3390],
        [0.6610, 0.3390],
        [0.6635, 0.3365],
        [0.6633, 0.3367],
        [0.6623, 0.3377],
        [0.6679, 0.3321],
        [0.6641, 0.3359],
        [0.6664, 0.3336],
        [0.6629, 0.3371],
        [0.6626, 0.3374],
        [0.6637, 0.3363],
        [0.6654, 0.3346],
        [0.6599, 0.3401],
        [0.6634, 0.3366],
        [0.6688, 0.3312],
        [0.6681, 0.3319],
        [0.6621, 0.3379],
        [0.6696, 0.3304],
        [0.6633, 0.3367],
        [0.6674, 0.3326],
        [0.6626, 0.3374],
        [0.6613, 0.3387],
        [0.6631, 0.3369],
        [0.6710, 0.3290],
        [0.6611, 0.3389],
        [0.6685, 0.3315],
        [0.6683, 0.3317],
        [0.6617, 0.3383],
        [0.6685, 0.3315],
        [0.6594, 0.3406],
        [0.6693, 0.3307],
        [0.6676, 0.3324],
        [0.6681, 0.3319],
        [0.6623, 0.3377],
        [0.6612, 0.3388],
        [0.6647, 0.3353],
        [0.6671, 0.3329],
        [0.6704, 0.3296],
        [0.6696, 0.3304],
        [0.6603, 0.3397],
        [0.6621, 0.3379],
        [0.6637, 0.3363],
        [0.6643, 0.3357],
        [0.6623, 0.3377],
        [0.6644, 0.3356],
        [0.6621, 0.3379],
        [0.6656, 0.3344],
        [0.6622, 0.3378],
        [0.6633, 0.3367],
        [0.6643, 0.3357],
        [0.6601, 0.3399],
        [0.6660, 0.3340],
        [0.6619, 0.3381],
        [0.6671, 0.3329],
        [0.6644, 0.3356],
        [0.6630, 0.3370],
        [0.6686, 0.3314],
        [0.6655, 0.3345],
        [0.6614, 0.3386],
        [0.6626, 0.3374],
        [0.6661, 0.3339],
        [0.6631, 0.3369],
        [0.6637, 0.3363],
        [0.6581, 0.3419],
        [0.6654, 0.3346],
        [0.6670, 0.3330],
        [0.6630, 0.3370],
        [0.6692, 0.3308],
        [0.6686, 0.3314],
        [0.6619, 0.3381],
        [0.6678, 0.3322],
        [0.6687, 0.3313],
        [0.6717, 0.3283],
        [0.6701, 0.3299],
        [0.6645, 0.3355],
        [0.6688, 0.3312],
        [0.6679, 0.3321],
        [0.6631, 0.3369],
        [0.6645, 0.3355],
        [0.6682, 0.3318],
        [0.6675, 0.3325],
        [0.6617, 0.3383],
        [0.6621, 0.3379],
        [0.6609, 0.3391],
        [0.6621, 0.3379],
        [0.6684, 0.3316],
        [0.6639, 0.3361],
        [0.6647, 0.3353],
        [0.6619, 0.3381],
        [0.6595, 0.3405],
        [0.6626, 0.3374],
        [0.6621, 0.3379],
        [0.6624, 0.3376],
        [0.6665, 0.3335],
        [0.6653, 0.3347],
        [0.6689, 0.3311],
        [0.6628, 0.3372],
        [0.6607, 0.3393],
        [0.6692, 0.3308],
        [0.6661, 0.3339],
        [0.6607, 0.3393],
        [0.6623, 0.3377],
        [0.6607, 0.3393],
        [0.6688, 0.3312],
        [0.6667, 0.3333],
        [0.6591, 0.3409],
        [0.6653, 0.3347],
        [0.6605, 0.3395],
        [0.6637, 0.3363],
        [0.6693, 0.3307],
        [0.6620, 0.3380],
        [0.6620, 0.3380],
        [0.6591, 0.3409],
        [0.6677, 0.3323],
        [0.6674, 0.3326],
        [0.6697, 0.3303],
        [0.6596, 0.3404],
        [0.6679, 0.3321],
        [0.6690, 0.3310],
        [0.6627, 0.3373],
        [0.6680, 0.3320],
        [0.6685, 0.3315],
        [0.6601, 0.3399],
        [0.6667, 0.3333],
        [0.6651, 0.3349],
        [0.6686, 0.3314],
        [0.6694, 0.3306],
        [0.6616, 0.3384],
        [0.6622, 0.3378],
        [0.6665, 0.3335],
        [0.6625, 0.3375],
        [0.6691, 0.3309],
        [0.6648, 0.3352],
        [0.6657, 0.3343],
        [0.6671, 0.3329],
        [0.6614, 0.3386],
        [0.6654, 0.3346],
        [0.6645, 0.3355],
        [0.6675, 0.3325],
        [0.6630, 0.3370],
        [0.6706, 0.3294],
        [0.6626, 0.3374],
        [0.6668, 0.3332],
        [0.6688, 0.3312],
        [0.6677, 0.3323],
        [0.6599, 0.3401],
        [0.6659, 0.3341],
        [0.6617, 0.3383],
        [0.6655, 0.3345],
        [0.6658, 0.3342],
        [0.6684, 0.3316],
        [0.6673, 0.3327],
        [0.6652, 0.3348],
        [0.6679, 0.3321],
        [0.6683, 0.3317],
        [0.6660, 0.3340],
        [0.6645, 0.3355],
        [0.6694, 0.3306],
        [0.6621, 0.3379],
        [0.6672, 0.3328],
        [0.6654, 0.3346],
        [0.6624, 0.3376],
        [0.6614, 0.3386],
        [0.6689, 0.3311],
        [0.6685, 0.3315],
        [0.6670, 0.3330],
        [0.6678, 0.3322],
        [0.6683, 0.3317],
        [0.6651, 0.3349],
        [0.6666, 0.3334],
        [0.6678, 0.3322],
        [0.6605, 0.3395],
        [0.6674, 0.3326],
        [0.6693, 0.3307],
        [0.6648, 0.3352],
        [0.6657, 0.3343],
        [0.6672, 0.3328],
        [0.6669, 0.3331],
        [0.6685, 0.3315],
        [0.6710, 0.3290],
        [0.6671, 0.3329],
        [0.6647, 0.3353],
        [0.6671, 0.3329],
        [0.6633, 0.3367],
        [0.6645, 0.3355],
        [0.6694, 0.3306],
        [0.6632, 0.3368],
        [0.6627, 0.3373],
        [0.6665, 0.3335],
        [0.6695, 0.3305],
        [0.6667, 0.3333]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0042 loss: 0.6690 acc_train: 0.6103 time: 0.1279s
tensor([[0.6648, 0.3352],
        [0.6694, 0.3306],
        [0.6668, 0.3332],
        [0.6645, 0.3355],
        [0.6690, 0.3310],
        [0.6605, 0.3395],
        [0.6592, 0.3408],
        [0.6660, 0.3340],
        [0.6676, 0.3324],
        [0.6605, 0.3395],
        [0.6660, 0.3340],
        [0.6634, 0.3366],
        [0.6614, 0.3386],
        [0.6613, 0.3387],
        [0.6665, 0.3335],
        [0.6617, 0.3383],
        [0.6704, 0.3296],
        [0.6634, 0.3366],
        [0.6672, 0.3328],
        [0.6605, 0.3395],
        [0.6693, 0.3307],
        [0.6606, 0.3394],
        [0.6680, 0.3320],
        [0.6675, 0.3325],
        [0.6633, 0.3367],
        [0.6628, 0.3372],
        [0.6636, 0.3364],
        [0.6667, 0.3333],
        [0.6621, 0.3379],
        [0.6622, 0.3378],
        [0.6654, 0.3346],
        [0.6608, 0.3392],
        [0.6644, 0.3356],
        [0.6635, 0.3365],
        [0.6684, 0.3316],
        [0.6622, 0.3378],
        [0.6626, 0.3374],
        [0.6633, 0.3367],
        [0.6666, 0.3334],
        [0.6614, 0.3386],
        [0.6673, 0.3327],
        [0.6655, 0.3345],
        [0.6584, 0.3416],
        [0.6677, 0.3323],
        [0.6653, 0.3347],
        [0.6627, 0.3373],
        [0.6695, 0.3305],
        [0.6686, 0.3314],
        [0.6660, 0.3340],
        [0.6631, 0.3369],
        [0.6650, 0.3350],
        [0.6658, 0.3342],
        [0.6632, 0.3368],
        [0.6679, 0.3321],
        [0.6666, 0.3334],
        [0.6676, 0.3324],
        [0.6699, 0.3301],
        [0.6646, 0.3354],
        [0.6643, 0.3357],
        [0.6610, 0.3390],
        [0.6596, 0.3404],
        [0.6614, 0.3386],
        [0.6665, 0.3335],
        [0.6659, 0.3341],
        [0.6650, 0.3350],
        [0.6636, 0.3364],
        [0.6661, 0.3339],
        [0.6649, 0.3351],
        [0.6656, 0.3344],
        [0.6654, 0.3346],
        [0.6618, 0.3382],
        [0.6609, 0.3391],
        [0.6651, 0.3349],
        [0.6657, 0.3343],
        [0.6641, 0.3359],
        [0.6640, 0.3360],
        [0.6645, 0.3355],
        [0.6638, 0.3362],
        [0.6663, 0.3337],
        [0.6607, 0.3393],
        [0.6590, 0.3410],
        [0.6610, 0.3390],
        [0.6610, 0.3390],
        [0.6633, 0.3367],
        [0.6631, 0.3369],
        [0.6624, 0.3376],
        [0.6677, 0.3323],
        [0.6640, 0.3360],
        [0.6662, 0.3338],
        [0.6629, 0.3371],
        [0.6626, 0.3374],
        [0.6635, 0.3365],
        [0.6653, 0.3347],
        [0.6598, 0.3402],
        [0.6631, 0.3369],
        [0.6686, 0.3314],
        [0.6679, 0.3321],
        [0.6620, 0.3380],
        [0.6695, 0.3305],
        [0.6632, 0.3368],
        [0.6671, 0.3329],
        [0.6626, 0.3374],
        [0.6611, 0.3389],
        [0.6629, 0.3371],
        [0.6708, 0.3292],
        [0.6611, 0.3389],
        [0.6684, 0.3316],
        [0.6681, 0.3319],
        [0.6614, 0.3386],
        [0.6685, 0.3315],
        [0.6595, 0.3405],
        [0.6692, 0.3308],
        [0.6675, 0.3325],
        [0.6680, 0.3320],
        [0.6621, 0.3379],
        [0.6614, 0.3386],
        [0.6647, 0.3353],
        [0.6670, 0.3330],
        [0.6700, 0.3300],
        [0.6692, 0.3308],
        [0.6599, 0.3401],
        [0.6621, 0.3379],
        [0.6637, 0.3363],
        [0.6642, 0.3358],
        [0.6622, 0.3378],
        [0.6644, 0.3356],
        [0.6620, 0.3380],
        [0.6656, 0.3344],
        [0.6621, 0.3379],
        [0.6632, 0.3368],
        [0.6642, 0.3358],
        [0.6601, 0.3399],
        [0.6658, 0.3342],
        [0.6616, 0.3384],
        [0.6669, 0.3331],
        [0.6643, 0.3357],
        [0.6629, 0.3371],
        [0.6685, 0.3315],
        [0.6653, 0.3347],
        [0.6614, 0.3386],
        [0.6624, 0.3376],
        [0.6660, 0.3340],
        [0.6630, 0.3370],
        [0.6635, 0.3365],
        [0.6581, 0.3419],
        [0.6654, 0.3346],
        [0.6668, 0.3332],
        [0.6629, 0.3371],
        [0.6690, 0.3310],
        [0.6685, 0.3315],
        [0.6618, 0.3382],
        [0.6677, 0.3323],
        [0.6687, 0.3313],
        [0.6716, 0.3284],
        [0.6699, 0.3301],
        [0.6645, 0.3355],
        [0.6685, 0.3315],
        [0.6679, 0.3321],
        [0.6631, 0.3369],
        [0.6643, 0.3357],
        [0.6680, 0.3320],
        [0.6674, 0.3326],
        [0.6617, 0.3383],
        [0.6620, 0.3380],
        [0.6609, 0.3391],
        [0.6621, 0.3379],
        [0.6681, 0.3319],
        [0.6636, 0.3364],
        [0.6646, 0.3354],
        [0.6618, 0.3382],
        [0.6595, 0.3405],
        [0.6626, 0.3374],
        [0.6618, 0.3382],
        [0.6623, 0.3377],
        [0.6663, 0.3337],
        [0.6652, 0.3348],
        [0.6687, 0.3313],
        [0.6626, 0.3374],
        [0.6607, 0.3393],
        [0.6690, 0.3310],
        [0.6660, 0.3340],
        [0.6605, 0.3395],
        [0.6621, 0.3379],
        [0.6606, 0.3394],
        [0.6688, 0.3312],
        [0.6664, 0.3336],
        [0.6590, 0.3410],
        [0.6652, 0.3348],
        [0.6605, 0.3395],
        [0.6636, 0.3364],
        [0.6693, 0.3307],
        [0.6619, 0.3381],
        [0.6620, 0.3380],
        [0.6590, 0.3410],
        [0.6677, 0.3323],
        [0.6674, 0.3326],
        [0.6693, 0.3307],
        [0.6596, 0.3404],
        [0.6678, 0.3322],
        [0.6690, 0.3310],
        [0.6627, 0.3373],
        [0.6680, 0.3320],
        [0.6685, 0.3315],
        [0.6600, 0.3400],
        [0.6666, 0.3334],
        [0.6650, 0.3350],
        [0.6684, 0.3316],
        [0.6693, 0.3307],
        [0.6615, 0.3385],
        [0.6621, 0.3379],
        [0.6666, 0.3334],
        [0.6622, 0.3378],
        [0.6688, 0.3312],
        [0.6644, 0.3356],
        [0.6656, 0.3344],
        [0.6670, 0.3330],
        [0.6613, 0.3387],
        [0.6654, 0.3346],
        [0.6643, 0.3357],
        [0.6672, 0.3328],
        [0.6630, 0.3370],
        [0.6704, 0.3296],
        [0.6624, 0.3376],
        [0.6668, 0.3332],
        [0.6687, 0.3313],
        [0.6675, 0.3325],
        [0.6600, 0.3400],
        [0.6658, 0.3342],
        [0.6615, 0.3385],
        [0.6652, 0.3348],
        [0.6658, 0.3342],
        [0.6681, 0.3319],
        [0.6672, 0.3328],
        [0.6652, 0.3348],
        [0.6677, 0.3323],
        [0.6681, 0.3319],
        [0.6659, 0.3341],
        [0.6645, 0.3355],
        [0.6692, 0.3308],
        [0.6620, 0.3380],
        [0.6672, 0.3328],
        [0.6653, 0.3347],
        [0.6623, 0.3377],
        [0.6612, 0.3388],
        [0.6687, 0.3313],
        [0.6684, 0.3316],
        [0.6669, 0.3331],
        [0.6676, 0.3324],
        [0.6682, 0.3318],
        [0.6649, 0.3351],
        [0.6664, 0.3336],
        [0.6678, 0.3322],
        [0.6603, 0.3397],
        [0.6674, 0.3326],
        [0.6692, 0.3308],
        [0.6646, 0.3354],
        [0.6655, 0.3345],
        [0.6671, 0.3329],
        [0.6668, 0.3332],
        [0.6684, 0.3316],
        [0.6707, 0.3293],
        [0.6669, 0.3331],
        [0.6645, 0.3355],
        [0.6671, 0.3329],
        [0.6632, 0.3368],
        [0.6643, 0.3357],
        [0.6693, 0.3307],
        [0.6630, 0.3370],
        [0.6627, 0.3373],
        [0.6664, 0.3336],
        [0.6693, 0.3307],
        [0.6665, 0.3335]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0043 loss: 0.6690 acc_train: 0.6103 time: 0.1299s
tensor([[0.6646, 0.3354],
        [0.6693, 0.3307],
        [0.6666, 0.3334],
        [0.6644, 0.3356],
        [0.6688, 0.3312],
        [0.6604, 0.3396],
        [0.6591, 0.3409],
        [0.6658, 0.3342],
        [0.6675, 0.3325],
        [0.6603, 0.3397],
        [0.6657, 0.3343],
        [0.6633, 0.3367],
        [0.6614, 0.3386],
        [0.6612, 0.3388],
        [0.6664, 0.3336],
        [0.6616, 0.3384],
        [0.6703, 0.3297],
        [0.6632, 0.3368],
        [0.6670, 0.3330],
        [0.6603, 0.3397],
        [0.6691, 0.3309],
        [0.6604, 0.3396],
        [0.6678, 0.3322],
        [0.6673, 0.3327],
        [0.6631, 0.3369],
        [0.6627, 0.3373],
        [0.6636, 0.3364],
        [0.6666, 0.3334],
        [0.6620, 0.3380],
        [0.6621, 0.3379],
        [0.6652, 0.3348],
        [0.6608, 0.3392],
        [0.6645, 0.3355],
        [0.6634, 0.3366],
        [0.6681, 0.3319],
        [0.6620, 0.3380],
        [0.6625, 0.3375],
        [0.6634, 0.3366],
        [0.6665, 0.3335],
        [0.6613, 0.3387],
        [0.6672, 0.3328],
        [0.6654, 0.3346],
        [0.6583, 0.3417],
        [0.6675, 0.3325],
        [0.6651, 0.3349],
        [0.6625, 0.3375],
        [0.6693, 0.3307],
        [0.6682, 0.3318],
        [0.6657, 0.3343],
        [0.6631, 0.3369],
        [0.6648, 0.3352],
        [0.6657, 0.3343],
        [0.6630, 0.3370],
        [0.6676, 0.3324],
        [0.6664, 0.3336],
        [0.6674, 0.3326],
        [0.6698, 0.3302],
        [0.6645, 0.3355],
        [0.6642, 0.3358],
        [0.6609, 0.3391],
        [0.6595, 0.3405],
        [0.6612, 0.3388],
        [0.6663, 0.3337],
        [0.6657, 0.3343],
        [0.6649, 0.3351],
        [0.6634, 0.3366],
        [0.6660, 0.3340],
        [0.6650, 0.3350],
        [0.6654, 0.3346],
        [0.6653, 0.3347],
        [0.6617, 0.3383],
        [0.6608, 0.3392],
        [0.6650, 0.3350],
        [0.6654, 0.3346],
        [0.6639, 0.3361],
        [0.6637, 0.3363],
        [0.6643, 0.3357],
        [0.6637, 0.3363],
        [0.6664, 0.3336],
        [0.6606, 0.3394],
        [0.6589, 0.3411],
        [0.6609, 0.3391],
        [0.6611, 0.3389],
        [0.6631, 0.3369],
        [0.6628, 0.3372],
        [0.6624, 0.3376],
        [0.6675, 0.3325],
        [0.6638, 0.3362],
        [0.6659, 0.3341],
        [0.6629, 0.3371],
        [0.6625, 0.3375],
        [0.6632, 0.3368],
        [0.6653, 0.3347],
        [0.6597, 0.3403],
        [0.6628, 0.3372],
        [0.6683, 0.3317],
        [0.6676, 0.3324],
        [0.6619, 0.3381],
        [0.6693, 0.3307],
        [0.6630, 0.3370],
        [0.6669, 0.3331],
        [0.6626, 0.3374],
        [0.6609, 0.3391],
        [0.6628, 0.3372],
        [0.6705, 0.3295],
        [0.6610, 0.3390],
        [0.6682, 0.3318],
        [0.6678, 0.3322],
        [0.6611, 0.3389],
        [0.6684, 0.3316],
        [0.6595, 0.3405],
        [0.6691, 0.3309],
        [0.6674, 0.3326],
        [0.6678, 0.3322],
        [0.6618, 0.3382],
        [0.6615, 0.3385],
        [0.6646, 0.3354],
        [0.6669, 0.3331],
        [0.6696, 0.3304],
        [0.6689, 0.3311],
        [0.6595, 0.3405],
        [0.6621, 0.3379],
        [0.6637, 0.3363],
        [0.6640, 0.3360],
        [0.6621, 0.3379],
        [0.6643, 0.3357],
        [0.6619, 0.3381],
        [0.6655, 0.3345],
        [0.6619, 0.3381],
        [0.6631, 0.3369],
        [0.6642, 0.3358],
        [0.6601, 0.3399],
        [0.6657, 0.3343],
        [0.6614, 0.3386],
        [0.6667, 0.3333],
        [0.6643, 0.3357],
        [0.6628, 0.3372],
        [0.6682, 0.3318],
        [0.6651, 0.3349],
        [0.6613, 0.3387],
        [0.6622, 0.3378],
        [0.6659, 0.3341],
        [0.6629, 0.3371],
        [0.6633, 0.3367],
        [0.6580, 0.3420],
        [0.6653, 0.3347],
        [0.6666, 0.3334],
        [0.6628, 0.3372],
        [0.6687, 0.3313],
        [0.6683, 0.3317],
        [0.6616, 0.3384],
        [0.6675, 0.3325],
        [0.6686, 0.3314],
        [0.6713, 0.3287],
        [0.6697, 0.3303],
        [0.6645, 0.3355],
        [0.6682, 0.3318],
        [0.6678, 0.3322],
        [0.6630, 0.3370],
        [0.6641, 0.3359],
        [0.6678, 0.3322],
        [0.6672, 0.3328],
        [0.6615, 0.3385],
        [0.6618, 0.3382],
        [0.6607, 0.3393],
        [0.6621, 0.3379],
        [0.6678, 0.3322],
        [0.6634, 0.3366],
        [0.6645, 0.3355],
        [0.6617, 0.3383],
        [0.6594, 0.3406],
        [0.6625, 0.3375],
        [0.6614, 0.3386],
        [0.6623, 0.3377],
        [0.6662, 0.3338],
        [0.6649, 0.3351],
        [0.6685, 0.3315],
        [0.6624, 0.3376],
        [0.6607, 0.3393],
        [0.6688, 0.3312],
        [0.6658, 0.3342],
        [0.6603, 0.3397],
        [0.6619, 0.3381],
        [0.6604, 0.3396],
        [0.6686, 0.3314],
        [0.6661, 0.3339],
        [0.6588, 0.3412],
        [0.6650, 0.3350],
        [0.6604, 0.3396],
        [0.6635, 0.3365],
        [0.6692, 0.3308],
        [0.6619, 0.3381],
        [0.6620, 0.3380],
        [0.6590, 0.3410],
        [0.6676, 0.3324],
        [0.6672, 0.3328],
        [0.6689, 0.3311],
        [0.6595, 0.3405],
        [0.6676, 0.3324],
        [0.6689, 0.3311],
        [0.6627, 0.3373],
        [0.6679, 0.3321],
        [0.6684, 0.3316],
        [0.6599, 0.3401],
        [0.6664, 0.3336],
        [0.6648, 0.3352],
        [0.6681, 0.3319],
        [0.6692, 0.3308],
        [0.6614, 0.3386],
        [0.6620, 0.3380],
        [0.6666, 0.3334],
        [0.6620, 0.3380],
        [0.6685, 0.3315],
        [0.6640, 0.3360],
        [0.6655, 0.3345],
        [0.6668, 0.3332],
        [0.6612, 0.3388],
        [0.6652, 0.3348],
        [0.6641, 0.3359],
        [0.6668, 0.3332],
        [0.6629, 0.3371],
        [0.6703, 0.3297],
        [0.6621, 0.3379],
        [0.6666, 0.3334],
        [0.6684, 0.3316],
        [0.6673, 0.3327],
        [0.6600, 0.3400],
        [0.6658, 0.3342],
        [0.6613, 0.3387],
        [0.6649, 0.3351],
        [0.6656, 0.3344],
        [0.6678, 0.3322],
        [0.6671, 0.3329],
        [0.6651, 0.3349],
        [0.6674, 0.3326],
        [0.6679, 0.3321],
        [0.6657, 0.3343],
        [0.6644, 0.3356],
        [0.6689, 0.3311],
        [0.6620, 0.3380],
        [0.6671, 0.3329],
        [0.6652, 0.3348],
        [0.6620, 0.3380],
        [0.6610, 0.3390],
        [0.6685, 0.3315],
        [0.6682, 0.3318],
        [0.6668, 0.3332],
        [0.6673, 0.3327],
        [0.6681, 0.3319],
        [0.6647, 0.3353],
        [0.6661, 0.3339],
        [0.6678, 0.3322],
        [0.6601, 0.3399],
        [0.6673, 0.3327],
        [0.6691, 0.3309],
        [0.6645, 0.3355],
        [0.6653, 0.3347],
        [0.6669, 0.3331],
        [0.6667, 0.3333],
        [0.6682, 0.3318],
        [0.6703, 0.3297],
        [0.6666, 0.3334],
        [0.6643, 0.3357],
        [0.6670, 0.3330],
        [0.6630, 0.3370],
        [0.6640, 0.3360],
        [0.6691, 0.3309],
        [0.6629, 0.3371],
        [0.6626, 0.3374],
        [0.6662, 0.3338],
        [0.6690, 0.3310],
        [0.6663, 0.3337]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0044 loss: 0.6691 acc_train: 0.6103 time: 0.1259s
tensor([[0.6644, 0.3356],
        [0.6691, 0.3309],
        [0.6663, 0.3337],
        [0.6642, 0.3358],
        [0.6686, 0.3314],
        [0.6603, 0.3397],
        [0.6590, 0.3410],
        [0.6655, 0.3345],
        [0.6674, 0.3326],
        [0.6602, 0.3398],
        [0.6654, 0.3346],
        [0.6632, 0.3368],
        [0.6613, 0.3387],
        [0.6611, 0.3389],
        [0.6663, 0.3337],
        [0.6615, 0.3385],
        [0.6702, 0.3298],
        [0.6631, 0.3369],
        [0.6667, 0.3333],
        [0.6602, 0.3398],
        [0.6689, 0.3311],
        [0.6602, 0.3398],
        [0.6675, 0.3325],
        [0.6672, 0.3328],
        [0.6628, 0.3372],
        [0.6625, 0.3375],
        [0.6636, 0.3364],
        [0.6664, 0.3336],
        [0.6618, 0.3382],
        [0.6620, 0.3380],
        [0.6649, 0.3351],
        [0.6608, 0.3392],
        [0.6645, 0.3355],
        [0.6632, 0.3368],
        [0.6679, 0.3321],
        [0.6618, 0.3382],
        [0.6624, 0.3376],
        [0.6634, 0.3366],
        [0.6663, 0.3337],
        [0.6612, 0.3388],
        [0.6671, 0.3329],
        [0.6652, 0.3348],
        [0.6582, 0.3418],
        [0.6673, 0.3327],
        [0.6649, 0.3351],
        [0.6623, 0.3377],
        [0.6690, 0.3310],
        [0.6678, 0.3322],
        [0.6655, 0.3345],
        [0.6630, 0.3370],
        [0.6646, 0.3354],
        [0.6655, 0.3345],
        [0.6628, 0.3372],
        [0.6673, 0.3327],
        [0.6661, 0.3339],
        [0.6671, 0.3329],
        [0.6698, 0.3302],
        [0.6644, 0.3356],
        [0.6641, 0.3359],
        [0.6608, 0.3392],
        [0.6594, 0.3406],
        [0.6609, 0.3391],
        [0.6661, 0.3339],
        [0.6655, 0.3345],
        [0.6648, 0.3352],
        [0.6633, 0.3367],
        [0.6658, 0.3342],
        [0.6649, 0.3351],
        [0.6652, 0.3348],
        [0.6652, 0.3348],
        [0.6615, 0.3385],
        [0.6607, 0.3393],
        [0.6648, 0.3352],
        [0.6652, 0.3348],
        [0.6637, 0.3363],
        [0.6635, 0.3365],
        [0.6641, 0.3359],
        [0.6636, 0.3364],
        [0.6665, 0.3335],
        [0.6605, 0.3395],
        [0.6589, 0.3411],
        [0.6609, 0.3391],
        [0.6611, 0.3389],
        [0.6629, 0.3371],
        [0.6626, 0.3374],
        [0.6623, 0.3377],
        [0.6671, 0.3329],
        [0.6635, 0.3365],
        [0.6657, 0.3343],
        [0.6629, 0.3371],
        [0.6625, 0.3375],
        [0.6630, 0.3370],
        [0.6652, 0.3348],
        [0.6596, 0.3404],
        [0.6625, 0.3375],
        [0.6680, 0.3320],
        [0.6673, 0.3327],
        [0.6618, 0.3382],
        [0.6690, 0.3310],
        [0.6627, 0.3373],
        [0.6666, 0.3334],
        [0.6626, 0.3374],
        [0.6606, 0.3394],
        [0.6626, 0.3374],
        [0.6702, 0.3298],
        [0.6610, 0.3390],
        [0.6680, 0.3320],
        [0.6676, 0.3324],
        [0.6609, 0.3391],
        [0.6683, 0.3317],
        [0.6595, 0.3405],
        [0.6690, 0.3310],
        [0.6673, 0.3327],
        [0.6677, 0.3323],
        [0.6615, 0.3385],
        [0.6615, 0.3385],
        [0.6645, 0.3355],
        [0.6668, 0.3332],
        [0.6692, 0.3308],
        [0.6685, 0.3315],
        [0.6592, 0.3408],
        [0.6621, 0.3379],
        [0.6637, 0.3363],
        [0.6639, 0.3361],
        [0.6619, 0.3381],
        [0.6641, 0.3359],
        [0.6617, 0.3383],
        [0.6654, 0.3346],
        [0.6617, 0.3383],
        [0.6630, 0.3370],
        [0.6641, 0.3359],
        [0.6600, 0.3400],
        [0.6655, 0.3345],
        [0.6613, 0.3387],
        [0.6665, 0.3335],
        [0.6643, 0.3357],
        [0.6627, 0.3373],
        [0.6680, 0.3320],
        [0.6649, 0.3351],
        [0.6612, 0.3388],
        [0.6619, 0.3381],
        [0.6656, 0.3344],
        [0.6629, 0.3371],
        [0.6631, 0.3369],
        [0.6579, 0.3421],
        [0.6652, 0.3348],
        [0.6663, 0.3337],
        [0.6627, 0.3373],
        [0.6684, 0.3316],
        [0.6680, 0.3320],
        [0.6613, 0.3387],
        [0.6672, 0.3328],
        [0.6683, 0.3317],
        [0.6710, 0.3290],
        [0.6696, 0.3304],
        [0.6644, 0.3356],
        [0.6679, 0.3321],
        [0.6676, 0.3324],
        [0.6629, 0.3371],
        [0.6639, 0.3361],
        [0.6674, 0.3326],
        [0.6670, 0.3330],
        [0.6614, 0.3386],
        [0.6616, 0.3384],
        [0.6605, 0.3395],
        [0.6620, 0.3380],
        [0.6674, 0.3326],
        [0.6631, 0.3369],
        [0.6644, 0.3356],
        [0.6615, 0.3385],
        [0.6592, 0.3408],
        [0.6623, 0.3377],
        [0.6612, 0.3388],
        [0.6622, 0.3378],
        [0.6660, 0.3340],
        [0.6647, 0.3353],
        [0.6683, 0.3317],
        [0.6623, 0.3377],
        [0.6606, 0.3394],
        [0.6684, 0.3316],
        [0.6655, 0.3345],
        [0.6602, 0.3398],
        [0.6617, 0.3383],
        [0.6602, 0.3398],
        [0.6683, 0.3317],
        [0.6657, 0.3343],
        [0.6586, 0.3414],
        [0.6649, 0.3351],
        [0.6603, 0.3397],
        [0.6634, 0.3366],
        [0.6690, 0.3310],
        [0.6619, 0.3381],
        [0.6619, 0.3381],
        [0.6589, 0.3411],
        [0.6674, 0.3326],
        [0.6669, 0.3331],
        [0.6684, 0.3316],
        [0.6595, 0.3405],
        [0.6674, 0.3326],
        [0.6687, 0.3313],
        [0.6626, 0.3374],
        [0.6676, 0.3324],
        [0.6683, 0.3317],
        [0.6598, 0.3402],
        [0.6663, 0.3337],
        [0.6646, 0.3354],
        [0.6678, 0.3322],
        [0.6691, 0.3309],
        [0.6613, 0.3387],
        [0.6619, 0.3381],
        [0.6667, 0.3333],
        [0.6618, 0.3382],
        [0.6681, 0.3319],
        [0.6637, 0.3363],
        [0.6653, 0.3347],
        [0.6666, 0.3334],
        [0.6611, 0.3389],
        [0.6650, 0.3350],
        [0.6638, 0.3362],
        [0.6664, 0.3336],
        [0.6628, 0.3372],
        [0.6701, 0.3299],
        [0.6619, 0.3381],
        [0.6664, 0.3336],
        [0.6681, 0.3319],
        [0.6670, 0.3330],
        [0.6598, 0.3402],
        [0.6656, 0.3344],
        [0.6612, 0.3388],
        [0.6646, 0.3354],
        [0.6655, 0.3345],
        [0.6676, 0.3324],
        [0.6669, 0.3331],
        [0.6650, 0.3350],
        [0.6670, 0.3330],
        [0.6677, 0.3323],
        [0.6655, 0.3345],
        [0.6643, 0.3357],
        [0.6686, 0.3314],
        [0.6619, 0.3381],
        [0.6670, 0.3330],
        [0.6652, 0.3348],
        [0.6618, 0.3382],
        [0.6608, 0.3392],
        [0.6682, 0.3318],
        [0.6681, 0.3319],
        [0.6666, 0.3334],
        [0.6671, 0.3329],
        [0.6679, 0.3321],
        [0.6644, 0.3356],
        [0.6658, 0.3342],
        [0.6676, 0.3324],
        [0.6599, 0.3401],
        [0.6671, 0.3329],
        [0.6688, 0.3312],
        [0.6643, 0.3357],
        [0.6651, 0.3349],
        [0.6666, 0.3334],
        [0.6666, 0.3334],
        [0.6679, 0.3321],
        [0.6700, 0.3300],
        [0.6663, 0.3337],
        [0.6640, 0.3360],
        [0.6669, 0.3331],
        [0.6628, 0.3372],
        [0.6638, 0.3362],
        [0.6688, 0.3312],
        [0.6627, 0.3373],
        [0.6624, 0.3376],
        [0.6659, 0.3341],
        [0.6686, 0.3314],
        [0.6660, 0.3340]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0045 loss: 0.6691 acc_train: 0.6103 time: 0.1464s
tensor([[0.6642, 0.3358],
        [0.6689, 0.3311],
        [0.6660, 0.3340],
        [0.6640, 0.3360],
        [0.6684, 0.3316],
        [0.6603, 0.3397],
        [0.6589, 0.3411],
        [0.6652, 0.3348],
        [0.6672, 0.3328],
        [0.6600, 0.3400],
        [0.6651, 0.3349],
        [0.6630, 0.3370],
        [0.6613, 0.3387],
        [0.6609, 0.3391],
        [0.6662, 0.3338],
        [0.6614, 0.3386],
        [0.6700, 0.3300],
        [0.6629, 0.3371],
        [0.6663, 0.3337],
        [0.6600, 0.3400],
        [0.6686, 0.3314],
        [0.6600, 0.3400],
        [0.6673, 0.3327],
        [0.6670, 0.3330],
        [0.6625, 0.3375],
        [0.6624, 0.3376],
        [0.6635, 0.3365],
        [0.6662, 0.3338],
        [0.6616, 0.3384],
        [0.6619, 0.3381],
        [0.6647, 0.3353],
        [0.6607, 0.3393],
        [0.6644, 0.3356],
        [0.6630, 0.3370],
        [0.6677, 0.3323],
        [0.6615, 0.3385],
        [0.6623, 0.3377],
        [0.6633, 0.3367],
        [0.6660, 0.3340],
        [0.6611, 0.3389],
        [0.6669, 0.3331],
        [0.6650, 0.3350],
        [0.6581, 0.3419],
        [0.6670, 0.3330],
        [0.6647, 0.3353],
        [0.6622, 0.3378],
        [0.6686, 0.3314],
        [0.6674, 0.3326],
        [0.6652, 0.3348],
        [0.6628, 0.3372],
        [0.6644, 0.3356],
        [0.6653, 0.3347],
        [0.6626, 0.3374],
        [0.6670, 0.3330],
        [0.6658, 0.3342],
        [0.6669, 0.3331],
        [0.6696, 0.3304],
        [0.6642, 0.3358],
        [0.6640, 0.3360],
        [0.6608, 0.3392],
        [0.6591, 0.3409],
        [0.6608, 0.3392],
        [0.6659, 0.3341],
        [0.6652, 0.3348],
        [0.6647, 0.3353],
        [0.6632, 0.3368],
        [0.6656, 0.3344],
        [0.6648, 0.3352],
        [0.6649, 0.3351],
        [0.6650, 0.3350],
        [0.6614, 0.3386],
        [0.6606, 0.3394],
        [0.6645, 0.3355],
        [0.6650, 0.3350],
        [0.6634, 0.3366],
        [0.6633, 0.3367],
        [0.6639, 0.3361],
        [0.6634, 0.3366],
        [0.6665, 0.3335],
        [0.6603, 0.3397],
        [0.6588, 0.3412],
        [0.6609, 0.3391],
        [0.6610, 0.3390],
        [0.6627, 0.3373],
        [0.6624, 0.3376],
        [0.6622, 0.3378],
        [0.6667, 0.3333],
        [0.6633, 0.3367],
        [0.6655, 0.3345],
        [0.6628, 0.3372],
        [0.6624, 0.3376],
        [0.6628, 0.3372],
        [0.6651, 0.3349],
        [0.6595, 0.3405],
        [0.6623, 0.3377],
        [0.6677, 0.3323],
        [0.6669, 0.3331],
        [0.6618, 0.3382],
        [0.6687, 0.3313],
        [0.6624, 0.3376],
        [0.6664, 0.3336],
        [0.6625, 0.3375],
        [0.6604, 0.3396],
        [0.6625, 0.3375],
        [0.6699, 0.3301],
        [0.6610, 0.3390],
        [0.6677, 0.3323],
        [0.6674, 0.3326],
        [0.6606, 0.3394],
        [0.6681, 0.3319],
        [0.6594, 0.3406],
        [0.6688, 0.3312],
        [0.6672, 0.3328],
        [0.6675, 0.3325],
        [0.6612, 0.3388],
        [0.6614, 0.3386],
        [0.6642, 0.3358],
        [0.6667, 0.3333],
        [0.6688, 0.3312],
        [0.6682, 0.3318],
        [0.6590, 0.3410],
        [0.6621, 0.3379],
        [0.6637, 0.3363],
        [0.6637, 0.3363],
        [0.6617, 0.3383],
        [0.6639, 0.3361],
        [0.6616, 0.3384],
        [0.6651, 0.3349],
        [0.6615, 0.3385],
        [0.6628, 0.3372],
        [0.6640, 0.3360],
        [0.6598, 0.3402],
        [0.6653, 0.3347],
        [0.6613, 0.3387],
        [0.6662, 0.3338],
        [0.6642, 0.3358],
        [0.6627, 0.3373],
        [0.6677, 0.3323],
        [0.6647, 0.3353],
        [0.6611, 0.3389],
        [0.6615, 0.3385],
        [0.6654, 0.3346],
        [0.6628, 0.3372],
        [0.6629, 0.3371],
        [0.6578, 0.3422],
        [0.6650, 0.3350],
        [0.6660, 0.3340],
        [0.6626, 0.3374],
        [0.6680, 0.3320],
        [0.6677, 0.3323],
        [0.6610, 0.3390],
        [0.6669, 0.3331],
        [0.6681, 0.3319],
        [0.6706, 0.3294],
        [0.6694, 0.3306],
        [0.6643, 0.3357],
        [0.6677, 0.3323],
        [0.6674, 0.3326],
        [0.6627, 0.3373],
        [0.6638, 0.3362],
        [0.6671, 0.3329],
        [0.6667, 0.3333],
        [0.6612, 0.3388],
        [0.6615, 0.3385],
        [0.6603, 0.3397],
        [0.6619, 0.3381],
        [0.6671, 0.3329],
        [0.6629, 0.3371],
        [0.6642, 0.3358],
        [0.6614, 0.3386],
        [0.6591, 0.3409],
        [0.6622, 0.3378],
        [0.6610, 0.3390],
        [0.6621, 0.3379],
        [0.6659, 0.3341],
        [0.6644, 0.3356],
        [0.6681, 0.3319],
        [0.6621, 0.3379],
        [0.6604, 0.3396],
        [0.6681, 0.3319],
        [0.6651, 0.3349],
        [0.6600, 0.3400],
        [0.6615, 0.3385],
        [0.6600, 0.3400],
        [0.6679, 0.3321],
        [0.6654, 0.3346],
        [0.6583, 0.3417],
        [0.6647, 0.3353],
        [0.6603, 0.3397],
        [0.6633, 0.3367],
        [0.6688, 0.3312],
        [0.6618, 0.3382],
        [0.6617, 0.3383],
        [0.6589, 0.3411],
        [0.6672, 0.3328],
        [0.6666, 0.3334],
        [0.6681, 0.3319],
        [0.6594, 0.3406],
        [0.6671, 0.3329],
        [0.6685, 0.3315],
        [0.6625, 0.3375],
        [0.6673, 0.3327],
        [0.6681, 0.3319],
        [0.6597, 0.3403],
        [0.6661, 0.3339],
        [0.6644, 0.3356],
        [0.6675, 0.3325],
        [0.6689, 0.3311],
        [0.6612, 0.3388],
        [0.6618, 0.3382],
        [0.6667, 0.3333],
        [0.6617, 0.3383],
        [0.6679, 0.3321],
        [0.6633, 0.3367],
        [0.6651, 0.3349],
        [0.6663, 0.3337],
        [0.6610, 0.3390],
        [0.6647, 0.3353],
        [0.6636, 0.3364],
        [0.6661, 0.3339],
        [0.6627, 0.3373],
        [0.6698, 0.3302],
        [0.6617, 0.3383],
        [0.6661, 0.3339],
        [0.6678, 0.3322],
        [0.6668, 0.3332],
        [0.6596, 0.3404],
        [0.6654, 0.3346],
        [0.6611, 0.3389],
        [0.6643, 0.3357],
        [0.6653, 0.3347],
        [0.6673, 0.3327],
        [0.6667, 0.3333],
        [0.6649, 0.3351],
        [0.6666, 0.3334],
        [0.6675, 0.3325],
        [0.6653, 0.3347],
        [0.6642, 0.3358],
        [0.6682, 0.3318],
        [0.6618, 0.3382],
        [0.6668, 0.3332],
        [0.6651, 0.3349],
        [0.6615, 0.3385],
        [0.6606, 0.3394],
        [0.6680, 0.3320],
        [0.6679, 0.3321],
        [0.6665, 0.3335],
        [0.6668, 0.3332],
        [0.6676, 0.3324],
        [0.6641, 0.3359],
        [0.6655, 0.3345],
        [0.6673, 0.3327],
        [0.6597, 0.3403],
        [0.6668, 0.3332],
        [0.6686, 0.3314],
        [0.6641, 0.3359],
        [0.6648, 0.3352],
        [0.6663, 0.3337],
        [0.6664, 0.3336],
        [0.6675, 0.3325],
        [0.6696, 0.3304],
        [0.6662, 0.3338],
        [0.6637, 0.3363],
        [0.6666, 0.3334],
        [0.6625, 0.3375],
        [0.6636, 0.3364],
        [0.6684, 0.3316],
        [0.6626, 0.3374],
        [0.6623, 0.3377],
        [0.6657, 0.3343],
        [0.6682, 0.3318],
        [0.6658, 0.3342]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0046 loss: 0.6691 acc_train: 0.6103 time: 0.1680s
tensor([[0.6640, 0.3360],
        [0.6686, 0.3314],
        [0.6658, 0.3342],
        [0.6638, 0.3362],
        [0.6681, 0.3319],
        [0.6603, 0.3397],
        [0.6588, 0.3412],
        [0.6650, 0.3350],
        [0.6671, 0.3329],
        [0.6600, 0.3400],
        [0.6648, 0.3352],
        [0.6629, 0.3371],
        [0.6612, 0.3388],
        [0.6607, 0.3393],
        [0.6661, 0.3339],
        [0.6613, 0.3387],
        [0.6698, 0.3302],
        [0.6628, 0.3372],
        [0.6659, 0.3341],
        [0.6598, 0.3402],
        [0.6683, 0.3317],
        [0.6599, 0.3401],
        [0.6670, 0.3330],
        [0.6668, 0.3332],
        [0.6622, 0.3378],
        [0.6622, 0.3378],
        [0.6634, 0.3366],
        [0.6660, 0.3340],
        [0.6615, 0.3385],
        [0.6617, 0.3383],
        [0.6644, 0.3356],
        [0.6607, 0.3393],
        [0.6643, 0.3357],
        [0.6628, 0.3372],
        [0.6675, 0.3325],
        [0.6612, 0.3388],
        [0.6621, 0.3379],
        [0.6631, 0.3369],
        [0.6656, 0.3344],
        [0.6609, 0.3391],
        [0.6666, 0.3334],
        [0.6648, 0.3352],
        [0.6581, 0.3419],
        [0.6668, 0.3332],
        [0.6646, 0.3354],
        [0.6620, 0.3380],
        [0.6683, 0.3317],
        [0.6669, 0.3331],
        [0.6649, 0.3351],
        [0.6626, 0.3374],
        [0.6641, 0.3359],
        [0.6651, 0.3349],
        [0.6623, 0.3377],
        [0.6668, 0.3332],
        [0.6654, 0.3346],
        [0.6667, 0.3333],
        [0.6694, 0.3306],
        [0.6640, 0.3360],
        [0.6638, 0.3362],
        [0.6608, 0.3392],
        [0.6589, 0.3411],
        [0.6606, 0.3394],
        [0.6657, 0.3343],
        [0.6651, 0.3349],
        [0.6645, 0.3355],
        [0.6631, 0.3369],
        [0.6655, 0.3345],
        [0.6647, 0.3353],
        [0.6647, 0.3353],
        [0.6648, 0.3352],
        [0.6613, 0.3387],
        [0.6605, 0.3395],
        [0.6642, 0.3358],
        [0.6649, 0.3351],
        [0.6631, 0.3369],
        [0.6632, 0.3368],
        [0.6638, 0.3362],
        [0.6632, 0.3368],
        [0.6665, 0.3335],
        [0.6602, 0.3398],
        [0.6587, 0.3413],
        [0.6609, 0.3391],
        [0.6609, 0.3391],
        [0.6625, 0.3375],
        [0.6622, 0.3378],
        [0.6620, 0.3380],
        [0.6662, 0.3338],
        [0.6630, 0.3370],
        [0.6653, 0.3347],
        [0.6627, 0.3373],
        [0.6622, 0.3378],
        [0.6626, 0.3374],
        [0.6649, 0.3351],
        [0.6594, 0.3406],
        [0.6622, 0.3378],
        [0.6676, 0.3324],
        [0.6666, 0.3334],
        [0.6617, 0.3383],
        [0.6685, 0.3315],
        [0.6621, 0.3379],
        [0.6662, 0.3338],
        [0.6623, 0.3377],
        [0.6601, 0.3399],
        [0.6623, 0.3377],
        [0.6695, 0.3305],
        [0.6610, 0.3390],
        [0.6674, 0.3326],
        [0.6672, 0.3328],
        [0.6604, 0.3396],
        [0.6678, 0.3322],
        [0.6592, 0.3408],
        [0.6686, 0.3314],
        [0.6670, 0.3330],
        [0.6673, 0.3327],
        [0.6610, 0.3390],
        [0.6613, 0.3387],
        [0.6640, 0.3360],
        [0.6665, 0.3335],
        [0.6685, 0.3315],
        [0.6680, 0.3320],
        [0.6589, 0.3411],
        [0.6620, 0.3380],
        [0.6636, 0.3364],
        [0.6636, 0.3364],
        [0.6615, 0.3385],
        [0.6637, 0.3363],
        [0.6614, 0.3386],
        [0.6648, 0.3352],
        [0.6614, 0.3386],
        [0.6626, 0.3374],
        [0.6638, 0.3362],
        [0.6597, 0.3403],
        [0.6652, 0.3348],
        [0.6613, 0.3387],
        [0.6660, 0.3340],
        [0.6642, 0.3358],
        [0.6626, 0.3374],
        [0.6675, 0.3325],
        [0.6644, 0.3356],
        [0.6610, 0.3390],
        [0.6612, 0.3388],
        [0.6652, 0.3348],
        [0.6628, 0.3372],
        [0.6628, 0.3372],
        [0.6577, 0.3423],
        [0.6648, 0.3352],
        [0.6657, 0.3343],
        [0.6625, 0.3375],
        [0.6677, 0.3323],
        [0.6674, 0.3326],
        [0.6608, 0.3392],
        [0.6666, 0.3334],
        [0.6677, 0.3323],
        [0.6702, 0.3298],
        [0.6692, 0.3308],
        [0.6642, 0.3358],
        [0.6674, 0.3326],
        [0.6672, 0.3328],
        [0.6625, 0.3375],
        [0.6637, 0.3363],
        [0.6667, 0.3333],
        [0.6665, 0.3335],
        [0.6610, 0.3390],
        [0.6613, 0.3387],
        [0.6601, 0.3399],
        [0.6618, 0.3382],
        [0.6668, 0.3332],
        [0.6627, 0.3373],
        [0.6641, 0.3359],
        [0.6612, 0.3388],
        [0.6590, 0.3410],
        [0.6620, 0.3380],
        [0.6608, 0.3392],
        [0.6619, 0.3381],
        [0.6657, 0.3343],
        [0.6641, 0.3359],
        [0.6679, 0.3321],
        [0.6620, 0.3380],
        [0.6603, 0.3397],
        [0.6677, 0.3323],
        [0.6648, 0.3352],
        [0.6599, 0.3401],
        [0.6614, 0.3386],
        [0.6598, 0.3402],
        [0.6675, 0.3325],
        [0.6651, 0.3349],
        [0.6581, 0.3419],
        [0.6645, 0.3355],
        [0.6602, 0.3398],
        [0.6631, 0.3369],
        [0.6686, 0.3314],
        [0.6617, 0.3383],
        [0.6616, 0.3384],
        [0.6589, 0.3411],
        [0.6670, 0.3330],
        [0.6662, 0.3338],
        [0.6677, 0.3323],
        [0.6593, 0.3407],
        [0.6669, 0.3331],
        [0.6683, 0.3317],
        [0.6624, 0.3376],
        [0.6670, 0.3330],
        [0.6679, 0.3321],
        [0.6596, 0.3404],
        [0.6659, 0.3341],
        [0.6643, 0.3357],
        [0.6672, 0.3328],
        [0.6687, 0.3313],
        [0.6612, 0.3388],
        [0.6618, 0.3382],
        [0.6666, 0.3334],
        [0.6616, 0.3384],
        [0.6677, 0.3323],
        [0.6631, 0.3369],
        [0.6650, 0.3350],
        [0.6660, 0.3340],
        [0.6610, 0.3390],
        [0.6644, 0.3356],
        [0.6634, 0.3366],
        [0.6658, 0.3342],
        [0.6626, 0.3374],
        [0.6695, 0.3305],
        [0.6615, 0.3385],
        [0.6658, 0.3342],
        [0.6675, 0.3325],
        [0.6665, 0.3335],
        [0.6594, 0.3406],
        [0.6652, 0.3348],
        [0.6611, 0.3389],
        [0.6641, 0.3359],
        [0.6650, 0.3350],
        [0.6671, 0.3329],
        [0.6664, 0.3336],
        [0.6648, 0.3352],
        [0.6663, 0.3337],
        [0.6673, 0.3327],
        [0.6650, 0.3350],
        [0.6641, 0.3359],
        [0.6678, 0.3322],
        [0.6617, 0.3383],
        [0.6666, 0.3334],
        [0.6650, 0.3350],
        [0.6613, 0.3387],
        [0.6606, 0.3394],
        [0.6678, 0.3322],
        [0.6677, 0.3323],
        [0.6662, 0.3338],
        [0.6666, 0.3334],
        [0.6672, 0.3328],
        [0.6638, 0.3362],
        [0.6652, 0.3348],
        [0.6669, 0.3331],
        [0.6596, 0.3404],
        [0.6666, 0.3334],
        [0.6683, 0.3317],
        [0.6639, 0.3361],
        [0.6646, 0.3354],
        [0.6660, 0.3340],
        [0.6663, 0.3337],
        [0.6672, 0.3328],
        [0.6693, 0.3307],
        [0.6660, 0.3340],
        [0.6635, 0.3365],
        [0.6663, 0.3337],
        [0.6622, 0.3378],
        [0.6634, 0.3366],
        [0.6680, 0.3320],
        [0.6625, 0.3375],
        [0.6621, 0.3379],
        [0.6654, 0.3346],
        [0.6678, 0.3322],
        [0.6655, 0.3345]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0047 loss: 0.6692 acc_train: 0.6103 time: 0.1475s
tensor([[0.6638, 0.3362],
        [0.6683, 0.3317],
        [0.6656, 0.3344],
        [0.6637, 0.3363],
        [0.6678, 0.3322],
        [0.6604, 0.3396],
        [0.6587, 0.3413],
        [0.6647, 0.3353],
        [0.6669, 0.3331],
        [0.6599, 0.3401],
        [0.6645, 0.3355],
        [0.6627, 0.3373],
        [0.6610, 0.3390],
        [0.6605, 0.3395],
        [0.6659, 0.3341],
        [0.6612, 0.3388],
        [0.6696, 0.3304],
        [0.6627, 0.3373],
        [0.6655, 0.3345],
        [0.6596, 0.3404],
        [0.6680, 0.3320],
        [0.6598, 0.3402],
        [0.6668, 0.3332],
        [0.6666, 0.3334],
        [0.6620, 0.3380],
        [0.6621, 0.3379],
        [0.6633, 0.3367],
        [0.6658, 0.3342],
        [0.6613, 0.3387],
        [0.6615, 0.3385],
        [0.6643, 0.3357],
        [0.6606, 0.3394],
        [0.6641, 0.3359],
        [0.6625, 0.3375],
        [0.6673, 0.3327],
        [0.6609, 0.3391],
        [0.6620, 0.3380],
        [0.6628, 0.3372],
        [0.6653, 0.3347],
        [0.6608, 0.3392],
        [0.6663, 0.3337],
        [0.6645, 0.3355],
        [0.6581, 0.3419],
        [0.6665, 0.3335],
        [0.6646, 0.3354],
        [0.6619, 0.3381],
        [0.6679, 0.3321],
        [0.6665, 0.3335],
        [0.6646, 0.3354],
        [0.6624, 0.3376],
        [0.6639, 0.3361],
        [0.6649, 0.3351],
        [0.6621, 0.3379],
        [0.6665, 0.3335],
        [0.6651, 0.3349],
        [0.6665, 0.3335],
        [0.6691, 0.3309],
        [0.6637, 0.3363],
        [0.6636, 0.3364],
        [0.6608, 0.3392],
        [0.6587, 0.3413],
        [0.6605, 0.3395],
        [0.6655, 0.3345],
        [0.6649, 0.3351],
        [0.6643, 0.3357],
        [0.6630, 0.3370],
        [0.6654, 0.3346],
        [0.6645, 0.3355],
        [0.6645, 0.3355],
        [0.6646, 0.3354],
        [0.6611, 0.3389],
        [0.6604, 0.3396],
        [0.6638, 0.3362],
        [0.6648, 0.3352],
        [0.6629, 0.3371],
        [0.6631, 0.3369],
        [0.6636, 0.3364],
        [0.6630, 0.3370],
        [0.6664, 0.3336],
        [0.6600, 0.3400],
        [0.6586, 0.3414],
        [0.6609, 0.3391],
        [0.6608, 0.3392],
        [0.6623, 0.3377],
        [0.6621, 0.3379],
        [0.6618, 0.3382],
        [0.6659, 0.3341],
        [0.6627, 0.3373],
        [0.6651, 0.3349],
        [0.6624, 0.3376],
        [0.6620, 0.3380],
        [0.6624, 0.3376],
        [0.6646, 0.3354],
        [0.6593, 0.3407],
        [0.6622, 0.3378],
        [0.6674, 0.3326],
        [0.6662, 0.3338],
        [0.6616, 0.3384],
        [0.6682, 0.3318],
        [0.6618, 0.3382],
        [0.6660, 0.3340],
        [0.6621, 0.3379],
        [0.6600, 0.3400],
        [0.6621, 0.3379],
        [0.6692, 0.3308],
        [0.6610, 0.3390],
        [0.6670, 0.3330],
        [0.6670, 0.3330],
        [0.6602, 0.3398],
        [0.6676, 0.3324],
        [0.6591, 0.3409],
        [0.6683, 0.3317],
        [0.6667, 0.3333],
        [0.6672, 0.3328],
        [0.6609, 0.3391],
        [0.6612, 0.3388],
        [0.6637, 0.3363],
        [0.6663, 0.3337],
        [0.6682, 0.3318],
        [0.6678, 0.3322],
        [0.6590, 0.3410],
        [0.6620, 0.3380],
        [0.6635, 0.3365],
        [0.6634, 0.3366],
        [0.6614, 0.3386],
        [0.6635, 0.3365],
        [0.6612, 0.3388],
        [0.6645, 0.3355],
        [0.6612, 0.3388],
        [0.6625, 0.3375],
        [0.6637, 0.3363],
        [0.6597, 0.3403],
        [0.6650, 0.3350],
        [0.6613, 0.3387],
        [0.6657, 0.3343],
        [0.6641, 0.3359],
        [0.6626, 0.3374],
        [0.6672, 0.3328],
        [0.6642, 0.3358],
        [0.6608, 0.3392],
        [0.6610, 0.3390],
        [0.6649, 0.3351],
        [0.6627, 0.3373],
        [0.6626, 0.3374],
        [0.6577, 0.3423],
        [0.6645, 0.3355],
        [0.6654, 0.3346],
        [0.6625, 0.3375],
        [0.6673, 0.3327],
        [0.6671, 0.3329],
        [0.6606, 0.3394],
        [0.6663, 0.3337],
        [0.6674, 0.3326],
        [0.6698, 0.3302],
        [0.6689, 0.3311],
        [0.6641, 0.3359],
        [0.6672, 0.3328],
        [0.6668, 0.3332],
        [0.6623, 0.3377],
        [0.6635, 0.3365],
        [0.6664, 0.3336],
        [0.6663, 0.3337],
        [0.6608, 0.3392],
        [0.6612, 0.3388],
        [0.6600, 0.3400],
        [0.6617, 0.3383],
        [0.6665, 0.3335],
        [0.6626, 0.3374],
        [0.6638, 0.3362],
        [0.6611, 0.3389],
        [0.6589, 0.3411],
        [0.6618, 0.3382],
        [0.6608, 0.3392],
        [0.6617, 0.3383],
        [0.6655, 0.3345],
        [0.6638, 0.3362],
        [0.6676, 0.3324],
        [0.6619, 0.3381],
        [0.6601, 0.3399],
        [0.6673, 0.3327],
        [0.6645, 0.3355],
        [0.6599, 0.3401],
        [0.6613, 0.3387],
        [0.6596, 0.3404],
        [0.6671, 0.3329],
        [0.6649, 0.3351],
        [0.6579, 0.3421],
        [0.6643, 0.3357],
        [0.6601, 0.3399],
        [0.6628, 0.3372],
        [0.6684, 0.3316],
        [0.6616, 0.3384],
        [0.6614, 0.3386],
        [0.6588, 0.3412],
        [0.6667, 0.3333],
        [0.6659, 0.3341],
        [0.6675, 0.3325],
        [0.6592, 0.3408],
        [0.6666, 0.3334],
        [0.6681, 0.3319],
        [0.6623, 0.3377],
        [0.6666, 0.3334],
        [0.6676, 0.3324],
        [0.6595, 0.3405],
        [0.6656, 0.3344],
        [0.6642, 0.3358],
        [0.6670, 0.3330],
        [0.6684, 0.3316],
        [0.6612, 0.3388],
        [0.6617, 0.3383],
        [0.6664, 0.3336],
        [0.6615, 0.3385],
        [0.6675, 0.3325],
        [0.6629, 0.3371],
        [0.6648, 0.3352],
        [0.6657, 0.3343],
        [0.6609, 0.3391],
        [0.6642, 0.3358],
        [0.6633, 0.3367],
        [0.6656, 0.3344],
        [0.6624, 0.3376],
        [0.6692, 0.3308],
        [0.6613, 0.3387],
        [0.6655, 0.3345],
        [0.6671, 0.3329],
        [0.6663, 0.3337],
        [0.6593, 0.3407],
        [0.6650, 0.3350],
        [0.6611, 0.3389],
        [0.6640, 0.3360],
        [0.6648, 0.3352],
        [0.6668, 0.3332],
        [0.6661, 0.3339],
        [0.6646, 0.3354],
        [0.6660, 0.3340],
        [0.6671, 0.3329],
        [0.6648, 0.3352],
        [0.6639, 0.3361],
        [0.6675, 0.3325],
        [0.6617, 0.3383],
        [0.6664, 0.3336],
        [0.6648, 0.3352],
        [0.6611, 0.3389],
        [0.6605, 0.3395],
        [0.6677, 0.3323],
        [0.6675, 0.3325],
        [0.6660, 0.3340],
        [0.6664, 0.3336],
        [0.6669, 0.3331],
        [0.6635, 0.3365],
        [0.6649, 0.3351],
        [0.6666, 0.3334],
        [0.6595, 0.3405],
        [0.6663, 0.3337],
        [0.6680, 0.3320],
        [0.6637, 0.3363],
        [0.6644, 0.3356],
        [0.6657, 0.3343],
        [0.6661, 0.3339],
        [0.6669, 0.3331],
        [0.6690, 0.3310],
        [0.6659, 0.3341],
        [0.6632, 0.3368],
        [0.6660, 0.3340],
        [0.6620, 0.3380],
        [0.6632, 0.3368],
        [0.6676, 0.3324],
        [0.6624, 0.3376],
        [0.6619, 0.3381],
        [0.6652, 0.3348],
        [0.6673, 0.3327],
        [0.6653, 0.3347]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0048 loss: 0.6692 acc_train: 0.6103 time: 0.1418s
tensor([[0.6636, 0.3364],
        [0.6680, 0.3320],
        [0.6654, 0.3346],
        [0.6635, 0.3365],
        [0.6676, 0.3324],
        [0.6605, 0.3395],
        [0.6587, 0.3413],
        [0.6645, 0.3355],
        [0.6667, 0.3333],
        [0.6598, 0.3402],
        [0.6644, 0.3356],
        [0.6625, 0.3375],
        [0.6609, 0.3391],
        [0.6603, 0.3397],
        [0.6657, 0.3343],
        [0.6611, 0.3389],
        [0.6693, 0.3307],
        [0.6626, 0.3374],
        [0.6652, 0.3348],
        [0.6596, 0.3404],
        [0.6677, 0.3323],
        [0.6598, 0.3402],
        [0.6666, 0.3334],
        [0.6664, 0.3336],
        [0.6618, 0.3382],
        [0.6619, 0.3381],
        [0.6631, 0.3369],
        [0.6656, 0.3344],
        [0.6611, 0.3389],
        [0.6613, 0.3387],
        [0.6641, 0.3359],
        [0.6605, 0.3395],
        [0.6638, 0.3362],
        [0.6623, 0.3377],
        [0.6671, 0.3329],
        [0.6606, 0.3394],
        [0.6619, 0.3381],
        [0.6626, 0.3374],
        [0.6649, 0.3351],
        [0.6607, 0.3393],
        [0.6660, 0.3340],
        [0.6643, 0.3357],
        [0.6581, 0.3419],
        [0.6662, 0.3338],
        [0.6645, 0.3355],
        [0.6618, 0.3382],
        [0.6676, 0.3324],
        [0.6662, 0.3338],
        [0.6644, 0.3356],
        [0.6622, 0.3378],
        [0.6636, 0.3364],
        [0.6647, 0.3353],
        [0.6619, 0.3381],
        [0.6663, 0.3337],
        [0.6648, 0.3352],
        [0.6663, 0.3337],
        [0.6688, 0.3312],
        [0.6635, 0.3365],
        [0.6633, 0.3367],
        [0.6608, 0.3392],
        [0.6586, 0.3414],
        [0.6605, 0.3395],
        [0.6653, 0.3347],
        [0.6647, 0.3353],
        [0.6641, 0.3359],
        [0.6629, 0.3371],
        [0.6652, 0.3348],
        [0.6643, 0.3357],
        [0.6643, 0.3357],
        [0.6643, 0.3357],
        [0.6610, 0.3390],
        [0.6604, 0.3396],
        [0.6635, 0.3365],
        [0.6647, 0.3353],
        [0.6626, 0.3374],
        [0.6630, 0.3370],
        [0.6635, 0.3365],
        [0.6628, 0.3372],
        [0.6662, 0.3338],
        [0.6599, 0.3401],
        [0.6586, 0.3414],
        [0.6609, 0.3391],
        [0.6606, 0.3394],
        [0.6622, 0.3378],
        [0.6620, 0.3380],
        [0.6616, 0.3384],
        [0.6655, 0.3345],
        [0.6625, 0.3375],
        [0.6650, 0.3350],
        [0.6622, 0.3378],
        [0.6617, 0.3383],
        [0.6623, 0.3377],
        [0.6644, 0.3356],
        [0.6593, 0.3407],
        [0.6622, 0.3378],
        [0.6673, 0.3327],
        [0.6659, 0.3341],
        [0.6616, 0.3384],
        [0.6679, 0.3321],
        [0.6615, 0.3385],
        [0.6658, 0.3342],
        [0.6619, 0.3381],
        [0.6599, 0.3401],
        [0.6619, 0.3381],
        [0.6689, 0.3311],
        [0.6609, 0.3391],
        [0.6667, 0.3333],
        [0.6668, 0.3332],
        [0.6601, 0.3399],
        [0.6673, 0.3327],
        [0.6589, 0.3411],
        [0.6681, 0.3319],
        [0.6665, 0.3335],
        [0.6671, 0.3329],
        [0.6608, 0.3392],
        [0.6610, 0.3390],
        [0.6634, 0.3366],
        [0.6661, 0.3339],
        [0.6680, 0.3320],
        [0.6677, 0.3323],
        [0.6591, 0.3409],
        [0.6619, 0.3381],
        [0.6633, 0.3367],
        [0.6633, 0.3367],
        [0.6613, 0.3387],
        [0.6633, 0.3367],
        [0.6610, 0.3390],
        [0.6642, 0.3358],
        [0.6611, 0.3389],
        [0.6623, 0.3377],
        [0.6636, 0.3364],
        [0.6596, 0.3404],
        [0.6649, 0.3351],
        [0.6613, 0.3387],
        [0.6655, 0.3345],
        [0.6639, 0.3361],
        [0.6625, 0.3375],
        [0.6669, 0.3331],
        [0.6640, 0.3360],
        [0.6607, 0.3393],
        [0.6609, 0.3391],
        [0.6647, 0.3353],
        [0.6626, 0.3374],
        [0.6626, 0.3374],
        [0.6577, 0.3423],
        [0.6643, 0.3357],
        [0.6653, 0.3347],
        [0.6624, 0.3376],
        [0.6671, 0.3329],
        [0.6668, 0.3332],
        [0.6605, 0.3395],
        [0.6660, 0.3340],
        [0.6670, 0.3330],
        [0.6694, 0.3306],
        [0.6687, 0.3313],
        [0.6639, 0.3361],
        [0.6671, 0.3329],
        [0.6665, 0.3335],
        [0.6621, 0.3379],
        [0.6634, 0.3366],
        [0.6661, 0.3339],
        [0.6661, 0.3339],
        [0.6607, 0.3393],
        [0.6611, 0.3389],
        [0.6599, 0.3401],
        [0.6616, 0.3384],
        [0.6663, 0.3337],
        [0.6625, 0.3375],
        [0.6636, 0.3364],
        [0.6610, 0.3390],
        [0.6588, 0.3412],
        [0.6616, 0.3384],
        [0.6608, 0.3392],
        [0.6615, 0.3385],
        [0.6653, 0.3347],
        [0.6636, 0.3364],
        [0.6673, 0.3327],
        [0.6618, 0.3382],
        [0.6599, 0.3401],
        [0.6670, 0.3330],
        [0.6642, 0.3358],
        [0.6598, 0.3402],
        [0.6612, 0.3388],
        [0.6594, 0.3406],
        [0.6667, 0.3333],
        [0.6648, 0.3352],
        [0.6578, 0.3422],
        [0.6641, 0.3359],
        [0.6600, 0.3400],
        [0.6626, 0.3374],
        [0.6682, 0.3318],
        [0.6615, 0.3385],
        [0.6613, 0.3387],
        [0.6588, 0.3412],
        [0.6664, 0.3336],
        [0.6656, 0.3344],
        [0.6673, 0.3327],
        [0.6591, 0.3409],
        [0.6663, 0.3337],
        [0.6678, 0.3322],
        [0.6621, 0.3379],
        [0.6662, 0.3338],
        [0.6673, 0.3327],
        [0.6594, 0.3406],
        [0.6654, 0.3346],
        [0.6641, 0.3359],
        [0.6668, 0.3332],
        [0.6681, 0.3319],
        [0.6611, 0.3389],
        [0.6615, 0.3385],
        [0.6662, 0.3338],
        [0.6614, 0.3386],
        [0.6674, 0.3326],
        [0.6628, 0.3372],
        [0.6647, 0.3353],
        [0.6655, 0.3345],
        [0.6608, 0.3392],
        [0.6640, 0.3360],
        [0.6632, 0.3368],
        [0.6655, 0.3345],
        [0.6622, 0.3378],
        [0.6688, 0.3312],
        [0.6612, 0.3388],
        [0.6652, 0.3348],
        [0.6668, 0.3332],
        [0.6661, 0.3339],
        [0.6592, 0.3408],
        [0.6648, 0.3352],
        [0.6610, 0.3390],
        [0.6640, 0.3360],
        [0.6646, 0.3354],
        [0.6666, 0.3334],
        [0.6658, 0.3342],
        [0.6645, 0.3355],
        [0.6658, 0.3342],
        [0.6669, 0.3331],
        [0.6645, 0.3355],
        [0.6637, 0.3363],
        [0.6672, 0.3328],
        [0.6616, 0.3384],
        [0.6662, 0.3338],
        [0.6646, 0.3354],
        [0.6610, 0.3390],
        [0.6606, 0.3394],
        [0.6675, 0.3325],
        [0.6673, 0.3327],
        [0.6658, 0.3342],
        [0.6662, 0.3338],
        [0.6666, 0.3334],
        [0.6633, 0.3367],
        [0.6647, 0.3353],
        [0.6662, 0.3338],
        [0.6594, 0.3406],
        [0.6660, 0.3340],
        [0.6676, 0.3324],
        [0.6635, 0.3365],
        [0.6642, 0.3358],
        [0.6654, 0.3346],
        [0.6659, 0.3341],
        [0.6666, 0.3334],
        [0.6688, 0.3312],
        [0.6657, 0.3343],
        [0.6631, 0.3369],
        [0.6657, 0.3343],
        [0.6618, 0.3382],
        [0.6631, 0.3369],
        [0.6673, 0.3327],
        [0.6623, 0.3377],
        [0.6617, 0.3383],
        [0.6650, 0.3350],
        [0.6669, 0.3331],
        [0.6651, 0.3349]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0049 loss: 0.6692 acc_train: 0.6103 time: 0.1236s
tensor([[0.6634, 0.3366],
        [0.6677, 0.3323],
        [0.6653, 0.3347],
        [0.6633, 0.3367],
        [0.6674, 0.3326],
        [0.6605, 0.3395],
        [0.6586, 0.3414],
        [0.6643, 0.3357],
        [0.6665, 0.3335],
        [0.6598, 0.3402],
        [0.6642, 0.3358],
        [0.6623, 0.3377],
        [0.6608, 0.3392],
        [0.6601, 0.3399],
        [0.6654, 0.3346],
        [0.6610, 0.3390],
        [0.6690, 0.3310],
        [0.6625, 0.3375],
        [0.6649, 0.3351],
        [0.6596, 0.3404],
        [0.6674, 0.3326],
        [0.6597, 0.3403],
        [0.6665, 0.3335],
        [0.6662, 0.3338],
        [0.6617, 0.3383],
        [0.6618, 0.3382],
        [0.6630, 0.3370],
        [0.6655, 0.3345],
        [0.6610, 0.3390],
        [0.6611, 0.3389],
        [0.6640, 0.3360],
        [0.6604, 0.3396],
        [0.6636, 0.3364],
        [0.6621, 0.3379],
        [0.6669, 0.3331],
        [0.6604, 0.3396],
        [0.6618, 0.3382],
        [0.6623, 0.3377],
        [0.6646, 0.3354],
        [0.6606, 0.3394],
        [0.6658, 0.3342],
        [0.6640, 0.3360],
        [0.6581, 0.3419],
        [0.6659, 0.3341],
        [0.6645, 0.3355],
        [0.6617, 0.3383],
        [0.6673, 0.3327],
        [0.6659, 0.3341],
        [0.6642, 0.3358],
        [0.6620, 0.3380],
        [0.6635, 0.3365],
        [0.6645, 0.3355],
        [0.6618, 0.3382],
        [0.6662, 0.3338],
        [0.6645, 0.3355],
        [0.6661, 0.3339],
        [0.6684, 0.3316],
        [0.6633, 0.3367],
        [0.6631, 0.3369],
        [0.6608, 0.3392],
        [0.6584, 0.3416],
        [0.6605, 0.3395],
        [0.6651, 0.3349],
        [0.6646, 0.3354],
        [0.6639, 0.3361],
        [0.6628, 0.3372],
        [0.6651, 0.3349],
        [0.6641, 0.3359],
        [0.6641, 0.3359],
        [0.6640, 0.3360],
        [0.6609, 0.3391],
        [0.6603, 0.3397],
        [0.6632, 0.3368],
        [0.6647, 0.3353],
        [0.6624, 0.3376],
        [0.6629, 0.3371],
        [0.6634, 0.3366],
        [0.6626, 0.3374],
        [0.6660, 0.3340],
        [0.6597, 0.3403],
        [0.6585, 0.3415],
        [0.6609, 0.3391],
        [0.6605, 0.3395],
        [0.6621, 0.3379],
        [0.6620, 0.3380],
        [0.6615, 0.3385],
        [0.6653, 0.3347],
        [0.6623, 0.3377],
        [0.6649, 0.3351],
        [0.6620, 0.3380],
        [0.6615, 0.3385],
        [0.6621, 0.3379],
        [0.6641, 0.3359],
        [0.6592, 0.3408],
        [0.6621, 0.3379],
        [0.6672, 0.3328],
        [0.6656, 0.3344],
        [0.6614, 0.3386],
        [0.6676, 0.3324],
        [0.6614, 0.3386],
        [0.6656, 0.3344],
        [0.6618, 0.3382],
        [0.6598, 0.3402],
        [0.6617, 0.3383],
        [0.6686, 0.3314],
        [0.6609, 0.3391],
        [0.6665, 0.3335],
        [0.6667, 0.3333],
        [0.6601, 0.3399],
        [0.6671, 0.3329],
        [0.6587, 0.3413],
        [0.6678, 0.3322],
        [0.6662, 0.3338],
        [0.6669, 0.3331],
        [0.6608, 0.3392],
        [0.6608, 0.3392],
        [0.6632, 0.3368],
        [0.6659, 0.3341],
        [0.6678, 0.3322],
        [0.6676, 0.3324],
        [0.6592, 0.3408],
        [0.6619, 0.3381],
        [0.6631, 0.3369],
        [0.6631, 0.3369],
        [0.6612, 0.3388],
        [0.6630, 0.3370],
        [0.6608, 0.3392],
        [0.6639, 0.3361],
        [0.6610, 0.3390],
        [0.6621, 0.3379],
        [0.6634, 0.3366],
        [0.6596, 0.3404],
        [0.6648, 0.3352],
        [0.6613, 0.3387],
        [0.6653, 0.3347],
        [0.6637, 0.3363],
        [0.6624, 0.3376],
        [0.6666, 0.3334],
        [0.6639, 0.3361],
        [0.6605, 0.3395],
        [0.6608, 0.3392],
        [0.6645, 0.3355],
        [0.6624, 0.3376],
        [0.6625, 0.3375],
        [0.6577, 0.3423],
        [0.6640, 0.3360],
        [0.6651, 0.3349],
        [0.6623, 0.3377],
        [0.6668, 0.3332],
        [0.6665, 0.3335],
        [0.6605, 0.3395],
        [0.6657, 0.3343],
        [0.6666, 0.3334],
        [0.6691, 0.3309],
        [0.6685, 0.3315],
        [0.6638, 0.3362],
        [0.6669, 0.3331],
        [0.6661, 0.3339],
        [0.6619, 0.3381],
        [0.6633, 0.3367],
        [0.6658, 0.3342],
        [0.6660, 0.3340],
        [0.6605, 0.3395],
        [0.6610, 0.3390],
        [0.6598, 0.3402],
        [0.6615, 0.3385],
        [0.6662, 0.3338],
        [0.6624, 0.3376],
        [0.6634, 0.3366],
        [0.6608, 0.3392],
        [0.6587, 0.3413],
        [0.6614, 0.3386],
        [0.6608, 0.3392],
        [0.6613, 0.3387],
        [0.6651, 0.3349],
        [0.6635, 0.3365],
        [0.6670, 0.3330],
        [0.6618, 0.3382],
        [0.6597, 0.3403],
        [0.6667, 0.3333],
        [0.6639, 0.3361],
        [0.6597, 0.3403],
        [0.6611, 0.3389],
        [0.6593, 0.3407],
        [0.6664, 0.3336],
        [0.6647, 0.3353],
        [0.6577, 0.3423],
        [0.6639, 0.3361],
        [0.6599, 0.3401],
        [0.6623, 0.3377],
        [0.6680, 0.3320],
        [0.6614, 0.3386],
        [0.6612, 0.3388],
        [0.6587, 0.3413],
        [0.6662, 0.3338],
        [0.6653, 0.3347],
        [0.6672, 0.3328],
        [0.6590, 0.3410],
        [0.6660, 0.3340],
        [0.6675, 0.3325],
        [0.6620, 0.3380],
        [0.6659, 0.3341],
        [0.6670, 0.3330],
        [0.6594, 0.3406],
        [0.6652, 0.3348],
        [0.6640, 0.3360],
        [0.6666, 0.3334],
        [0.6679, 0.3321],
        [0.6611, 0.3389],
        [0.6614, 0.3386],
        [0.6660, 0.3340],
        [0.6614, 0.3386],
        [0.6672, 0.3328],
        [0.6627, 0.3373],
        [0.6645, 0.3355],
        [0.6652, 0.3348],
        [0.6607, 0.3393],
        [0.6638, 0.3362],
        [0.6631, 0.3369],
        [0.6653, 0.3347],
        [0.6620, 0.3380],
        [0.6684, 0.3316],
        [0.6612, 0.3388],
        [0.6649, 0.3351],
        [0.6665, 0.3335],
        [0.6659, 0.3341],
        [0.6591, 0.3409],
        [0.6645, 0.3355],
        [0.6610, 0.3390],
        [0.6640, 0.3360],
        [0.6644, 0.3356],
        [0.6665, 0.3335],
        [0.6655, 0.3345],
        [0.6644, 0.3356],
        [0.6656, 0.3344],
        [0.6666, 0.3334],
        [0.6643, 0.3357],
        [0.6635, 0.3365],
        [0.6669, 0.3331],
        [0.6615, 0.3385],
        [0.6660, 0.3340],
        [0.6644, 0.3356],
        [0.6609, 0.3391],
        [0.6606, 0.3394],
        [0.6672, 0.3328],
        [0.6670, 0.3330],
        [0.6655, 0.3345],
        [0.6660, 0.3340],
        [0.6663, 0.3337],
        [0.6631, 0.3369],
        [0.6645, 0.3355],
        [0.6658, 0.3342],
        [0.6594, 0.3406],
        [0.6658, 0.3342],
        [0.6673, 0.3327],
        [0.6634, 0.3366],
        [0.6640, 0.3360],
        [0.6651, 0.3349],
        [0.6656, 0.3344],
        [0.6662, 0.3338],
        [0.6685, 0.3315],
        [0.6656, 0.3344],
        [0.6630, 0.3370],
        [0.6654, 0.3346],
        [0.6617, 0.3383],
        [0.6631, 0.3369],
        [0.6670, 0.3330],
        [0.6622, 0.3378],
        [0.6615, 0.3385],
        [0.6649, 0.3351],
        [0.6666, 0.3334],
        [0.6650, 0.3350]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0050 loss: 0.6693 acc_train: 0.6103 time: 0.1258s
tensor([[0.6632, 0.3368],
        [0.6674, 0.3326],
        [0.6651, 0.3349],
        [0.6632, 0.3368],
        [0.6672, 0.3328],
        [0.6605, 0.3395],
        [0.6586, 0.3414],
        [0.6642, 0.3358],
        [0.6662, 0.3338],
        [0.6597, 0.3403],
        [0.6641, 0.3359],
        [0.6621, 0.3379],
        [0.6606, 0.3394],
        [0.6600, 0.3400],
        [0.6652, 0.3348],
        [0.6608, 0.3392],
        [0.6687, 0.3313],
        [0.6624, 0.3376],
        [0.6646, 0.3354],
        [0.6596, 0.3404],
        [0.6671, 0.3329],
        [0.6597, 0.3403],
        [0.6664, 0.3336],
        [0.6660, 0.3340],
        [0.6616, 0.3384],
        [0.6617, 0.3383],
        [0.6628, 0.3372],
        [0.6654, 0.3346],
        [0.6609, 0.3391],
        [0.6610, 0.3390],
        [0.6638, 0.3362],
        [0.6603, 0.3397],
        [0.6634, 0.3366],
        [0.6619, 0.3381],
        [0.6667, 0.3333],
        [0.6602, 0.3398],
        [0.6617, 0.3383],
        [0.6620, 0.3380],
        [0.6643, 0.3357],
        [0.6606, 0.3394],
        [0.6656, 0.3344],
        [0.6638, 0.3362],
        [0.6581, 0.3419],
        [0.6657, 0.3343],
        [0.6644, 0.3356],
        [0.6615, 0.3385],
        [0.6671, 0.3329],
        [0.6657, 0.3343],
        [0.6641, 0.3359],
        [0.6618, 0.3382],
        [0.6633, 0.3367],
        [0.6643, 0.3357],
        [0.6617, 0.3383],
        [0.6661, 0.3339],
        [0.6643, 0.3357],
        [0.6659, 0.3341],
        [0.6680, 0.3320],
        [0.6631, 0.3369],
        [0.6629, 0.3371],
        [0.6607, 0.3393],
        [0.6584, 0.3416],
        [0.6605, 0.3395],
        [0.6649, 0.3351],
        [0.6644, 0.3356],
        [0.6637, 0.3363],
        [0.6627, 0.3373],
        [0.6650, 0.3350],
        [0.6638, 0.3362],
        [0.6639, 0.3361],
        [0.6638, 0.3362],
        [0.6608, 0.3392],
        [0.6602, 0.3398],
        [0.6630, 0.3370],
        [0.6645, 0.3355],
        [0.6623, 0.3377],
        [0.6628, 0.3372],
        [0.6633, 0.3367],
        [0.6624, 0.3376],
        [0.6658, 0.3342],
        [0.6596, 0.3404],
        [0.6585, 0.3415],
        [0.6608, 0.3392],
        [0.6603, 0.3397],
        [0.6620, 0.3380],
        [0.6619, 0.3381],
        [0.6613, 0.3387],
        [0.6651, 0.3349],
        [0.6621, 0.3379],
        [0.6648, 0.3352],
        [0.6618, 0.3382],
        [0.6612, 0.3388],
        [0.6620, 0.3380],
        [0.6638, 0.3362],
        [0.6592, 0.3408],
        [0.6621, 0.3379],
        [0.6670, 0.3330],
        [0.6653, 0.3347],
        [0.6613, 0.3387],
        [0.6674, 0.3326],
        [0.6612, 0.3388],
        [0.6654, 0.3346],
        [0.6616, 0.3384],
        [0.6598, 0.3402],
        [0.6615, 0.3385],
        [0.6684, 0.3316],
        [0.6608, 0.3392],
        [0.6662, 0.3338],
        [0.6666, 0.3334],
        [0.6600, 0.3400],
        [0.6668, 0.3332],
        [0.6584, 0.3416],
        [0.6675, 0.3325],
        [0.6659, 0.3341],
        [0.6668, 0.3332],
        [0.6608, 0.3392],
        [0.6606, 0.3394],
        [0.6630, 0.3370],
        [0.6657, 0.3343],
        [0.6676, 0.3324],
        [0.6674, 0.3326],
        [0.6593, 0.3407],
        [0.6618, 0.3382],
        [0.6629, 0.3371],
        [0.6630, 0.3370],
        [0.6611, 0.3389],
        [0.6628, 0.3372],
        [0.6607, 0.3393],
        [0.6636, 0.3364],
        [0.6609, 0.3391],
        [0.6619, 0.3381],
        [0.6633, 0.3367],
        [0.6595, 0.3405],
        [0.6646, 0.3354],
        [0.6613, 0.3387],
        [0.6651, 0.3349],
        [0.6635, 0.3365],
        [0.6622, 0.3378],
        [0.6664, 0.3336],
        [0.6637, 0.3363],
        [0.6604, 0.3396],
        [0.6608, 0.3392],
        [0.6644, 0.3356],
        [0.6623, 0.3377],
        [0.6624, 0.3376],
        [0.6578, 0.3422],
        [0.6638, 0.3362],
        [0.6650, 0.3350],
        [0.6622, 0.3378],
        [0.6666, 0.3334],
        [0.6663, 0.3337],
        [0.6604, 0.3396],
        [0.6655, 0.3345],
        [0.6663, 0.3337],
        [0.6688, 0.3312],
        [0.6683, 0.3317],
        [0.6636, 0.3364],
        [0.6667, 0.3333],
        [0.6658, 0.3342],
        [0.6617, 0.3383],
        [0.6631, 0.3369],
        [0.6656, 0.3344],
        [0.6658, 0.3342],
        [0.6605, 0.3395],
        [0.6609, 0.3391],
        [0.6598, 0.3402],
        [0.6614, 0.3386],
        [0.6661, 0.3339],
        [0.6624, 0.3376],
        [0.6631, 0.3369],
        [0.6607, 0.3393],
        [0.6587, 0.3413],
        [0.6613, 0.3387],
        [0.6609, 0.3391],
        [0.6611, 0.3389],
        [0.6649, 0.3351],
        [0.6634, 0.3366],
        [0.6668, 0.3332],
        [0.6617, 0.3383],
        [0.6595, 0.3405],
        [0.6664, 0.3336],
        [0.6637, 0.3363],
        [0.6597, 0.3403],
        [0.6610, 0.3390],
        [0.6592, 0.3408],
        [0.6661, 0.3339],
        [0.6646, 0.3354],
        [0.6577, 0.3423],
        [0.6637, 0.3363],
        [0.6598, 0.3402],
        [0.6621, 0.3379],
        [0.6677, 0.3323],
        [0.6612, 0.3388],
        [0.6610, 0.3390],
        [0.6587, 0.3413],
        [0.6659, 0.3341],
        [0.6651, 0.3349],
        [0.6670, 0.3330],
        [0.6589, 0.3411],
        [0.6657, 0.3343],
        [0.6672, 0.3328],
        [0.6619, 0.3381],
        [0.6656, 0.3344],
        [0.6667, 0.3333],
        [0.6593, 0.3407],
        [0.6649, 0.3351],
        [0.6638, 0.3362],
        [0.6664, 0.3336],
        [0.6676, 0.3324],
        [0.6610, 0.3390],
        [0.6613, 0.3387],
        [0.6657, 0.3343],
        [0.6614, 0.3386],
        [0.6671, 0.3329],
        [0.6627, 0.3373],
        [0.6644, 0.3356],
        [0.6649, 0.3351],
        [0.6606, 0.3394],
        [0.6637, 0.3363],
        [0.6630, 0.3370],
        [0.6652, 0.3348],
        [0.6618, 0.3382],
        [0.6681, 0.3319],
        [0.6611, 0.3389],
        [0.6646, 0.3354],
        [0.6663, 0.3337],
        [0.6657, 0.3343],
        [0.6591, 0.3409],
        [0.6643, 0.3357],
        [0.6609, 0.3391],
        [0.6639, 0.3361],
        [0.6642, 0.3358],
        [0.6664, 0.3336],
        [0.6652, 0.3348],
        [0.6642, 0.3358],
        [0.6655, 0.3345],
        [0.6665, 0.3335],
        [0.6641, 0.3359],
        [0.6633, 0.3367],
        [0.6666, 0.3334],
        [0.6614, 0.3386],
        [0.6657, 0.3343],
        [0.6642, 0.3358],
        [0.6608, 0.3392],
        [0.6606, 0.3394],
        [0.6670, 0.3330],
        [0.6668, 0.3332],
        [0.6652, 0.3348],
        [0.6658, 0.3342],
        [0.6661, 0.3339],
        [0.6630, 0.3370],
        [0.6643, 0.3357],
        [0.6655, 0.3345],
        [0.6593, 0.3407],
        [0.6655, 0.3345],
        [0.6670, 0.3330],
        [0.6632, 0.3368],
        [0.6639, 0.3361],
        [0.6649, 0.3351],
        [0.6653, 0.3347],
        [0.6660, 0.3340],
        [0.6683, 0.3317],
        [0.6654, 0.3346],
        [0.6629, 0.3371],
        [0.6652, 0.3348],
        [0.6615, 0.3385],
        [0.6630, 0.3370],
        [0.6667, 0.3333],
        [0.6621, 0.3379],
        [0.6613, 0.3387],
        [0.6647, 0.3353],
        [0.6663, 0.3337],
        [0.6649, 0.3351]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0051 loss: 0.6693 acc_train: 0.6103 time: 0.1283s
[Epoch 50] Loss: 0.66932 Forward: 0.067s Backward: 0.061s Train Accuracy: 61.03 Test Accuracy: 66.18
Training is complete!
(0, tensor(12917, device='cuda:7'))
12917
tensor(indices=tensor([[12917],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  301,   301,   301,  ..., 22447, 22447, 22447],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1532e-04, -2.5548e-06,  1.4010e-05,  ...,
                       6.3806e-05,  1.1627e-04, -1.6139e-05]),
       size=(22540, 50), nnz=3015, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1099e-06, -3.9019e-06, -3.7601e-06,  ...,
                      -6.6862e-07,  2.1175e-08, -7.2058e-07]),
       size=(22540, 50), nnz=21650, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(1, tensor(21950, device='cuda:7'))
21950
tensor(indices=tensor([[21950],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1004,  1004,  1004,  ..., 22400, 22400, 22400],
                       [    0,     1,     2,  ...,    45,    46,    48]]),
       values=tensor([ 3.4839e-05,  2.0732e-04, -2.5250e-05,  ...,
                       9.8695e-07,  3.1058e-06,  4.8096e-05]),
       size=(22540, 50), nnz=3149, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1156e-06, -3.9218e-06, -3.7793e-06,  ...,
                      -6.7203e-07,  2.1283e-08, -7.2426e-07]),
       size=(22540, 50), nnz=21800, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(2, tensor(3144, device='cuda:7'))
3144
tensor(indices=tensor([[3144],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  888,   888,   888,  ..., 22146, 22146, 22146],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.8529e-04, -3.2905e-06,  2.7872e-05,  ...,
                       1.4625e-04,  5.4211e-04,  1.8497e-05]),
       size=(22540, 50), nnz=2189, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1750e-06, -4.1309e-06, -3.9807e-06,  ...,
                      -7.0785e-07,  2.2417e-08, -7.6286e-07]),
       size=(22540, 50), nnz=20850, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(3, tensor(20225, device='cuda:7'))
20225
tensor(indices=tensor([[20225],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  169,   169,   169,  ..., 22530, 22530, 22530],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.6940e-05, -7.2137e-07,  6.0294e-06,  ...,
                       3.1053e-05,  6.9402e-05, -5.6825e-06]),
       size=(22540, 50), nnz=11131, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1054e-06, -3.8861e-06, -3.7449e-06,  ...,
                      -6.6592e-07,  2.1089e-08, -7.1767e-07]),
       size=(22540, 50), nnz=30700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(4, tensor(7271, device='cuda:7'))
7271
tensor(indices=tensor([[7271],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  406,   406,   406,  ..., 22441, 22441, 22441],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.0753e-05,  1.0763e-04, -2.5621e-05,  ...,
                      -2.0263e-04,  3.9050e-05,  6.7697e-05]),
       size=(22540, 50), nnz=4562, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1344e-06, -3.9881e-06, -3.8432e-06,  ...,
                      -6.8339e-07,  2.1642e-08, -7.3650e-07]),
       size=(22540, 50), nnz=23650, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
1
(5, tensor(10768, device='cuda:7'))
10768
tensor(indices=tensor([[10768],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  604,   604,   604,  ..., 21768, 21768, 21768],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 3.0916e-04, -5.1882e-06,  4.5502e-05,  ...,
                       1.9058e-04,  5.9375e-04,  2.1525e-05]),
       size=(22540, 50), nnz=1476, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.0713e-06, -3.7663e-06, -3.6294e-06,  ...,
                      -6.4538e-07,  2.0439e-08, -6.9553e-07]),
       size=(22540, 50), nnz=19900, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
1
2
(6, tensor(11934, device='cuda:7'))
11934
tensor(indices=tensor([[11934],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1570,  1570,  1570,  ..., 22510, 22510, 22510],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.9200e-05,  1.2778e-04, -1.0871e-04,  ...,
                      -2.8232e-04,  7.9787e-05,  6.9058e-05]),
       size=(22540, 50), nnz=2011, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.2424e-06, -4.3675e-06, -4.2088e-06,  ...,
                      -7.4841e-07,  2.3701e-08, -8.0657e-07]),
       size=(22540, 50), nnz=20550, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(7, tensor(4336, device='cuda:7'))
4336
tensor(indices=tensor([[4336],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   93,    93,    93,  ..., 22478, 22478, 22478],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.8574e-05,  2.7154e-04, -3.6088e-05,  ...,
                       1.3990e-04,  2.9760e-04, -1.5714e-05]),
       size=(22540, 50), nnz=2539, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.0969e-06, -3.8561e-06, -3.7160e-06,  ...,
                      -6.6077e-07,  2.0926e-08, -7.1213e-07]),
       size=(22540, 50), nnz=21700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
2
3
(8, tensor(10172, device='cuda:7'))
10172
tensor(indices=tensor([[10172],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  154,   154,   154,  ..., 22502, 22502, 22502],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.7497e-05,  1.6627e-04, -5.6074e-05,  ...,
                       9.8323e-06,  5.3540e-05, -5.0914e-06]),
       size=(22540, 50), nnz=3401, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1539e-06, -4.0564e-06, -3.9089e-06,  ...,
                      -6.9508e-07,  2.2013e-08, -7.4910e-07]),
       size=(22540, 50), nnz=21950, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(9, tensor(13510, device='cuda:7'))
13510
tensor(indices=tensor([[13510],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   42,    42,    42,  ..., 22429, 22429, 22429],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.0488e-04, -2.1877e-06,  1.0194e-05,  ...,
                       5.8352e-05,  1.2552e-04, -2.4293e-05]),
       size=(22540, 50), nnz=3267, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   42,    42,    42,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-6.3543e-04, -8.2862e-05,  3.6071e-05,  ...,
                      -6.5139e-07,  2.0629e-08, -7.0201e-07]),
       size=(22540, 50), nnz=21950, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(10, tensor(19233, device='cuda:7'))
19233
tensor(indices=tensor([[19233],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1667,  1667,  1667,  ..., 21474, 21474, 21474],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([4.7521e-05, 8.8682e-05, 6.2047e-05,  ...,
                      6.6002e-05, 2.5541e-04, 3.8327e-06]),
       size=(22540, 50), nnz=3058, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.0680e-06, -3.7546e-06, -3.6182e-06,  ...,
                      -6.4338e-07,  2.0375e-08, -6.9338e-07]),
       size=(22540, 50), nnz=21650, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
4
(11, tensor(19260, device='cuda:7'))
19260
tensor(indices=tensor([[19260],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  112,   112,   112,  ..., 22455, 22455, 22455],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 6.9315e-05, -1.7766e-06,  1.5089e-05,  ...,
                       1.9457e-05,  7.1828e-05, -3.8499e-06]),
       size=(22540, 50), nnz=4309, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1108e-06, -3.9050e-06, -3.7631e-06,  ...,
                      -6.6915e-07,  2.1191e-08, -7.2116e-07]),
       size=(22540, 50), nnz=23450, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(12, tensor(7860, device='cuda:7'))
7860
tensor(indices=tensor([[7860],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  206,   206,   206,  ..., 22444, 22444, 22444],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 7.9311e-05, -1.9728e-06,  4.3413e-06,  ...,
                       1.8388e-05,  8.3902e-05, -2.5533e-06]),
       size=(22540, 50), nnz=4843, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.2105e-06, -4.2556e-06, -4.1010e-06,  ...,
                      -7.2923e-07,  2.3094e-08, -7.8590e-07]),
       size=(22540, 50), nnz=23750, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(13, tensor(9637, device='cuda:7'))
9637
tensor(indices=tensor([[9637],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   16,    16,    16,  ..., 22208, 22208, 22208],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.1574e-05,  2.0539e-04, -7.4197e-05,  ...,
                       7.5506e-05,  3.4684e-04,  1.1779e-05]),
       size=(22540, 50), nnz=3231, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   16,    16,    16,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 5.1924e-04, -1.0801e-04, -7.1717e-04,  ...,
                      -7.2915e-07,  2.3091e-08, -7.8581e-07]),
       size=(22540, 50), nnz=21950, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
3
5
(14, tensor(7315, device='cuda:7'))
7315
tensor(indices=tensor([[7315],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  135,   135,   135,  ..., 21920, 21920, 21920],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([8.5224e-05, 1.4678e-04, 9.9558e-05,  ...,
                      1.6640e-04, 5.5922e-04, 2.1236e-05]),
       size=(22540, 50), nnz=2212, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1032e-06, -3.8783e-06, -3.7374e-06,  ...,
                      -6.6458e-07,  2.1047e-08, -7.1623e-07]),
       size=(22540, 50), nnz=21000, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(15, tensor(21185, device='cuda:7'))
21185
tensor(indices=tensor([[21185],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 2547,  2547,  2547,  ..., 22453, 22453, 22453],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.9221e-04, -4.3899e-06,  3.4376e-05,  ...,
                       7.6736e-05,  1.0478e-04, -2.8652e-05]),
       size=(22540, 50), nnz=1677, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1864e-06, -4.1707e-06, -4.0191e-06,  ...,
                      -7.1467e-07,  2.2633e-08, -7.7022e-07]),
       size=(22540, 50), nnz=20050, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
4
6
(16, tensor(9704, device='cuda:7'))
9704
tensor(indices=tensor([[9704],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   44,    44,    44,  ..., 21806, 21806, 21806],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.7441e-05,  1.3234e-04, -1.2906e-04,  ...,
                       1.5552e-04,  3.1334e-04, -3.7385e-05]),
       size=(22540, 50), nnz=2314, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   44,    44,    44,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-4.9354e-04,  6.5112e-05,  4.8303e-05,  ...,
                      -6.6190e-07,  2.0962e-08, -7.1334e-07]),
       size=(22540, 50), nnz=21000, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(17, tensor(15542, device='cuda:7'))
15542
tensor(indices=tensor([[15542],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1508,  1508,  1508,  ..., 22413, 22413, 22413],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([7.1101e-05, 1.4911e-04, 9.8041e-05,  ...,
                      2.5836e-04, 8.4825e-04, 3.9993e-05]),
       size=(22540, 50), nnz=1264, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.2495e-06, -4.3926e-06, -4.2330e-06,  ...,
                      -7.5270e-07,  2.3837e-08, -8.1120e-07]),
       size=(22540, 50), nnz=19650, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(18, tensor(1543, device='cuda:7'))
1543
tensor(indices=tensor([[1543],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  170,   170,   170,  ..., 22535, 22535, 22535],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.4739e-05,  1.4046e-04, -4.0180e-05,  ...,
                       8.1023e-05,  1.9228e-04, -2.7119e-05]),
       size=(22540, 50), nnz=3538, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22535, 22535, 22535],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1877e-06, -4.1753e-06, -4.0236e-06,  ...,
                      -2.5960e-04,  8.9056e-04, -1.6395e-03]),
       size=(22540, 50), nnz=22300, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
5
7
(19, tensor(9956, device='cuda:7'))
9956
tensor(indices=tensor([[9956],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   77,    77,    77,  ..., 22356, 22356, 22356],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.9555e-04, -4.0465e-06,  1.8409e-05,  ...,
                       6.1544e-05,  2.0830e-04, -4.2005e-05]),
       size=(22540, 50), nnz=2024, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.0845e-06, -3.8124e-06, -3.6739e-06,  ...,
                      -6.5328e-07,  2.0689e-08, -7.0405e-07]),
       size=(22540, 50), nnz=20800, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(20, tensor(19946, device='cuda:7'))
19946
tensor(indices=tensor([[19946],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  104,   104,   104,  ..., 21864, 21864, 21864],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.9871e-05,  7.9557e-05, -1.0380e-04,  ...,
                       8.5030e-05,  2.8710e-04,  1.2303e-05]),
       size=(22540, 50), nnz=3805, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1117e-06, -3.9081e-06, -3.7661e-06,  ...,
                      -6.6968e-07,  2.1208e-08, -7.2173e-07]),
       size=(22540, 50), nnz=22700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(21, tensor(2144, device='cuda:7'))
2144
tensor(indices=tensor([[2144],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   29,    29,    29,  ..., 22515, 22515, 22515],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.0630e-04, -2.7394e-06,  1.6713e-05,  ...,
                       7.7025e-05,  2.9661e-04,  1.4907e-05]),
       size=(22540, 50), nnz=3084, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   29,    29,    29,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.0763e-04, -2.3177e-04, -6.0837e-04,  ...,
                      -7.0824e-07,  2.2430e-08, -7.6329e-07]),
       size=(22540, 50), nnz=22050, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
6
(22, tensor(17777, device='cuda:7'))
17777
tensor(indices=tensor([[17777],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  977,   977,   977,  ..., 21095, 21095, 21095],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 6.2035e-05,  4.1635e-04, -1.2475e-04,  ...,
                       1.1419e-04,  2.2267e-04, -1.8170e-05]),
       size=(22540, 50), nnz=1675, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1769e-06, -4.1375e-06, -3.9871e-06,  ...,
                      -7.0898e-07,  2.2453e-08, -7.6409e-07]),
       size=(22540, 50), nnz=20250, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(23, tensor(13745, device='cuda:7'))
13745
tensor(indices=tensor([[13745],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  839,   839,   839,  ..., 22233, 22233, 22233],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.9452e-04,  3.6154e-04,  2.5730e-04,  ...,
                       5.8368e-05,  1.3277e-04, -1.2472e-05]),
       size=(22540, 50), nnz=1679, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1383e-06, -4.0016e-06, -3.8562e-06,  ...,
                      -6.8570e-07,  2.1716e-08, -7.3900e-07]),
       size=(22540, 50), nnz=20250, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(24, tensor(5234, device='cuda:7'))
5234
tensor(indices=tensor([[5234],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  397,   397,   397,  ..., 22290, 22290, 22290],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 6.2467e-05,  2.3504e-04, -1.1238e-04,  ...,
                       1.5115e-04,  5.3622e-04,  1.7752e-05]),
       size=(22540, 50), nnz=2110, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.0919e-06, -3.8385e-06, -3.6990e-06,  ...,
                      -6.5776e-07,  2.0831e-08, -7.0888e-07]),
       size=(22540, 50), nnz=20950, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(25, tensor(20943, device='cuda:7'))
20943
tensor(indices=tensor([[20943],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   10,    10,    10,  ..., 22483, 22483, 22483],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.8914e-05, -5.1244e-07,  3.0914e-06,  ...,
                       1.3650e-05,  5.7559e-05,  2.3214e-06]),
       size=(22540, 50), nnz=16471, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   10,    10,    10,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.9585e-06,  1.2531e-05, -6.9560e-06,  ...,
                      -7.2006e-07,  2.2804e-08, -7.7602e-07]),
       size=(22540, 50), nnz=35150, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(26, tensor(3410, device='cuda:7'))
3410
tensor(indices=tensor([[3410],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  160,   160,   160,  ..., 22330, 22330, 22330],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.8625e-04, -4.0802e-06,  3.4273e-05,  ...,
                       1.7272e-04,  4.0205e-04, -1.3325e-05]),
       size=(22540, 50), nnz=1916, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.0745e-06, -3.7773e-06, -3.6400e-06,  ...,
                      -6.4726e-07,  2.0498e-08, -6.9756e-07]),
       size=(22540, 50), nnz=20500, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(27, tensor(5643, device='cuda:7'))
5643
tensor(indices=tensor([[5643],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  577,   577,   577,  ..., 22279, 22279, 22279],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 3.7618e-05,  7.5969e-05,  2.2221e-05,  ...,
                       3.5346e-05,  1.1464e-04, -1.3073e-05]),
       size=(22540, 50), nnz=5510, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1277e-06, -3.9644e-06, -3.8204e-06,  ...,
                      -6.7933e-07,  2.1514e-08, -7.3213e-07]),
       size=(22540, 50), nnz=24600, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
7
8
(28, tensor(211, device='cuda:7'))
211
tensor(indices=tensor([[211],
                       [  0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  211,   211,   211,  ..., 22270, 22270, 22270],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 0.0028,  0.0036, -0.0005,  ..., -0.0008,  0.0003,
                       0.0008]),
       size=(22540, 50), nnz=1365, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.0895e-06, -3.8302e-06, -3.6910e-06,  ...,
                      -6.5633e-07,  2.0785e-08, -7.0734e-07]),
       size=(22540, 50), nnz=19700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(29, tensor(3969, device='cuda:7'))
3969
tensor(indices=tensor([[3969],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1274,  1274,  1274,  ..., 21527, 21527, 21527],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.2350e-04, -2.4024e-06,  1.9841e-05,  ...,
                       1.0017e-04,  3.8287e-04,  1.1526e-05]),
       size=(22540, 50), nnz=2865, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.0880e-06, -3.8248e-06, -3.6858e-06,  ...,
                      -6.5541e-07,  2.0756e-08, -7.0635e-07]),
       size=(22540, 50), nnz=21500, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(30, tensor(11213, device='cuda:7'))
11213
tensor(indices=tensor([[11213],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[    1,     1,     1,  ..., 22191, 22191, 22191],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.5114e-05,  1.1351e-04, -3.5914e-05,  ...,
                       3.2977e-05,  9.0442e-05, -1.6803e-05]),
       size=(22540, 50), nnz=4685, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[    1,     1,     1,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.7931e-05, -2.0679e-04,  2.0372e-05,  ...,
                      -6.6000e-07,  2.0902e-08, -7.1130e-07]),
       size=(22540, 50), nnz=23550, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([ 0.0000, -0.0012,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
       grad_fn=<SumBackward1>)
(31, tensor(10620, device='cuda:7'))
10620
tensor(indices=tensor([[10620],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   20,    20,    20,  ..., 22527, 22527, 22527],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.9762e-05,  1.8010e-04, -3.8450e-05,  ...,
                       1.0262e-04,  3.7222e-04,  1.4339e-05]),
       size=(22540, 50), nnz=3043, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   20,    20,    20,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 3.1881e-04,  8.1907e-04,  2.0054e-04,  ...,
                      -7.0373e-07,  2.2287e-08, -7.5843e-07]),
       size=(22540, 50), nnz=22000, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(32, tensor(11150, device='cuda:7'))
11150
tensor(indices=tensor([[11150],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  410,   410,   410,  ..., 22484, 22484, 22484],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 5.1012e-05,  2.2650e-04, -1.7141e-04,  ...,
                      -2.5086e-04,  1.0253e-04,  8.5472e-05]),
       size=(22540, 50), nnz=2173, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1243e-06, -3.9526e-06, -3.8089e-06,  ...,
                      -6.7730e-07,  2.1450e-08, -7.2994e-07]),
       size=(22540, 50), nnz=20950, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
8
9
(33, tensor(10248, device='cuda:7'))
10248
tensor(indices=tensor([[10248],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1484,  1484,  1484,  ..., 22397, 22397, 22397],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.0357e-04, -5.5811e-06,  1.8142e-05,  ...,
                       6.8563e-05,  3.2021e-04, -3.6053e-05]),
       size=(22540, 50), nnz=1174, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.2575e-06, -4.4206e-06, -4.2599e-06,  ...,
                      -7.5750e-07,  2.3989e-08, -8.1637e-07]),
       size=(22540, 50), nnz=19650, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(34, tensor(19890, device='cuda:7'))
19890
tensor(indices=tensor([[19890],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   23,    23,    23,  ..., 22079, 22079, 22079],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.4258e-04, -4.7376e-06,  2.3037e-05,  ...,
                       1.8378e-04,  8.1106e-04,  3.0895e-05]),
       size=(22540, 50), nnz=1524, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   23,    23,    23,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-4.1908e-04,  9.0284e-04,  5.7212e-04,  ...,
                      -6.8120e-07,  2.1573e-08, -7.3415e-07]),
       size=(22540, 50), nnz=20000, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(35, tensor(18276, device='cuda:7'))
18276
tensor(indices=tensor([[18276],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1296,  1296,  1296,  ..., 22095, 22095, 22095],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.0892e-04,  3.3611e-04, -3.4201e-04,  ...,
                       7.2301e-05,  2.6001e-04, -1.7447e-05]),
       size=(22540, 50), nnz=1579, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1841e-06, -4.1626e-06, -4.0113e-06,  ...,
                      -7.1329e-07,  2.2589e-08, -7.6872e-07]),
       size=(22540, 50), nnz=20200, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(36, tensor(1166, device='cuda:7'))
1166
tensor(indices=tensor([[1166],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  593,   593,   593,  ..., 20686, 20686, 20686],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.1501e-05,  2.7734e-04, -8.5952e-05,  ...,
                       7.6474e-06,  8.6604e-05, -6.6051e-06]),
       size=(22540, 50), nnz=2312, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1531e-06, -4.0538e-06, -3.9065e-06,  ...,
                      -6.9464e-07,  2.1999e-08, -7.4863e-07]),
       size=(22540, 50), nnz=21000, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(37, tensor(10336, device='cuda:7'))
10336
tensor(indices=tensor([[10336],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  201,   201,   201,  ..., 22311, 22311, 22311],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 3.1642e-05,  1.8603e-04, -4.5332e-05,  ...,
                       2.3197e-05,  8.5426e-05, -1.5817e-05]),
       size=(22540, 50), nnz=3374, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.0964e-06, -3.8543e-06, -3.7142e-06,  ...,
                      -6.6045e-07,  2.0916e-08, -7.1178e-07]),
       size=(22540, 50), nnz=22050, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(38, tensor(4256, device='cuda:7'))
4256
tensor(indices=tensor([[4256],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  486,   486,   486,  ..., 20095, 20095, 20095],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.9281e-04, -3.7393e-06,  7.9408e-06,  ...,
                       1.5687e-04,  3.0632e-04, -2.5262e-05]),
       size=(22540, 50), nnz=2168, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1004e-06, -3.8684e-06, -3.7278e-06,  ...,
                      -6.6288e-07,  2.0993e-08, -7.1440e-07]),
       size=(22540, 50), nnz=21100, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(39, tensor(963, device='cuda:7'))
963
tensor(indices=tensor([[963],
                       [  0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  347,   347,   347,  ..., 21723, 21723, 21723],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 8.6789e-05,  2.3827e-04, -2.0357e-04,  ...,
                      -5.3345e-04,  1.2106e-04,  5.8634e-05]),
       size=(22540, 50), nnz=1422, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.2011e-06, -4.2223e-06, -4.0689e-06,  ...,
                      -7.2352e-07,  2.2913e-08, -7.7976e-07]),
       size=(22540, 50), nnz=19850, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(40, tensor(4369, device='cuda:7'))
4369
tensor(indices=tensor([[4369],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  517,   517,   517,  ..., 22472, 22472, 22472],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 9.8201e-05, -2.1997e-06,  1.2988e-05,  ...,
                       6.3181e-05,  1.5405e-04, -2.3825e-05]),
       size=(22540, 50), nnz=3479, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1290e-06, -3.9691e-06, -3.8249e-06,  ...,
                      -6.8013e-07,  2.1539e-08, -7.3299e-07]),
       size=(22540, 50), nnz=22650, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(41, tensor(6785, device='cuda:7'))
6785
tensor(indices=tensor([[6785],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1074,  1074,  1074,  ..., 22522, 22522, 22522],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.3415e-05,  1.2838e-04, -3.6026e-05,  ...,
                       6.2325e-05,  1.2490e-04, -1.0371e-05]),
       size=(22540, 50), nnz=4084, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1213e-06, -3.9421e-06, -3.7988e-06,  ...,
                      -6.7550e-07,  2.1393e-08, -7.2800e-07]),
       size=(22540, 50), nnz=23050, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(42, tensor(2579, device='cuda:7'))
2579
tensor(indices=tensor([[2579],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  278,   278,   278,  ..., 21657, 21657, 21657],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.0778e-04, -2.8814e-06,  1.0139e-05,  ...,
                       6.6717e-05,  1.9318e-04, -1.0695e-05]),
       size=(22540, 50), nnz=2997, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1832e-06, -4.1594e-06, -4.0082e-06,  ...,
                      -7.1273e-07,  2.2572e-08, -7.6813e-07]),
       size=(22540, 50), nnz=21700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(43, tensor(17531, device='cuda:7'))
17531
tensor(indices=tensor([[17531],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   91,    91,    91,  ..., 22300, 22300, 22300],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.8555e-05,  1.0462e-04, -1.0907e-05,  ...,
                       6.7536e-05,  1.2834e-04, -9.9561e-06]),
       size=(22540, 50), nnz=4978, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.0746e-06, -3.7778e-06, -3.6405e-06,  ...,
                      -6.4735e-07,  2.0501e-08, -6.9766e-07]),
       size=(22540, 50), nnz=24200, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(44, tensor(541, device='cuda:7'))
541
tensor(indices=tensor([[541],
                       [  0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  541,   541,   541,  ..., 21195, 21195, 21195],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 0.0029,  0.0039, -0.0005,  ..., -0.0004,  0.0001,
                       0.0003]),
       size=(22540, 50), nnz=1525, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.2050e-06, -4.2360e-06, -4.0821e-06,  ...,
                      -7.2587e-07,  2.2988e-08, -7.8229e-07]),
       size=(22540, 50), nnz=20000, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(45, tensor(13333, device='cuda:7'))
13333
tensor(indices=tensor([[13333],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  222,   222,   222,  ..., 22334, 22334, 22334],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 8.4990e-05, -1.9921e-06,  2.2055e-05,  ...,
                       8.7382e-05,  1.8877e-04, -6.6213e-06]),
       size=(22540, 50), nnz=3717, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1129e-06, -3.9123e-06, -3.7701e-06,  ...,
                      -6.7040e-07,  2.1231e-08, -7.2250e-07]),
       size=(22540, 50), nnz=22550, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(46, tensor(19769, device='cuda:7'))
19769
tensor(indices=tensor([[19769],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  848,   848,   848,   848,   848,   848,   848,   848,
                          848,   848,   848,   848,   848,   848,   848,   848,
                          848,   848,   848,   848,   848,   848,   848,   848,
                          848,   848,   848,   848,   848,   848,   848,   848,
                          848,   848,   848,   848,   848,   848,   848,   848,
                          848,   848,   848,   848,   848,   848,   848,   848,
                          848,   848,  3369,  3369,  3369,  3369,  3369,  3369,
                         3369,  3369,  3369,  3369,  3369,  3369,  3369,  3369,
                         3369,  3369,  3369,  3369,  3369,  3369,  3369,  3369,
                         3369,  3369,  3369,  3369,  3369,  3369,  3369,  3369,
                         3369,  3369,  3369,  3369,  3369,  3369,  3369,  3369,
                         3369,  3369,  3369,  3369,  3369,  3369,  3369,  3369,
                         3369,  3369,  3369,  3369,  4374,  4374,  4374,  4374,
                         4374,  4374,  4374,  4374,  4374,  4374,  4374,  4374,
                         4374,  4374,  4374,  4374,  4374,  4374,  4374,  4374,
                         4374,  4374,  4374,  4374,  4374,  4374,  4374,  4374,
                         4374,  4374,  4374,  4374,  4374,  4374,  4374,  4374,
                         4374,  4374,  4374,  4374,  4374,  4374,  4374,  4374,
                         4374,  4374,  4374,  4374,  4374, 13556, 13556, 13556,
                        13556, 13556, 13556, 13556, 13556, 13556, 13556, 13556,
                        13556, 13556, 13556, 13556, 13556, 13556, 13556, 13556,
                        13556, 13556, 13556, 13556, 13556, 13556, 13556, 13556,
                        13556, 13556, 13556, 13556, 13556, 13556, 13556, 13556,
                        13556, 13556, 13556, 13556, 13556, 13556, 13556, 13556,
                        13556, 13556, 13556, 13556, 13556, 13556, 15665, 15665,
                        15665, 15665, 15665, 15665, 15665, 15665, 15665, 15665,
                        15665, 15665, 15665, 15665, 15665, 15665, 15665, 15665,
                        15665, 15665, 15665, 15665, 15665, 15665, 15665, 15665,
                        15665, 15665, 15665, 15665, 15665, 15665, 15665, 15665,
                        15665, 15665, 15665, 15665, 15665, 15665, 15665, 15665,
                        15665, 15665, 15665, 15665, 15665, 15665, 17492, 17492,
                        17492, 17492, 17492, 17492, 17492, 17492, 17492, 17492,
                        17492, 17492, 17492, 17492, 17492, 17492, 17492, 17492,
                        17492, 17492, 17492, 17492, 17492, 17492, 17492, 17492,
                        17492, 17492, 17492, 17492, 17492, 17492, 17492, 17492,
                        17492, 17492, 17492, 17492, 17492, 17492, 17492, 17492,
                        17492, 17492, 17492, 17492, 17492, 17492, 17492, 17492,
                        19769, 19769, 19769, 19769, 19769, 19769, 19769, 19769,
                        19769, 19769, 19769, 19769, 19769, 19769, 19769, 19769,
                        19769, 19769, 19769, 19769, 19769, 19769, 19769, 19769,
                        19769, 19769, 19769, 19769, 19769, 19769, 19769, 19769,
                        19769, 19769, 19769, 19769, 19769, 19769, 19769, 19769,
                        19769, 19769, 19769, 19769, 19769, 19769, 19769, 19769,
                        19769, 20523, 20523, 20523, 20523, 20523, 20523, 20523,
                        20523, 20523, 20523, 20523, 20523, 20523, 20523, 20523,
                        20523, 20523, 20523, 20523, 20523, 20523, 20523, 20523,
                        20523, 20523, 20523, 20523, 20523, 20523, 20523, 20523,
                        20523, 20523, 20523, 20523, 20523, 20523, 20523, 20523,
                        20523, 20523, 20523, 20523, 20523, 20523, 20523, 20523,
                        21110, 21110, 21110, 21110, 21110, 21110, 21110, 21110,
                        21110, 21110, 21110, 21110, 21110, 21110, 21110, 21110,
                        21110, 21110, 21110, 21110, 21110, 21110, 21110, 21110,
                        21110, 21110, 21110, 21110, 21110, 21110, 21110, 21110,
                        21110, 21110, 21110, 21110, 21110, 21110, 21110, 21110,
                        21110, 21110, 21110, 21110, 21110, 21110, 21110, 21110,
                        21110],
                       [    0,     1,     2,     3,     4,     5,     6,     7,
                            8,     9,    10,    11,    12,    13,    14,    15,
                           16,    17,    18,    19,    20,    21,    22,    23,
                           24,    25,    26,    27,    28,    29,    30,    31,
                           32,    33,    34,    35,    36,    37,    38,    39,
                           40,    41,    42,    43,    44,    45,    46,    47,
                           48,    49,     0,     1,     2,     3,     4,     5,
                            6,     7,     8,     9,    10,    11,    12,    13,
                           14,    15,    16,    17,    18,    19,    20,    21,
                           22,    23,    24,    25,    26,    27,    28,    29,
                           30,    31,    32,    33,    34,    35,    36,    37,
                           38,    39,    40,    41,    42,    43,    44,    45,
                           46,    47,    48,    49,     0,     1,     2,     3,
                            4,     5,     6,     7,     8,     9,    10,    11,
                           12,    13,    14,    15,    16,    17,    18,    19,
                           20,    21,    22,    23,    24,    25,    27,    28,
                           29,    30,    31,    32,    33,    34,    35,    36,
                           37,    38,    39,    40,    41,    42,    43,    44,
                           45,    46,    47,    48,    49,     0,     1,     2,
                            3,     4,     5,     6,     7,     8,     9,    10,
                           11,    12,    13,    14,    15,    16,    17,    18,
                           19,    20,    21,    22,    23,    24,    25,    26,
                           27,    28,    29,    31,    32,    33,    34,    35,
                           36,    37,    38,    39,    40,    41,    42,    43,
                           44,    45,    46,    47,    48,    49,     0,     1,
                            3,     4,     5,     6,     7,     8,     9,    10,
                           11,    12,    13,    14,    15,    16,    17,    18,
                           19,    20,    21,    22,    23,    24,    25,    26,
                           27,    29,    30,    31,    32,    33,    34,    35,
                           36,    37,    38,    39,    40,    41,    42,    43,
                           44,    45,    46,    47,    48,    49,     0,     1,
                            2,     3,     4,     5,     6,     7,     8,     9,
                           10,    11,    12,    13,    14,    15,    16,    17,
                           18,    19,    20,    21,    22,    23,    24,    25,
                           26,    27,    28,    29,    30,    31,    32,    33,
                           34,    35,    36,    37,    38,    39,    40,    41,
                           42,    43,    44,    45,    46,    47,    48,    49,
                            0,     1,     2,     3,     4,     5,     6,     7,
                            8,     9,    10,    11,    12,    13,    14,    15,
                           16,    17,    18,    19,    20,    21,    22,    23,
                           24,    25,    26,    27,    28,    29,    30,    31,
                           32,    33,    34,    35,    36,    37,    38,    39,
                           40,    41,    42,    43,    44,    45,    46,    47,
                           48,     0,     1,     2,     3,     4,     5,     7,
                            8,     9,    10,    11,    12,    13,    14,    15,
                           16,    17,    18,    19,    20,    21,    22,    23,
                           24,    25,    26,    27,    28,    29,    30,    31,
                           32,    33,    34,    35,    36,    37,    38,    39,
                           40,    41,    42,    43,    44,    45,    47,    48,
                            0,     1,     2,     3,     4,     5,     6,     7,
                            8,     9,    10,    11,    12,    13,    14,    15,
                           16,    17,    18,    19,    20,    21,    22,    23,
                           24,    25,    26,    27,    28,    29,    30,    31,
                           32,    33,    34,    35,    36,    37,    38,    39,
                           40,    41,    42,    43,    44,    45,    46,    47,
                           48]]),
       values=tensor([ 2.1636e-04,  1.2099e-03, -6.1566e-04,  6.7024e-05,
                       1.5543e-03,  6.3668e-03,  3.0657e-04,  2.4692e-03,
                       6.1306e-04,  8.8545e-04,  6.9295e-04,  6.2783e-03,
                       4.8801e-04,  4.6488e-04,  5.0295e-05,  1.9040e-04,
                       1.7306e-03,  6.0129e-04,  1.3965e-03,  5.8035e-03,
                       2.6285e-03,  2.9015e-03,  5.6134e-03,  2.0657e-03,
                       7.1383e-04,  9.3670e-04, -4.6371e-06,  1.2746e-03,
                       9.2679e-06,  2.5379e-03, -8.6170e-05, -1.0098e-05,
                       4.5180e-03,  6.9546e-04, -3.6070e-05,  5.4353e-05,
                      -2.0429e-05,  4.8070e-04,  3.0247e-04,  4.7484e-04,
                       3.4935e-04,  8.2167e-03, -4.1622e-04,  2.8665e-04,
                       1.2384e-04,  3.1327e-05,  1.4131e-05,  3.3560e-04,
                       8.3979e-04, -1.1260e-04,  1.9330e-04,  9.0176e-04,
                      -3.8253e-04,  2.6940e-05,  1.3998e-03,  5.1493e-03,
                       7.7046e-05,  2.1653e-03,  4.0612e-04,  6.1200e-04,
                       5.1645e-04,  5.6807e-03,  3.9794e-04,  6.0393e-04,
                       4.6206e-05,  1.2715e-04,  1.5057e-03,  6.5513e-04,
                       1.1455e-03,  4.1616e-03,  2.0925e-03,  2.4699e-03,
                       4.6998e-03,  1.8098e-03,  5.5691e-04,  5.6475e-04,
                      -7.4506e-06,  8.8953e-04,  6.1461e-07,  1.9473e-03,
                      -6.0627e-05, -7.9743e-06,  3.1530e-03,  3.0784e-04,
                      -4.8512e-05,  6.5489e-05, -1.2302e-05,  2.6089e-04,
                       6.1010e-04,  2.4725e-04,  2.2186e-04,  6.6199e-03,
                      -3.8635e-04,  2.1374e-04,  1.5511e-04,  1.7090e-05,
                       1.5446e-05,  2.4144e-04,  8.5987e-04, -1.3255e-04,
                       7.9212e-04, -1.6524e-05,  2.7829e-04,  2.4552e-04,
                       1.2448e-03,  6.9873e-04,  4.2521e-04,  3.0491e-03,
                       7.4498e-04,  8.2827e-04,  1.5479e-03,  4.4580e-03,
                       5.3408e-03,  1.8202e-03,  3.1797e-04,  1.6023e-04,
                       7.9671e-04,  1.0012e-03,  1.4519e-03,  5.1315e-03,
                       1.9303e-03,  5.7392e-03,  4.0580e-03,  3.0987e-03,
                       3.6561e-04,  8.3287e-04,  1.0582e-03, -7.5523e-06,
                       3.0256e-03,  1.4831e-05, -1.0824e-04,  3.1415e-03,
                       6.1633e-04, -1.8596e-06,  3.6143e-04,  9.0639e-05,
                       6.9171e-04, -3.2268e-04, -1.1569e-04, -2.7902e-04,
                       6.6836e-03,  2.7701e-03,  1.7895e-04,  6.5820e-04,
                       7.6179e-04,  2.6018e-05,  5.3682e-04,  1.2122e-03,
                       1.3845e-04,  8.5235e-04, -1.9511e-05,  8.2786e-05,
                       2.5890e-04,  1.6048e-03,  7.8648e-04,  3.5954e-04,
                       3.4057e-03,  5.5231e-04,  1.0879e-03,  2.5893e-03,
                       5.3286e-03,  5.6500e-03,  2.5375e-03,  2.1817e-04,
                       1.7392e-04,  1.0320e-03,  8.9398e-04,  1.3406e-03,
                       7.0905e-03,  2.6478e-03,  6.7755e-03,  4.9623e-03,
                       3.3066e-03,  2.8293e-04,  6.1271e-04,  1.1670e-04,
                       9.6255e-04, -1.9801e-06,  3.3267e-03, -1.7447e-04,
                       3.3241e-03,  6.5358e-04, -8.4979e-06,  7.0608e-04,
                       1.1025e-04,  6.9434e-04, -8.2431e-04, -8.2959e-05,
                      -2.5464e-04,  7.8845e-03,  2.5550e-03,  5.9343e-05,
                       5.7270e-04,  7.3873e-04,  2.2373e-05,  9.1848e-04,
                       2.7918e-03,  1.7455e-04, -1.4614e-04,  9.0871e-03,
                      -1.2652e-04,  2.1125e-03,  1.7308e-02, -7.2920e-05,
                       1.0751e-02,  2.6534e-03,  3.2368e-03,  1.3443e-03,
                       3.2198e-02,  1.6219e-02, -1.7620e-04, -1.0267e-03,
                       1.3112e-03,  1.0084e-02,  8.1294e-04,  3.6222e-03,
                       1.4188e-02,  2.8763e-02,  9.3267e-03,  2.0338e-02,
                       3.3471e-02,  3.5919e-03,  9.0800e-05,  8.0262e-03,
                       3.9258e-03,  2.3959e-02,  3.5736e-04,  4.8314e-04,
                       2.2022e-02,  3.9550e-03, -5.0224e-04,  1.2522e-03,
                      -1.6381e-04,  1.9710e-03,  1.3686e-03, -6.6410e-04,
                       2.6272e-03,  4.2682e-02, -7.3599e-04, -8.7021e-05,
                       2.7676e-04,  8.4952e-03,  1.4735e-03,  5.4081e-03,
                       9.2976e-03,  6.1993e-03,  9.1940e-04, -2.1032e-05,
                       1.4093e-04,  4.0910e-04,  1.7332e-03,  7.8653e-04,
                       5.0937e-04,  3.1440e-03,  8.3033e-04,  1.1574e-03,
                       2.2495e-03,  5.5824e-03,  6.0201e-03,  1.8176e-03,
                       3.6524e-04,  1.4131e-04,  8.8475e-04,  1.1583e-03,
                       1.5298e-03,  6.9721e-03,  2.2737e-03,  6.3325e-03,
                       4.8972e-03,  3.4747e-03,  4.5618e-04,  9.0497e-04,
                       8.7784e-05,  1.1039e-03, -4.1999e-06,  3.4916e-03,
                       7.3229e-05, -1.5775e-04,  4.0483e-03,  6.6138e-04,
                      -1.0446e-05,  5.8565e-04,  9.2602e-05,  6.4507e-04,
                      -4.4769e-04, -1.3668e-04, -2.1701e-04,  7.8712e-03,
                       3.1180e-03,  1.9468e-04,  5.4224e-04,  7.4499e-04,
                       1.7070e-05,  8.7642e-04,  2.2088e-03,  1.5257e-04,
                       2.9297e-03,  4.2762e-03, -5.4550e-04,  1.4135e-03,
                       6.3965e-03,  1.5111e-02,  1.3193e-05, -4.8288e-04,
                       8.2932e-03,  3.4914e-03,  6.9878e-03,  3.2803e-02,
                       4.1257e-03, -5.7777e-05,  1.5122e-03, -1.1802e-04,
                       2.2812e-03, -2.1968e-03,  4.6192e-03,  4.2478e-03,
                       5.9419e-03,  2.8983e-03,  1.1335e-02,  7.9812e-03,
                       1.6456e-03,  5.3400e-03,  4.4354e-04, -4.6976e-05,
                       2.2441e-03, -2.5071e-03,  4.1960e-04, -6.8989e-05,
                       1.7377e-02,  8.4607e-04, -1.2116e-04, -2.1831e-04,
                       2.9036e-03,  4.0607e-03,  1.0550e-03,  2.5880e-03,
                       1.9631e-03,  2.4342e-02,  1.9906e-03,  3.0575e-03,
                       6.6959e-04, -1.3952e-03,  5.1742e-05,  1.9677e-03,
                      -2.9695e-04,  2.2391e-04,  8.0766e-04, -4.7074e-04,
                       3.4719e-05,  1.2980e-03,  5.0588e-03,  1.9124e-03,
                       6.2087e-04,  6.8026e-04,  7.0577e-04,  5.3042e-03,
                       4.0699e-04,  5.4377e-04,  5.7214e-05,  1.9210e-04,
                       1.1446e-03,  5.1843e-04,  1.2189e-03,  3.9539e-03,
                       1.8806e-03,  2.2759e-03,  4.2511e-03,  1.4386e-03,
                       5.0693e-04,  5.5111e-04, -5.0969e-06,  8.4235e-04,
                       6.2768e-06,  1.6811e-03, -2.4132e-05, -7.2740e-06,
                       3.1683e-03,  4.9594e-04, -3.6653e-06,  4.4148e-05,
                      -1.3644e-05,  3.9092e-04,  1.2906e-04,  3.4443e-04,
                       3.0456e-04,  7.0267e-03, -3.0932e-04,  1.7636e-04,
                       1.0760e-04,  1.4023e-05,  1.5750e-04,  5.6153e-04,
                       2.4602e-04,  8.6107e-04, -6.4585e-04,  3.1037e-05,
                       1.2504e-03,  5.3757e-03,  2.7968e-05,  2.1103e-03,
                       6.8584e-04,  6.4741e-04,  7.0592e-04,  5.6484e-03,
                       4.4706e-04,  6.0994e-04,  4.1881e-05,  2.4745e-04,
                       1.3747e-03,  5.8045e-04,  1.3672e-03,  4.2563e-03,
                       1.9829e-03,  2.4403e-03,  4.2043e-03,  1.4674e-03,
                       5.5110e-04,  6.0263e-04, -6.4500e-06,  7.7400e-04,
                       6.6020e-06,  1.9875e-03, -4.5579e-05, -7.2669e-06,
                       3.2668e-03,  5.3641e-04, -5.8153e-06,  3.6943e-05,
                      -1.3391e-05,  4.8390e-04,  9.8562e-05,  2.5210e-04,
                       3.0035e-04,  7.5234e-03, -3.8529e-04,  1.9114e-04,
                       1.2345e-04,  1.7851e-05,  3.9254e-06,  1.3039e-04,
                       6.4761e-04]),
       size=(22540, 50), nnz=441, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.3124e-06, -4.6138e-06, -4.4461e-06,  ...,
                      -7.9060e-07,  2.5038e-08, -8.5205e-07]),
       size=(22540, 50), nnz=18750, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(47, tensor(16980, device='cuda:7'))
16980
tensor(indices=tensor([[16980],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   73,    73,    73,  ..., 22209, 22209, 22209],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.6571e-05,  1.0655e-04,  2.9449e-05,  ...,
                       2.6935e-05,  6.4893e-05, -8.7173e-06]),
       size=(22540, 50), nnz=3351, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1380e-06, -4.0006e-06, -3.8553e-06,  ...,
                      -6.8553e-07,  2.1710e-08, -7.3881e-07]),
       size=(22540, 50), nnz=22550, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(48, tensor(14021, device='cuda:7'))
14021
tensor(indices=tensor([[14021],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  370,   370,   370,  ..., 22418, 22418, 22418],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 3.4696e-05, -6.2685e-07,  3.2886e-06,  ...,
                       1.9213e-05,  7.9538e-05,  1.8253e-06]),
       size=(22540, 50), nnz=10886, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1579e-06, -4.0706e-06, -3.9227e-06,  ...,
                      -6.9753e-07,  2.2090e-08, -7.5174e-07]),
       size=(22540, 50), nnz=30250, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(49, tensor(9082, device='cuda:7'))
9082
tensor(indices=tensor([[9082],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   94,    94,    94,  ..., 22128, 22128, 22128],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 3.8080e-05,  1.4357e-04, -9.1053e-05,  ...,
                       6.5632e-05,  1.3300e-04, -2.1878e-05]),
       size=(22540, 50), nnz=3490, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1287e-06, -3.9679e-06, -3.8237e-06,  ...,
                      -6.7993e-07,  2.1533e-08, -7.3277e-07]),
       size=(22540, 50), nnz=22700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(50, tensor(15956, device='cuda:7'))
15956
tensor(indices=tensor([[15956],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  121,   121,   121,  ..., 21697, 21697, 21697],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 8.4215e-05, -2.4864e-06,  1.0544e-05,  ...,
                       7.0563e-05,  2.2929e-04,  1.2642e-05]),
       size=(22540, 50), nnz=2702, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1022e-06, -3.8749e-06, -3.7341e-06,  ...,
                      -6.6399e-07,  2.1028e-08, -7.1560e-07]),
       size=(22540, 50), nnz=21350, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(51, tensor(19216, device='cuda:7'))
19216
tensor(indices=tensor([[19216],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  242,   242,   242,  ..., 22516, 22516, 22516],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.2341e-05, -6.3494e-07,  6.9505e-06,  ...,
                       2.2589e-05,  6.5373e-05,  5.7405e-06]),
       size=(22540, 50), nnz=10015, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1193e-06, -3.9349e-06, -3.7920e-06,  ...,
                      -6.7428e-07,  2.1354e-08, -7.2668e-07]),
       size=(22540, 50), nnz=29350, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(52, tensor(18218, device='cuda:7'))
18218
tensor(indices=tensor([[18218],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   38,    38,    38,  ..., 22531, 22531, 22531],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.4145e-05,  7.3365e-05, -1.4731e-05,  ...,
                       1.1701e-05,  2.5840e-05, -1.8968e-06]),
       size=(22540, 50), nnz=7744, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   38,    38,    38,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.3204e-04,  4.2025e-05, -1.5801e-04,  ...,
                      -7.1243e-07,  2.2562e-08, -7.6780e-07]),
       size=(22540, 50), nnz=26800, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(53, tensor(101, device='cuda:7'))
101
tensor(indices=tensor([[101],
                       [  0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  101,   101,   101,  ..., 22479, 22479, 22479],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.3199e-03,  3.5187e-03, -4.3333e-04,  ...,
                       3.5047e-05,  7.2116e-05, -2.3310e-05]),
       size=(22540, 50), nnz=2510, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1188e-06, -3.9330e-06, -3.7901e-06,  ...,
                      -6.7394e-07,  2.1343e-08, -7.2632e-07]),
       size=(22540, 50), nnz=21350, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(54, tensor(5170, device='cuda:7'))
5170
tensor(indices=tensor([[5170],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1324,  1324,  1324,  ..., 22331, 22331, 22331],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 5.4001e-05,  3.5577e-04, -1.3015e-04,  ...,
                       1.9129e-04,  4.2329e-04, -2.6790e-05]),
       size=(22540, 50), nnz=1776, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.0912e-06, -3.8361e-06, -3.6967e-06,  ...,
                      -6.5734e-07,  2.0818e-08, -7.0843e-07]),
       size=(22540, 50), nnz=20450, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(55, tensor(6744, device='cuda:7'))
6744
tensor(indices=tensor([[6744],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  539,   539,   539,  ..., 22480, 22480, 22480],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.4790e-04, -4.1055e-06,  3.3868e-05,  ...,
                      -3.8833e-04,  9.3063e-05,  3.9698e-04]),
       size=(22540, 50), nnz=2073, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.0625e-06, -3.7351e-06, -3.5994e-06,  ...,
                      -6.4004e-07,  2.0270e-08, -6.8978e-07]),
       size=(22540, 50), nnz=20750, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
10
(56, tensor(10582, device='cuda:7'))
10582
tensor(indices=tensor([[10582],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  337,   337,   337,  ..., 22391, 22391, 22391],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.4439e-05,  1.1984e-04, -3.3395e-05,  ...,
                       2.4812e-05,  6.2401e-05, -9.4549e-06]),
       size=(22540, 50), nnz=5097, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.0850e-06, -3.8142e-06, -3.6756e-06,  ...,
                      -6.5359e-07,  2.0699e-08, -7.0438e-07]),
       size=(22540, 50), nnz=24200, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(57, tensor(7417, device='cuda:7'))
7417
tensor(indices=tensor([[7417],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  349,   349,   349,  ..., 21585, 21585, 21585],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.4667e-05,  2.5539e-04, -1.0498e-04,  ...,
                       1.4207e-04,  5.1732e-04,  1.9494e-05]),
       size=(22540, 50), nnz=2416, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1219e-06, -3.9439e-06, -3.8006e-06,  ...,
                      -6.7582e-07,  2.1403e-08, -7.2834e-07]),
       size=(22540, 50), nnz=21300, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(58, tensor(15108, device='cuda:7'))
15108
tensor(indices=tensor([[15108],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  905,   905,   905,  ..., 21522, 21522, 21522],
                       [    0,     1,     2,  ...,    46,    47,    48]]),
       values=tensor([ 1.1869e-04, -4.1496e-06,  2.1631e-05,  ...,
                       1.0702e-04, -1.1853e-04,  9.6441e-05]),
       size=(22540, 50), nnz=2258, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1448e-06, -4.0246e-06, -3.8783e-06,  ...,
                      -6.8964e-07,  2.1840e-08, -7.4324e-07]),
       size=(22540, 50), nnz=20900, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(59, tensor(22241, device='cuda:7'))
22241
tensor(indices=tensor([[22241],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  340,   340,   340,  ..., 22488, 22488, 22488],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.0284e-05,  1.3415e-04, -4.5418e-05,  ...,
                       1.7561e-05,  5.0435e-05, -7.7486e-06]),
       size=(22540, 50), nnz=4563, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1460e-06, -4.0287e-06, -3.8823e-06,  ...,
                      -6.9035e-07,  2.1863e-08, -7.4400e-07]),
       size=(22540, 50), nnz=23350, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(60, tensor(21863, device='cuda:7'))
21863
tensor(indices=tensor([[21863],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   49,    49,    49,  ..., 22495, 22495, 22495],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1452e-04,  4.0450e-04, -2.4070e-04,  ...,
                       2.5071e-04,  5.2099e-04, -8.7615e-05]),
       size=(22540, 50), nnz=1132, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   49,    49,    49,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.0815e-03,  9.2962e-06,  7.7072e-04,  ...,
                      -7.4514e-07,  2.3598e-08, -8.0305e-07]),
       size=(22540, 50), nnz=19550, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(61, tensor(2846, device='cuda:7'))
2846
tensor(indices=tensor([[2846],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  645,   645,   645,  ..., 22102, 22102, 22102],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 7.8239e-05,  2.1054e-04, -1.3213e-04,  ...,
                       1.1955e-04,  3.3318e-04,  1.6984e-05]),
       size=(22540, 50), nnz=1873, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.2135e-06, -4.2660e-06, -4.1110e-06,  ...,
                      -7.3101e-07,  2.3151e-08, -7.8783e-07]),
       size=(22540, 50), nnz=20550, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(62, tensor(6607, device='cuda:7'))
6607
tensor(indices=tensor([[6607],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  285,   285,   285,  ..., 22448, 22448, 22448],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 8.0008e-05, -1.7920e-06,  1.0903e-05,  ...,
                       1.0610e-05,  1.9939e-05, -7.3837e-06]),
       size=(22540, 50), nnz=4336, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1102e-06, -3.9031e-06, -3.7612e-06,  ...,
                      -6.6882e-07,  2.1181e-08, -7.2080e-07]),
       size=(22540, 50), nnz=23350, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
9
11
(63, tensor(22189, device='cuda:7'))
22189
tensor(indices=tensor([[22189],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  840,   840,   840,  ..., 22189, 22189, 22189],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 8.8305e-05, -1.9038e-06,  1.9382e-05,  ...,
                       1.8735e-03, -2.3171e-04, -6.7158e-04]),
       size=(22540, 50), nnz=4317, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   25,    25,    25,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-3.7079e-05,  1.3508e-03, -3.1571e-05,  ...,
                      -7.1888e-07,  2.2766e-08, -7.7475e-07]),
       size=(22540, 50), nnz=23200, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(64, tensor(8783, device='cuda:7'))
8783
tensor(indices=tensor([[8783],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   26,    26,    26,  ..., 22463, 22463, 22463],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 7.8680e-05, -1.8123e-06,  1.7860e-05,  ...,
                       6.8588e-05,  2.3105e-04,  5.9983e-06]),
       size=(22540, 50), nnz=3492, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   26,    26,    26,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-7.9887e-05,  1.5499e-04, -2.9482e-05,  ...,
                      -6.5132e-07,  2.0627e-08, -7.0194e-07]),
       size=(22540, 50), nnz=22350, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(65, tensor(9376, device='cuda:7'))
9376
tensor(indices=tensor([[9376],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  745,   745,   745,  ..., 22492, 22492, 22492],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 8.9784e-05, -1.9173e-06,  1.9334e-05,  ...,
                      -2.1021e-04,  4.8907e-05,  5.3001e-05]),
       size=(22540, 50), nnz=3740, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1486e-06, -4.0381e-06, -3.8913e-06,  ...,
                      -6.9195e-07,  2.1913e-08, -7.4573e-07]),
       size=(22540, 50), nnz=22650, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(66, tensor(12544, device='cuda:7'))
12544
tensor(indices=tensor([[12544],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  799,   799,   799,  ..., 22462, 22462, 22462],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.8298e-05,  2.3789e-04, -2.4312e-05,  ...,
                       3.4356e-05,  8.7642e-05, -2.5484e-05]),
       size=(22540, 50), nnz=2558, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1293e-06, -3.9699e-06, -3.8257e-06,  ...,
                      -6.8028e-07,  2.1544e-08, -7.3315e-07]),
       size=(22540, 50), nnz=21600, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(67, tensor(20261, device='cuda:7'))
20261
tensor(indices=tensor([[20261],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   41,    41,    41,  ..., 21504, 21504, 21504],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 8.7269e-05, -1.9498e-06,  1.1094e-05,  ...,
                       6.6915e-05,  2.1606e-04,  9.7364e-06]),
       size=(22540, 50), nnz=3681, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   41,    41,    41,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 5.5409e-04,  4.5727e-04,  1.4939e-04,  ...,
                      -6.7233e-07,  2.1292e-08, -7.2458e-07]),
       size=(22540, 50), nnz=22700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
10
12
7315
torch.Size([2, 149304])
tensor(indices=tensor([[7315],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   14,    14,    14,  ..., 21920, 21920, 21920],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.5285e-04, -2.1436e-06,  4.0825e-05,  ...,
                       1.6724e-04,  5.6205e-04,  2.1344e-05]),
       size=(22540, 50), nnz=2214, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   14,    14,    14,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.8642e-06, -3.8761e-05, -3.9801e-05,  ...,
                      -6.6794e-07,  2.1153e-08, -7.1985e-07]),
       size=(22540, 50), nnz=21100, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
7417
torch.Size([2, 149304])
tensor(indices=tensor([[7417],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  349,   349,   349,  ..., 21585, 21585, 21585],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.4667e-05,  2.5539e-04, -1.0498e-04,  ...,
                       1.4207e-04,  5.1732e-04,  1.9494e-05]),
       size=(22540, 50), nnz=2416, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1219e-06, -3.9439e-06, -3.8006e-06,  ...,
                      -6.7582e-07,  2.1403e-08, -7.2834e-07]),
       size=(22540, 50), nnz=21300, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
10582
torch.Size([2, 149304])
tensor(indices=tensor([[10582],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  337,   337,   337,  ..., 22391, 22391, 22391],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.4439e-05,  1.1984e-04, -3.3395e-05,  ...,
                       2.4812e-05,  6.2401e-05, -9.4549e-06]),
       size=(22540, 50), nnz=5097, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.0850e-06, -3.8142e-06, -3.6756e-06,  ...,
                      -6.5359e-07,  2.0699e-08, -7.0438e-07]),
       size=(22540, 50), nnz=24200, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
7315
tensor(indices=tensor([[7315],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  135,   135,   135,  ..., 21920, 21920, 21920],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([8.5226e-05, 1.4678e-04, 9.9560e-05,  ...,
                      1.6640e-04, 5.5923e-04, 2.1237e-05]),
       size=(22540, 50), nnz=2211, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1032e-06, -3.8784e-06, -3.7375e-06,  ...,
                      -6.6459e-07,  2.1047e-08, -7.1624e-07]),
       size=(22540, 50), nnz=21000, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
7417
tensor(indices=tensor([[7417],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  349,   349,   349,  ..., 21585, 21585, 21585],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.4667e-05,  2.5539e-04, -1.0498e-04,  ...,
                       1.4207e-04,  5.1732e-04,  1.9494e-05]),
       size=(22540, 50), nnz=2416, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1219e-06, -3.9439e-06, -3.8006e-06,  ...,
                      -6.7582e-07,  2.1403e-08, -7.2834e-07]),
       size=(22540, 50), nnz=21300, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
10582
tensor(indices=tensor([[10582],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  337,   337,   337,  ..., 22391, 22391, 22391],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.4439e-05,  1.1984e-04, -3.3395e-05,  ...,
                       2.4812e-05,  6.2401e-05, -9.4549e-06]),
       size=(22540, 50), nnz=5097, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.0850e-06, -3.8142e-06, -3.6756e-06,  ...,
                      -6.5359e-07,  2.0699e-08, -7.0438e-07]),
       size=(22540, 50), nnz=24200, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
7315
tensor(indices=tensor([[7315],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  135,   135,   135,  ..., 21920, 21920, 21920],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([8.5224e-05, 1.4678e-04, 9.9558e-05,  ...,
                      1.6640e-04, 5.5922e-04, 2.1236e-05]),
       size=(22540, 50), nnz=2212, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1032e-06, -3.8783e-06, -3.7374e-06,  ...,
                      -6.6458e-07,  2.1047e-08, -7.1623e-07]),
       size=(22540, 50), nnz=21000, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
7417
tensor(indices=tensor([[7417],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  349,   349,   349,  ..., 21585, 21585, 21585],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.4667e-05,  2.5539e-04, -1.0498e-04,  ...,
                       1.4208e-04,  5.1733e-04,  1.9494e-05]),
       size=(22540, 50), nnz=2418, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1219e-06, -3.9440e-06, -3.8007e-06,  ...,
                      -6.7583e-07,  2.1403e-08, -7.2835e-07]),
       size=(22540, 50), nnz=21300, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
19216
tensor(indices=tensor([[19216],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  242,   242,   242,  ..., 22516, 22516, 22516],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.2341e-05, -6.3494e-07,  6.9505e-06,  ...,
                       2.2589e-05,  6.5373e-05,  5.7405e-06]),
       size=(22540, 50), nnz=10015, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1193e-06, -3.9349e-06, -3.7920e-06,  ...,
                      -6.7428e-07,  2.1354e-08, -7.2668e-07]),
       size=(22540, 50), nnz=29350, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
7315
torch.Size([2, 149304])
tensor(indices=tensor([[7315],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  135,   135,   135,  ..., 21920, 21920, 21920],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([8.5224e-05, 1.4678e-04, 9.9558e-05,  ...,
                      1.6640e-04, 5.5922e-04, 2.1236e-05]),
       size=(22540, 50), nnz=2212, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1032e-06, -3.8783e-06, -3.7374e-06,  ...,
                      -6.6458e-07,  2.1047e-08, -7.1623e-07]),
       size=(22540, 50), nnz=21000, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
7417
torch.Size([2, 149304])
tensor(indices=tensor([[7417],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   14,    14,    14,  ..., 21585, 21585, 21585],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([5.8349e-05, 7.0748e-05, 8.7489e-05,  ...,
                      1.4240e-04, 5.1850e-04, 1.9539e-05]),
       size=(22540, 50), nnz=2418, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   14,    14,    14,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.7086e-04, -3.5050e-04,  6.5824e-06,  ...,
                      -6.7736e-07,  2.1452e-08, -7.3001e-07]),
       size=(22540, 50), nnz=21300, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
19216
torch.Size([2, 149304])
tensor(indices=tensor([[19216],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  242,   242,   242,  ..., 22516, 22516, 22516],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.2341e-05, -6.3494e-07,  6.9505e-06,  ...,
                       2.2589e-05,  6.5373e-05,  5.7405e-06]),
       size=(22540, 50), nnz=10015, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1193e-06, -3.9349e-06, -3.7920e-06,  ...,
                      -6.7428e-07,  2.1354e-08, -7.2668e-07]),
       size=(22540, 50), nnz=29350, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
count_nodes_self:  10
count_edges_self:  12
Starting evaluation...
[Evaluation] Test Accuracy: 66.18
emb_type:  TransH
Labels loaded.
RDF loaded.
Graph loaded.
cuda:  True
shape edges:  torch.Size([63382, 3])
test_idx:  tensor([12917, 21950,  3144, 20225,  7271, 10768, 11934,  4336, 10172, 13510,
        19233, 19260,  7860,  9637,  7315, 21185,  9704, 15542,  1543,  9956,
        19946,  2144, 17777, 13745,  5234, 20943,  3410,  5643,   211,  3969,
        11213, 10620, 11150, 10248, 19890, 18276,  1166, 10336,  4256,   963,
         4369,  6785,  2579, 17531,   541, 13333, 19769, 16980, 14021,  9082,
        15956, 19216, 18218,   101,  5170,  6744, 10582,  7417, 15108, 22241,
        21863,  2846,  6607, 22189,  8783,  9376, 12544, 20261],
       device='cuda:7')
num_classes:  2
num_nodes:  22540
num_relations:  9
tensor([[0.5167, 0.4833],
        [0.5327, 0.4673],
        [0.5192, 0.4808],
        [0.5102, 0.4898],
        [0.5138, 0.4862],
        [0.5175, 0.4825],
        [0.5137, 0.4863],
        [0.4906, 0.5094],
        [0.4662, 0.5338],
        [0.5159, 0.4841],
        [0.4814, 0.5186],
        [0.5348, 0.4652],
        [0.5283, 0.4717],
        [0.5314, 0.4686],
        [0.4966, 0.5034],
        [0.4936, 0.5064],
        [0.5041, 0.4959],
        [0.4928, 0.5072],
        [0.4779, 0.5221],
        [0.4605, 0.5395],
        [0.5395, 0.4605],
        [0.4897, 0.5103],
        [0.5191, 0.4809],
        [0.5184, 0.4816],
        [0.5104, 0.4896],
        [0.4987, 0.5013],
        [0.5286, 0.4714],
        [0.4897, 0.5103],
        [0.5092, 0.4908],
        [0.5436, 0.4564],
        [0.5109, 0.4891],
        [0.5244, 0.4756],
        [0.5133, 0.4867],
        [0.5205, 0.4795],
        [0.5247, 0.4753],
        [0.5434, 0.4566],
        [0.5187, 0.4813],
        [0.5207, 0.4793],
        [0.4963, 0.5037],
        [0.5368, 0.4632],
        [0.5217, 0.4783],
        [0.5170, 0.4830],
        [0.5035, 0.4965],
        [0.5030, 0.4970],
        [0.4704, 0.5296],
        [0.4643, 0.5357],
        [0.5252, 0.4748],
        [0.5371, 0.4629],
        [0.5077, 0.4923],
        [0.5206, 0.4794],
        [0.4775, 0.5225],
        [0.4711, 0.5289],
        [0.5059, 0.4941],
        [0.4949, 0.5051],
        [0.4893, 0.5107],
        [0.4666, 0.5334],
        [0.5168, 0.4832],
        [0.5386, 0.4614],
        [0.5365, 0.4635],
        [0.5177, 0.4823],
        [0.5315, 0.4685],
        [0.4747, 0.5253],
        [0.5352, 0.4648],
        [0.5168, 0.4832],
        [0.5351, 0.4649],
        [0.5096, 0.4904],
        [0.4898, 0.5102],
        [0.5317, 0.4683],
        [0.4706, 0.5294],
        [0.5483, 0.4517],
        [0.5206, 0.4794],
        [0.5384, 0.4616],
        [0.5339, 0.4661],
        [0.4723, 0.5277],
        [0.5359, 0.4641],
        [0.4951, 0.5049],
        [0.4840, 0.5160],
        [0.5161, 0.4839],
        [0.5245, 0.4755],
        [0.5323, 0.4677],
        [0.5213, 0.4787],
        [0.5165, 0.4835],
        [0.5120, 0.4880],
        [0.4734, 0.5266],
        [0.5002, 0.4998],
        [0.5314, 0.4686],
        [0.4968, 0.5032],
        [0.5327, 0.4673],
        [0.5184, 0.4816],
        [0.5465, 0.4535],
        [0.5006, 0.4994],
        [0.5018, 0.4982],
        [0.5180, 0.4820],
        [0.5318, 0.4682],
        [0.4624, 0.5376],
        [0.4820, 0.5180],
        [0.5092, 0.4908],
        [0.5251, 0.4749],
        [0.5104, 0.4896],
        [0.4924, 0.5076],
        [0.5060, 0.4940],
        [0.5537, 0.4463],
        [0.5041, 0.4959],
        [0.4735, 0.5265],
        [0.5107, 0.4893],
        [0.5163, 0.4837],
        [0.5124, 0.4876],
        [0.5065, 0.4935],
        [0.5256, 0.4744],
        [0.5183, 0.4817],
        [0.5052, 0.4948],
        [0.5046, 0.4954],
        [0.5301, 0.4699],
        [0.5186, 0.4814],
        [0.4763, 0.5237],
        [0.4900, 0.5100],
        [0.5211, 0.4789],
        [0.5088, 0.4912],
        [0.5279, 0.4721],
        [0.5003, 0.4997],
        [0.5132, 0.4868],
        [0.5132, 0.4868],
        [0.5164, 0.4836],
        [0.5230, 0.4770],
        [0.4708, 0.5292],
        [0.4637, 0.5363],
        [0.4787, 0.5213],
        [0.5411, 0.4589],
        [0.5019, 0.4981],
        [0.5153, 0.4847],
        [0.4932, 0.5068],
        [0.4821, 0.5179],
        [0.5147, 0.4853],
        [0.4808, 0.5192],
        [0.5210, 0.4790],
        [0.5482, 0.4518],
        [0.4798, 0.5202],
        [0.5404, 0.4596],
        [0.5142, 0.4858],
        [0.5180, 0.4820],
        [0.4645, 0.5355],
        [0.5505, 0.4495],
        [0.5374, 0.4626],
        [0.5183, 0.4817],
        [0.5070, 0.4930],
        [0.5222, 0.4778],
        [0.5056, 0.4944],
        [0.4687, 0.5313],
        [0.4625, 0.5375],
        [0.5226, 0.4774],
        [0.5104, 0.4896],
        [0.4810, 0.5190],
        [0.5492, 0.4508],
        [0.4717, 0.5283],
        [0.5209, 0.4791],
        [0.5237, 0.4763],
        [0.4750, 0.5250],
        [0.5598, 0.4402],
        [0.5490, 0.4510],
        [0.4905, 0.5095],
        [0.5091, 0.4909],
        [0.4770, 0.5230],
        [0.5123, 0.4877],
        [0.5122, 0.4878],
        [0.4706, 0.5294],
        [0.5158, 0.4842],
        [0.5140, 0.4860],
        [0.4989, 0.5011],
        [0.4922, 0.5078],
        [0.5065, 0.4935],
        [0.4809, 0.5191],
        [0.4973, 0.5027],
        [0.5168, 0.4832],
        [0.5295, 0.4705],
        [0.5090, 0.4910],
        [0.5178, 0.4822],
        [0.4827, 0.5173],
        [0.4590, 0.5410],
        [0.5236, 0.4764],
        [0.5225, 0.4775],
        [0.5081, 0.4919],
        [0.5241, 0.4759],
        [0.4729, 0.5271],
        [0.4957, 0.5043],
        [0.5439, 0.4561],
        [0.4834, 0.5166],
        [0.5398, 0.4602],
        [0.5217, 0.4783],
        [0.5191, 0.4809],
        [0.5147, 0.4853],
        [0.4965, 0.5035],
        [0.5039, 0.4961],
        [0.5524, 0.4476],
        [0.5256, 0.4744],
        [0.5203, 0.4797],
        [0.4803, 0.5197],
        [0.5089, 0.4911],
        [0.5190, 0.4810],
        [0.5276, 0.4724],
        [0.5278, 0.4722],
        [0.5290, 0.4710],
        [0.5292, 0.4708],
        [0.5205, 0.4795],
        [0.4885, 0.5115],
        [0.5202, 0.4798],
        [0.4927, 0.5073],
        [0.4742, 0.5258],
        [0.5117, 0.4883],
        [0.5309, 0.4691],
        [0.5110, 0.4890],
        [0.5040, 0.4960],
        [0.5042, 0.4958],
        [0.4735, 0.5265],
        [0.5013, 0.4987],
        [0.5326, 0.4674],
        [0.5006, 0.4994],
        [0.5309, 0.4691],
        [0.4899, 0.5101],
        [0.5020, 0.4980],
        [0.4791, 0.5209],
        [0.5028, 0.4972],
        [0.5308, 0.4692],
        [0.5102, 0.4898],
        [0.5450, 0.4550],
        [0.4890, 0.5110],
        [0.5042, 0.4958],
        [0.5061, 0.4939],
        [0.5521, 0.4479],
        [0.5085, 0.4915],
        [0.4680, 0.5320],
        [0.5062, 0.4938],
        [0.5270, 0.4730],
        [0.5011, 0.4989],
        [0.5276, 0.4724],
        [0.4728, 0.5272],
        [0.5308, 0.4692],
        [0.5192, 0.4808],
        [0.5236, 0.4764],
        [0.5130, 0.4870],
        [0.4766, 0.5234],
        [0.5137, 0.4863],
        [0.4954, 0.5046],
        [0.4803, 0.5197],
        [0.4959, 0.5041],
        [0.5055, 0.4945],
        [0.5114, 0.4886],
        [0.4893, 0.5107],
        [0.5263, 0.4737],
        [0.5369, 0.4631],
        [0.4972, 0.5028],
        [0.4845, 0.5155],
        [0.5083, 0.4917],
        [0.5145, 0.4855],
        [0.5252, 0.4748],
        [0.5346, 0.4654],
        [0.5282, 0.4718],
        [0.5169, 0.4831],
        [0.5010, 0.4990],
        [0.4936, 0.5064],
        [0.5224, 0.4776],
        [0.5285, 0.4715],
        [0.5150, 0.4850],
        [0.5109, 0.4891],
        [0.4974, 0.5026],
        [0.4827, 0.5173],
        [0.5312, 0.4688],
        [0.5392, 0.4608],
        [0.5278, 0.4722],
        [0.5074, 0.4926],
        [0.4964, 0.5036],
        [0.5317, 0.4683],
        [0.5022, 0.4978]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0002 loss: 0.6930 acc_train: 0.4926 time: 0.1215s
tensor([[0.6907, 0.3093],
        [0.6579, 0.3421],
        [0.6944, 0.3056],
        [0.6833, 0.3167],
        [0.6964, 0.3036],
        [0.6791, 0.3209],
        [0.6850, 0.3150],
        [0.6598, 0.3402],
        [0.6118, 0.3882],
        [0.6733, 0.3267],
        [0.6347, 0.3653],
        [0.7058, 0.2942],
        [0.6801, 0.3199],
        [0.6587, 0.3413],
        [0.6707, 0.3293],
        [0.6354, 0.3646],
        [0.6613, 0.3387],
        [0.6683, 0.3317],
        [0.6220, 0.3780],
        [0.6348, 0.3652],
        [0.6739, 0.3261],
        [0.6636, 0.3364],
        [0.6631, 0.3369],
        [0.6960, 0.3040],
        [0.6819, 0.3181],
        [0.6162, 0.3838],
        [0.6529, 0.3471],
        [0.6373, 0.3627],
        [0.6501, 0.3499],
        [0.6593, 0.3407],
        [0.6383, 0.3617],
        [0.6502, 0.3498],
        [0.6637, 0.3363],
        [0.6976, 0.3024],
        [0.6933, 0.3067],
        [0.6702, 0.3298],
        [0.6583, 0.3417],
        [0.6527, 0.3473],
        [0.6705, 0.3295],
        [0.6914, 0.3086],
        [0.6657, 0.3343],
        [0.6411, 0.3589],
        [0.6173, 0.3827],
        [0.6563, 0.3437],
        [0.6589, 0.3411],
        [0.6558, 0.3442],
        [0.7081, 0.2919],
        [0.6987, 0.3013],
        [0.6570, 0.3430],
        [0.6934, 0.3066],
        [0.6619, 0.3381],
        [0.6523, 0.3477],
        [0.6653, 0.3347],
        [0.6371, 0.3629],
        [0.6435, 0.3565],
        [0.6671, 0.3329],
        [0.6539, 0.3461],
        [0.6862, 0.3138],
        [0.6930, 0.3070],
        [0.6560, 0.3440],
        [0.6530, 0.3470],
        [0.6192, 0.3808],
        [0.6989, 0.3011],
        [0.6915, 0.3085],
        [0.6638, 0.3362],
        [0.6700, 0.3300],
        [0.6362, 0.3638],
        [0.6467, 0.3533],
        [0.6257, 0.3743],
        [0.6823, 0.3177],
        [0.6635, 0.3365],
        [0.6978, 0.3022],
        [0.6868, 0.3132],
        [0.6615, 0.3385],
        [0.6789, 0.3211],
        [0.6547, 0.3453],
        [0.6711, 0.3289],
        [0.6708, 0.3292],
        [0.6522, 0.3478],
        [0.6893, 0.3107],
        [0.6758, 0.3242],
        [0.6873, 0.3127],
        [0.6432, 0.3568],
        [0.6546, 0.3454],
        [0.6455, 0.3545],
        [0.6539, 0.3461],
        [0.6396, 0.3604],
        [0.6891, 0.3109],
        [0.6908, 0.3092],
        [0.6897, 0.3103],
        [0.6787, 0.3213],
        [0.6756, 0.3244],
        [0.7063, 0.2937],
        [0.6465, 0.3535],
        [0.6501, 0.3499],
        [0.6708, 0.3292],
        [0.6875, 0.3125],
        [0.6334, 0.3666],
        [0.6969, 0.3031],
        [0.6393, 0.3607],
        [0.6852, 0.3148],
        [0.6954, 0.3046],
        [0.6236, 0.3764],
        [0.6159, 0.3841],
        [0.6388, 0.3612],
        [0.6872, 0.3128],
        [0.6698, 0.3302],
        [0.6650, 0.3350],
        [0.6705, 0.3295],
        [0.6911, 0.3089],
        [0.6279, 0.3721],
        [0.6392, 0.3608],
        [0.6959, 0.3041],
        [0.6942, 0.3058],
        [0.6480, 0.3520],
        [0.6680, 0.3320],
        [0.6878, 0.3122],
        [0.6675, 0.3325],
        [0.6852, 0.3148],
        [0.6610, 0.3390],
        [0.6415, 0.3585],
        [0.6338, 0.3662],
        [0.6843, 0.3157],
        [0.7023, 0.2977],
        [0.6281, 0.3719],
        [0.6403, 0.3597],
        [0.6118, 0.3882],
        [0.6919, 0.3081],
        [0.6561, 0.3439],
        [0.6881, 0.3119],
        [0.6612, 0.3388],
        [0.6166, 0.3834],
        [0.6506, 0.3494],
        [0.6711, 0.3289],
        [0.7067, 0.2933],
        [0.6654, 0.3346],
        [0.6183, 0.3817],
        [0.6573, 0.3427],
        [0.6960, 0.3040],
        [0.6850, 0.3150],
        [0.6166, 0.3834],
        [0.6763, 0.3237],
        [0.6832, 0.3168],
        [0.6989, 0.3011],
        [0.6187, 0.3813],
        [0.6599, 0.3401],
        [0.6279, 0.3721],
        [0.6514, 0.3486],
        [0.6536, 0.3464],
        [0.6914, 0.3086],
        [0.6785, 0.3215],
        [0.6694, 0.3306],
        [0.6808, 0.3192],
        [0.6715, 0.3285],
        [0.6928, 0.3072],
        [0.6460, 0.3540],
        [0.6597, 0.3403],
        [0.6940, 0.3060],
        [0.6725, 0.3275],
        [0.6548, 0.3452],
        [0.6763, 0.3237],
        [0.6333, 0.3667],
        [0.6694, 0.3306],
        [0.6397, 0.3603],
        [0.6406, 0.3594],
        [0.6843, 0.3157],
        [0.6448, 0.3552],
        [0.6612, 0.3388],
        [0.6654, 0.3346],
        [0.6667, 0.3333],
        [0.6361, 0.3639],
        [0.6468, 0.3532],
        [0.6900, 0.3100],
        [0.6963, 0.3037],
        [0.6943, 0.3057],
        [0.6433, 0.3567],
        [0.6519, 0.3481],
        [0.6479, 0.3521],
        [0.6737, 0.3263],
        [0.6672, 0.3328],
        [0.6850, 0.3150],
        [0.6773, 0.3227],
        [0.6104, 0.3896],
        [0.6242, 0.3758],
        [0.6994, 0.3006],
        [0.6798, 0.3202],
        [0.6977, 0.3023],
        [0.6547, 0.3453],
        [0.6432, 0.3567],
        [0.6727, 0.3273],
        [0.6620, 0.3380],
        [0.6781, 0.3219],
        [0.6996, 0.3004],
        [0.6660, 0.3340],
        [0.6600, 0.3400],
        [0.6212, 0.3788],
        [0.6592, 0.3408],
        [0.6343, 0.3657],
        [0.6974, 0.3026],
        [0.7047, 0.2953],
        [0.6745, 0.3255],
        [0.6979, 0.3021],
        [0.6986, 0.3014],
        [0.6376, 0.3624],
        [0.6757, 0.3243],
        [0.6285, 0.3715],
        [0.6588, 0.3412],
        [0.6896, 0.3104],
        [0.6845, 0.3155],
        [0.6883, 0.3117],
        [0.6632, 0.3368],
        [0.6850, 0.3150],
        [0.6422, 0.3578],
        [0.6376, 0.3624],
        [0.6820, 0.3180],
        [0.6482, 0.3518],
        [0.6600, 0.3400],
        [0.6541, 0.3459],
        [0.6771, 0.3229],
        [0.6631, 0.3369],
        [0.6717, 0.3283],
        [0.6893, 0.3107],
        [0.6359, 0.3641],
        [0.6712, 0.3288],
        [0.6875, 0.3125],
        [0.6812, 0.3188],
        [0.6678, 0.3322],
        [0.6836, 0.3164],
        [0.6585, 0.3415],
        [0.6623, 0.3377],
        [0.6189, 0.3811],
        [0.7053, 0.2947],
        [0.6620, 0.3380],
        [0.6731, 0.3269],
        [0.6574, 0.3426],
        [0.6883, 0.3117],
        [0.6895, 0.3105],
        [0.6682, 0.3318],
        [0.6555, 0.3445],
        [0.6135, 0.3865],
        [0.6792, 0.3208],
        [0.6823, 0.3177],
        [0.6510, 0.3490],
        [0.6650, 0.3350],
        [0.6215, 0.3785],
        [0.6646, 0.3354],
        [0.6743, 0.3257],
        [0.6855, 0.3145],
        [0.6650, 0.3350],
        [0.6725, 0.3275],
        [0.6195, 0.3805],
        [0.6774, 0.3226],
        [0.6727, 0.3273],
        [0.6792, 0.3208],
        [0.6556, 0.3444],
        [0.6888, 0.3112],
        [0.6790, 0.3210],
        [0.6710, 0.3290],
        [0.6469, 0.3531],
        [0.6803, 0.3197],
        [0.6919, 0.3081],
        [0.6435, 0.3565],
        [0.6427, 0.3573],
        [0.6794, 0.3206],
        [0.6247, 0.3753],
        [0.6822, 0.3178],
        [0.7091, 0.2909],
        [0.6882, 0.3118],
        [0.6425, 0.3575],
        [0.6725, 0.3275],
        [0.6992, 0.3008],
        [0.6869, 0.3131]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0003 loss: 0.6660 acc_train: 0.6103 time: 0.1329s
tensor([[0.7427, 0.2573],
        [0.6936, 0.3064],
        [0.7500, 0.2500],
        [0.7324, 0.2676],
        [0.7599, 0.2401],
        [0.7210, 0.2790],
        [0.7314, 0.2686],
        [0.7201, 0.2799],
        [0.6669, 0.3331],
        [0.7191, 0.2809],
        [0.6905, 0.3095],
        [0.7584, 0.2416],
        [0.7280, 0.2720],
        [0.6972, 0.3028],
        [0.7235, 0.2765],
        [0.6731, 0.3269],
        [0.7135, 0.2865],
        [0.7283, 0.2717],
        [0.6633, 0.3367],
        [0.6891, 0.3109],
        [0.7141, 0.2859],
        [0.7200, 0.2800],
        [0.7156, 0.2844],
        [0.7539, 0.2461],
        [0.7303, 0.2697],
        [0.6454, 0.3546],
        [0.6853, 0.3147],
        [0.6969, 0.3031],
        [0.6949, 0.3051],
        [0.6912, 0.3088],
        [0.6773, 0.3227],
        [0.6862, 0.3138],
        [0.7183, 0.2817],
        [0.7459, 0.2541],
        [0.7367, 0.2633],
        [0.7089, 0.2911],
        [0.6873, 0.3127],
        [0.6876, 0.3124],
        [0.7236, 0.2764],
        [0.7406, 0.2594],
        [0.7192, 0.2808],
        [0.6753, 0.3247],
        [0.6512, 0.3488],
        [0.7118, 0.2882],
        [0.7253, 0.2747],
        [0.7143, 0.2857],
        [0.7663, 0.2337],
        [0.7431, 0.2569],
        [0.6996, 0.3004],
        [0.7443, 0.2557],
        [0.7224, 0.2776],
        [0.7165, 0.2835],
        [0.7149, 0.2851],
        [0.6874, 0.3126],
        [0.6881, 0.3119],
        [0.7361, 0.2639],
        [0.6918, 0.3082],
        [0.7197, 0.2803],
        [0.7460, 0.2540],
        [0.7013, 0.2987],
        [0.6803, 0.3197],
        [0.6692, 0.3308],
        [0.7537, 0.2463],
        [0.7443, 0.2557],
        [0.6994, 0.3006],
        [0.7122, 0.2878],
        [0.6860, 0.3140],
        [0.6738, 0.3262],
        [0.6839, 0.3161],
        [0.7160, 0.2840],
        [0.7043, 0.2957],
        [0.7435, 0.2565],
        [0.7384, 0.2616],
        [0.7284, 0.2716],
        [0.7127, 0.2873],
        [0.6980, 0.3020],
        [0.7338, 0.2662],
        [0.7225, 0.2775],
        [0.6803, 0.3197],
        [0.7348, 0.2652],
        [0.7232, 0.2768],
        [0.7411, 0.2589],
        [0.6783, 0.3217],
        [0.7119, 0.2881],
        [0.6917, 0.3083],
        [0.6863, 0.3137],
        [0.6869, 0.3131],
        [0.7321, 0.2679],
        [0.7410, 0.2590],
        [0.7268, 0.2732],
        [0.7364, 0.2636],
        [0.7296, 0.2704],
        [0.7588, 0.2412],
        [0.6764, 0.3236],
        [0.7145, 0.2855],
        [0.7397, 0.2603],
        [0.7468, 0.2532],
        [0.6561, 0.3439],
        [0.7585, 0.2415],
        [0.6882, 0.3118],
        [0.7429, 0.2571],
        [0.7377, 0.2623],
        [0.6564, 0.3436],
        [0.6679, 0.3321],
        [0.6870, 0.3130],
        [0.7416, 0.2584],
        [0.7173, 0.2827],
        [0.7221, 0.2779],
        [0.7033, 0.2967],
        [0.7505, 0.2495],
        [0.6765, 0.3235],
        [0.6804, 0.3196],
        [0.7425, 0.2575],
        [0.7434, 0.2566],
        [0.6960, 0.3040],
        [0.7292, 0.2708],
        [0.7455, 0.2545],
        [0.7248, 0.2752],
        [0.7294, 0.2706],
        [0.7152, 0.2848],
        [0.6702, 0.3298],
        [0.6648, 0.3352],
        [0.7406, 0.2594],
        [0.7490, 0.2510],
        [0.6785, 0.3215],
        [0.7053, 0.2947],
        [0.6442, 0.3558],
        [0.7458, 0.2542],
        [0.7004, 0.2996],
        [0.7388, 0.2612],
        [0.7193, 0.2807],
        [0.6643, 0.3357],
        [0.6956, 0.3044],
        [0.7285, 0.2715],
        [0.7565, 0.2435],
        [0.6938, 0.3062],
        [0.6586, 0.3414],
        [0.6927, 0.3073],
        [0.7466, 0.2534],
        [0.7316, 0.2684],
        [0.6580, 0.3420],
        [0.7116, 0.2884],
        [0.7309, 0.2691],
        [0.7501, 0.2499],
        [0.6473, 0.3527],
        [0.7051, 0.2949],
        [0.6674, 0.3326],
        [0.7141, 0.2859],
        [0.7181, 0.2819],
        [0.7503, 0.2497],
        [0.7304, 0.2696],
        [0.7317, 0.2683],
        [0.7229, 0.2771],
        [0.7395, 0.2605],
        [0.7462, 0.2538],
        [0.6793, 0.3207],
        [0.7306, 0.2694],
        [0.7338, 0.2662],
        [0.7075, 0.2925],
        [0.6989, 0.3011],
        [0.7237, 0.2763],
        [0.7007, 0.2993],
        [0.7111, 0.2889],
        [0.6706, 0.3294],
        [0.6985, 0.3015],
        [0.7324, 0.2676],
        [0.6859, 0.3141],
        [0.7102, 0.2898],
        [0.7223, 0.2777],
        [0.7193, 0.2807],
        [0.6955, 0.3045],
        [0.6891, 0.3109],
        [0.7324, 0.2676],
        [0.7542, 0.2458],
        [0.7480, 0.2520],
        [0.6813, 0.3187],
        [0.7098, 0.2902],
        [0.7174, 0.2826],
        [0.7207, 0.2793],
        [0.7094, 0.2906],
        [0.7412, 0.2588],
        [0.7098, 0.2902],
        [0.6555, 0.3445],
        [0.6550, 0.3450],
        [0.7559, 0.2441],
        [0.7452, 0.2548],
        [0.7371, 0.2629],
        [0.6924, 0.3076],
        [0.6699, 0.3301],
        [0.7124, 0.2876],
        [0.7243, 0.2757],
        [0.7261, 0.2739],
        [0.7371, 0.2629],
        [0.7081, 0.2919],
        [0.7041, 0.2959],
        [0.6743, 0.3257],
        [0.7162, 0.2838],
        [0.6621, 0.3379],
        [0.7585, 0.2415],
        [0.7662, 0.2338],
        [0.7101, 0.2899],
        [0.7554, 0.2446],
        [0.7566, 0.2434],
        [0.6780, 0.3220],
        [0.7188, 0.2812],
        [0.6803, 0.3197],
        [0.7308, 0.2692],
        [0.7543, 0.2457],
        [0.7330, 0.2670],
        [0.7452, 0.2548],
        [0.7127, 0.2873],
        [0.7353, 0.2647],
        [0.7086, 0.2914],
        [0.6729, 0.3271],
        [0.7304, 0.2696],
        [0.6924, 0.3076],
        [0.6961, 0.3039],
        [0.7074, 0.2926],
        [0.7291, 0.2709],
        [0.7258, 0.2742],
        [0.7162, 0.2838],
        [0.7406, 0.2594],
        [0.6618, 0.3382],
        [0.7035, 0.2965],
        [0.7519, 0.2481],
        [0.7394, 0.2606],
        [0.7200, 0.2800],
        [0.7186, 0.2814],
        [0.7034, 0.2966],
        [0.7290, 0.2710],
        [0.6521, 0.3479],
        [0.7611, 0.2389],
        [0.7141, 0.2859],
        [0.7162, 0.2838],
        [0.7186, 0.2814],
        [0.7458, 0.2542],
        [0.7371, 0.2629],
        [0.7121, 0.2879],
        [0.7031, 0.2969],
        [0.6604, 0.3396],
        [0.7355, 0.2645],
        [0.7409, 0.2591],
        [0.7084, 0.2916],
        [0.7240, 0.2760],
        [0.6556, 0.3444],
        [0.7047, 0.2953],
        [0.7347, 0.2653],
        [0.7350, 0.2650],
        [0.7007, 0.2993],
        [0.7261, 0.2739],
        [0.6613, 0.3387],
        [0.7375, 0.2625],
        [0.7160, 0.2840],
        [0.7237, 0.2763],
        [0.6945, 0.3055],
        [0.7314, 0.2686],
        [0.7248, 0.2752],
        [0.7275, 0.2725],
        [0.6910, 0.3090],
        [0.7243, 0.2757],
        [0.7362, 0.2638],
        [0.6801, 0.3199],
        [0.6808, 0.3192],
        [0.7337, 0.2663],
        [0.6721, 0.3279],
        [0.7267, 0.2733],
        [0.7682, 0.2318],
        [0.7271, 0.2729],
        [0.6765, 0.3235],
        [0.7290, 0.2710],
        [0.7424, 0.2576],
        [0.7483, 0.2517]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0004 loss: 0.6608 acc_train: 0.6103 time: 0.1203s
tensor([[0.7465, 0.2535],
        [0.6864, 0.3136],
        [0.7550, 0.2450],
        [0.7331, 0.2669],
        [0.7735, 0.2265],
        [0.7130, 0.2870],
        [0.7299, 0.2701],
        [0.7296, 0.2704],
        [0.6713, 0.3287],
        [0.7190, 0.2810],
        [0.6937, 0.3063],
        [0.7643, 0.2357],
        [0.7259, 0.2741],
        [0.6914, 0.3086],
        [0.7260, 0.2740],
        [0.6556, 0.3444],
        [0.7210, 0.2790],
        [0.7384, 0.2616],
        [0.6537, 0.3463],
        [0.6857, 0.3143],
        [0.7097, 0.2903],
        [0.7248, 0.2752],
        [0.7226, 0.2774],
        [0.7588, 0.2412],
        [0.7239, 0.2761],
        [0.6240, 0.3760],
        [0.6694, 0.3306],
        [0.7076, 0.2924],
        [0.6844, 0.3156],
        [0.6747, 0.3253],
        [0.6645, 0.3355],
        [0.6757, 0.3243],
        [0.7279, 0.2721],
        [0.7466, 0.2534],
        [0.7298, 0.2702],
        [0.7064, 0.2936],
        [0.6701, 0.3299],
        [0.6726, 0.3274],
        [0.7216, 0.2784],
        [0.7418, 0.2582],
        [0.7254, 0.2746],
        [0.6653, 0.3347],
        [0.6436, 0.3564],
        [0.7108, 0.2892],
        [0.7458, 0.2542],
        [0.7220, 0.2780],
        [0.7750, 0.2250],
        [0.7415, 0.2585],
        [0.6940, 0.3060],
        [0.7456, 0.2544],
        [0.7339, 0.2661],
        [0.7293, 0.2707],
        [0.7164, 0.2836],
        [0.6901, 0.3099],
        [0.6792, 0.3208],
        [0.7522, 0.2478],
        [0.6789, 0.3211],
        [0.7079, 0.2921],
        [0.7532, 0.2468],
        [0.6995, 0.3005],
        [0.6574, 0.3426],
        [0.6681, 0.3319],
        [0.7606, 0.2394],
        [0.7440, 0.2560],
        [0.6897, 0.3103],
        [0.7022, 0.2978],
        [0.6840, 0.3160],
        [0.6549, 0.3451],
        [0.6938, 0.3062],
        [0.7049, 0.2951],
        [0.6981, 0.3019],
        [0.7419, 0.2581],
        [0.7432, 0.2568],
        [0.7417, 0.2583],
        [0.6979, 0.3021],
        [0.6924, 0.3076],
        [0.7464, 0.2536],
        [0.7280, 0.2720],
        [0.6603, 0.3397],
        [0.7326, 0.2674],
        [0.7254, 0.2746],
        [0.7474, 0.2526],
        [0.6644, 0.3356],
        [0.7146, 0.2854],
        [0.6854, 0.3146],
        [0.6705, 0.3295],
        [0.6836, 0.3164],
        [0.7295, 0.2705],
        [0.7421, 0.2579],
        [0.7210, 0.2790],
        [0.7465, 0.2535],
        [0.7349, 0.2651],
        [0.7598, 0.2402],
        [0.6614, 0.3386],
        [0.7246, 0.2754],
        [0.7583, 0.2417],
        [0.7595, 0.2405],
        [0.6302, 0.3698],
        [0.7687, 0.2313],
        [0.6838, 0.3162],
        [0.7544, 0.2456],
        [0.7346, 0.2654],
        [0.6369, 0.3631],
        [0.6693, 0.3307],
        [0.6876, 0.3124],
        [0.7447, 0.2553],
        [0.7179, 0.2821],
        [0.7353, 0.2647],
        [0.6870, 0.3130],
        [0.7641, 0.2359],
        [0.6852, 0.3148],
        [0.6672, 0.3328],
        [0.7367, 0.2633],
        [0.7435, 0.2565],
        [0.6911, 0.3089],
        [0.7417, 0.2583],
        [0.7534, 0.2466],
        [0.7320, 0.2680],
        [0.7260, 0.2740],
        [0.7234, 0.2766],
        [0.6514, 0.3486],
        [0.6485, 0.3515],
        [0.7500, 0.2500],
        [0.7445, 0.2555],
        [0.6731, 0.3269],
        [0.7135, 0.2865],
        [0.6222, 0.3778],
        [0.7525, 0.2475],
        [0.6944, 0.3056],
        [0.7426, 0.2574],
        [0.7266, 0.2734],
        [0.6615, 0.3385],
        [0.6950, 0.3050],
        [0.7326, 0.2674],
        [0.7548, 0.2452],
        [0.6751, 0.3249],
        [0.6460, 0.3540],
        [0.6831, 0.3169],
        [0.7455, 0.2545],
        [0.7294, 0.2706],
        [0.6448, 0.3552],
        [0.7052, 0.2948],
        [0.7337, 0.2663],
        [0.7528, 0.2472],
        [0.6232, 0.3768],
        [0.7071, 0.2929],
        [0.6556, 0.3444],
        [0.7190, 0.2810],
        [0.7284, 0.2716],
        [0.7605, 0.2395],
        [0.7345, 0.2655],
        [0.7428, 0.2572],
        [0.7211, 0.2789],
        [0.7587, 0.2413],
        [0.7508, 0.2492],
        [0.6653, 0.3347],
        [0.7466, 0.2534],
        [0.7285, 0.2715],
        [0.6986, 0.3014],
        [0.6903, 0.3097],
        [0.7198, 0.2802],
        [0.7155, 0.2845],
        [0.7032, 0.2968],
        [0.6511, 0.3489],
        [0.7104, 0.2896],
        [0.7309, 0.2691],
        [0.6811, 0.3189],
        [0.7127, 0.2873],
        [0.7300, 0.2700],
        [0.7222, 0.2778],
        [0.7055, 0.2945],
        [0.6800, 0.3200],
        [0.7215, 0.2785],
        [0.7634, 0.2366],
        [0.7501, 0.2499],
        [0.6724, 0.3276],
        [0.7148, 0.2852],
        [0.7284, 0.2716],
        [0.7202, 0.2798],
        [0.7056, 0.2944],
        [0.7470, 0.2530],
        [0.6900, 0.3100],
        [0.6475, 0.3525],
        [0.6333, 0.3667],
        [0.7650, 0.2350],
        [0.7588, 0.2412],
        [0.7311, 0.2689],
        [0.6807, 0.3193],
        [0.6488, 0.3512],
        [0.7017, 0.2983],
        [0.7416, 0.2584],
        [0.7246, 0.2754],
        [0.7238, 0.2762],
        [0.7040, 0.2960],
        [0.7003, 0.2997],
        [0.6732, 0.3268],
        [0.7217, 0.2783],
        [0.6408, 0.3592],
        [0.7736, 0.2264],
        [0.7792, 0.2208],
        [0.6977, 0.3023],
        [0.7625, 0.2375],
        [0.7670, 0.2330],
        [0.6640, 0.3360],
        [0.7097, 0.2903],
        [0.6810, 0.3190],
        [0.7524, 0.2476],
        [0.7709, 0.2291],
        [0.7345, 0.2655],
        [0.7514, 0.2486],
        [0.7114, 0.2886],
        [0.7339, 0.2661],
        [0.7215, 0.2785],
        [0.6603, 0.3397],
        [0.7323, 0.2677],
        [0.6880, 0.3120],
        [0.6881, 0.3119],
        [0.7074, 0.2926],
        [0.7349, 0.2651],
        [0.7382, 0.2618],
        [0.7074, 0.2926],
        [0.7454, 0.2546],
        [0.6335, 0.3665],
        [0.6892, 0.3108],
        [0.7675, 0.2325],
        [0.7548, 0.2452],
        [0.7259, 0.2741],
        [0.7074, 0.2926],
        [0.6988, 0.3012],
        [0.7392, 0.2608],
        [0.6344, 0.3656],
        [0.7682, 0.2318],
        [0.7147, 0.2853],
        [0.7129, 0.2871],
        [0.7272, 0.2728],
        [0.7546, 0.2454],
        [0.7339, 0.2661],
        [0.7045, 0.2955],
        [0.7058, 0.2942],
        [0.6592, 0.3408],
        [0.7430, 0.2570],
        [0.7484, 0.2516],
        [0.7090, 0.2910],
        [0.7337, 0.2663],
        [0.6377, 0.3623],
        [0.6946, 0.3054],
        [0.7469, 0.2531],
        [0.7368, 0.2632],
        [0.6918, 0.3082],
        [0.7322, 0.2678],
        [0.6521, 0.3479],
        [0.7461, 0.2539],
        [0.7105, 0.2895],
        [0.7216, 0.2784],
        [0.6873, 0.3127],
        [0.7241, 0.2759],
        [0.7207, 0.2793],
        [0.7322, 0.2678],
        [0.6821, 0.3179],
        [0.7194, 0.2806],
        [0.7315, 0.2685],
        [0.6662, 0.3338],
        [0.6693, 0.3307],
        [0.7365, 0.2635],
        [0.6644, 0.3356],
        [0.7230, 0.2770],
        [0.7805, 0.2195],
        [0.7175, 0.2825],
        [0.6573, 0.3427],
        [0.7347, 0.2653],
        [0.7387, 0.2613],
        [0.7585, 0.2415]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0005 loss: 0.6575 acc_train: 0.6103 time: 0.1213s
tensor([[0.7258, 0.2742],
        [0.6578, 0.3422],
        [0.7361, 0.2639],
        [0.7088, 0.2912],
        [0.7628, 0.2372],
        [0.6808, 0.3192],
        [0.7004, 0.2996],
        [0.7114, 0.2886],
        [0.6467, 0.3533],
        [0.6966, 0.3034],
        [0.6721, 0.3279],
        [0.7467, 0.2533],
        [0.6997, 0.3003],
        [0.6627, 0.3373],
        [0.7019, 0.2981],
        [0.6113, 0.3887],
        [0.7051, 0.2949],
        [0.7215, 0.2785],
        [0.6190, 0.3810],
        [0.6527, 0.3473],
        [0.6804, 0.3196],
        [0.7033, 0.2967],
        [0.7050, 0.2950],
        [0.7391, 0.2609],
        [0.6954, 0.3046],
        [0.5781, 0.4219],
        [0.6303, 0.3697],
        [0.6945, 0.3055],
        [0.6462, 0.3538],
        [0.6329, 0.3671],
        [0.6271, 0.3729],
        [0.6413, 0.3587],
        [0.7124, 0.2876],
        [0.7234, 0.2766],
        [0.6979, 0.3021],
        [0.6776, 0.3224],
        [0.6287, 0.3713],
        [0.6295, 0.3705],
        [0.6945, 0.3055],
        [0.7174, 0.2826],
        [0.7065, 0.2935],
        [0.6323, 0.3677],
        [0.6109, 0.3891],
        [0.6830, 0.3170],
        [0.7423, 0.2577],
        [0.7008, 0.2992],
        [0.7593, 0.2407],
        [0.7195, 0.2805],
        [0.6624, 0.3376],
        [0.7231, 0.2769],
        [0.7181, 0.2819],
        [0.7174, 0.2826],
        [0.6910, 0.3090],
        [0.6659, 0.3341],
        [0.6441, 0.3559],
        [0.7434, 0.2566],
        [0.6406, 0.3594],
        [0.6714, 0.3286],
        [0.7371, 0.2629],
        [0.6741, 0.3259],
        [0.6080, 0.3920],
        [0.6412, 0.3588],
        [0.7438, 0.2562],
        [0.7218, 0.2782],
        [0.6557, 0.3443],
        [0.6655, 0.3345],
        [0.6577, 0.3423],
        [0.6096, 0.3904],
        [0.6778, 0.3222],
        [0.6706, 0.3294],
        [0.6662, 0.3338],
        [0.7169, 0.2831],
        [0.7242, 0.2758],
        [0.7289, 0.2711],
        [0.6560, 0.3440],
        [0.6623, 0.3377],
        [0.7317, 0.2683],
        [0.7065, 0.2935],
        [0.6164, 0.3836],
        [0.7059, 0.2941],
        [0.7022, 0.2978],
        [0.7289, 0.2711],
        [0.6244, 0.3756],
        [0.6912, 0.3088],
        [0.6548, 0.3452],
        [0.6286, 0.3714],
        [0.6533, 0.3467],
        [0.7023, 0.2977],
        [0.7190, 0.2810],
        [0.6906, 0.3094],
        [0.7288, 0.2712],
        [0.7138, 0.2862],
        [0.7350, 0.2650],
        [0.6214, 0.3786],
        [0.7065, 0.2935],
        [0.7511, 0.2489],
        [0.7521, 0.2479],
        [0.5821, 0.4179],
        [0.7542, 0.2458],
        [0.6525, 0.3475],
        [0.7455, 0.2545],
        [0.7086, 0.2914],
        [0.5919, 0.4081],
        [0.6460, 0.3540],
        [0.6662, 0.3338],
        [0.7229, 0.2771],
        [0.6949, 0.3051],
        [0.7265, 0.2735],
        [0.6447, 0.3553],
        [0.7551, 0.2449],
        [0.6689, 0.3311],
        [0.6287, 0.3713],
        [0.7083, 0.2917],
        [0.7188, 0.2812],
        [0.6596, 0.3404],
        [0.7274, 0.2726],
        [0.7361, 0.2639],
        [0.7118, 0.2882],
        [0.6977, 0.3023],
        [0.7081, 0.2919],
        [0.6068, 0.3932],
        [0.6049, 0.3951],
        [0.7352, 0.2648],
        [0.7145, 0.2855],
        [0.6401, 0.3599],
        [0.6940, 0.3060],
        [0.5715, 0.4285],
        [0.7348, 0.2652],
        [0.6595, 0.3405],
        [0.7193, 0.2807],
        [0.7084, 0.2916],
        [0.6306, 0.3694],
        [0.6694, 0.3306],
        [0.7098, 0.2902],
        [0.7297, 0.2703],
        [0.6299, 0.3701],
        [0.6067, 0.3933],
        [0.6471, 0.3529],
        [0.7185, 0.2815],
        [0.7002, 0.2998],
        [0.6022, 0.3978],
        [0.6763, 0.3237],
        [0.7121, 0.2879],
        [0.7317, 0.2683],
        [0.5747, 0.4253],
        [0.6871, 0.3129],
        [0.6191, 0.3809],
        [0.6981, 0.3019],
        [0.7126, 0.2874],
        [0.7479, 0.2521],
        [0.7144, 0.2856],
        [0.7287, 0.2713],
        [0.6956, 0.3044],
        [0.7518, 0.2482],
        [0.7320, 0.2680],
        [0.6257, 0.3743],
        [0.7380, 0.2620],
        [0.7017, 0.2983],
        [0.6644, 0.3356],
        [0.6563, 0.3437],
        [0.6890, 0.3110],
        [0.7038, 0.2962],
        [0.6731, 0.3269],
        [0.6070, 0.3930],
        [0.6984, 0.3016],
        [0.7052, 0.2948],
        [0.6509, 0.3491],
        [0.6895, 0.3105],
        [0.7088, 0.2912],
        [0.7001, 0.2999],
        [0.6927, 0.3073],
        [0.6438, 0.3562],
        [0.6861, 0.3139],
        [0.7491, 0.2509],
        [0.7266, 0.2734],
        [0.6370, 0.3630],
        [0.6961, 0.3039],
        [0.7145, 0.2855],
        [0.6922, 0.3078],
        [0.6763, 0.3237],
        [0.7274, 0.2726],
        [0.6446, 0.3554],
        [0.6145, 0.3855],
        [0.5869, 0.4131],
        [0.7509, 0.2491],
        [0.7469, 0.2531],
        [0.6999, 0.3001],
        [0.6411, 0.3589],
        [0.6019, 0.3981],
        [0.6651, 0.3349],
        [0.7358, 0.2642],
        [0.6995, 0.3005],
        [0.6870, 0.3130],
        [0.6745, 0.3255],
        [0.6712, 0.3288],
        [0.6472, 0.3528],
        [0.7045, 0.2955],
        [0.5942, 0.4058],
        [0.7648, 0.2352],
        [0.7687, 0.2313],
        [0.6607, 0.3393],
        [0.7479, 0.2521],
        [0.7519, 0.2481],
        [0.6253, 0.3747],
        [0.6748, 0.3252],
        [0.6578, 0.3422],
        [0.7512, 0.2488],
        [0.7636, 0.2364],
        [0.7129, 0.2871],
        [0.7324, 0.2676],
        [0.6848, 0.3152],
        [0.7077, 0.2923],
        [0.7091, 0.2909],
        [0.6211, 0.3789],
        [0.7120, 0.2880],
        [0.6589, 0.3411],
        [0.6540, 0.3460],
        [0.6817, 0.3183],
        [0.7189, 0.2811],
        [0.7244, 0.2756],
        [0.6716, 0.3284],
        [0.7279, 0.2721],
        [0.5825, 0.4175],
        [0.6501, 0.3499],
        [0.7589, 0.2411],
        [0.7482, 0.2518],
        [0.7056, 0.2944],
        [0.6721, 0.3279],
        [0.6654, 0.3346],
        [0.7243, 0.2757],
        [0.5933, 0.4067],
        [0.7522, 0.2478],
        [0.6898, 0.3102],
        [0.6851, 0.3149],
        [0.7122, 0.2878],
        [0.7409, 0.2591],
        [0.7044, 0.2956],
        [0.6707, 0.3293],
        [0.6857, 0.3143],
        [0.6317, 0.3683],
        [0.7250, 0.2750],
        [0.7285, 0.2715],
        [0.6847, 0.3153],
        [0.7195, 0.2805],
        [0.5959, 0.4041],
        [0.6603, 0.3397],
        [0.7344, 0.2656],
        [0.7157, 0.2843],
        [0.6585, 0.3415],
        [0.7131, 0.2869],
        [0.6190, 0.3810],
        [0.7289, 0.2711],
        [0.6806, 0.3194],
        [0.6949, 0.3051],
        [0.6548, 0.3452],
        [0.6910, 0.3090],
        [0.6916, 0.3084],
        [0.7118, 0.2882],
        [0.6488, 0.3512],
        [0.6907, 0.3093],
        [0.7025, 0.2975],
        [0.6262, 0.3738],
        [0.6314, 0.3686],
        [0.7149, 0.2851],
        [0.6284, 0.3716],
        [0.7000, 0.3000],
        [0.7703, 0.2297],
        [0.6834, 0.3166],
        [0.6133, 0.3867],
        [0.7157, 0.2843],
        [0.7106, 0.2894],
        [0.7459, 0.2541]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0006 loss: 0.6547 acc_train: 0.6103 time: 0.1240s
tensor([[0.7117, 0.2883],
        [0.6372, 0.3628],
        [0.7230, 0.2770],
        [0.6917, 0.3083],
        [0.7551, 0.2449],
        [0.6537, 0.3463],
        [0.6785, 0.3215],
        [0.6974, 0.3026],
        [0.6276, 0.3724],
        [0.6791, 0.3209],
        [0.6558, 0.3442],
        [0.7337, 0.2663],
        [0.6810, 0.3190],
        [0.6410, 0.3590],
        [0.6843, 0.3157],
        [0.5785, 0.4215],
        [0.6945, 0.3055],
        [0.7106, 0.2894],
        [0.5918, 0.4082],
        [0.6265, 0.3735],
        [0.6569, 0.3431],
        [0.6885, 0.3115],
        [0.6917, 0.3083],
        [0.7257, 0.2743],
        [0.6775, 0.3225],
        [0.5447, 0.4553],
        [0.6000, 0.4000],
        [0.6866, 0.3134],
        [0.6158, 0.3842],
        [0.5988, 0.4012],
        [0.6003, 0.3997],
        [0.6152, 0.3848],
        [0.7030, 0.2970],
        [0.7071, 0.2929],
        [0.6746, 0.3254],
        [0.6568, 0.3432],
        [0.5958, 0.4042],
        [0.5948, 0.4052],
        [0.6740, 0.3260],
        [0.6989, 0.3011],
        [0.6901, 0.3099],
        [0.6074, 0.3926],
        [0.5856, 0.4144],
        [0.6616, 0.3384],
        [0.7410, 0.2590],
        [0.6835, 0.3165],
        [0.7489, 0.2511],
        [0.7046, 0.2954],
        [0.6397, 0.3603],
        [0.7070, 0.2930],
        [0.7068, 0.2932],
        [0.7098, 0.2902],
        [0.6706, 0.3294],
        [0.6490, 0.3510],
        [0.6166, 0.3834],
        [0.7376, 0.2624],
        [0.6106, 0.3894],
        [0.6439, 0.3561],
        [0.7253, 0.2747],
        [0.6556, 0.3444],
        [0.5672, 0.4328],
        [0.6219, 0.3781],
        [0.7324, 0.2676],
        [0.7093, 0.2907],
        [0.6281, 0.3719],
        [0.6369, 0.3631],
        [0.6400, 0.3600],
        [0.5728, 0.4272],
        [0.6637, 0.3363],
        [0.6430, 0.3570],
        [0.6404, 0.3596],
        [0.6987, 0.3013],
        [0.7098, 0.2902],
        [0.7205, 0.2795],
        [0.6227, 0.3773],
        [0.6375, 0.3625],
        [0.7225, 0.2775],
        [0.6906, 0.3094],
        [0.5829, 0.4171],
        [0.6854, 0.3146],
        [0.6845, 0.3155],
        [0.7156, 0.2844],
        [0.5929, 0.4071],
        [0.6734, 0.3266],
        [0.6326, 0.3674],
        [0.5963, 0.4037],
        [0.6320, 0.3680],
        [0.6812, 0.3188],
        [0.7027, 0.2973],
        [0.6675, 0.3325],
        [0.7147, 0.2853],
        [0.6980, 0.3020],
        [0.7189, 0.2811],
        [0.5894, 0.4106],
        [0.6914, 0.3086],
        [0.7489, 0.2511],
        [0.7463, 0.2537],
        [0.5501, 0.4499],
        [0.7436, 0.2564],
        [0.6294, 0.3706],
        [0.7395, 0.2605],
        [0.6894, 0.3106],
        [0.5618, 0.4382],
        [0.6292, 0.3708],
        [0.6493, 0.3507],
        [0.7063, 0.2937],
        [0.6780, 0.3220],
        [0.7209, 0.2791],
        [0.6134, 0.3866],
        [0.7508, 0.2492],
        [0.6521, 0.3479],
        [0.6024, 0.3976],
        [0.6871, 0.3129],
        [0.7019, 0.2981],
        [0.6355, 0.3645],
        [0.7169, 0.2831],
        [0.7246, 0.2754],
        [0.6973, 0.3027],
        [0.6772, 0.3228],
        [0.6998, 0.3002],
        [0.5759, 0.4241],
        [0.5685, 0.4315],
        [0.7253, 0.2747],
        [0.6936, 0.3064],
        [0.6140, 0.3860],
        [0.6787, 0.3213],
        [0.5320, 0.4680],
        [0.7228, 0.2772],
        [0.6336, 0.3664],
        [0.7019, 0.2981],
        [0.6964, 0.3036],
        [0.6076, 0.3924],
        [0.6496, 0.3504],
        [0.6902, 0.3098],
        [0.7125, 0.2875],
        [0.5940, 0.4060],
        [0.5760, 0.4240],
        [0.6182, 0.3818],
        [0.6987, 0.3013],
        [0.6773, 0.3227],
        [0.5691, 0.4309],
        [0.6550, 0.3450],
        [0.6946, 0.3054],
        [0.7173, 0.2827],
        [0.5399, 0.4601],
        [0.6733, 0.3267],
        [0.5950, 0.4050],
        [0.6825, 0.3175],
        [0.7017, 0.2983],
        [0.7402, 0.2598],
        [0.7007, 0.2993],
        [0.7202, 0.2798],
        [0.6753, 0.3247],
        [0.7484, 0.2516],
        [0.7199, 0.2801],
        [0.5945, 0.4055],
        [0.7340, 0.2660],
        [0.6829, 0.3171],
        [0.6369, 0.3631],
        [0.6339, 0.3661],
        [0.6668, 0.3332],
        [0.6945, 0.3055],
        [0.6506, 0.3494],
        [0.5765, 0.4235],
        [0.6904, 0.3096],
        [0.6869, 0.3131],
        [0.6311, 0.3689],
        [0.6729, 0.3271],
        [0.6920, 0.3080],
        [0.6837, 0.3163],
        [0.6836, 0.3164],
        [0.6147, 0.3853],
        [0.6613, 0.3387],
        [0.7396, 0.2604],
        [0.7107, 0.2893],
        [0.6135, 0.3865],
        [0.6825, 0.3175],
        [0.7066, 0.2934],
        [0.6707, 0.3293],
        [0.6561, 0.3439],
        [0.7138, 0.2862],
        [0.6109, 0.3891],
        [0.5921, 0.4079],
        [0.5526, 0.4474],
        [0.7397, 0.2603],
        [0.7392, 0.2608],
        [0.6759, 0.3241],
        [0.6091, 0.3909],
        [0.5650, 0.4350],
        [0.6372, 0.3628],
        [0.7351, 0.2649],
        [0.6834, 0.3166],
        [0.6616, 0.3384],
        [0.6522, 0.3478],
        [0.6507, 0.3493],
        [0.6281, 0.3719],
        [0.6937, 0.3063],
        [0.5605, 0.4395],
        [0.7597, 0.2403],
        [0.7612, 0.2388],
        [0.6317, 0.3683],
        [0.7383, 0.2617],
        [0.7415, 0.2585],
        [0.5954, 0.4046],
        [0.6486, 0.3514],
        [0.6390, 0.3610],
        [0.7526, 0.2474],
        [0.7598, 0.2402],
        [0.6975, 0.3025],
        [0.7175, 0.2825],
        [0.6628, 0.3372],
        [0.6890, 0.3110],
        [0.7012, 0.2988],
        [0.5891, 0.4109],
        [0.6977, 0.3023],
        [0.6390, 0.3610],
        [0.6266, 0.3734],
        [0.6636, 0.3364],
        [0.7102, 0.2898],
        [0.7138, 0.2862],
        [0.6444, 0.3556],
        [0.7163, 0.2837],
        [0.5449, 0.4551],
        [0.6215, 0.3785],
        [0.7538, 0.2462],
        [0.7429, 0.2571],
        [0.6911, 0.3089],
        [0.6446, 0.3554],
        [0.6426, 0.3574],
        [0.7135, 0.2865],
        [0.5664, 0.4336],
        [0.7416, 0.2584],
        [0.6723, 0.3277],
        [0.6627, 0.3373],
        [0.7024, 0.2976],
        [0.7310, 0.2690],
        [0.6811, 0.3189],
        [0.6460, 0.3540],
        [0.6729, 0.3271],
        [0.6109, 0.3891],
        [0.7127, 0.2873],
        [0.7157, 0.2843],
        [0.6651, 0.3349],
        [0.7102, 0.2898],
        [0.5666, 0.4334],
        [0.6350, 0.3650],
        [0.7262, 0.2738],
        [0.7013, 0.2987],
        [0.6340, 0.3660],
        [0.7005, 0.2995],
        [0.5939, 0.4061],
        [0.7176, 0.2824],
        [0.6572, 0.3428],
        [0.6758, 0.3242],
        [0.6303, 0.3697],
        [0.6666, 0.3334],
        [0.6717, 0.3283],
        [0.6979, 0.3021],
        [0.6238, 0.3762],
        [0.6721, 0.3279],
        [0.6831, 0.3169],
        [0.5981, 0.4019],
        [0.6045, 0.3955],
        [0.6995, 0.3005],
        [0.5995, 0.4005],
        [0.6854, 0.3146],
        [0.7634, 0.2366],
        [0.6570, 0.3430],
        [0.5841, 0.4159],
        [0.7031, 0.2969],
        [0.6899, 0.3101],
        [0.7382, 0.2618]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0007 loss: 0.6528 acc_train: 0.6103 time: 0.1330s
tensor([[0.7108, 0.2892],
        [0.6349, 0.3651],
        [0.7231, 0.2769],
        [0.6885, 0.3115],
        [0.7577, 0.2423],
        [0.6428, 0.3572],
        [0.6717, 0.3283],
        [0.6952, 0.3048],
        [0.6245, 0.3755],
        [0.6739, 0.3261],
        [0.6547, 0.3453],
        [0.7334, 0.2666],
        [0.6776, 0.3224],
        [0.6350, 0.3650],
        [0.6822, 0.3178],
        [0.5685, 0.4315],
        [0.6969, 0.3031],
        [0.7131, 0.2869],
        [0.5830, 0.4170],
        [0.6189, 0.3811],
        [0.6515, 0.3485],
        [0.6899, 0.3101],
        [0.6942, 0.3058],
        [0.7264, 0.2736],
        [0.6784, 0.3216],
        [0.5333, 0.4667],
        [0.5904, 0.4096],
        [0.6913, 0.3087],
        [0.6025, 0.3975],
        [0.5849, 0.4151],
        [0.5943, 0.4057],
        [0.6082, 0.3918],
        [0.7053, 0.2947],
        [0.7054, 0.2946],
        [0.6702, 0.3298],
        [0.6527, 0.3473],
        [0.5822, 0.4178],
        [0.5793, 0.4207],
        [0.6701, 0.3299],
        [0.6943, 0.3057],
        [0.6874, 0.3126],
        [0.6006, 0.3994],
        [0.5783, 0.4217],
        [0.6559, 0.3441],
        [0.7476, 0.2524],
        [0.6802, 0.3198],
        [0.7504, 0.2496],
        [0.7053, 0.2947],
        [0.6345, 0.3655],
        [0.7056, 0.2944],
        [0.7072, 0.2928],
        [0.7137, 0.2863],
        [0.6655, 0.3345],
        [0.6479, 0.3521],
        [0.6080, 0.3920],
        [0.7420, 0.2580],
        [0.6000, 0.4000],
        [0.6359, 0.3641],
        [0.7252, 0.2748],
        [0.6538, 0.3462],
        [0.5486, 0.4514],
        [0.6193, 0.3807],
        [0.7326, 0.2674],
        [0.7116, 0.2884],
        [0.6186, 0.3814],
        [0.6287, 0.3713],
        [0.6385, 0.3615],
        [0.5575, 0.4425],
        [0.6581, 0.3419],
        [0.6336, 0.3664],
        [0.6332, 0.3668],
        [0.6956, 0.3044],
        [0.7092, 0.2908],
        [0.7256, 0.2744],
        [0.6111, 0.3889],
        [0.6294, 0.3706],
        [0.7253, 0.2747],
        [0.6875, 0.3125],
        [0.5701, 0.4299],
        [0.6803, 0.3197],
        [0.6806, 0.3194],
        [0.7161, 0.2839],
        [0.5790, 0.4210],
        [0.6704, 0.3296],
        [0.6274, 0.3726],
        [0.5846, 0.4154],
        [0.6302, 0.3698],
        [0.6763, 0.3237],
        [0.7006, 0.2994],
        [0.6610, 0.3390],
        [0.7139, 0.2861],
        [0.6966, 0.3034],
        [0.7178, 0.2822],
        [0.5755, 0.4245],
        [0.6889, 0.3111],
        [0.7567, 0.2433],
        [0.7480, 0.2520],
        [0.5417, 0.4583],
        [0.7445, 0.2555],
        [0.6250, 0.3750],
        [0.7416, 0.2584],
        [0.6855, 0.3145],
        [0.5548, 0.4452],
        [0.6276, 0.3724],
        [0.6472, 0.3528],
        [0.7033, 0.2967],
        [0.6744, 0.3256],
        [0.7242, 0.2758],
        [0.6047, 0.3953],
        [0.7573, 0.2427],
        [0.6482, 0.3518],
        [0.5977, 0.4023],
        [0.6836, 0.3164],
        [0.7005, 0.2995],
        [0.6295, 0.3705],
        [0.7166, 0.2834],
        [0.7252, 0.2748],
        [0.6966, 0.3034],
        [0.6748, 0.3252],
        [0.7055, 0.2945],
        [0.5698, 0.4302],
        [0.5532, 0.4468],
        [0.7271, 0.2729],
        [0.6896, 0.3104],
        [0.6076, 0.3924],
        [0.6766, 0.3234],
        [0.5147, 0.4853],
        [0.7236, 0.2764],
        [0.6277, 0.3723],
        [0.6991, 0.3009],
        [0.6969, 0.3031],
        [0.6010, 0.3990],
        [0.6447, 0.3553],
        [0.6846, 0.3154],
        [0.7103, 0.2897],
        [0.5808, 0.4192],
        [0.5654, 0.4346],
        [0.6081, 0.3919],
        [0.6941, 0.3059],
        [0.6703, 0.3297],
        [0.5576, 0.4424],
        [0.6498, 0.3502],
        [0.6906, 0.3094],
        [0.7159, 0.2841],
        [0.5279, 0.4721],
        [0.6739, 0.3261],
        [0.5912, 0.4088],
        [0.6811, 0.3189],
        [0.7039, 0.2961],
        [0.7439, 0.2561],
        [0.7006, 0.2994],
        [0.7247, 0.2753],
        [0.6710, 0.3290],
        [0.7542, 0.2458],
        [0.7204, 0.2796],
        [0.5836, 0.4164],
        [0.7405, 0.2595],
        [0.6794, 0.3206],
        [0.6271, 0.3729],
        [0.6313, 0.3687],
        [0.6628, 0.3372],
        [0.6966, 0.3034],
        [0.6441, 0.3559],
        [0.5687, 0.4313],
        [0.6950, 0.3050],
        [0.6854, 0.3146],
        [0.6299, 0.3701],
        [0.6705, 0.3295],
        [0.6897, 0.3103],
        [0.6805, 0.3195],
        [0.6870, 0.3130],
        [0.6025, 0.3975],
        [0.6561, 0.3439],
        [0.7413, 0.2587],
        [0.7102, 0.2898],
        [0.6093, 0.3907],
        [0.6833, 0.3167],
        [0.7131, 0.2869],
        [0.6641, 0.3359],
        [0.6537, 0.3463],
        [0.7138, 0.2862],
        [0.5994, 0.4006],
        [0.5895, 0.4105],
        [0.5398, 0.4602],
        [0.7396, 0.2604],
        [0.7420, 0.2580],
        [0.6687, 0.3313],
        [0.5969, 0.4031],
        [0.5482, 0.4518],
        [0.6291, 0.3709],
        [0.7436, 0.2564],
        [0.6847, 0.3153],
        [0.6546, 0.3454],
        [0.6435, 0.3565],
        [0.6473, 0.3527],
        [0.6265, 0.3735],
        [0.6965, 0.3035],
        [0.5498, 0.4502],
        [0.7648, 0.2352],
        [0.7639, 0.2361],
        [0.6191, 0.3809],
        [0.7408, 0.2592],
        [0.7423, 0.2577],
        [0.5853, 0.4147],
        [0.6421, 0.3579],
        [0.6350, 0.3650],
        [0.7617, 0.2383],
        [0.7652, 0.2348],
        [0.6964, 0.3036],
        [0.7156, 0.2844],
        [0.6573, 0.3427],
        [0.6867, 0.3133],
        [0.7050, 0.2950],
        [0.5770, 0.4230],
        [0.6978, 0.3022],
        [0.6376, 0.3624],
        [0.6176, 0.3824],
        [0.6620, 0.3380],
        [0.7167, 0.2833],
        [0.7132, 0.2868],
        [0.6342, 0.3658],
        [0.7170, 0.2830],
        [0.5317, 0.4683],
        [0.6123, 0.3877],
        [0.7579, 0.2421],
        [0.7453, 0.2547],
        [0.6912, 0.3088],
        [0.6365, 0.3635],
        [0.6405, 0.3595],
        [0.7147, 0.2853],
        [0.5614, 0.4386],
        [0.7426, 0.2574],
        [0.6714, 0.3286],
        [0.6558, 0.3442],
        [0.7061, 0.2939],
        [0.7331, 0.2669],
        [0.6745, 0.3255],
        [0.6401, 0.3599],
        [0.6744, 0.3256],
        [0.6060, 0.3940],
        [0.7141, 0.2859],
        [0.7157, 0.2843],
        [0.6606, 0.3394],
        [0.7138, 0.2862],
        [0.5595, 0.4405],
        [0.6283, 0.3717],
        [0.7292, 0.2708],
        [0.7018, 0.2982],
        [0.6292, 0.3708],
        [0.7012, 0.2988],
        [0.5889, 0.4111],
        [0.7211, 0.2789],
        [0.6501, 0.3499],
        [0.6717, 0.3283],
        [0.6239, 0.3761],
        [0.6612, 0.3388],
        [0.6709, 0.3291],
        [0.6975, 0.3025],
        [0.6156, 0.3844],
        [0.6716, 0.3284],
        [0.6825, 0.3175],
        [0.5920, 0.4080],
        [0.5972, 0.4028],
        [0.6982, 0.3018],
        [0.5898, 0.4102],
        [0.6863, 0.3137],
        [0.7672, 0.2328],
        [0.6499, 0.3501],
        [0.5793, 0.4207],
        [0.7040, 0.2960],
        [0.6871, 0.3129],
        [0.7420, 0.2580]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0008 loss: 0.6512 acc_train: 0.6103 time: 0.1003s
tensor([[0.7170, 0.2830],
        [0.6435, 0.3565],
        [0.7316, 0.2684],
        [0.6925, 0.3075],
        [0.7664, 0.2336],
        [0.6422, 0.3578],
        [0.6741, 0.3259],
        [0.6992, 0.3008],
        [0.6314, 0.3686],
        [0.6763, 0.3237],
        [0.6628, 0.3372],
        [0.7396, 0.2604],
        [0.6820, 0.3180],
        [0.6395, 0.3605],
        [0.6896, 0.3104],
        [0.5710, 0.4290],
        [0.7064, 0.2936],
        [0.7213, 0.2787],
        [0.5860, 0.4140],
        [0.6232, 0.3768],
        [0.6572, 0.3428],
        [0.6989, 0.3011],
        [0.7046, 0.2954],
        [0.7356, 0.2644],
        [0.6894, 0.3106],
        [0.5354, 0.4646],
        [0.5962, 0.4038],
        [0.7024, 0.2976],
        [0.6027, 0.3973],
        [0.5839, 0.4161],
        [0.6005, 0.3995],
        [0.6143, 0.3857],
        [0.7129, 0.2871],
        [0.7119, 0.2881],
        [0.6775, 0.3225],
        [0.6602, 0.3398],
        [0.5821, 0.4179],
        [0.5780, 0.4220],
        [0.6768, 0.3232],
        [0.6962, 0.3038],
        [0.6944, 0.3056],
        [0.6052, 0.3948],
        [0.5808, 0.4192],
        [0.6612, 0.3388],
        [0.7582, 0.2418],
        [0.6846, 0.3154],
        [0.7593, 0.2407],
        [0.7147, 0.2853],
        [0.6406, 0.3594],
        [0.7128, 0.2872],
        [0.7133, 0.2867],
        [0.7217, 0.2783],
        [0.6684, 0.3316],
        [0.6564, 0.3436],
        [0.6131, 0.3869],
        [0.7511, 0.2489],
        [0.6037, 0.3963],
        [0.6404, 0.3596],
        [0.7316, 0.2684],
        [0.6624, 0.3376],
        [0.5472, 0.4528],
        [0.6262, 0.3738],
        [0.7391, 0.2609],
        [0.7228, 0.2772],
        [0.6212, 0.3788],
        [0.6335, 0.3665],
        [0.6452, 0.3548],
        [0.5567, 0.4433],
        [0.6589, 0.3411],
        [0.6367, 0.3633],
        [0.6384, 0.3616],
        [0.7008, 0.2992],
        [0.7163, 0.2837],
        [0.7366, 0.2634],
        [0.6141, 0.3859],
        [0.6319, 0.3681],
        [0.7334, 0.2666],
        [0.6914, 0.3086],
        [0.5734, 0.4266],
        [0.6839, 0.3161],
        [0.6847, 0.3153],
        [0.7225, 0.2775],
        [0.5791, 0.4209],
        [0.6758, 0.3242],
        [0.6326, 0.3674],
        [0.5871, 0.4129],
        [0.6385, 0.3615],
        [0.6827, 0.3173],
        [0.7077, 0.2923],
        [0.6659, 0.3341],
        [0.7199, 0.2801],
        [0.7023, 0.2977],
        [0.7259, 0.2741],
        [0.5741, 0.4259],
        [0.6929, 0.3071],
        [0.7670, 0.2330],
        [0.7528, 0.2472],
        [0.5463, 0.4537],
        [0.7523, 0.2477],
        [0.6306, 0.3694],
        [0.7475, 0.2525],
        [0.6897, 0.3103],
        [0.5601, 0.4399],
        [0.6331, 0.3669],
        [0.6539, 0.3461],
        [0.7085, 0.2915],
        [0.6794, 0.3206],
        [0.7321, 0.2679],
        [0.6100, 0.3900],
        [0.7682, 0.2318],
        [0.6528, 0.3472],
        [0.6042, 0.3958],
        [0.6903, 0.3097],
        [0.7082, 0.2918],
        [0.6347, 0.3653],
        [0.7221, 0.2779],
        [0.7318, 0.2682],
        [0.7025, 0.2975],
        [0.6826, 0.3174],
        [0.7159, 0.2841],
        [0.5758, 0.4242],
        [0.5528, 0.4472],
        [0.7346, 0.2654],
        [0.6965, 0.3035],
        [0.6128, 0.3872],
        [0.6805, 0.3195],
        [0.5122, 0.4878],
        [0.7300, 0.2700],
        [0.6324, 0.3676],
        [0.7029, 0.2971],
        [0.7042, 0.2958],
        [0.6064, 0.3936],
        [0.6493, 0.3507],
        [0.6865, 0.3135],
        [0.7176, 0.2824],
        [0.5824, 0.4176],
        [0.5682, 0.4318],
        [0.6114, 0.3886],
        [0.6986, 0.3014],
        [0.6742, 0.3258],
        [0.5606, 0.4394],
        [0.6552, 0.3448],
        [0.6937, 0.3063],
        [0.7228, 0.2772],
        [0.5303, 0.4697],
        [0.6822, 0.3178],
        [0.5997, 0.4003],
        [0.6862, 0.3138],
        [0.7125, 0.2875],
        [0.7524, 0.2476],
        [0.7071, 0.2929],
        [0.7358, 0.2642],
        [0.6763, 0.3237],
        [0.7635, 0.2365],
        [0.7280, 0.2720],
        [0.5862, 0.4138],
        [0.7501, 0.2499],
        [0.6849, 0.3151],
        [0.6283, 0.3717],
        [0.6407, 0.3593],
        [0.6701, 0.3299],
        [0.7033, 0.2967],
        [0.6480, 0.3520],
        [0.5746, 0.4254],
        [0.7038, 0.2962],
        [0.6927, 0.3073],
        [0.6378, 0.3622],
        [0.6763, 0.3237],
        [0.6953, 0.3047],
        [0.6845, 0.3155],
        [0.6948, 0.3052],
        [0.6020, 0.3980],
        [0.6620, 0.3380],
        [0.7484, 0.2516],
        [0.7185, 0.2815],
        [0.6160, 0.3840],
        [0.6914, 0.3086],
        [0.7248, 0.2752],
        [0.6660, 0.3340],
        [0.6627, 0.3373],
        [0.7216, 0.2784],
        [0.6021, 0.3979],
        [0.5977, 0.4023],
        [0.5419, 0.4581],
        [0.7455, 0.2545],
        [0.7491, 0.2509],
        [0.6702, 0.3298],
        [0.5986, 0.4014],
        [0.5458, 0.4542],
        [0.6336, 0.3664],
        [0.7563, 0.2437],
        [0.6952, 0.3048],
        [0.6587, 0.3413],
        [0.6437, 0.3563],
        [0.6547, 0.3453],
        [0.6350, 0.3650],
        [0.7058, 0.2942],
        [0.5529, 0.4471],
        [0.7730, 0.2270],
        [0.7710, 0.2290],
        [0.6177, 0.3823],
        [0.7493, 0.2507],
        [0.7490, 0.2510],
        [0.5865, 0.4135],
        [0.6486, 0.3514],
        [0.6392, 0.3608],
        [0.7725, 0.2275],
        [0.7746, 0.2254],
        [0.7026, 0.2974],
        [0.7218, 0.2782],
        [0.6637, 0.3363],
        [0.6946, 0.3054],
        [0.7136, 0.2864],
        [0.5786, 0.4214],
        [0.7048, 0.2952],
        [0.6469, 0.3531],
        [0.6191, 0.3809],
        [0.6697, 0.3303],
        [0.7311, 0.2689],
        [0.7178, 0.2822],
        [0.6371, 0.3629],
        [0.7244, 0.2756],
        [0.5334, 0.4666],
        [0.6157, 0.3843],
        [0.7657, 0.2343],
        [0.7498, 0.2502],
        [0.6979, 0.3021],
        [0.6414, 0.3586],
        [0.6490, 0.3510],
        [0.7217, 0.2783],
        [0.5689, 0.4311],
        [0.7504, 0.2496],
        [0.6798, 0.3202],
        [0.6589, 0.3411],
        [0.7172, 0.2828],
        [0.7417, 0.2583],
        [0.6786, 0.3214],
        [0.6454, 0.3546],
        [0.6838, 0.3162],
        [0.6106, 0.3894],
        [0.7224, 0.2776],
        [0.7231, 0.2769],
        [0.6653, 0.3347],
        [0.7232, 0.2768],
        [0.5654, 0.4346],
        [0.6331, 0.3669],
        [0.7378, 0.2622],
        [0.7096, 0.2904],
        [0.6364, 0.3636],
        [0.7089, 0.2911],
        [0.5959, 0.4041],
        [0.7308, 0.2692],
        [0.6530, 0.3470],
        [0.6780, 0.3220],
        [0.6280, 0.3720],
        [0.6673, 0.3327],
        [0.6807, 0.3193],
        [0.7036, 0.2964],
        [0.6197, 0.3803],
        [0.6820, 0.3180],
        [0.6923, 0.3077],
        [0.5984, 0.4016],
        [0.6014, 0.3986],
        [0.7059, 0.2941],
        [0.5925, 0.4075],
        [0.6949, 0.3051],
        [0.7762, 0.2238],
        [0.6553, 0.3447],
        [0.5888, 0.4112],
        [0.7109, 0.2891],
        [0.6948, 0.3052],
        [0.7520, 0.2480]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0009 loss: 0.6498 acc_train: 0.6103 time: 0.1251s
tensor([[0.7202, 0.2798],
        [0.6523, 0.3477],
        [0.7375, 0.2625],
        [0.6955, 0.3045],
        [0.7727, 0.2273],
        [0.6420, 0.3580],
        [0.6767, 0.3233],
        [0.7012, 0.2988],
        [0.6371, 0.3629],
        [0.6771, 0.3229],
        [0.6689, 0.3311],
        [0.7437, 0.2563],
        [0.6854, 0.3146],
        [0.6438, 0.3562],
        [0.6969, 0.3031],
        [0.5734, 0.4266],
        [0.7140, 0.2860],
        [0.7270, 0.2730],
        [0.5894, 0.4106],
        [0.6270, 0.3730],
        [0.6648, 0.3352],
        [0.7042, 0.2958],
        [0.7139, 0.2861],
        [0.7423, 0.2577],
        [0.6979, 0.3021],
        [0.5402, 0.4598],
        [0.6037, 0.3963],
        [0.7105, 0.2895],
        [0.6062, 0.3938],
        [0.5862, 0.4138],
        [0.6067, 0.3933],
        [0.6223, 0.3777],
        [0.7184, 0.2816],
        [0.7160, 0.2840],
        [0.6842, 0.3158],
        [0.6685, 0.3315],
        [0.5855, 0.4145],
        [0.5813, 0.4187],
        [0.6842, 0.3158],
        [0.6961, 0.3039],
        [0.7009, 0.2991],
        [0.6093, 0.3907],
        [0.5837, 0.4163],
        [0.6687, 0.3313],
        [0.7641, 0.2359],
        [0.6870, 0.3130],
        [0.7652, 0.2348],
        [0.7217, 0.2783],
        [0.6480, 0.3520],
        [0.7175, 0.2825],
        [0.7157, 0.2843],
        [0.7263, 0.2737],
        [0.6687, 0.3313],
        [0.6633, 0.3367],
        [0.6185, 0.3815],
        [0.7562, 0.2438],
        [0.6120, 0.3880],
        [0.6458, 0.3542],
        [0.7362, 0.2638],
        [0.6702, 0.3298],
        [0.5513, 0.4487],
        [0.6320, 0.3680],
        [0.7435, 0.2565],
        [0.7316, 0.2684],
        [0.6252, 0.3748],
        [0.6388, 0.3612],
        [0.6508, 0.3492],
        [0.5610, 0.4390],
        [0.6590, 0.3410],
        [0.6416, 0.3584],
        [0.6445, 0.3555],
        [0.7043, 0.2957],
        [0.7218, 0.2782],
        [0.7437, 0.2563],
        [0.6182, 0.3818],
        [0.6339, 0.3661],
        [0.7380, 0.2620],
        [0.6953, 0.3047],
        [0.5806, 0.4194],
        [0.6869, 0.3131],
        [0.6874, 0.3126],
        [0.7269, 0.2731],
        [0.5824, 0.4176],
        [0.6792, 0.3208],
        [0.6377, 0.3623],
        [0.5935, 0.4065],
        [0.6458, 0.3542],
        [0.6892, 0.3108],
        [0.7128, 0.2872],
        [0.6722, 0.3278],
        [0.7233, 0.2767],
        [0.7054, 0.2946],
        [0.7316, 0.2684],
        [0.5759, 0.4241],
        [0.6949, 0.3051],
        [0.7724, 0.2276],
        [0.7542, 0.2458],
        [0.5513, 0.4487],
        [0.7571, 0.2429],
        [0.6351, 0.3649],
        [0.7487, 0.2513],
        [0.6928, 0.3072],
        [0.5651, 0.4349],
        [0.6370, 0.3630],
        [0.6587, 0.3413],
        [0.7128, 0.2872],
        [0.6843, 0.3157],
        [0.7365, 0.2635],
        [0.6164, 0.3836],
        [0.7759, 0.2241],
        [0.6568, 0.3432],
        [0.6101, 0.3899],
        [0.6957, 0.3043],
        [0.7143, 0.2857],
        [0.6377, 0.3623],
        [0.7251, 0.2749],
        [0.7369, 0.2631],
        [0.7067, 0.2933],
        [0.6897, 0.3103],
        [0.7225, 0.2775],
        [0.5816, 0.4184],
        [0.5560, 0.4440],
        [0.7396, 0.2604],
        [0.7025, 0.2975],
        [0.6172, 0.3828],
        [0.6827, 0.3173],
        [0.5139, 0.4861],
        [0.7346, 0.2654],
        [0.6360, 0.3640],
        [0.7059, 0.2941],
        [0.7083, 0.2917],
        [0.6109, 0.3891],
        [0.6547, 0.3453],
        [0.6860, 0.3140],
        [0.7234, 0.2766],
        [0.5863, 0.4137],
        [0.5726, 0.4274],
        [0.6169, 0.3831],
        [0.7012, 0.2988],
        [0.6776, 0.3224],
        [0.5657, 0.4343],
        [0.6609, 0.3391],
        [0.6953, 0.3047],
        [0.7274, 0.2726],
        [0.5341, 0.4659],
        [0.6896, 0.3104],
        [0.6079, 0.3921],
        [0.6888, 0.3112],
        [0.7179, 0.2821],
        [0.7587, 0.2413],
        [0.7107, 0.2893],
        [0.7446, 0.2554],
        [0.6816, 0.3184],
        [0.7681, 0.2319],
        [0.7332, 0.2668],
        [0.5919, 0.4081],
        [0.7559, 0.2441],
        [0.6900, 0.3100],
        [0.6315, 0.3685],
        [0.6515, 0.3485],
        [0.6771, 0.3229],
        [0.7070, 0.2930],
        [0.6508, 0.3492],
        [0.5806, 0.4194],
        [0.7084, 0.2916],
        [0.6980, 0.3020],
        [0.6444, 0.3556],
        [0.6799, 0.3201],
        [0.6992, 0.3008],
        [0.6872, 0.3128],
        [0.6992, 0.3008],
        [0.6059, 0.3941],
        [0.6674, 0.3326],
        [0.7529, 0.2471],
        [0.7240, 0.2760],
        [0.6224, 0.3776],
        [0.6978, 0.3022],
        [0.7323, 0.2677],
        [0.6676, 0.3324],
        [0.6723, 0.3277],
        [0.7277, 0.2723],
        [0.6064, 0.3936],
        [0.6056, 0.3944],
        [0.5453, 0.4547],
        [0.7497, 0.2503],
        [0.7526, 0.2474],
        [0.6715, 0.3285],
        [0.6050, 0.3950],
        [0.5477, 0.4523],
        [0.6381, 0.3619],
        [0.7659, 0.2341],
        [0.7040, 0.2960],
        [0.6626, 0.3374],
        [0.6448, 0.3552],
        [0.6633, 0.3367],
        [0.6411, 0.3589],
        [0.7124, 0.2876],
        [0.5569, 0.4431],
        [0.7784, 0.2216],
        [0.7758, 0.2242],
        [0.6186, 0.3814],
        [0.7551, 0.2449],
        [0.7535, 0.2465],
        [0.5888, 0.4112],
        [0.6579, 0.3421],
        [0.6411, 0.3589],
        [0.7789, 0.2211],
        [0.7804, 0.2196],
        [0.7071, 0.2929],
        [0.7267, 0.2733],
        [0.6718, 0.3282],
        [0.7006, 0.2994],
        [0.7187, 0.2813],
        [0.5807, 0.4193],
        [0.7092, 0.2908],
        [0.6563, 0.3437],
        [0.6218, 0.3782],
        [0.6761, 0.3239],
        [0.7410, 0.2590],
        [0.7200, 0.2800],
        [0.6421, 0.3579],
        [0.7295, 0.2705],
        [0.5373, 0.4627],
        [0.6220, 0.3780],
        [0.7698, 0.2302],
        [0.7502, 0.2498],
        [0.7026, 0.2974],
        [0.6481, 0.3519],
        [0.6551, 0.3449],
        [0.7252, 0.2748],
        [0.5768, 0.4232],
        [0.7554, 0.2446],
        [0.6868, 0.3132],
        [0.6637, 0.3363],
        [0.7245, 0.2755],
        [0.7481, 0.2519],
        [0.6827, 0.3173],
        [0.6525, 0.3475],
        [0.6929, 0.3071],
        [0.6144, 0.3856],
        [0.7292, 0.2708],
        [0.7288, 0.2712],
        [0.6687, 0.3313],
        [0.7293, 0.2707],
        [0.5725, 0.4275],
        [0.6402, 0.3598],
        [0.7438, 0.2562],
        [0.7157, 0.2843],
        [0.6447, 0.3553],
        [0.7129, 0.2871],
        [0.6026, 0.3974],
        [0.7389, 0.2611],
        [0.6548, 0.3452],
        [0.6852, 0.3148],
        [0.6342, 0.3658],
        [0.6728, 0.3272],
        [0.6884, 0.3116],
        [0.7068, 0.2932],
        [0.6263, 0.3737],
        [0.6907, 0.3093],
        [0.7006, 0.2994],
        [0.6049, 0.3951],
        [0.6058, 0.3942],
        [0.7131, 0.2869],
        [0.5954, 0.4046],
        [0.7018, 0.2982],
        [0.7829, 0.2171],
        [0.6605, 0.3395],
        [0.5984, 0.4016],
        [0.7148, 0.2852],
        [0.7017, 0.2983],
        [0.7586, 0.2414]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0010 loss: 0.6490 acc_train: 0.6103 time: 0.1196s
tensor([[0.7193, 0.2807],
        [0.6580, 0.3420],
        [0.7393, 0.2607],
        [0.6960, 0.3040],
        [0.7744, 0.2256],
        [0.6410, 0.3590],
        [0.6776, 0.3224],
        [0.6999, 0.3001],
        [0.6408, 0.3592],
        [0.6751, 0.3249],
        [0.6710, 0.3290],
        [0.7440, 0.2560],
        [0.6856, 0.3144],
        [0.6462, 0.3538],
        [0.7016, 0.2984],
        [0.5743, 0.4257],
        [0.7172, 0.2828],
        [0.7286, 0.2714],
        [0.5909, 0.4091],
        [0.6288, 0.3712],
        [0.6709, 0.3291],
        [0.7045, 0.2955],
        [0.7194, 0.2806],
        [0.7442, 0.2558],
        [0.7017, 0.2983],
        [0.5453, 0.4547],
        [0.6090, 0.3910],
        [0.7142, 0.2858],
        [0.6102, 0.3898],
        [0.5886, 0.4114],
        [0.6114, 0.3886],
        [0.6292, 0.3708],
        [0.7203, 0.2797],
        [0.7160, 0.2840],
        [0.6876, 0.3124],
        [0.6747, 0.3253],
        [0.5896, 0.4104],
        [0.5857, 0.4143],
        [0.6890, 0.3110],
        [0.6934, 0.3066],
        [0.7048, 0.2952],
        [0.6113, 0.3887],
        [0.5856, 0.4144],
        [0.6747, 0.3253],
        [0.7651, 0.2349],
        [0.6857, 0.3143],
        [0.7669, 0.2331],
        [0.7244, 0.2756],
        [0.6529, 0.3471],
        [0.7181, 0.2819],
        [0.7145, 0.2855],
        [0.7268, 0.2732],
        [0.6661, 0.3339],
        [0.6668, 0.3332],
        [0.6222, 0.3778],
        [0.7571, 0.2429],
        [0.6209, 0.3791],
        [0.6490, 0.3510],
        [0.7372, 0.2628],
        [0.6751, 0.3249],
        [0.5575, 0.4425],
        [0.6353, 0.3647],
        [0.7442, 0.2558],
        [0.7350, 0.2650],
        [0.6287, 0.3713],
        [0.6408, 0.3592],
        [0.6529, 0.3471],
        [0.5665, 0.4335],
        [0.6589, 0.3411],
        [0.6454, 0.3546],
        [0.6481, 0.3519],
        [0.7047, 0.2953],
        [0.7241, 0.2759],
        [0.7455, 0.2545],
        [0.6212, 0.3788],
        [0.6346, 0.3654],
        [0.7387, 0.2613],
        [0.6968, 0.3032],
        [0.5878, 0.4122],
        [0.6867, 0.3133],
        [0.6870, 0.3130],
        [0.7278, 0.2722],
        [0.5858, 0.4142],
        [0.6799, 0.3201],
        [0.6404, 0.3596],
        [0.5992, 0.4008],
        [0.6502, 0.3498],
        [0.6919, 0.3081],
        [0.7142, 0.2858],
        [0.6767, 0.3233],
        [0.7235, 0.2765],
        [0.7045, 0.2955],
        [0.7324, 0.2676],
        [0.5784, 0.4216],
        [0.6941, 0.3059],
        [0.7725, 0.2275],
        [0.7520, 0.2480],
        [0.5559, 0.4441],
        [0.7575, 0.2425],
        [0.6377, 0.3623],
        [0.7459, 0.2541],
        [0.6929, 0.3071],
        [0.5685, 0.4315],
        [0.6377, 0.3623],
        [0.6612, 0.3388],
        [0.7140, 0.2860],
        [0.6871, 0.3129],
        [0.7363, 0.2637],
        [0.6209, 0.3791],
        [0.7791, 0.2209],
        [0.6585, 0.3415],
        [0.6139, 0.3861],
        [0.6970, 0.3030],
        [0.7163, 0.2837],
        [0.6380, 0.3620],
        [0.7244, 0.2756],
        [0.7389, 0.2611],
        [0.7078, 0.2922],
        [0.6933, 0.3067],
        [0.7239, 0.2761],
        [0.5851, 0.4149],
        [0.5605, 0.4395],
        [0.7405, 0.2595],
        [0.7052, 0.2948],
        [0.6201, 0.3799],
        [0.6818, 0.3182],
        [0.5175, 0.4825],
        [0.7354, 0.2646],
        [0.6371, 0.3629],
        [0.7065, 0.2935],
        [0.7083, 0.2917],
        [0.6130, 0.3870],
        [0.6578, 0.3422],
        [0.6831, 0.3169],
        [0.7254, 0.2746],
        [0.5904, 0.4096],
        [0.5769, 0.4231],
        [0.6217, 0.3783],
        [0.7001, 0.2999],
        [0.6782, 0.3218],
        [0.5703, 0.4297],
        [0.6648, 0.3352],
        [0.6942, 0.3058],
        [0.7280, 0.2720],
        [0.5376, 0.4624],
        [0.6937, 0.3063],
        [0.6138, 0.3862],
        [0.6878, 0.3122],
        [0.7194, 0.2806],
        [0.7610, 0.2390],
        [0.7111, 0.2889],
        [0.7487, 0.2513],
        [0.6840, 0.3160],
        [0.7683, 0.2317],
        [0.7338, 0.2662],
        [0.5971, 0.4029],
        [0.7570, 0.2430],
        [0.6925, 0.3075],
        [0.6341, 0.3659],
        [0.6591, 0.3409],
        [0.6811, 0.3189],
        [0.7077, 0.2923],
        [0.6506, 0.3494],
        [0.5847, 0.4153],
        [0.7086, 0.2914],
        [0.6996, 0.3004],
        [0.6476, 0.3524],
        [0.6793, 0.3207],
        [0.7000, 0.3000],
        [0.6870, 0.3130],
        [0.6999, 0.3001],
        [0.6098, 0.3902],
        [0.6707, 0.3293],
        [0.7530, 0.2470],
        [0.7255, 0.2745],
        [0.6253, 0.3747],
        [0.7009, 0.2991],
        [0.7344, 0.2656],
        [0.6669, 0.3331],
        [0.6800, 0.3200],
        [0.7304, 0.2696],
        [0.6094, 0.3906],
        [0.6106, 0.3894],
        [0.5485, 0.4515],
        [0.7506, 0.2494],
        [0.7510, 0.2490],
        [0.6704, 0.3296],
        [0.6122, 0.3878],
        [0.5519, 0.4481],
        [0.6402, 0.3598],
        [0.7707, 0.2293],
        [0.7080, 0.2920],
        [0.6640, 0.3360],
        [0.6458, 0.3542],
        [0.6687, 0.3313],
        [0.6440, 0.3560],
        [0.7148, 0.2852],
        [0.5594, 0.4406],
        [0.7797, 0.2203],
        [0.7764, 0.2236],
        [0.6194, 0.3806],
        [0.7570, 0.2430],
        [0.7545, 0.2455],
        [0.5897, 0.4103],
        [0.6648, 0.3352],
        [0.6399, 0.3601],
        [0.7797, 0.2203],
        [0.7819, 0.2181],
        [0.7079, 0.2921],
        [0.7282, 0.2718],
        [0.6774, 0.3226],
        [0.7025, 0.2975],
        [0.7188, 0.2812],
        [0.5829, 0.4171],
        [0.7102, 0.2898],
        [0.6631, 0.3369],
        [0.6233, 0.3767],
        [0.6795, 0.3205],
        [0.7454, 0.2546],
        [0.7189, 0.2811],
        [0.6464, 0.3536],
        [0.7312, 0.2688],
        [0.5415, 0.4585],
        [0.6276, 0.3724],
        [0.7691, 0.2309],
        [0.7465, 0.2535],
        [0.7037, 0.2963],
        [0.6521, 0.3479],
        [0.6573, 0.3427],
        [0.7240, 0.2760],
        [0.5825, 0.4175],
        [0.7562, 0.2438],
        [0.6896, 0.3104],
        [0.6674, 0.3326],
        [0.7274, 0.2726],
        [0.7506, 0.2494],
        [0.6845, 0.3155],
        [0.6578, 0.3422],
        [0.6988, 0.3012],
        [0.6173, 0.3827],
        [0.7328, 0.2672],
        [0.7314, 0.2686],
        [0.6698, 0.3302],
        [0.7301, 0.2699],
        [0.5789, 0.4211],
        [0.6468, 0.3532],
        [0.7460, 0.2540],
        [0.7178, 0.2822],
        [0.6508, 0.3492],
        [0.7126, 0.2874],
        [0.6075, 0.3925],
        [0.7433, 0.2567],
        [0.6538, 0.3462],
        [0.6902, 0.3099],
        [0.6394, 0.3606],
        [0.6749, 0.3251],
        [0.6922, 0.3078],
        [0.7067, 0.2933],
        [0.6313, 0.3687],
        [0.6950, 0.3050],
        [0.7044, 0.2956],
        [0.6091, 0.3909],
        [0.6079, 0.3921],
        [0.7171, 0.2829],
        [0.5967, 0.4033],
        [0.7048, 0.2952],
        [0.7849, 0.2151],
        [0.6628, 0.3372],
        [0.6051, 0.3949],
        [0.7147, 0.2853],
        [0.7048, 0.2952],
        [0.7597, 0.2403]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0011 loss: 0.6488 acc_train: 0.6103 time: 0.1331s
tensor([[0.7131, 0.2869],
        [0.6576, 0.3424],
        [0.7349, 0.2651],
        [0.6912, 0.3088],
        [0.7701, 0.2299],
        [0.6363, 0.3637],
        [0.6740, 0.3260],
        [0.6942, 0.3058],
        [0.6397, 0.3603],
        [0.6689, 0.3311],
        [0.6673, 0.3327],
        [0.7385, 0.2615],
        [0.6805, 0.3195],
        [0.6439, 0.3561],
        [0.7004, 0.2996],
        [0.5717, 0.4283],
        [0.7145, 0.2855],
        [0.7241, 0.2759],
        [0.5886, 0.4114],
        [0.6263, 0.3737],
        [0.6715, 0.3285],
        [0.6991, 0.3009],
        [0.7180, 0.2820],
        [0.7399, 0.2601],
        [0.6985, 0.3015],
        [0.5475, 0.4525],
        [0.6090, 0.3910],
        [0.7115, 0.2885],
        [0.6105, 0.3895],
        [0.5874, 0.4126],
        [0.6115, 0.3885],
        [0.6303, 0.3697],
        [0.7164, 0.2836],
        [0.7099, 0.2901],
        [0.6845, 0.3155],
        [0.6747, 0.3253],
        [0.5904, 0.4096],
        [0.5869, 0.4131],
        [0.6879, 0.3121],
        [0.6865, 0.3135],
        [0.7030, 0.2970],
        [0.6085, 0.3915],
        [0.5845, 0.4155],
        [0.6751, 0.3249],
        [0.7596, 0.2404],
        [0.6795, 0.3205],
        [0.7626, 0.2374],
        [0.7206, 0.2794],
        [0.6521, 0.3479],
        [0.7130, 0.2870],
        [0.7081, 0.2919],
        [0.7219, 0.2781],
        [0.6598, 0.3402],
        [0.6653, 0.3347],
        [0.6216, 0.3784],
        [0.7524, 0.2476],
        [0.6245, 0.3755],
        [0.6466, 0.3534],
        [0.7326, 0.2674],
        [0.6737, 0.3263],
        [0.5608, 0.4392],
        [0.6340, 0.3660],
        [0.7394, 0.2606],
        [0.7315, 0.2685],
        [0.6277, 0.3723],
        [0.6379, 0.3621],
        [0.6502, 0.3498],
        [0.5682, 0.4318],
        [0.6555, 0.3445],
        [0.6447, 0.3553],
        [0.6462, 0.3538],
        [0.6998, 0.3002],
        [0.7208, 0.2792],
        [0.7405, 0.2595],
        [0.6193, 0.3807],
        [0.6314, 0.3686],
        [0.7332, 0.2668],
        [0.6933, 0.3067],
        [0.5913, 0.4087],
        [0.6810, 0.3190],
        [0.6817, 0.3183],
        [0.7228, 0.2772],
        [0.5852, 0.4148],
        [0.6755, 0.3245],
        [0.6383, 0.3617],
        [0.5996, 0.4004],
        [0.6498, 0.3502],
        [0.6889, 0.3111],
        [0.7099, 0.2901],
        [0.6761, 0.3239],
        [0.7185, 0.2815],
        [0.6984, 0.3016],
        [0.7271, 0.2729],
        [0.5776, 0.4224],
        [0.6891, 0.3109],
        [0.7665, 0.2335],
        [0.7444, 0.2556],
        [0.5567, 0.4433],
        [0.7519, 0.2481],
        [0.6357, 0.3643],
        [0.7380, 0.2620],
        [0.6879, 0.3121],
        [0.5678, 0.4322],
        [0.6342, 0.3658],
        [0.6591, 0.3409],
        [0.7093, 0.2907],
        [0.6846, 0.3154],
        [0.7309, 0.2691],
        [0.6197, 0.3803],
        [0.7755, 0.2245],
        [0.6553, 0.3447],
        [0.6131, 0.3869],
        [0.6927, 0.3073],
        [0.7120, 0.2880],
        [0.6334, 0.3666],
        [0.7180, 0.2820],
        [0.7355, 0.2645],
        [0.7034, 0.2966],
        [0.6903, 0.3097],
        [0.7192, 0.2808],
        [0.5840, 0.4160],
        [0.5622, 0.4378],
        [0.7354, 0.2646],
        [0.7020, 0.2980],
        [0.6187, 0.3813],
        [0.6760, 0.3240],
        [0.5192, 0.4808],
        [0.7306, 0.2694],
        [0.6341, 0.3659],
        [0.7027, 0.2973],
        [0.7027, 0.2973],
        [0.6107, 0.3893],
        [0.6557, 0.3443],
        [0.6765, 0.3235],
        [0.7214, 0.2786],
        [0.5909, 0.4091],
        [0.5776, 0.4224],
        [0.6213, 0.3787],
        [0.6939, 0.3061],
        [0.6740, 0.3260],
        [0.5714, 0.4286],
        [0.6631, 0.3369],
        [0.6886, 0.3114],
        [0.7228, 0.2772],
        [0.5373, 0.4627],
        [0.6919, 0.3081],
        [0.6152, 0.3848],
        [0.6816, 0.3184],
        [0.7150, 0.2850],
        [0.7573, 0.2427],
        [0.7062, 0.2938],
        [0.7459, 0.2541],
        [0.6815, 0.3185],
        [0.7627, 0.2373],
        [0.7284, 0.2716],
        [0.5975, 0.4025],
        [0.7521, 0.2479],
        [0.6894, 0.3106],
        [0.6326, 0.3674],
        [0.6602, 0.3398],
        [0.6790, 0.3210],
        [0.7036, 0.2964],
        [0.6459, 0.3541],
        [0.5843, 0.4157],
        [0.7031, 0.2969],
        [0.6953, 0.3047],
        [0.6457, 0.3543],
        [0.6734, 0.3266],
        [0.6955, 0.3045],
        [0.6818, 0.3182],
        [0.6951, 0.3049],
        [0.6098, 0.3902],
        [0.6687, 0.3313],
        [0.7473, 0.2527],
        [0.7207, 0.2793],
        [0.6231, 0.3769],
        [0.6987, 0.3013],
        [0.7296, 0.2704],
        [0.6616, 0.3384],
        [0.6818, 0.3182],
        [0.7270, 0.2730],
        [0.6075, 0.3925],
        [0.6104, 0.3896],
        [0.5482, 0.4518],
        [0.7462, 0.2538],
        [0.7436, 0.2564],
        [0.6649, 0.3351],
        [0.6142, 0.3858],
        [0.5531, 0.4469],
        [0.6370, 0.3630],
        [0.7690, 0.2310],
        [0.7049, 0.2951],
        [0.6602, 0.3398],
        [0.6430, 0.3570],
        [0.6678, 0.3322],
        [0.6418, 0.3582],
        [0.7113, 0.2887],
        [0.5580, 0.4420],
        [0.7751, 0.2249],
        [0.7711, 0.2289],
        [0.6168, 0.3832],
        [0.7529, 0.2471],
        [0.7500, 0.2500],
        [0.5872, 0.4128],
        [0.6657, 0.3343],
        [0.6345, 0.3655],
        [0.7739, 0.2261],
        [0.7775, 0.2225],
        [0.7032, 0.2968],
        [0.7241, 0.2759],
        [0.6770, 0.3230],
        [0.6981, 0.3019],
        [0.7129, 0.2871],
        [0.5820, 0.4180],
        [0.7057, 0.2943],
        [0.6641, 0.3359],
        [0.6207, 0.3793],
        [0.6775, 0.3225],
        [0.7422, 0.2578],
        [0.7132, 0.2868],
        [0.6458, 0.3542],
        [0.7265, 0.2735],
        [0.5429, 0.4571],
        [0.6282, 0.3718],
        [0.7625, 0.2375],
        [0.7376, 0.2624],
        [0.6999, 0.3001],
        [0.6512, 0.3488],
        [0.6544, 0.3456],
        [0.7179, 0.2821],
        [0.5832, 0.4168],
        [0.7510, 0.2490],
        [0.6860, 0.3140],
        [0.6663, 0.3337],
        [0.7243, 0.2757],
        [0.7470, 0.2530],
        [0.6807, 0.3193],
        [0.6572, 0.3428],
        [0.6981, 0.3019],
        [0.6160, 0.3840],
        [0.7306, 0.2694],
        [0.7284, 0.2716],
        [0.6660, 0.3340],
        [0.7248, 0.2752],
        [0.5813, 0.4187],
        [0.6483, 0.3517],
        [0.7423, 0.2577],
        [0.7141, 0.2859],
        [0.6509, 0.3491],
        [0.7068, 0.2932],
        [0.6082, 0.3918],
        [0.7415, 0.2585],
        [0.6489, 0.3511],
        [0.6897, 0.3103],
        [0.6388, 0.3612],
        [0.6716, 0.3284],
        [0.6899, 0.3101],
        [0.7016, 0.2984],
        [0.6309, 0.3691],
        [0.6925, 0.3075],
        [0.7015, 0.2985],
        [0.6086, 0.3914],
        [0.6055, 0.3945],
        [0.7147, 0.2853],
        [0.5943, 0.4057],
        [0.7016, 0.2984],
        [0.7803, 0.2197],
        [0.6595, 0.3405],
        [0.6063, 0.3937],
        [0.7090, 0.2910],
        [0.7018, 0.2982],
        [0.7543, 0.2457]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0012 loss: 0.6492 acc_train: 0.6103 time: 0.1218s
tensor([[0.7058, 0.2942],
        [0.6547, 0.3453],
        [0.7280, 0.2720],
        [0.6850, 0.3150],
        [0.7628, 0.2372],
        [0.6316, 0.3684],
        [0.6692, 0.3308],
        [0.6872, 0.3128],
        [0.6379, 0.3621],
        [0.6624, 0.3376],
        [0.6618, 0.3382],
        [0.7310, 0.2690],
        [0.6739, 0.3261],
        [0.6404, 0.3596],
        [0.6964, 0.3036],
        [0.5697, 0.4303],
        [0.7093, 0.2907],
        [0.7172, 0.2828],
        [0.5861, 0.4139],
        [0.6231, 0.3769],
        [0.6696, 0.3304],
        [0.6916, 0.3084],
        [0.7136, 0.2864],
        [0.7324, 0.2676],
        [0.6924, 0.3076],
        [0.5498, 0.4502],
        [0.6070, 0.3930],
        [0.7064, 0.2936],
        [0.6099, 0.3901],
        [0.5861, 0.4139],
        [0.6103, 0.3897],
        [0.6289, 0.3711],
        [0.7103, 0.2897],
        [0.7016, 0.2984],
        [0.6791, 0.3209],
        [0.6721, 0.3279],
        [0.5904, 0.4096],
        [0.5872, 0.4128],
        [0.6843, 0.3157],
        [0.6792, 0.3208],
        [0.6988, 0.3012],
        [0.6053, 0.3947],
        [0.5835, 0.4165],
        [0.6728, 0.3272],
        [0.7514, 0.2486],
        [0.6729, 0.3271],
        [0.7550, 0.2450],
        [0.7139, 0.2861],
        [0.6494, 0.3506],
        [0.7058, 0.2942],
        [0.7005, 0.2995],
        [0.7149, 0.2851],
        [0.6533, 0.3467],
        [0.6621, 0.3379],
        [0.6203, 0.3797],
        [0.7454, 0.2546],
        [0.6255, 0.3745],
        [0.6426, 0.3574],
        [0.7259, 0.2741],
        [0.6696, 0.3304],
        [0.5630, 0.4370],
        [0.6315, 0.3685],
        [0.7328, 0.2672],
        [0.7247, 0.2753],
        [0.6252, 0.3748],
        [0.6334, 0.3666],
        [0.6459, 0.3541],
        [0.5696, 0.4304],
        [0.6520, 0.3480],
        [0.6427, 0.3573],
        [0.6430, 0.3570],
        [0.6933, 0.3067],
        [0.7152, 0.2848],
        [0.7327, 0.2673],
        [0.6159, 0.3841],
        [0.6280, 0.3720],
        [0.7253, 0.2747],
        [0.6879, 0.3121],
        [0.5934, 0.4066],
        [0.6740, 0.3260],
        [0.6752, 0.3248],
        [0.7156, 0.2844],
        [0.5843, 0.4157],
        [0.6699, 0.3301],
        [0.6351, 0.3649],
        [0.5984, 0.4016],
        [0.6473, 0.3527],
        [0.6841, 0.3159],
        [0.7036, 0.2964],
        [0.6737, 0.3263],
        [0.7121, 0.2879],
        [0.6909, 0.3091],
        [0.7193, 0.2807],
        [0.5762, 0.4238],
        [0.6831, 0.3169],
        [0.7580, 0.2420],
        [0.7352, 0.2648],
        [0.5569, 0.4431],
        [0.7438, 0.2562],
        [0.6330, 0.3670],
        [0.7288, 0.2712],
        [0.6815, 0.3185],
        [0.5671, 0.4329],
        [0.6301, 0.3699],
        [0.6558, 0.3442],
        [0.7029, 0.2971],
        [0.6800, 0.3200],
        [0.7236, 0.2764],
        [0.6165, 0.3835],
        [0.7686, 0.2314],
        [0.6500, 0.3500],
        [0.6113, 0.3887],
        [0.6865, 0.3135],
        [0.7053, 0.2947],
        [0.6283, 0.3717],
        [0.7103, 0.2897],
        [0.7299, 0.2701],
        [0.6971, 0.3029],
        [0.6845, 0.3155],
        [0.7114, 0.2886],
        [0.5822, 0.4178],
        [0.5632, 0.4368],
        [0.7283, 0.2717],
        [0.6967, 0.3033],
        [0.6167, 0.3833],
        [0.6700, 0.3300],
        [0.5219, 0.4781],
        [0.7237, 0.2763],
        [0.6305, 0.3695],
        [0.6976, 0.3024],
        [0.6954, 0.3046],
        [0.6077, 0.3923],
        [0.6522, 0.3478],
        [0.6697, 0.3303],
        [0.7152, 0.2848],
        [0.5899, 0.4101],
        [0.5784, 0.4216],
        [0.6198, 0.3802],
        [0.6861, 0.3139],
        [0.6687, 0.3313],
        [0.5720, 0.4280],
        [0.6596, 0.3404],
        [0.6821, 0.3179],
        [0.7157, 0.2843],
        [0.5371, 0.4629],
        [0.6876, 0.3124],
        [0.6150, 0.3850],
        [0.6740, 0.3260],
        [0.7085, 0.2915],
        [0.7508, 0.2492],
        [0.6998, 0.3002],
        [0.7394, 0.2606],
        [0.6769, 0.3231],
        [0.7550, 0.2450],
        [0.7205, 0.2795],
        [0.5964, 0.4036],
        [0.7444, 0.2556],
        [0.6844, 0.3156],
        [0.6303, 0.3697],
        [0.6586, 0.3414],
        [0.6745, 0.3255],
        [0.6980, 0.3020],
        [0.6405, 0.3595],
        [0.5831, 0.4169],
        [0.6963, 0.3037],
        [0.6887, 0.3113],
        [0.6422, 0.3578],
        [0.6661, 0.3339],
        [0.6891, 0.3109],
        [0.6749, 0.3251],
        [0.6887, 0.3113],
        [0.6088, 0.3912],
        [0.6647, 0.3353],
        [0.7396, 0.2604],
        [0.7138, 0.2862],
        [0.6197, 0.3803],
        [0.6946, 0.3054],
        [0.7222, 0.2778],
        [0.6552, 0.3448],
        [0.6797, 0.3203],
        [0.7212, 0.2788],
        [0.6045, 0.3955],
        [0.6087, 0.3913],
        [0.5483, 0.4517],
        [0.7396, 0.2604],
        [0.7342, 0.2658],
        [0.6591, 0.3409],
        [0.6145, 0.3855],
        [0.5544, 0.4456],
        [0.6323, 0.3677],
        [0.7636, 0.2364],
        [0.6987, 0.3013],
        [0.6548, 0.3452],
        [0.6400, 0.3600],
        [0.6642, 0.3358],
        [0.6381, 0.3619],
        [0.7052, 0.2948],
        [0.5564, 0.4436],
        [0.7679, 0.2321],
        [0.7632, 0.2368],
        [0.6146, 0.3854],
        [0.7463, 0.2537],
        [0.7430, 0.2570],
        [0.5850, 0.4150],
        [0.6639, 0.3361],
        [0.6288, 0.3712],
        [0.7650, 0.2350],
        [0.7702, 0.2298],
        [0.6969, 0.3031],
        [0.7177, 0.2823],
        [0.6741, 0.3259],
        [0.6918, 0.3082],
        [0.7049, 0.2951],
        [0.5812, 0.4188],
        [0.6995, 0.3005],
        [0.6626, 0.3374],
        [0.6178, 0.3822],
        [0.6738, 0.3262],
        [0.7351, 0.2649],
        [0.7065, 0.2935],
        [0.6433, 0.3567],
        [0.7196, 0.2804],
        [0.5445, 0.4555],
        [0.6268, 0.3732],
        [0.7537, 0.2463],
        [0.7278, 0.2722],
        [0.6940, 0.3060],
        [0.6486, 0.3514],
        [0.6501, 0.3499],
        [0.7105, 0.2895],
        [0.5826, 0.4174],
        [0.7433, 0.2567],
        [0.6800, 0.3200],
        [0.6636, 0.3364],
        [0.7187, 0.2813],
        [0.7405, 0.2595],
        [0.6752, 0.3248],
        [0.6545, 0.3455],
        [0.6942, 0.3058],
        [0.6141, 0.3859],
        [0.7257, 0.2743],
        [0.7230, 0.2770],
        [0.6609, 0.3391],
        [0.7169, 0.2831],
        [0.5827, 0.4173],
        [0.6475, 0.3525],
        [0.7360, 0.2640],
        [0.7081, 0.2919],
        [0.6487, 0.3513],
        [0.6996, 0.3004],
        [0.6081, 0.3919],
        [0.7368, 0.2632],
        [0.6436, 0.3564],
        [0.6862, 0.3138],
        [0.6363, 0.3637],
        [0.6666, 0.3334],
        [0.6849, 0.3151],
        [0.6951, 0.3049],
        [0.6282, 0.3718],
        [0.6874, 0.3126],
        [0.6958, 0.3042],
        [0.6071, 0.3929],
        [0.6025, 0.3975],
        [0.7093, 0.2907],
        [0.5918, 0.4082],
        [0.6960, 0.3040],
        [0.7727, 0.2273],
        [0.6546, 0.3454],
        [0.6061, 0.3939],
        [0.7015, 0.2985],
        [0.6965, 0.3035],
        [0.7462, 0.2538]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0013 loss: 0.6500 acc_train: 0.6103 time: 0.1084s
tensor([[0.6992, 0.3008],
        [0.6514, 0.3486],
        [0.7202, 0.2798],
        [0.6793, 0.3207],
        [0.7546, 0.2454],
        [0.6287, 0.3713],
        [0.6649, 0.3351],
        [0.6808, 0.3192],
        [0.6364, 0.3636],
        [0.6576, 0.3424],
        [0.6570, 0.3430],
        [0.7236, 0.2764],
        [0.6684, 0.3316],
        [0.6376, 0.3624],
        [0.6916, 0.3084],
        [0.5699, 0.4301],
        [0.7034, 0.2966],
        [0.7096, 0.2904],
        [0.5853, 0.4147],
        [0.6212, 0.3788],
        [0.6667, 0.3333],
        [0.6847, 0.3153],
        [0.7078, 0.2922],
        [0.7241, 0.2759],
        [0.6857, 0.3143],
        [0.5534, 0.4466],
        [0.6055, 0.3945],
        [0.7010, 0.2990],
        [0.6101, 0.3899],
        [0.5863, 0.4137],
        [0.6095, 0.3905],
        [0.6272, 0.3728],
        [0.7036, 0.2964],
        [0.6936, 0.3064],
        [0.6736, 0.3264],
        [0.6689, 0.3311],
        [0.5911, 0.4089],
        [0.5884, 0.4116],
        [0.6803, 0.3197],
        [0.6730, 0.3270],
        [0.6936, 0.3064],
        [0.6035, 0.3965],
        [0.5845, 0.4155],
        [0.6697, 0.3303],
        [0.7429, 0.2571],
        [0.6675, 0.3325],
        [0.7461, 0.2539],
        [0.7064, 0.2936],
        [0.6461, 0.3539],
        [0.6983, 0.3017],
        [0.6938, 0.3062],
        [0.7076, 0.2924],
        [0.6486, 0.3514],
        [0.6592, 0.3408],
        [0.6199, 0.3801],
        [0.7380, 0.2620],
        [0.6256, 0.3744],
        [0.6389, 0.3611],
        [0.7191, 0.2809],
        [0.6654, 0.3346],
        [0.5657, 0.4343],
        [0.6295, 0.3705],
        [0.7256, 0.2744],
        [0.7168, 0.2832],
        [0.6233, 0.3767],
        [0.6294, 0.3706],
        [0.6423, 0.3577],
        [0.5719, 0.4281],
        [0.6491, 0.3509],
        [0.6405, 0.3595],
        [0.6404, 0.3596],
        [0.6870, 0.3130],
        [0.7093, 0.2907],
        [0.7244, 0.2756],
        [0.6135, 0.3865],
        [0.6264, 0.3736],
        [0.7180, 0.2820],
        [0.6830, 0.3170],
        [0.5954, 0.4046],
        [0.6682, 0.3318],
        [0.6697, 0.3303],
        [0.7085, 0.2915],
        [0.5847, 0.4153],
        [0.6653, 0.3347],
        [0.6326, 0.3674],
        [0.5976, 0.4024],
        [0.6452, 0.3548],
        [0.6794, 0.3206],
        [0.6972, 0.3028],
        [0.6710, 0.3290],
        [0.7056, 0.2944],
        [0.6844, 0.3156],
        [0.7115, 0.2885],
        [0.5755, 0.4245],
        [0.6776, 0.3224],
        [0.7491, 0.2509],
        [0.7266, 0.2734],
        [0.5588, 0.4412],
        [0.7350, 0.2650],
        [0.6312, 0.3688],
        [0.7203, 0.2797],
        [0.6760, 0.3240],
        [0.5682, 0.4318],
        [0.6270, 0.3730],
        [0.6528, 0.3472],
        [0.6966, 0.3034],
        [0.6751, 0.3249],
        [0.7164, 0.2836],
        [0.6138, 0.3862],
        [0.7605, 0.2395],
        [0.6446, 0.3554],
        [0.6102, 0.3898],
        [0.6806, 0.3194],
        [0.6981, 0.3019],
        [0.6250, 0.3750],
        [0.7031, 0.2969],
        [0.7238, 0.2762],
        [0.6906, 0.3094],
        [0.6781, 0.3219],
        [0.7029, 0.2971],
        [0.5818, 0.4182],
        [0.5653, 0.4347],
        [0.7208, 0.2792],
        [0.6912, 0.3088],
        [0.6157, 0.3843],
        [0.6655, 0.3345],
        [0.5269, 0.4731],
        [0.7167, 0.2833],
        [0.6283, 0.3717],
        [0.6927, 0.3073],
        [0.6886, 0.3114],
        [0.6055, 0.3945],
        [0.6488, 0.3512],
        [0.6644, 0.3356],
        [0.7083, 0.2917],
        [0.5899, 0.4101],
        [0.5805, 0.4195],
        [0.6188, 0.3812],
        [0.6789, 0.3211],
        [0.6640, 0.3360],
        [0.5739, 0.4261],
        [0.6557, 0.3443],
        [0.6764, 0.3236],
        [0.7083, 0.2917],
        [0.5388, 0.4612],
        [0.6824, 0.3176],
        [0.6147, 0.3853],
        [0.6672, 0.3328],
        [0.7019, 0.2981],
        [0.7435, 0.2565],
        [0.6942, 0.3058],
        [0.7317, 0.2683],
        [0.6726, 0.3274],
        [0.7468, 0.2532],
        [0.7121, 0.2879],
        [0.5959, 0.4041],
        [0.7359, 0.2641],
        [0.6796, 0.3204],
        [0.6288, 0.3712],
        [0.6558, 0.3442],
        [0.6699, 0.3301],
        [0.6925, 0.3075],
        [0.6369, 0.3631],
        [0.5834, 0.4166],
        [0.6901, 0.3099],
        [0.6817, 0.3183],
        [0.6393, 0.3607],
        [0.6598, 0.3402],
        [0.6831, 0.3169],
        [0.6684, 0.3316],
        [0.6825, 0.3175],
        [0.6085, 0.3915],
        [0.6608, 0.3392],
        [0.7319, 0.2681],
        [0.7064, 0.2936],
        [0.6171, 0.3829],
        [0.6901, 0.3099],
        [0.7143, 0.2857],
        [0.6500, 0.3500],
        [0.6761, 0.3239],
        [0.7149, 0.2851],
        [0.6022, 0.3978],
        [0.6073, 0.3927],
        [0.5505, 0.4495],
        [0.7323, 0.2677],
        [0.7251, 0.2749],
        [0.6546, 0.3454],
        [0.6147, 0.3853],
        [0.5571, 0.4429],
        [0.6281, 0.3719],
        [0.7560, 0.2440],
        [0.6917, 0.3083],
        [0.6504, 0.3496],
        [0.6373, 0.3627],
        [0.6601, 0.3399],
        [0.6352, 0.3648],
        [0.6987, 0.3013],
        [0.5565, 0.4435],
        [0.7595, 0.2405],
        [0.7545, 0.2455],
        [0.6141, 0.3859],
        [0.7387, 0.2613],
        [0.7355, 0.2645],
        [0.5847, 0.4153],
        [0.6614, 0.3386],
        [0.6249, 0.3751],
        [0.7556, 0.2444],
        [0.7619, 0.2381],
        [0.6908, 0.3092],
        [0.7112, 0.2888],
        [0.6706, 0.3294],
        [0.6856, 0.3144],
        [0.6972, 0.3028],
        [0.5824, 0.4176],
        [0.6932, 0.3068],
        [0.6601, 0.3399],
        [0.6160, 0.3840],
        [0.6704, 0.3296],
        [0.7267, 0.2733],
        [0.7008, 0.2992],
        [0.6408, 0.3592],
        [0.7123, 0.2877],
        [0.5483, 0.4517],
        [0.6257, 0.3743],
        [0.7450, 0.2550],
        [0.7190, 0.2810],
        [0.6879, 0.3121],
        [0.6461, 0.3539],
        [0.6461, 0.3539],
        [0.7039, 0.2961],
        [0.5825, 0.4175],
        [0.7346, 0.2654],
        [0.6736, 0.3264],
        [0.6609, 0.3391],
        [0.7126, 0.2874],
        [0.7330, 0.2670],
        [0.6699, 0.3301],
        [0.6510, 0.3490],
        [0.6894, 0.3106],
        [0.6132, 0.3868],
        [0.7197, 0.2803],
        [0.7171, 0.2829],
        [0.6565, 0.3435],
        [0.7092, 0.2908],
        [0.5846, 0.4154],
        [0.6462, 0.3538],
        [0.7290, 0.2710],
        [0.7020, 0.2980],
        [0.6460, 0.3540],
        [0.6930, 0.3070],
        [0.6081, 0.3919],
        [0.7310, 0.2690],
        [0.6402, 0.3598],
        [0.6821, 0.3179],
        [0.6337, 0.3663],
        [0.6615, 0.3385],
        [0.6791, 0.3209],
        [0.6893, 0.3107],
        [0.6258, 0.3742],
        [0.6817, 0.3183],
        [0.6892, 0.3108],
        [0.6067, 0.3933],
        [0.6007, 0.3993],
        [0.7030, 0.2970],
        [0.5911, 0.4089],
        [0.6900, 0.3100],
        [0.7638, 0.2362],
        [0.6498, 0.3502],
        [0.6061, 0.3939],
        [0.6942, 0.3058],
        [0.6905, 0.3095],
        [0.7371, 0.2629]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0014 loss: 0.6512 acc_train: 0.6103 time: 0.1119s
tensor([[0.6946, 0.3054],
        [0.6497, 0.3503],
        [0.7139, 0.2861],
        [0.6759, 0.3241],
        [0.7471, 0.2529],
        [0.6290, 0.3710],
        [0.6628, 0.3372],
        [0.6768, 0.3232],
        [0.6367, 0.3633],
        [0.6558, 0.3442],
        [0.6547, 0.3453],
        [0.7179, 0.2821],
        [0.6655, 0.3345],
        [0.6371, 0.3629],
        [0.6877, 0.3123],
        [0.5737, 0.4263],
        [0.6987, 0.3013],
        [0.7038, 0.2962],
        [0.5877, 0.4123],
        [0.6221, 0.3779],
        [0.6647, 0.3353],
        [0.6801, 0.3199],
        [0.7030, 0.2970],
        [0.7175, 0.2825],
        [0.6809, 0.3191],
        [0.5598, 0.4402],
        [0.6066, 0.3934],
        [0.6964, 0.3036],
        [0.6127, 0.3873],
        [0.5893, 0.4107],
        [0.6106, 0.3894],
        [0.6274, 0.3726],
        [0.6985, 0.3015],
        [0.6881, 0.3119],
        [0.6701, 0.3299],
        [0.6666, 0.3334],
        [0.5943, 0.4057],
        [0.5916, 0.4084],
        [0.6775, 0.3225],
        [0.6697, 0.3303],
        [0.6897, 0.3103],
        [0.6047, 0.3953],
        [0.5879, 0.4121],
        [0.6675, 0.3325],
        [0.7359, 0.2641],
        [0.6651, 0.3349],
        [0.7384, 0.2616],
        [0.7000, 0.3000],
        [0.6446, 0.3554],
        [0.6931, 0.3069],
        [0.6893, 0.3107],
        [0.7017, 0.2983],
        [0.6471, 0.3529],
        [0.6578, 0.3422],
        [0.6217, 0.3783],
        [0.7316, 0.2684],
        [0.6269, 0.3731],
        [0.6376, 0.3624],
        [0.7135, 0.2865],
        [0.6629, 0.3371],
        [0.5709, 0.4291],
        [0.6297, 0.3703],
        [0.7197, 0.2803],
        [0.7104, 0.2896],
        [0.6240, 0.3760],
        [0.6286, 0.3714],
        [0.6410, 0.3590],
        [0.5767, 0.4233],
        [0.6482, 0.3518],
        [0.6403, 0.3597],
        [0.6396, 0.3604],
        [0.6829, 0.3171],
        [0.7052, 0.2948],
        [0.7173, 0.2827],
        [0.6139, 0.3861],
        [0.6276, 0.3724],
        [0.7126, 0.2874],
        [0.6802, 0.3198],
        [0.5993, 0.4007],
        [0.6649, 0.3351],
        [0.6665, 0.3335],
        [0.7034, 0.2966],
        [0.5873, 0.4127],
        [0.6627, 0.3373],
        [0.6319, 0.3681],
        [0.5995, 0.4005],
        [0.6446, 0.3554],
        [0.6765, 0.3235],
        [0.6923, 0.3077],
        [0.6697, 0.3303],
        [0.7006, 0.2994],
        [0.6803, 0.3197],
        [0.7054, 0.2946],
        [0.5781, 0.4219],
        [0.6740, 0.3260],
        [0.7414, 0.2586],
        [0.7200, 0.2800],
        [0.5633, 0.4367],
        [0.7275, 0.2725],
        [0.6316, 0.3684],
        [0.7140, 0.2860],
        [0.6729, 0.3271],
        [0.5725, 0.4275],
        [0.6256, 0.3744],
        [0.6513, 0.3487],
        [0.6926, 0.3074],
        [0.6721, 0.3279],
        [0.7106, 0.2894],
        [0.6139, 0.3861],
        [0.7527, 0.2473],
        [0.6413, 0.3587],
        [0.6113, 0.3887],
        [0.6768, 0.3232],
        [0.6926, 0.3074],
        [0.6246, 0.3754],
        [0.6974, 0.3026],
        [0.7191, 0.2809],
        [0.6862, 0.3138],
        [0.6737, 0.3263],
        [0.6959, 0.3041],
        [0.5844, 0.4156],
        [0.5702, 0.4298],
        [0.7145, 0.2855],
        [0.6873, 0.3127],
        [0.6169, 0.3831],
        [0.6637, 0.3363],
        [0.5353, 0.4647],
        [0.7116, 0.2884],
        [0.6284, 0.3716],
        [0.6895, 0.3105],
        [0.6839, 0.3161],
        [0.6060, 0.3940],
        [0.6469, 0.3531],
        [0.6619, 0.3381],
        [0.7033, 0.2967],
        [0.5926, 0.4074],
        [0.5850, 0.4150],
        [0.6198, 0.3802],
        [0.6743, 0.3257],
        [0.6616, 0.3384],
        [0.5782, 0.4218],
        [0.6538, 0.3462],
        [0.6732, 0.3268],
        [0.7026, 0.2974],
        [0.5436, 0.4564],
        [0.6785, 0.3215],
        [0.6159, 0.3841],
        [0.6630, 0.3370],
        [0.6970, 0.3030],
        [0.7369, 0.2631],
        [0.6904, 0.3096],
        [0.7246, 0.2754],
        [0.6700, 0.3300],
        [0.7399, 0.2601],
        [0.7055, 0.2945],
        [0.5979, 0.4021],
        [0.7285, 0.2715],
        [0.6762, 0.3238],
        [0.6296, 0.3704],
        [0.6542, 0.3458],
        [0.6668, 0.3332],
        [0.6886, 0.3114],
        [0.6359, 0.3641],
        [0.5865, 0.4135],
        [0.6855, 0.3145],
        [0.6767, 0.3233],
        [0.6383, 0.3617],
        [0.6562, 0.3438],
        [0.6791, 0.3209],
        [0.6646, 0.3354],
        [0.6777, 0.3223],
        [0.6106, 0.3894],
        [0.6590, 0.3410],
        [0.7253, 0.2747],
        [0.7009, 0.2991],
        [0.6171, 0.3829],
        [0.6869, 0.3131],
        [0.7077, 0.2923],
        [0.6478, 0.3522],
        [0.6733, 0.3267],
        [0.7098, 0.2902],
        [0.6031, 0.3969],
        [0.6082, 0.3918],
        [0.5559, 0.4441],
        [0.7261, 0.2739],
        [0.7180, 0.2820],
        [0.6530, 0.3470],
        [0.6166, 0.3834],
        [0.5629, 0.4371],
        [0.6269, 0.3731],
        [0.7483, 0.2517],
        [0.6866, 0.3134],
        [0.6490, 0.3510],
        [0.6370, 0.3630],
        [0.6577, 0.3423],
        [0.6344, 0.3656],
        [0.6934, 0.3066],
        [0.5603, 0.4397],
        [0.7519, 0.2481],
        [0.7468, 0.2532],
        [0.6163, 0.3837],
        [0.7325, 0.2675],
        [0.7291, 0.2709],
        [0.5878, 0.4122],
        [0.6595, 0.3405],
        [0.6241, 0.3759],
        [0.7471, 0.2529],
        [0.7542, 0.2458],
        [0.6869, 0.3131],
        [0.7060, 0.2940],
        [0.6679, 0.3321],
        [0.6811, 0.3189],
        [0.6913, 0.3087],
        [0.5866, 0.4134],
        [0.6885, 0.3115],
        [0.6587, 0.3413],
        [0.6169, 0.3831],
        [0.6687, 0.3313],
        [0.7192, 0.2808],
        [0.6970, 0.3030],
        [0.6400, 0.3600],
        [0.7064, 0.2936],
        [0.5547, 0.4453],
        [0.6262, 0.3738],
        [0.7377, 0.2623],
        [0.7126, 0.2874],
        [0.6833, 0.3167],
        [0.6458, 0.3542],
        [0.6448, 0.3552],
        [0.6993, 0.3007],
        [0.5849, 0.4151],
        [0.7274, 0.2726],
        [0.6693, 0.3307],
        [0.6594, 0.3406],
        [0.7077, 0.2923],
        [0.7267, 0.2733],
        [0.6668, 0.3332],
        [0.6490, 0.3510],
        [0.6851, 0.3149],
        [0.6143, 0.3857],
        [0.7148, 0.2852],
        [0.7121, 0.2879],
        [0.6545, 0.3455],
        [0.7033, 0.2967],
        [0.5883, 0.4117],
        [0.6462, 0.3538],
        [0.7227, 0.2773],
        [0.6973, 0.3027],
        [0.6447, 0.3553],
        [0.6885, 0.3115],
        [0.6096, 0.3904],
        [0.7254, 0.2746],
        [0.6394, 0.3606],
        [0.6793, 0.3207],
        [0.6330, 0.3670],
        [0.6584, 0.3416],
        [0.6751, 0.3249],
        [0.6854, 0.3146],
        [0.6255, 0.3745],
        [0.6775, 0.3225],
        [0.6842, 0.3158],
        [0.6085, 0.3915],
        [0.6018, 0.3982],
        [0.6980, 0.3020],
        [0.5933, 0.4067],
        [0.6855, 0.3145],
        [0.7558, 0.2442],
        [0.6476, 0.3524],
        [0.6082, 0.3918],
        [0.6890, 0.3110],
        [0.6862, 0.3138],
        [0.7292, 0.2708]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0015 loss: 0.6526 acc_train: 0.6103 time: 0.0985s
tensor([[0.6922, 0.3078],
        [0.6502, 0.3498],
        [0.7090, 0.2910],
        [0.6748, 0.3252],
        [0.7409, 0.2591],
        [0.6323, 0.3677],
        [0.6630, 0.3370],
        [0.6747, 0.3253],
        [0.6385, 0.3615],
        [0.6563, 0.3437],
        [0.6542, 0.3458],
        [0.7140, 0.2860],
        [0.6650, 0.3350],
        [0.6388, 0.3612],
        [0.6851, 0.3149],
        [0.5805, 0.4195],
        [0.6955, 0.3045],
        [0.6999, 0.3001],
        [0.5930, 0.4070],
        [0.6254, 0.3746],
        [0.6640, 0.3360],
        [0.6778, 0.3222],
        [0.6993, 0.3007],
        [0.7126, 0.2874],
        [0.6782, 0.3218],
        [0.5679, 0.4321],
        [0.6101, 0.3899],
        [0.6927, 0.3073],
        [0.6174, 0.3826],
        [0.5949, 0.4051],
        [0.6135, 0.3865],
        [0.6294, 0.3706],
        [0.6952, 0.3048],
        [0.6851, 0.3149],
        [0.6685, 0.3315],
        [0.6654, 0.3346],
        [0.5997, 0.4003],
        [0.5970, 0.4030],
        [0.6763, 0.3237],
        [0.6692, 0.3308],
        [0.6872, 0.3128],
        [0.6083, 0.3917],
        [0.5925, 0.4075],
        [0.6664, 0.3336],
        [0.7301, 0.2699],
        [0.6650, 0.3350],
        [0.7324, 0.2676],
        [0.6957, 0.3043],
        [0.6452, 0.3548],
        [0.6899, 0.3101],
        [0.6868, 0.3132],
        [0.6976, 0.3024],
        [0.6484, 0.3516],
        [0.6576, 0.3424],
        [0.6250, 0.3750],
        [0.7264, 0.2736],
        [0.6296, 0.3704],
        [0.6387, 0.3613],
        [0.7097, 0.2903],
        [0.6620, 0.3380],
        [0.5783, 0.4217],
        [0.6318, 0.3682],
        [0.7155, 0.2845],
        [0.7058, 0.2942],
        [0.6267, 0.3733],
        [0.6304, 0.3696],
        [0.6413, 0.3587],
        [0.5836, 0.4164],
        [0.6485, 0.3515],
        [0.6419, 0.3581],
        [0.6407, 0.3593],
        [0.6811, 0.3189],
        [0.7026, 0.2974],
        [0.7116, 0.2884],
        [0.6169, 0.3831],
        [0.6309, 0.3691],
        [0.7086, 0.2914],
        [0.6794, 0.3206],
        [0.6045, 0.3955],
        [0.6643, 0.3357],
        [0.6659, 0.3341],
        [0.7003, 0.2997],
        [0.5921, 0.4079],
        [0.6622, 0.3378],
        [0.6335, 0.3665],
        [0.6037, 0.3963],
        [0.6453, 0.3547],
        [0.6752, 0.3248],
        [0.6892, 0.3108],
        [0.6699, 0.3301],
        [0.6978, 0.3022],
        [0.6784, 0.3216],
        [0.7013, 0.2987],
        [0.5836, 0.4164],
        [0.6725, 0.3275],
        [0.7352, 0.2648],
        [0.7156, 0.2844],
        [0.5703, 0.4297],
        [0.7219, 0.2781],
        [0.6336, 0.3664],
        [0.7098, 0.2902],
        [0.6722, 0.3278],
        [0.5788, 0.4212],
        [0.6266, 0.3734],
        [0.6516, 0.3484],
        [0.6907, 0.3093],
        [0.6712, 0.3288],
        [0.7063, 0.2937],
        [0.6165, 0.3835],
        [0.7456, 0.2544],
        [0.6396, 0.3604],
        [0.6144, 0.3856],
        [0.6750, 0.3250],
        [0.6892, 0.3108],
        [0.6267, 0.3733],
        [0.6932, 0.3068],
        [0.7156, 0.2844],
        [0.6839, 0.3161],
        [0.6713, 0.3287],
        [0.6906, 0.3094],
        [0.5899, 0.4101],
        [0.5776, 0.4224],
        [0.7101, 0.2899],
        [0.6849, 0.3151],
        [0.6203, 0.3797],
        [0.6641, 0.3359],
        [0.5462, 0.4538],
        [0.7082, 0.2918],
        [0.6304, 0.3696],
        [0.6881, 0.3119],
        [0.6811, 0.3189],
        [0.6094, 0.3906],
        [0.6469, 0.3531],
        [0.6622, 0.3378],
        [0.7000, 0.3000],
        [0.5977, 0.4023],
        [0.5914, 0.4086],
        [0.6229, 0.3771],
        [0.6725, 0.3275],
        [0.6616, 0.3384],
        [0.5846, 0.4154],
        [0.6538, 0.3462],
        [0.6728, 0.3272],
        [0.6987, 0.3013],
        [0.5515, 0.4485],
        [0.6761, 0.3239],
        [0.6186, 0.3814],
        [0.6616, 0.3384],
        [0.6937, 0.3063],
        [0.7316, 0.2684],
        [0.6881, 0.3119],
        [0.7190, 0.2810],
        [0.6694, 0.3306],
        [0.7342, 0.2658],
        [0.7015, 0.2985],
        [0.6022, 0.3978],
        [0.7225, 0.2775],
        [0.6748, 0.3252],
        [0.6323, 0.3677],
        [0.6541, 0.3459],
        [0.6656, 0.3344],
        [0.6862, 0.3138],
        [0.6373, 0.3627],
        [0.5918, 0.4082],
        [0.6826, 0.3174],
        [0.6740, 0.3260],
        [0.6392, 0.3608],
        [0.6555, 0.3445],
        [0.6773, 0.3227],
        [0.6636, 0.3364],
        [0.6743, 0.3257],
        [0.6148, 0.3852],
        [0.6591, 0.3409],
        [0.7202, 0.2798],
        [0.6973, 0.3027],
        [0.6193, 0.3807],
        [0.6849, 0.3151],
        [0.7027, 0.2973],
        [0.6486, 0.3514],
        [0.6716, 0.3284],
        [0.7062, 0.2938],
        [0.6067, 0.3933],
        [0.6108, 0.3892],
        [0.5636, 0.4364],
        [0.7217, 0.2783],
        [0.7129, 0.2871],
        [0.6541, 0.3459],
        [0.6202, 0.3798],
        [0.5711, 0.4289],
        [0.6285, 0.3715],
        [0.7413, 0.2587],
        [0.6836, 0.3164],
        [0.6495, 0.3505],
        [0.6387, 0.3613],
        [0.6573, 0.3427],
        [0.6353, 0.3647],
        [0.6896, 0.3104],
        [0.5670, 0.4330],
        [0.7454, 0.2546],
        [0.7405, 0.2595],
        [0.6210, 0.3790],
        [0.7279, 0.2721],
        [0.7244, 0.2756],
        [0.5932, 0.4068],
        [0.6587, 0.3413],
        [0.6258, 0.3742],
        [0.7398, 0.2602],
        [0.7473, 0.2527],
        [0.6853, 0.3147],
        [0.7025, 0.2975],
        [0.6666, 0.3334],
        [0.6785, 0.3215],
        [0.6878, 0.3122],
        [0.5931, 0.4069],
        [0.6858, 0.3142],
        [0.6586, 0.3414],
        [0.6202, 0.3798],
        [0.6684, 0.3316],
        [0.7135, 0.2865],
        [0.6945, 0.3055],
        [0.6411, 0.3589],
        [0.7024, 0.2976],
        [0.5634, 0.4366],
        [0.6283, 0.3717],
        [0.7320, 0.2680],
        [0.7081, 0.2919],
        [0.6806, 0.3194],
        [0.6477, 0.3523],
        [0.6454, 0.3546],
        [0.6962, 0.3038],
        [0.5897, 0.4103],
        [0.7219, 0.2781],
        [0.6670, 0.3330],
        [0.6596, 0.3404],
        [0.7041, 0.2959],
        [0.7219, 0.2781],
        [0.6657, 0.3343],
        [0.6488, 0.3512],
        [0.6817, 0.3183],
        [0.6175, 0.3825],
        [0.7113, 0.2887],
        [0.7086, 0.2914],
        [0.6549, 0.3452],
        [0.6987, 0.3013],
        [0.5934, 0.4066],
        [0.6476, 0.3524],
        [0.7179, 0.2821],
        [0.6942, 0.3058],
        [0.6453, 0.3547],
        [0.6855, 0.3145],
        [0.6130, 0.3870],
        [0.7207, 0.2793],
        [0.6409, 0.3591],
        [0.6779, 0.3221],
        [0.6345, 0.3655],
        [0.6578, 0.3422],
        [0.6729, 0.3271],
        [0.6834, 0.3166],
        [0.6275, 0.3725],
        [0.6751, 0.3249],
        [0.6810, 0.3190],
        [0.6120, 0.3880],
        [0.6056, 0.3944],
        [0.6946, 0.3054],
        [0.5977, 0.4023],
        [0.6821, 0.3179],
        [0.7491, 0.2509],
        [0.6481, 0.3519],
        [0.6121, 0.3879],
        [0.6858, 0.3142],
        [0.6838, 0.3162],
        [0.7229, 0.2771]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0016 loss: 0.6540 acc_train: 0.6103 time: 0.1135s
tensor([[0.6905, 0.3095],
        [0.6513, 0.3487],
        [0.7047, 0.2953],
        [0.6747, 0.3253],
        [0.7349, 0.2651],
        [0.6364, 0.3636],
        [0.6638, 0.3362],
        [0.6735, 0.3265],
        [0.6409, 0.3591],
        [0.6574, 0.3426],
        [0.6545, 0.3455],
        [0.7108, 0.2892],
        [0.6655, 0.3345],
        [0.6408, 0.3592],
        [0.6829, 0.3171],
        [0.5880, 0.4120],
        [0.6929, 0.3071],
        [0.6970, 0.3030],
        [0.5989, 0.4011],
        [0.6292, 0.3708],
        [0.6639, 0.3361],
        [0.6765, 0.3235],
        [0.6961, 0.3039],
        [0.7084, 0.2916],
        [0.6765, 0.3235],
        [0.5770, 0.4230],
        [0.6149, 0.3851],
        [0.6892, 0.3108],
        [0.6226, 0.3774],
        [0.6012, 0.3988],
        [0.6175, 0.3825],
        [0.6324, 0.3676],
        [0.6928, 0.3072],
        [0.6835, 0.3165],
        [0.6678, 0.3322],
        [0.6646, 0.3354],
        [0.6060, 0.3940],
        [0.6031, 0.3969],
        [0.6756, 0.3244],
        [0.6697, 0.3303],
        [0.6852, 0.3148],
        [0.6135, 0.3865],
        [0.5983, 0.4017],
        [0.6658, 0.3342],
        [0.7244, 0.2756],
        [0.6658, 0.3342],
        [0.7271, 0.2729],
        [0.6926, 0.3074],
        [0.6467, 0.3533],
        [0.6879, 0.3121],
        [0.6845, 0.3155],
        [0.6940, 0.3060],
        [0.6510, 0.3490],
        [0.6580, 0.3420],
        [0.6287, 0.3713],
        [0.7215, 0.2785],
        [0.6327, 0.3673],
        [0.6410, 0.3590],
        [0.7065, 0.2935],
        [0.6616, 0.3384],
        [0.5860, 0.4140],
        [0.6345, 0.3655],
        [0.7119, 0.2881],
        [0.7019, 0.2981],
        [0.6306, 0.3694],
        [0.6334, 0.3666],
        [0.6427, 0.3573],
        [0.5912, 0.4088],
        [0.6498, 0.3502],
        [0.6445, 0.3555],
        [0.6427, 0.3573],
        [0.6804, 0.3196],
        [0.7002, 0.2998],
        [0.7065, 0.2935],
        [0.6212, 0.3788],
        [0.6352, 0.3648],
        [0.7051, 0.2949],
        [0.6794, 0.3206],
        [0.6102, 0.3898],
        [0.6650, 0.3350],
        [0.6665, 0.3335],
        [0.6981, 0.3019],
        [0.5980, 0.4020],
        [0.6625, 0.3375],
        [0.6361, 0.3639],
        [0.6089, 0.3911],
        [0.6462, 0.3538],
        [0.6748, 0.3252],
        [0.6870, 0.3130],
        [0.6704, 0.3296],
        [0.6960, 0.3040],
        [0.6779, 0.3221],
        [0.6981, 0.3019],
        [0.5905, 0.4095],
        [0.6718, 0.3282],
        [0.7295, 0.2705],
        [0.7118, 0.2882],
        [0.5786, 0.4214],
        [0.7172, 0.2828],
        [0.6362, 0.3638],
        [0.7064, 0.2936],
        [0.6725, 0.3275],
        [0.5864, 0.4136],
        [0.6290, 0.3710],
        [0.6526, 0.3474],
        [0.6894, 0.3106],
        [0.6713, 0.3287],
        [0.7026, 0.2974],
        [0.6205, 0.3795],
        [0.7387, 0.2613],
        [0.6391, 0.3609],
        [0.6181, 0.3819],
        [0.6742, 0.3258],
        [0.6868, 0.3132],
        [0.6304, 0.3696],
        [0.6898, 0.3102],
        [0.7124, 0.2876],
        [0.6827, 0.3173],
        [0.6698, 0.3302],
        [0.6868, 0.3132],
        [0.5969, 0.4031],
        [0.5858, 0.4142],
        [0.7066, 0.2934],
        [0.6833, 0.3167],
        [0.6242, 0.3758],
        [0.6648, 0.3352],
        [0.5576, 0.4424],
        [0.7053, 0.2947],
        [0.6332, 0.3668],
        [0.6872, 0.3128],
        [0.6792, 0.3208],
        [0.6143, 0.3857],
        [0.6480, 0.3520],
        [0.6636, 0.3364],
        [0.6971, 0.3029],
        [0.6040, 0.3960],
        [0.5985, 0.4015],
        [0.6268, 0.3732],
        [0.6719, 0.3281],
        [0.6624, 0.3376],
        [0.5913, 0.4087],
        [0.6548, 0.3452],
        [0.6733, 0.3267],
        [0.6957, 0.3043],
        [0.5610, 0.4390],
        [0.6741, 0.3259],
        [0.6221, 0.3779],
        [0.6616, 0.3384],
        [0.6908, 0.3092],
        [0.7264, 0.2736],
        [0.6860, 0.3140],
        [0.7140, 0.2860],
        [0.6696, 0.3304],
        [0.7288, 0.2712],
        [0.6986, 0.3014],
        [0.6075, 0.3925],
        [0.7169, 0.2831],
        [0.6742, 0.3258],
        [0.6361, 0.3639],
        [0.6546, 0.3454],
        [0.6653, 0.3347],
        [0.6838, 0.3162],
        [0.6400, 0.3600],
        [0.5983, 0.4017],
        [0.6801, 0.3199],
        [0.6725, 0.3275],
        [0.6411, 0.3589],
        [0.6563, 0.3437],
        [0.6767, 0.3233],
        [0.6639, 0.3361],
        [0.6713, 0.3287],
        [0.6198, 0.3802],
        [0.6597, 0.3403],
        [0.7159, 0.2841],
        [0.6949, 0.3051],
        [0.6227, 0.3773],
        [0.6828, 0.3172],
        [0.6985, 0.3015],
        [0.6510, 0.3490],
        [0.6703, 0.3297],
        [0.7030, 0.2970],
        [0.6116, 0.3884],
        [0.6144, 0.3856],
        [0.5727, 0.4273],
        [0.7179, 0.2821],
        [0.7085, 0.2915],
        [0.6565, 0.3435],
        [0.6243, 0.3757],
        [0.5802, 0.4198],
        [0.6316, 0.3684],
        [0.7343, 0.2657],
        [0.6814, 0.3186],
        [0.6509, 0.3491],
        [0.6411, 0.3589],
        [0.6580, 0.3420],
        [0.6369, 0.3631],
        [0.6866, 0.3134],
        [0.5757, 0.4243],
        [0.7393, 0.2607],
        [0.7350, 0.2650],
        [0.6267, 0.3733],
        [0.7239, 0.2761],
        [0.7205, 0.2795],
        [0.5997, 0.4003],
        [0.6581, 0.3419],
        [0.6290, 0.3710],
        [0.7332, 0.2668],
        [0.7410, 0.2590],
        [0.6844, 0.3156],
        [0.6996, 0.3004],
        [0.6661, 0.3339],
        [0.6770, 0.3230],
        [0.6850, 0.3150],
        [0.6001, 0.3999],
        [0.6840, 0.3160],
        [0.6588, 0.3412],
        [0.6244, 0.3756],
        [0.6682, 0.3318],
        [0.7086, 0.2914],
        [0.6924, 0.3076],
        [0.6433, 0.3567],
        [0.6990, 0.3010],
        [0.5730, 0.4270],
        [0.6312, 0.3688],
        [0.7265, 0.2735],
        [0.7048, 0.2952],
        [0.6784, 0.3216],
        [0.6507, 0.3493],
        [0.6468, 0.3532],
        [0.6937, 0.3063],
        [0.5956, 0.4044],
        [0.7171, 0.2829],
        [0.6661, 0.3339],
        [0.6603, 0.3397],
        [0.7009, 0.2991],
        [0.7179, 0.2821],
        [0.6658, 0.3342],
        [0.6494, 0.3506],
        [0.6787, 0.3213],
        [0.6214, 0.3786],
        [0.7081, 0.2919],
        [0.7056, 0.2944],
        [0.6558, 0.3442],
        [0.6951, 0.3049],
        [0.5992, 0.4008],
        [0.6496, 0.3504],
        [0.7134, 0.2866],
        [0.6918, 0.3082],
        [0.6466, 0.3534],
        [0.6832, 0.3168],
        [0.6173, 0.3827],
        [0.7159, 0.2841],
        [0.6430, 0.3570],
        [0.6772, 0.3228],
        [0.6371, 0.3629],
        [0.6585, 0.3415],
        [0.6718, 0.3282],
        [0.6821, 0.3179],
        [0.6306, 0.3694],
        [0.6738, 0.3262],
        [0.6791, 0.3209],
        [0.6165, 0.3835],
        [0.6103, 0.3897],
        [0.6920, 0.3080],
        [0.6032, 0.3968],
        [0.6796, 0.3204],
        [0.7427, 0.2573],
        [0.6498, 0.3502],
        [0.6168, 0.3832],
        [0.6834, 0.3166],
        [0.6823, 0.3177],
        [0.7175, 0.2825]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0017 loss: 0.6554 acc_train: 0.6103 time: 0.1218s
tensor([[0.6889, 0.3111],
        [0.6528, 0.3472],
        [0.7009, 0.2991],
        [0.6749, 0.3251],
        [0.7291, 0.2709],
        [0.6403, 0.3597],
        [0.6644, 0.3356],
        [0.6728, 0.3272],
        [0.6431, 0.3569],
        [0.6588, 0.3412],
        [0.6554, 0.3446],
        [0.7076, 0.2924],
        [0.6662, 0.3338],
        [0.6431, 0.3569],
        [0.6810, 0.3190],
        [0.5957, 0.4043],
        [0.6907, 0.3093],
        [0.6941, 0.3059],
        [0.6055, 0.3945],
        [0.6332, 0.3668],
        [0.6641, 0.3359],
        [0.6752, 0.3248],
        [0.6933, 0.3067],
        [0.7046, 0.2954],
        [0.6753, 0.3247],
        [0.5862, 0.4138],
        [0.6203, 0.3797],
        [0.6861, 0.3139],
        [0.6279, 0.3721],
        [0.6080, 0.3920],
        [0.6219, 0.3781],
        [0.6360, 0.3640],
        [0.6906, 0.3094],
        [0.6826, 0.3174],
        [0.6677, 0.3323],
        [0.6636, 0.3364],
        [0.6127, 0.3873],
        [0.6096, 0.3904],
        [0.6751, 0.3249],
        [0.6706, 0.3294],
        [0.6833, 0.3167],
        [0.6192, 0.3808],
        [0.6044, 0.3956],
        [0.6654, 0.3346],
        [0.7188, 0.2812],
        [0.6663, 0.3337],
        [0.7217, 0.2783],
        [0.6903, 0.3097],
        [0.6487, 0.3513],
        [0.6864, 0.3136],
        [0.6824, 0.3176],
        [0.6906, 0.3094],
        [0.6540, 0.3460],
        [0.6589, 0.3411],
        [0.6326, 0.3674],
        [0.7165, 0.2835],
        [0.6358, 0.3642],
        [0.6436, 0.3564],
        [0.7035, 0.2965],
        [0.6617, 0.3383],
        [0.5940, 0.4060],
        [0.6372, 0.3628],
        [0.7084, 0.2916],
        [0.6984, 0.3016],
        [0.6351, 0.3649],
        [0.6371, 0.3629],
        [0.6449, 0.3551],
        [0.5991, 0.4009],
        [0.6514, 0.3486],
        [0.6474, 0.3526],
        [0.6450, 0.3550],
        [0.6799, 0.3201],
        [0.6979, 0.3021],
        [0.7016, 0.2984],
        [0.6258, 0.3742],
        [0.6393, 0.3607],
        [0.7018, 0.2982],
        [0.6790, 0.3210],
        [0.6163, 0.3837],
        [0.6660, 0.3340],
        [0.6672, 0.3328],
        [0.6957, 0.3043],
        [0.6047, 0.3953],
        [0.6631, 0.3369],
        [0.6389, 0.3611],
        [0.6148, 0.3852],
        [0.6475, 0.3525],
        [0.6746, 0.3254],
        [0.6852, 0.3148],
        [0.6710, 0.3290],
        [0.6941, 0.3059],
        [0.6776, 0.3224],
        [0.6953, 0.3047],
        [0.5982, 0.4018],
        [0.6711, 0.3289],
        [0.7240, 0.2760],
        [0.7082, 0.2918],
        [0.5874, 0.4126],
        [0.7132, 0.2868],
        [0.6391, 0.3609],
        [0.7030, 0.2970],
        [0.6731, 0.3269],
        [0.5945, 0.4055],
        [0.6319, 0.3681],
        [0.6536, 0.3464],
        [0.6876, 0.3124],
        [0.6716, 0.3284],
        [0.6993, 0.3007],
        [0.6252, 0.3748],
        [0.7317, 0.2683],
        [0.6396, 0.3604],
        [0.6225, 0.3775],
        [0.6741, 0.3259],
        [0.6848, 0.3152],
        [0.6344, 0.3656],
        [0.6866, 0.3134],
        [0.7087, 0.2913],
        [0.6818, 0.3182],
        [0.6691, 0.3309],
        [0.6840, 0.3160],
        [0.6044, 0.3956],
        [0.5943, 0.4057],
        [0.7034, 0.2966],
        [0.6819, 0.3181],
        [0.6284, 0.3716],
        [0.6654, 0.3346],
        [0.5692, 0.4308],
        [0.7025, 0.2975],
        [0.6362, 0.3638],
        [0.6865, 0.3135],
        [0.6778, 0.3222],
        [0.6193, 0.3807],
        [0.6497, 0.3503],
        [0.6649, 0.3351],
        [0.6942, 0.3058],
        [0.6108, 0.3892],
        [0.6056, 0.3944],
        [0.6311, 0.3689],
        [0.6722, 0.3278],
        [0.6634, 0.3366],
        [0.5983, 0.4017],
        [0.6565, 0.3435],
        [0.6741, 0.3259],
        [0.6931, 0.3069],
        [0.5711, 0.4289],
        [0.6727, 0.3273],
        [0.6260, 0.3740],
        [0.6618, 0.3382],
        [0.6882, 0.3118],
        [0.7214, 0.2786],
        [0.6842, 0.3158],
        [0.7094, 0.2906],
        [0.6702, 0.3298],
        [0.7235, 0.2765],
        [0.6963, 0.3037],
        [0.6135, 0.3865],
        [0.7116, 0.2884],
        [0.6742, 0.3258],
        [0.6402, 0.3598],
        [0.6552, 0.3448],
        [0.6655, 0.3345],
        [0.6815, 0.3185],
        [0.6431, 0.3569],
        [0.6053, 0.3947],
        [0.6776, 0.3224],
        [0.6716, 0.3284],
        [0.6436, 0.3564],
        [0.6578, 0.3422],
        [0.6764, 0.3236],
        [0.6647, 0.3353],
        [0.6692, 0.3308],
        [0.6250, 0.3750],
        [0.6604, 0.3396],
        [0.7118, 0.2882],
        [0.6926, 0.3074],
        [0.6268, 0.3732],
        [0.6808, 0.3192],
        [0.6944, 0.3056],
        [0.6538, 0.3462],
        [0.6694, 0.3306],
        [0.6998, 0.3002],
        [0.6171, 0.3829],
        [0.6186, 0.3814],
        [0.5822, 0.4178],
        [0.7141, 0.2859],
        [0.7045, 0.2955],
        [0.6591, 0.3409],
        [0.6284, 0.3716],
        [0.5894, 0.4106],
        [0.6354, 0.3646],
        [0.7274, 0.2726],
        [0.6796, 0.3204],
        [0.6525, 0.3475],
        [0.6436, 0.3564],
        [0.6590, 0.3410],
        [0.6392, 0.3608],
        [0.6842, 0.3158],
        [0.5850, 0.4150],
        [0.7331, 0.2669],
        [0.7294, 0.2706],
        [0.6324, 0.3676],
        [0.7198, 0.2802],
        [0.7165, 0.2835],
        [0.6068, 0.3932],
        [0.6579, 0.3421],
        [0.6331, 0.3669],
        [0.7268, 0.2732],
        [0.7347, 0.2653],
        [0.6835, 0.3165],
        [0.6969, 0.3031],
        [0.6658, 0.3342],
        [0.6759, 0.3241],
        [0.6830, 0.3170],
        [0.6075, 0.3925],
        [0.6827, 0.3173],
        [0.6592, 0.3408],
        [0.6290, 0.3710],
        [0.6681, 0.3319],
        [0.7040, 0.2960],
        [0.6904, 0.3096],
        [0.6457, 0.3543],
        [0.6963, 0.3037],
        [0.5827, 0.4173],
        [0.6345, 0.3655],
        [0.7213, 0.2787],
        [0.7022, 0.2978],
        [0.6761, 0.3239],
        [0.6538, 0.3462],
        [0.6486, 0.3514],
        [0.6911, 0.3089],
        [0.6020, 0.3980],
        [0.7129, 0.2871],
        [0.6656, 0.3344],
        [0.6613, 0.3387],
        [0.6978, 0.3022],
        [0.7140, 0.2860],
        [0.6663, 0.3337],
        [0.6507, 0.3493],
        [0.6761, 0.3239],
        [0.6253, 0.3747],
        [0.7048, 0.2952],
        [0.7025, 0.2975],
        [0.6570, 0.3430],
        [0.6919, 0.3081],
        [0.6053, 0.3947],
        [0.6520, 0.3480],
        [0.7092, 0.2908],
        [0.6898, 0.3102],
        [0.6483, 0.3517],
        [0.6813, 0.3187],
        [0.6224, 0.3776],
        [0.7111, 0.2889],
        [0.6454, 0.3546],
        [0.6767, 0.3233],
        [0.6403, 0.3597],
        [0.6597, 0.3403],
        [0.6712, 0.3288],
        [0.6811, 0.3189],
        [0.6341, 0.3659],
        [0.6730, 0.3270],
        [0.6779, 0.3221],
        [0.6214, 0.3786],
        [0.6155, 0.3845],
        [0.6896, 0.3104],
        [0.6093, 0.3907],
        [0.6778, 0.3222],
        [0.7361, 0.2639],
        [0.6523, 0.3477],
        [0.6217, 0.3783],
        [0.6817, 0.3183],
        [0.6811, 0.3189],
        [0.7126, 0.2874]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0018 loss: 0.6569 acc_train: 0.6103 time: 0.1235s
tensor([[0.6869, 0.3131],
        [0.6541, 0.3459],
        [0.6970, 0.3030],
        [0.6748, 0.3252],
        [0.7230, 0.2770],
        [0.6434, 0.3566],
        [0.6648, 0.3352],
        [0.6717, 0.3283],
        [0.6449, 0.3551],
        [0.6597, 0.3403],
        [0.6561, 0.3439],
        [0.7041, 0.2959],
        [0.6666, 0.3334],
        [0.6453, 0.3547],
        [0.6789, 0.3211],
        [0.6031, 0.3969],
        [0.6882, 0.3118],
        [0.6910, 0.3090],
        [0.6117, 0.3883],
        [0.6363, 0.3637],
        [0.6643, 0.3357],
        [0.6735, 0.3265],
        [0.6901, 0.3099],
        [0.7006, 0.2994],
        [0.6739, 0.3261],
        [0.5947, 0.4053],
        [0.6254, 0.3746],
        [0.6828, 0.3172],
        [0.6324, 0.3676],
        [0.6145, 0.3855],
        [0.6263, 0.3737],
        [0.6391, 0.3609],
        [0.6881, 0.3119],
        [0.6813, 0.3187],
        [0.6674, 0.3326],
        [0.6622, 0.3378],
        [0.6190, 0.3810],
        [0.6156, 0.3844],
        [0.6739, 0.3261],
        [0.6711, 0.3289],
        [0.6810, 0.3190],
        [0.6246, 0.3754],
        [0.6102, 0.3898],
        [0.6648, 0.3352],
        [0.7130, 0.2870],
        [0.6660, 0.3340],
        [0.7163, 0.2837],
        [0.6879, 0.3121],
        [0.6503, 0.3497],
        [0.6848, 0.3152],
        [0.6800, 0.3200],
        [0.6870, 0.3130],
        [0.6566, 0.3434],
        [0.6595, 0.3405],
        [0.6359, 0.3641],
        [0.7110, 0.2890],
        [0.6384, 0.3616],
        [0.6463, 0.3537],
        [0.7001, 0.2999],
        [0.6615, 0.3385],
        [0.6014, 0.3986],
        [0.6395, 0.3605],
        [0.7044, 0.2956],
        [0.6946, 0.3054],
        [0.6391, 0.3609],
        [0.6406, 0.3594],
        [0.6467, 0.3533],
        [0.6065, 0.3935],
        [0.6529, 0.3471],
        [0.6500, 0.3500],
        [0.6470, 0.3530],
        [0.6792, 0.3208],
        [0.6950, 0.3050],
        [0.6965, 0.3035],
        [0.6303, 0.3697],
        [0.6429, 0.3571],
        [0.6977, 0.3023],
        [0.6779, 0.3221],
        [0.6216, 0.3784],
        [0.6666, 0.3334],
        [0.6677, 0.3323],
        [0.6929, 0.3071],
        [0.6112, 0.3888],
        [0.6629, 0.3371],
        [0.6412, 0.3588],
        [0.6204, 0.3796],
        [0.6487, 0.3513],
        [0.6739, 0.3261],
        [0.6833, 0.3167],
        [0.6710, 0.3290],
        [0.6917, 0.3083],
        [0.6771, 0.3229],
        [0.6921, 0.3079],
        [0.6059, 0.3941],
        [0.6696, 0.3304],
        [0.7182, 0.2818],
        [0.7044, 0.2956],
        [0.5958, 0.4042],
        [0.7088, 0.2912],
        [0.6415, 0.3585],
        [0.6995, 0.3005],
        [0.6734, 0.3266],
        [0.6021, 0.3979],
        [0.6346, 0.3654],
        [0.6543, 0.3457],
        [0.6852, 0.3148],
        [0.6716, 0.3284],
        [0.6960, 0.3040],
        [0.6295, 0.3705],
        [0.7244, 0.2756],
        [0.6400, 0.3600],
        [0.6268, 0.3732],
        [0.6737, 0.3263],
        [0.6824, 0.3176],
        [0.6377, 0.3623],
        [0.6833, 0.3167],
        [0.7042, 0.2958],
        [0.6807, 0.3193],
        [0.6685, 0.3315],
        [0.6813, 0.3187],
        [0.6116, 0.3884],
        [0.6024, 0.3976],
        [0.6997, 0.3003],
        [0.6802, 0.3198],
        [0.6320, 0.3680],
        [0.6654, 0.3346],
        [0.5800, 0.4200],
        [0.6993, 0.3007],
        [0.6386, 0.3614],
        [0.6850, 0.3150],
        [0.6762, 0.3238],
        [0.6242, 0.3758],
        [0.6512, 0.3488],
        [0.6656, 0.3344],
        [0.6911, 0.3089],
        [0.6172, 0.3828],
        [0.6120, 0.3880],
        [0.6351, 0.3649],
        [0.6720, 0.3280],
        [0.6641, 0.3359],
        [0.6049, 0.3951],
        [0.6580, 0.3420],
        [0.6746, 0.3254],
        [0.6906, 0.3094],
        [0.5814, 0.4186],
        [0.6712, 0.3288],
        [0.6295, 0.3705],
        [0.6619, 0.3381],
        [0.6852, 0.3148],
        [0.7159, 0.2841],
        [0.6819, 0.3181],
        [0.7049, 0.2951],
        [0.6705, 0.3295],
        [0.7176, 0.2824],
        [0.6938, 0.3062],
        [0.6192, 0.3808],
        [0.7062, 0.2938],
        [0.6740, 0.3260],
        [0.6438, 0.3562],
        [0.6556, 0.3444],
        [0.6656, 0.3344],
        [0.6790, 0.3210],
        [0.6458, 0.3542],
        [0.6119, 0.3881],
        [0.6746, 0.3254],
        [0.6706, 0.3294],
        [0.6459, 0.3541],
        [0.6590, 0.3410],
        [0.6757, 0.3243],
        [0.6655, 0.3345],
        [0.6672, 0.3328],
        [0.6295, 0.3705],
        [0.6606, 0.3394],
        [0.7073, 0.2927],
        [0.6899, 0.3101],
        [0.6308, 0.3692],
        [0.6783, 0.3217],
        [0.6902, 0.3098],
        [0.6562, 0.3438],
        [0.6685, 0.3315],
        [0.6962, 0.3038],
        [0.6223, 0.3777],
        [0.6228, 0.3772],
        [0.5912, 0.4088],
        [0.7098, 0.2902],
        [0.7004, 0.2996],
        [0.6609, 0.3391],
        [0.6319, 0.3681],
        [0.5979, 0.4021],
        [0.6390, 0.3610],
        [0.7204, 0.2796],
        [0.6776, 0.3224],
        [0.6537, 0.3463],
        [0.6458, 0.3542],
        [0.6597, 0.3403],
        [0.6414, 0.3586],
        [0.6817, 0.3183],
        [0.5942, 0.4058],
        [0.7267, 0.2733],
        [0.7236, 0.2764],
        [0.6373, 0.3627],
        [0.7151, 0.2849],
        [0.7118, 0.2882],
        [0.6135, 0.3865],
        [0.6575, 0.3425],
        [0.6369, 0.3631],
        [0.7200, 0.2800],
        [0.7280, 0.2720],
        [0.6820, 0.3180],
        [0.6939, 0.3061],
        [0.6653, 0.3347],
        [0.6747, 0.3253],
        [0.6810, 0.3190],
        [0.6144, 0.3856],
        [0.6812, 0.3188],
        [0.6593, 0.3407],
        [0.6333, 0.3667],
        [0.6674, 0.3326],
        [0.6994, 0.3006],
        [0.6879, 0.3121],
        [0.6480, 0.3520],
        [0.6937, 0.3063],
        [0.5918, 0.4082],
        [0.6377, 0.3623],
        [0.7160, 0.2840],
        [0.6993, 0.3007],
        [0.6735, 0.3265],
        [0.6564, 0.3436],
        [0.6500, 0.3500],
        [0.6880, 0.3120],
        [0.6084, 0.3916],
        [0.7085, 0.2915],
        [0.6651, 0.3349],
        [0.6618, 0.3382],
        [0.6942, 0.3058],
        [0.7097, 0.2903],
        [0.6666, 0.3334],
        [0.6518, 0.3482],
        [0.6736, 0.3264],
        [0.6288, 0.3712],
        [0.7009, 0.2991],
        [0.6990, 0.3010],
        [0.6577, 0.3423],
        [0.6885, 0.3115],
        [0.6108, 0.3892],
        [0.6540, 0.3460],
        [0.7046, 0.2954],
        [0.6874, 0.3126],
        [0.6499, 0.3501],
        [0.6790, 0.3210],
        [0.6266, 0.3734],
        [0.7059, 0.2941],
        [0.6471, 0.3529],
        [0.6758, 0.3242],
        [0.6433, 0.3567],
        [0.6608, 0.3392],
        [0.6704, 0.3296],
        [0.6797, 0.3203],
        [0.6377, 0.3623],
        [0.6721, 0.3279],
        [0.6766, 0.3234],
        [0.6261, 0.3739],
        [0.6207, 0.3793],
        [0.6868, 0.3132],
        [0.6151, 0.3849],
        [0.6758, 0.3242],
        [0.7291, 0.2709],
        [0.6546, 0.3454],
        [0.6261, 0.3739],
        [0.6799, 0.3201],
        [0.6798, 0.3202],
        [0.7075, 0.2925]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0019 loss: 0.6584 acc_train: 0.6103 time: 0.1258s
tensor([[0.6844, 0.3156],
        [0.6552, 0.3448],
        [0.6935, 0.3065],
        [0.6742, 0.3258],
        [0.7165, 0.2835],
        [0.6460, 0.3540],
        [0.6648, 0.3352],
        [0.6704, 0.3296],
        [0.6465, 0.3535],
        [0.6603, 0.3397],
        [0.6568, 0.3432],
        [0.7002, 0.2998],
        [0.6668, 0.3332],
        [0.6473, 0.3527],
        [0.6770, 0.3230],
        [0.6102, 0.3898],
        [0.6856, 0.3144],
        [0.6878, 0.3122],
        [0.6178, 0.3822],
        [0.6393, 0.3607],
        [0.6645, 0.3355],
        [0.6716, 0.3284],
        [0.6870, 0.3130],
        [0.6966, 0.3034],
        [0.6726, 0.3274],
        [0.6028, 0.3972],
        [0.6305, 0.3695],
        [0.6794, 0.3206],
        [0.6366, 0.3634],
        [0.6206, 0.3794],
        [0.6306, 0.3694],
        [0.6421, 0.3579],
        [0.6853, 0.3147],
        [0.6800, 0.3200],
        [0.6673, 0.3327],
        [0.6606, 0.3394],
        [0.6250, 0.3750],
        [0.6216, 0.3784],
        [0.6727, 0.3273],
        [0.6713, 0.3287],
        [0.6788, 0.3212],
        [0.6298, 0.3702],
        [0.6156, 0.3844],
        [0.6643, 0.3357],
        [0.7073, 0.2927],
        [0.6654, 0.3346],
        [0.7108, 0.2892],
        [0.6855, 0.3145],
        [0.6517, 0.3483],
        [0.6831, 0.3169],
        [0.6775, 0.3225],
        [0.6835, 0.3165],
        [0.6588, 0.3412],
        [0.6598, 0.3402],
        [0.6388, 0.3612],
        [0.7053, 0.2947],
        [0.6411, 0.3589],
        [0.6490, 0.3510],
        [0.6964, 0.3036],
        [0.6614, 0.3386],
        [0.6084, 0.3916],
        [0.6417, 0.3583],
        [0.7002, 0.2998],
        [0.6910, 0.3090],
        [0.6429, 0.3571],
        [0.6441, 0.3559],
        [0.6484, 0.3516],
        [0.6138, 0.3862],
        [0.6541, 0.3459],
        [0.6524, 0.3476],
        [0.6488, 0.3512],
        [0.6783, 0.3217],
        [0.6918, 0.3082],
        [0.6916, 0.3084],
        [0.6348, 0.3652],
        [0.6459, 0.3541],
        [0.6935, 0.3065],
        [0.6767, 0.3233],
        [0.6266, 0.3734],
        [0.6671, 0.3329],
        [0.6678, 0.3322],
        [0.6899, 0.3101],
        [0.6177, 0.3823],
        [0.6627, 0.3373],
        [0.6432, 0.3568],
        [0.6259, 0.3741],
        [0.6498, 0.3502],
        [0.6731, 0.3269],
        [0.6814, 0.3186],
        [0.6703, 0.3297],
        [0.6888, 0.3112],
        [0.6761, 0.3239],
        [0.6890, 0.3110],
        [0.6135, 0.3865],
        [0.6680, 0.3320],
        [0.7121, 0.2879],
        [0.7005, 0.2995],
        [0.6040, 0.3960],
        [0.7044, 0.2956],
        [0.6437, 0.3563],
        [0.6956, 0.3044],
        [0.6734, 0.3266],
        [0.6094, 0.3906],
        [0.6372, 0.3628],
        [0.6552, 0.3448],
        [0.6827, 0.3173],
        [0.6715, 0.3285],
        [0.6927, 0.3073],
        [0.6339, 0.3661],
        [0.7172, 0.2828],
        [0.6411, 0.3589],
        [0.6312, 0.3688],
        [0.6733, 0.3267],
        [0.6804, 0.3196],
        [0.6403, 0.3597],
        [0.6800, 0.3200],
        [0.6996, 0.3004],
        [0.6794, 0.3206],
        [0.6680, 0.3320],
        [0.6788, 0.3212],
        [0.6182, 0.3818],
        [0.6100, 0.3900],
        [0.6959, 0.3041],
        [0.6782, 0.3218],
        [0.6355, 0.3645],
        [0.6651, 0.3349],
        [0.5905, 0.4095],
        [0.6959, 0.3041],
        [0.6409, 0.3591],
        [0.6833, 0.3167],
        [0.6744, 0.3256],
        [0.6289, 0.3711],
        [0.6528, 0.3472],
        [0.6658, 0.3342],
        [0.6880, 0.3120],
        [0.6235, 0.3765],
        [0.6181, 0.3819],
        [0.6390, 0.3610],
        [0.6719, 0.3281],
        [0.6644, 0.3356],
        [0.6114, 0.3886],
        [0.6595, 0.3405],
        [0.6748, 0.3252],
        [0.6879, 0.3121],
        [0.5914, 0.4086],
        [0.6698, 0.3302],
        [0.6331, 0.3669],
        [0.6620, 0.3380],
        [0.6821, 0.3179],
        [0.7102, 0.2898],
        [0.6793, 0.3207],
        [0.7002, 0.2998],
        [0.6707, 0.3293],
        [0.7116, 0.2884],
        [0.6912, 0.3088],
        [0.6247, 0.3753],
        [0.7007, 0.2993],
        [0.6737, 0.3263],
        [0.6470, 0.3530],
        [0.6557, 0.3443],
        [0.6656, 0.3344],
        [0.6765, 0.3235],
        [0.6483, 0.3517],
        [0.6182, 0.3818],
        [0.6716, 0.3284],
        [0.6698, 0.3302],
        [0.6479, 0.3521],
        [0.6599, 0.3401],
        [0.6749, 0.3251],
        [0.6662, 0.3338],
        [0.6654, 0.3346],
        [0.6335, 0.3665],
        [0.6607, 0.3393],
        [0.7027, 0.2973],
        [0.6872, 0.3128],
        [0.6347, 0.3653],
        [0.6759, 0.3241],
        [0.6859, 0.3141],
        [0.6582, 0.3418],
        [0.6676, 0.3324],
        [0.6925, 0.3075],
        [0.6275, 0.3725],
        [0.6269, 0.3731],
        [0.5998, 0.4002],
        [0.7053, 0.2947],
        [0.6961, 0.3039],
        [0.6623, 0.3377],
        [0.6351, 0.3649],
        [0.6060, 0.3940],
        [0.6426, 0.3574],
        [0.7137, 0.2863],
        [0.6758, 0.3242],
        [0.6549, 0.3451],
        [0.6480, 0.3520],
        [0.6602, 0.3398],
        [0.6437, 0.3563],
        [0.6794, 0.3206],
        [0.6032, 0.3968],
        [0.7201, 0.2799],
        [0.7177, 0.2823],
        [0.6415, 0.3585],
        [0.7100, 0.2900],
        [0.7070, 0.2930],
        [0.6197, 0.3803],
        [0.6573, 0.3427],
        [0.6406, 0.3594],
        [0.7134, 0.2866],
        [0.7210, 0.2790],
        [0.6803, 0.3197],
        [0.6910, 0.3090],
        [0.6650, 0.3350],
        [0.6736, 0.3264],
        [0.6788, 0.3212],
        [0.6210, 0.3790],
        [0.6796, 0.3204],
        [0.6592, 0.3408],
        [0.6373, 0.3627],
        [0.6664, 0.3336],
        [0.6949, 0.3051],
        [0.6851, 0.3149],
        [0.6501, 0.3499],
        [0.6911, 0.3089],
        [0.6004, 0.3996],
        [0.6409, 0.3591],
        [0.7106, 0.2894],
        [0.6963, 0.3037],
        [0.6709, 0.3291],
        [0.6585, 0.3415],
        [0.6511, 0.3489],
        [0.6848, 0.3152],
        [0.6148, 0.3852],
        [0.7040, 0.2960],
        [0.6648, 0.3352],
        [0.6623, 0.3377],
        [0.6903, 0.3097],
        [0.7053, 0.2947],
        [0.6668, 0.3332],
        [0.6529, 0.3471],
        [0.6715, 0.3285],
        [0.6325, 0.3675],
        [0.6968, 0.3032],
        [0.6952, 0.3048],
        [0.6581, 0.3419],
        [0.6849, 0.3151],
        [0.6166, 0.3834],
        [0.6558, 0.3442],
        [0.7000, 0.3000],
        [0.6848, 0.3152],
        [0.6516, 0.3484],
        [0.6767, 0.3233],
        [0.6307, 0.3693],
        [0.7006, 0.2994],
        [0.6485, 0.3515],
        [0.6746, 0.3254],
        [0.6463, 0.3537],
        [0.6618, 0.3382],
        [0.6698, 0.3302],
        [0.6781, 0.3219],
        [0.6410, 0.3590],
        [0.6713, 0.3287],
        [0.6754, 0.3246],
        [0.6305, 0.3695],
        [0.6258, 0.3742],
        [0.6840, 0.3160],
        [0.6206, 0.3794],
        [0.6735, 0.3265],
        [0.7221, 0.2779],
        [0.6567, 0.3433],
        [0.6302, 0.3698],
        [0.6782, 0.3218],
        [0.6784, 0.3216],
        [0.7027, 0.2973]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0020 loss: 0.6599 acc_train: 0.6103 time: 0.1145s
tensor([[0.6811, 0.3189],
        [0.6556, 0.3444],
        [0.6894, 0.3106],
        [0.6726, 0.3274],
        [0.7097, 0.2903],
        [0.6476, 0.3524],
        [0.6641, 0.3359],
        [0.6685, 0.3315],
        [0.6476, 0.3524],
        [0.6600, 0.3400],
        [0.6570, 0.3430],
        [0.6955, 0.3045],
        [0.6661, 0.3339],
        [0.6487, 0.3513],
        [0.6746, 0.3254],
        [0.6161, 0.3839],
        [0.6827, 0.3173],
        [0.6839, 0.3161],
        [0.6231, 0.3769],
        [0.6414, 0.3586],
        [0.6643, 0.3357],
        [0.6690, 0.3310],
        [0.6832, 0.3168],
        [0.6920, 0.3080],
        [0.6704, 0.3296],
        [0.6098, 0.3902],
        [0.6345, 0.3655],
        [0.6759, 0.3241],
        [0.6398, 0.3602],
        [0.6257, 0.3743],
        [0.6341, 0.3659],
        [0.6441, 0.3559],
        [0.6820, 0.3180],
        [0.6780, 0.3220],
        [0.6666, 0.3334],
        [0.6584, 0.3416],
        [0.6299, 0.3701],
        [0.6267, 0.3733],
        [0.6707, 0.3293],
        [0.6704, 0.3296],
        [0.6763, 0.3237],
        [0.6342, 0.3658],
        [0.6201, 0.3799],
        [0.6631, 0.3369],
        [0.7012, 0.2988],
        [0.6639, 0.3361],
        [0.7048, 0.2952],
        [0.6826, 0.3174],
        [0.6525, 0.3475],
        [0.6808, 0.3192],
        [0.6746, 0.3254],
        [0.6798, 0.3202],
        [0.6598, 0.3402],
        [0.6594, 0.3406],
        [0.6407, 0.3593],
        [0.6992, 0.3008],
        [0.6432, 0.3568],
        [0.6507, 0.3493],
        [0.6919, 0.3081],
        [0.6606, 0.3394],
        [0.6143, 0.3857],
        [0.6433, 0.3567],
        [0.6952, 0.3048],
        [0.6869, 0.3131],
        [0.6456, 0.3544],
        [0.6467, 0.3533],
        [0.6496, 0.3504],
        [0.6200, 0.3800],
        [0.6547, 0.3453],
        [0.6540, 0.3460],
        [0.6499, 0.3501],
        [0.6764, 0.3236],
        [0.6879, 0.3121],
        [0.6865, 0.3135],
        [0.6385, 0.3615],
        [0.6478, 0.3522],
        [0.6886, 0.3114],
        [0.6747, 0.3253],
        [0.6308, 0.3692],
        [0.6665, 0.3335],
        [0.6670, 0.3330],
        [0.6862, 0.3138],
        [0.6234, 0.3766],
        [0.6620, 0.3380],
        [0.6446, 0.3554],
        [0.6304, 0.3696],
        [0.6504, 0.3496],
        [0.6711, 0.3289],
        [0.6789, 0.3211],
        [0.6689, 0.3311],
        [0.6853, 0.3147],
        [0.6742, 0.3258],
        [0.6854, 0.3146],
        [0.6202, 0.3798],
        [0.6658, 0.3342],
        [0.7054, 0.2946],
        [0.6959, 0.3041],
        [0.6110, 0.3890],
        [0.6994, 0.3006],
        [0.6451, 0.3549],
        [0.6912, 0.3088],
        [0.6725, 0.3275],
        [0.6156, 0.3844],
        [0.6395, 0.3605],
        [0.6554, 0.3446],
        [0.6793, 0.3207],
        [0.6706, 0.3294],
        [0.6888, 0.3112],
        [0.6374, 0.3626],
        [0.7098, 0.2902],
        [0.6419, 0.3581],
        [0.6350, 0.3650],
        [0.6723, 0.3277],
        [0.6779, 0.3221],
        [0.6418, 0.3582],
        [0.6762, 0.3238],
        [0.6944, 0.3056],
        [0.6774, 0.3226],
        [0.6670, 0.3330],
        [0.6759, 0.3241],
        [0.6235, 0.3765],
        [0.6164, 0.3836],
        [0.6914, 0.3086],
        [0.6757, 0.3243],
        [0.6383, 0.3617],
        [0.6639, 0.3361],
        [0.5998, 0.4002],
        [0.6917, 0.3083],
        [0.6424, 0.3576],
        [0.6807, 0.3193],
        [0.6720, 0.3280],
        [0.6328, 0.3672],
        [0.6538, 0.3462],
        [0.6651, 0.3349],
        [0.6843, 0.3157],
        [0.6286, 0.3714],
        [0.6232, 0.3768],
        [0.6421, 0.3579],
        [0.6711, 0.3289],
        [0.6638, 0.3362],
        [0.6170, 0.3830],
        [0.6601, 0.3399],
        [0.6739, 0.3261],
        [0.6846, 0.3154],
        [0.6004, 0.3996],
        [0.6680, 0.3320],
        [0.6360, 0.3640],
        [0.6616, 0.3384],
        [0.6785, 0.3215],
        [0.7040, 0.2960],
        [0.6762, 0.3238],
        [0.6952, 0.3048],
        [0.6701, 0.3299],
        [0.7051, 0.2949],
        [0.6879, 0.3121],
        [0.6294, 0.3706],
        [0.6951, 0.3049],
        [0.6726, 0.3274],
        [0.6490, 0.3510],
        [0.6552, 0.3448],
        [0.6651, 0.3349],
        [0.6737, 0.3263],
        [0.6498, 0.3502],
        [0.6235, 0.3765],
        [0.6680, 0.3320],
        [0.6684, 0.3316],
        [0.6492, 0.3508],
        [0.6599, 0.3401],
        [0.6733, 0.3267],
        [0.6661, 0.3339],
        [0.6634, 0.3366],
        [0.6365, 0.3635],
        [0.6598, 0.3402],
        [0.6975, 0.3025],
        [0.6838, 0.3162],
        [0.6379, 0.3621],
        [0.6731, 0.3269],
        [0.6815, 0.3185],
        [0.6592, 0.3408],
        [0.6664, 0.3336],
        [0.6884, 0.3116],
        [0.6317, 0.3683],
        [0.6304, 0.3696],
        [0.6073, 0.3927],
        [0.7002, 0.2998],
        [0.6915, 0.3085],
        [0.6625, 0.3375],
        [0.6377, 0.3623],
        [0.6130, 0.3870],
        [0.6452, 0.3548],
        [0.7065, 0.2935],
        [0.6737, 0.3263],
        [0.6551, 0.3449],
        [0.6492, 0.3508],
        [0.6599, 0.3401],
        [0.6456, 0.3544],
        [0.6766, 0.3234],
        [0.6110, 0.3890],
        [0.7129, 0.2871],
        [0.7113, 0.2887],
        [0.6444, 0.3556],
        [0.7042, 0.2958],
        [0.7015, 0.2985],
        [0.6249, 0.3751],
        [0.6570, 0.3430],
        [0.6435, 0.3565],
        [0.7064, 0.2936],
        [0.7136, 0.2864],
        [0.6778, 0.3222],
        [0.6873, 0.3127],
        [0.6644, 0.3356],
        [0.6718, 0.3282],
        [0.6762, 0.3238],
        [0.6266, 0.3734],
        [0.6774, 0.3226],
        [0.6588, 0.3412],
        [0.6403, 0.3597],
        [0.6647, 0.3353],
        [0.6898, 0.3102],
        [0.6817, 0.3183],
        [0.6515, 0.3485],
        [0.6879, 0.3121],
        [0.6078, 0.3922],
        [0.6434, 0.3566],
        [0.7046, 0.2954],
        [0.6926, 0.3074],
        [0.6676, 0.3324],
        [0.6594, 0.3406],
        [0.6514, 0.3486],
        [0.6811, 0.3189],
        [0.6204, 0.3796],
        [0.6989, 0.3011],
        [0.6641, 0.3359],
        [0.6619, 0.3381],
        [0.6859, 0.3141],
        [0.7004, 0.2996],
        [0.6664, 0.3336],
        [0.6533, 0.3467],
        [0.6693, 0.3307],
        [0.6356, 0.3644],
        [0.6921, 0.3079],
        [0.6906, 0.3094],
        [0.6579, 0.3421],
        [0.6809, 0.3191],
        [0.6217, 0.3783],
        [0.6566, 0.3434],
        [0.6950, 0.3050],
        [0.6817, 0.3183],
        [0.6527, 0.3473],
        [0.6738, 0.3262],
        [0.6340, 0.3660],
        [0.6946, 0.3054],
        [0.6493, 0.3507],
        [0.6727, 0.3273],
        [0.6487, 0.3513],
        [0.6620, 0.3380],
        [0.6687, 0.3313],
        [0.6760, 0.3240],
        [0.6437, 0.3563],
        [0.6699, 0.3301],
        [0.6735, 0.3265],
        [0.6341, 0.3659],
        [0.6301, 0.3699],
        [0.6807, 0.3193],
        [0.6252, 0.3748],
        [0.6708, 0.3292],
        [0.7145, 0.2855],
        [0.6578, 0.3422],
        [0.6333, 0.3667],
        [0.6760, 0.3240],
        [0.6763, 0.3237],
        [0.6974, 0.3026]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0021 loss: 0.6613 acc_train: 0.6103 time: 0.1060s
tensor([[0.6779, 0.3221],
        [0.6559, 0.3441],
        [0.6856, 0.3144],
        [0.6708, 0.3292],
        [0.7031, 0.2969],
        [0.6488, 0.3512],
        [0.6634, 0.3366],
        [0.6667, 0.3333],
        [0.6486, 0.3514],
        [0.6594, 0.3406],
        [0.6573, 0.3427],
        [0.6908, 0.3092],
        [0.6651, 0.3349],
        [0.6499, 0.3501],
        [0.6723, 0.3277],
        [0.6215, 0.3785],
        [0.6798, 0.3202],
        [0.6800, 0.3200],
        [0.6280, 0.3720],
        [0.6433, 0.3567],
        [0.6641, 0.3359],
        [0.6664, 0.3336],
        [0.6796, 0.3204],
        [0.6876, 0.3124],
        [0.6682, 0.3318],
        [0.6163, 0.3837],
        [0.6381, 0.3619],
        [0.6726, 0.3274],
        [0.6425, 0.3575],
        [0.6303, 0.3697],
        [0.6375, 0.3625],
        [0.6457, 0.3543],
        [0.6787, 0.3213],
        [0.6758, 0.3242],
        [0.6659, 0.3341],
        [0.6565, 0.3435],
        [0.6343, 0.3657],
        [0.6315, 0.3685],
        [0.6687, 0.3313],
        [0.6693, 0.3307],
        [0.6738, 0.3262],
        [0.6382, 0.3618],
        [0.6244, 0.3756],
        [0.6620, 0.3380],
        [0.6952, 0.3048],
        [0.6621, 0.3379],
        [0.6989, 0.3011],
        [0.6797, 0.3203],
        [0.6531, 0.3469],
        [0.6784, 0.3216],
        [0.6720, 0.3280],
        [0.6766, 0.3234],
        [0.6604, 0.3396],
        [0.6590, 0.3410],
        [0.6425, 0.3575],
        [0.6934, 0.3066],
        [0.6452, 0.3548],
        [0.6522, 0.3478],
        [0.6876, 0.3124],
        [0.6599, 0.3401],
        [0.6197, 0.3803],
        [0.6448, 0.3552],
        [0.6903, 0.3097],
        [0.6829, 0.3171],
        [0.6479, 0.3521],
        [0.6489, 0.3511],
        [0.6509, 0.3491],
        [0.6258, 0.3742],
        [0.6554, 0.3446],
        [0.6552, 0.3448],
        [0.6508, 0.3492],
        [0.6744, 0.3256],
        [0.6840, 0.3160],
        [0.6819, 0.3181],
        [0.6417, 0.3583],
        [0.6495, 0.3505],
        [0.6839, 0.3161],
        [0.6725, 0.3275],
        [0.6346, 0.3654],
        [0.6656, 0.3344],
        [0.6659, 0.3341],
        [0.6824, 0.3176],
        [0.6287, 0.3713],
        [0.6613, 0.3387],
        [0.6459, 0.3541],
        [0.6343, 0.3657],
        [0.6512, 0.3488],
        [0.6691, 0.3309],
        [0.6763, 0.3237],
        [0.6674, 0.3326],
        [0.6816, 0.3184],
        [0.6723, 0.3277],
        [0.6817, 0.3183],
        [0.6262, 0.3738],
        [0.6638, 0.3362],
        [0.6990, 0.3010],
        [0.6915, 0.3085],
        [0.6174, 0.3826],
        [0.6947, 0.3053],
        [0.6467, 0.3533],
        [0.6870, 0.3130],
        [0.6711, 0.3289],
        [0.6214, 0.3786],
        [0.6419, 0.3581],
        [0.6557, 0.3443],
        [0.6762, 0.3238],
        [0.6692, 0.3308],
        [0.6849, 0.3151],
        [0.6404, 0.3596],
        [0.7027, 0.2973],
        [0.6429, 0.3571],
        [0.6386, 0.3614],
        [0.6711, 0.3289],
        [0.6754, 0.3246],
        [0.6430, 0.3570],
        [0.6725, 0.3275],
        [0.6892, 0.3108],
        [0.6754, 0.3246],
        [0.6662, 0.3338],
        [0.6733, 0.3267],
        [0.6282, 0.3718],
        [0.6222, 0.3778],
        [0.6870, 0.3130],
        [0.6731, 0.3269],
        [0.6409, 0.3591],
        [0.6628, 0.3372],
        [0.6084, 0.3916],
        [0.6874, 0.3126],
        [0.6439, 0.3561],
        [0.6781, 0.3219],
        [0.6698, 0.3302],
        [0.6364, 0.3636],
        [0.6548, 0.3452],
        [0.6642, 0.3358],
        [0.6806, 0.3194],
        [0.6331, 0.3669],
        [0.6278, 0.3722],
        [0.6448, 0.3552],
        [0.6700, 0.3300],
        [0.6630, 0.3370],
        [0.6223, 0.3777],
        [0.6603, 0.3397],
        [0.6726, 0.3274],
        [0.6812, 0.3188],
        [0.6086, 0.3914],
        [0.6664, 0.3336],
        [0.6388, 0.3612],
        [0.6613, 0.3387],
        [0.6751, 0.3249],
        [0.6979, 0.3021],
        [0.6733, 0.3267],
        [0.6905, 0.3095],
        [0.6692, 0.3308],
        [0.6988, 0.3012],
        [0.6847, 0.3153],
        [0.6336, 0.3664],
        [0.6899, 0.3101],
        [0.6713, 0.3287],
        [0.6506, 0.3494],
        [0.6546, 0.3454],
        [0.6646, 0.3354],
        [0.6713, 0.3287],
        [0.6512, 0.3488],
        [0.6281, 0.3719],
        [0.6647, 0.3353],
        [0.6669, 0.3331],
        [0.6504, 0.3496],
        [0.6595, 0.3405],
        [0.6715, 0.3285],
        [0.6658, 0.3342],
        [0.6617, 0.3383],
        [0.6392, 0.3608],
        [0.6588, 0.3412],
        [0.6921, 0.3079],
        [0.6802, 0.3198],
        [0.6408, 0.3592],
        [0.6706, 0.3294],
        [0.6774, 0.3226],
        [0.6598, 0.3402],
        [0.6655, 0.3345],
        [0.6842, 0.3158],
        [0.6355, 0.3645],
        [0.6338, 0.3662],
        [0.6142, 0.3858],
        [0.6951, 0.3049],
        [0.6871, 0.3129],
        [0.6623, 0.3377],
        [0.6400, 0.3600],
        [0.6193, 0.3807],
        [0.6476, 0.3524],
        [0.6998, 0.3002],
        [0.6716, 0.3284],
        [0.6550, 0.3450],
        [0.6503, 0.3497],
        [0.6594, 0.3406],
        [0.6474, 0.3526],
        [0.6740, 0.3260],
        [0.6181, 0.3819],
        [0.7057, 0.2943],
        [0.7050, 0.2950],
        [0.6466, 0.3534],
        [0.6984, 0.3016],
        [0.6959, 0.3041],
        [0.6295, 0.3705],
        [0.6570, 0.3430],
        [0.6460, 0.3540],
        [0.6998, 0.3002],
        [0.7065, 0.2935],
        [0.6750, 0.3250],
        [0.6837, 0.3163],
        [0.6640, 0.3360],
        [0.6699, 0.3301],
        [0.6739, 0.3261],
        [0.6316, 0.3684],
        [0.6751, 0.3249],
        [0.6584, 0.3416],
        [0.6428, 0.3572],
        [0.6630, 0.3370],
        [0.6850, 0.3150],
        [0.6787, 0.3213],
        [0.6526, 0.3474],
        [0.6848, 0.3152],
        [0.6144, 0.3856],
        [0.6457, 0.3543],
        [0.6989, 0.3011],
        [0.6889, 0.3111],
        [0.6644, 0.3356],
        [0.6600, 0.3400],
        [0.6516, 0.3484],
        [0.6777, 0.3223],
        [0.6258, 0.3742],
        [0.6941, 0.3059],
        [0.6635, 0.3365],
        [0.6613, 0.3387],
        [0.6818, 0.3182],
        [0.6953, 0.3047],
        [0.6659, 0.3341],
        [0.6539, 0.3461],
        [0.6674, 0.3326],
        [0.6386, 0.3614],
        [0.6876, 0.3124],
        [0.6860, 0.3140],
        [0.6577, 0.3423],
        [0.6772, 0.3228],
        [0.6265, 0.3735],
        [0.6572, 0.3428],
        [0.6901, 0.3099],
        [0.6785, 0.3215],
        [0.6535, 0.3465],
        [0.6711, 0.3289],
        [0.6370, 0.3630],
        [0.6889, 0.3111],
        [0.6500, 0.3500],
        [0.6707, 0.3293],
        [0.6509, 0.3491],
        [0.6620, 0.3380],
        [0.6675, 0.3325],
        [0.6739, 0.3261],
        [0.6462, 0.3538],
        [0.6686, 0.3314],
        [0.6717, 0.3283],
        [0.6374, 0.3626],
        [0.6341, 0.3659],
        [0.6775, 0.3225],
        [0.6295, 0.3705],
        [0.6682, 0.3318],
        [0.7071, 0.2929],
        [0.6585, 0.3415],
        [0.6359, 0.3641],
        [0.6739, 0.3261],
        [0.6741, 0.3259],
        [0.6923, 0.3077]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0022 loss: 0.6627 acc_train: 0.6103 time: 0.1072s
tensor([[0.6749, 0.3251],
        [0.6562, 0.3438],
        [0.6821, 0.3179],
        [0.6691, 0.3309],
        [0.6970, 0.3030],
        [0.6500, 0.3500],
        [0.6627, 0.3373],
        [0.6652, 0.3348],
        [0.6495, 0.3505],
        [0.6590, 0.3410],
        [0.6575, 0.3425],
        [0.6865, 0.3135],
        [0.6640, 0.3360],
        [0.6509, 0.3491],
        [0.6704, 0.3296],
        [0.6265, 0.3735],
        [0.6772, 0.3228],
        [0.6765, 0.3235],
        [0.6325, 0.3675],
        [0.6450, 0.3550],
        [0.6639, 0.3361],
        [0.6642, 0.3358],
        [0.6764, 0.3236],
        [0.6835, 0.3165],
        [0.6662, 0.3338],
        [0.6222, 0.3778],
        [0.6413, 0.3587],
        [0.6697, 0.3303],
        [0.6449, 0.3551],
        [0.6344, 0.3656],
        [0.6406, 0.3594],
        [0.6471, 0.3529],
        [0.6758, 0.3242],
        [0.6737, 0.3263],
        [0.6652, 0.3348],
        [0.6547, 0.3453],
        [0.6382, 0.3618],
        [0.6359, 0.3641],
        [0.6670, 0.3330],
        [0.6682, 0.3318],
        [0.6714, 0.3286],
        [0.6418, 0.3582],
        [0.6281, 0.3719],
        [0.6610, 0.3390],
        [0.6897, 0.3103],
        [0.6605, 0.3395],
        [0.6934, 0.3066],
        [0.6772, 0.3228],
        [0.6537, 0.3463],
        [0.6761, 0.3239],
        [0.6697, 0.3303],
        [0.6738, 0.3262],
        [0.6606, 0.3394],
        [0.6585, 0.3415],
        [0.6442, 0.3558],
        [0.6882, 0.3118],
        [0.6472, 0.3528],
        [0.6534, 0.3466],
        [0.6835, 0.3165],
        [0.6594, 0.3406],
        [0.6246, 0.3754],
        [0.6461, 0.3539],
        [0.6858, 0.3142],
        [0.6794, 0.3206],
        [0.6498, 0.3502],
        [0.6506, 0.3494],
        [0.6521, 0.3479],
        [0.6311, 0.3689],
        [0.6561, 0.3439],
        [0.6562, 0.3438],
        [0.6516, 0.3484],
        [0.6724, 0.3276],
        [0.6805, 0.3195],
        [0.6779, 0.3221],
        [0.6446, 0.3554],
        [0.6508, 0.3492],
        [0.6798, 0.3202],
        [0.6705, 0.3295],
        [0.6381, 0.3619],
        [0.6647, 0.3353],
        [0.6648, 0.3352],
        [0.6788, 0.3212],
        [0.6334, 0.3666],
        [0.6607, 0.3393],
        [0.6472, 0.3528],
        [0.6378, 0.3622],
        [0.6519, 0.3481],
        [0.6671, 0.3329],
        [0.6739, 0.3261],
        [0.6659, 0.3341],
        [0.6781, 0.3219],
        [0.6704, 0.3296],
        [0.6783, 0.3217],
        [0.6315, 0.3685],
        [0.6620, 0.3380],
        [0.6930, 0.3070],
        [0.6874, 0.3126],
        [0.6231, 0.3769],
        [0.6902, 0.3098],
        [0.6483, 0.3517],
        [0.6831, 0.3169],
        [0.6698, 0.3302],
        [0.6266, 0.3734],
        [0.6442, 0.3558],
        [0.6559, 0.3441],
        [0.6734, 0.3266],
        [0.6678, 0.3322],
        [0.6813, 0.3187],
        [0.6432, 0.3568],
        [0.6963, 0.3037],
        [0.6439, 0.3561],
        [0.6419, 0.3581],
        [0.6698, 0.3302],
        [0.6731, 0.3269],
        [0.6440, 0.3560],
        [0.6691, 0.3309],
        [0.6846, 0.3154],
        [0.6734, 0.3266],
        [0.6654, 0.3346],
        [0.6709, 0.3291],
        [0.6322, 0.3678],
        [0.6274, 0.3726],
        [0.6831, 0.3169],
        [0.6708, 0.3292],
        [0.6434, 0.3566],
        [0.6617, 0.3383],
        [0.6161, 0.3839],
        [0.6835, 0.3165],
        [0.6454, 0.3546],
        [0.6755, 0.3245],
        [0.6679, 0.3321],
        [0.6395, 0.3605],
        [0.6557, 0.3443],
        [0.6633, 0.3367],
        [0.6772, 0.3228],
        [0.6370, 0.3630],
        [0.6320, 0.3680],
        [0.6473, 0.3527],
        [0.6690, 0.3310],
        [0.6621, 0.3379],
        [0.6272, 0.3728],
        [0.6602, 0.3398],
        [0.6711, 0.3289],
        [0.6780, 0.3220],
        [0.6160, 0.3840],
        [0.6651, 0.3349],
        [0.6414, 0.3586],
        [0.6612, 0.3388],
        [0.6723, 0.3277],
        [0.6924, 0.3076],
        [0.6707, 0.3293],
        [0.6861, 0.3139],
        [0.6682, 0.3318],
        [0.6930, 0.3070],
        [0.6818, 0.3182],
        [0.6374, 0.3626],
        [0.6853, 0.3147],
        [0.6699, 0.3301],
        [0.6518, 0.3482],
        [0.6540, 0.3460],
        [0.6642, 0.3358],
        [0.6692, 0.3308],
        [0.6525, 0.3475],
        [0.6324, 0.3676],
        [0.6618, 0.3382],
        [0.6655, 0.3345],
        [0.6516, 0.3484],
        [0.6591, 0.3409],
        [0.6697, 0.3303],
        [0.6653, 0.3347],
        [0.6602, 0.3398],
        [0.6415, 0.3585],
        [0.6578, 0.3422],
        [0.6871, 0.3129],
        [0.6770, 0.3230],
        [0.6436, 0.3564],
        [0.6686, 0.3314],
        [0.6737, 0.3263],
        [0.6603, 0.3397],
        [0.6647, 0.3353],
        [0.6803, 0.3197],
        [0.6389, 0.3611],
        [0.6369, 0.3631],
        [0.6205, 0.3795],
        [0.6904, 0.3096],
        [0.6832, 0.3168],
        [0.6621, 0.3379],
        [0.6423, 0.3577],
        [0.6251, 0.3749],
        [0.6496, 0.3504],
        [0.6935, 0.3065],
        [0.6697, 0.3303],
        [0.6549, 0.3451],
        [0.6514, 0.3486],
        [0.6591, 0.3409],
        [0.6489, 0.3511],
        [0.6714, 0.3286],
        [0.6244, 0.3756],
        [0.6992, 0.3008],
        [0.6990, 0.3010],
        [0.6485, 0.3515],
        [0.6929, 0.3071],
        [0.6908, 0.3092],
        [0.6336, 0.3664],
        [0.6572, 0.3428],
        [0.6483, 0.3517],
        [0.6939, 0.3061],
        [0.6999, 0.3001],
        [0.6724, 0.3276],
        [0.6804, 0.3196],
        [0.6637, 0.3363],
        [0.6680, 0.3320],
        [0.6717, 0.3283],
        [0.6359, 0.3641],
        [0.6730, 0.3270],
        [0.6582, 0.3418],
        [0.6450, 0.3550],
        [0.6615, 0.3385],
        [0.6806, 0.3194],
        [0.6760, 0.3240],
        [0.6537, 0.3463],
        [0.6817, 0.3183],
        [0.6204, 0.3796],
        [0.6479, 0.3521],
        [0.6935, 0.3065],
        [0.6856, 0.3144],
        [0.6616, 0.3384],
        [0.6603, 0.3397],
        [0.6518, 0.3482],
        [0.6747, 0.3253],
        [0.6306, 0.3694],
        [0.6896, 0.3104],
        [0.6630, 0.3370],
        [0.6608, 0.3392],
        [0.6781, 0.3219],
        [0.6905, 0.3095],
        [0.6652, 0.3348],
        [0.6544, 0.3456],
        [0.6659, 0.3341],
        [0.6412, 0.3588],
        [0.6836, 0.3164],
        [0.6818, 0.3182],
        [0.6574, 0.3426],
        [0.6739, 0.3261],
        [0.6311, 0.3689],
        [0.6577, 0.3423],
        [0.6857, 0.3143],
        [0.6756, 0.3244],
        [0.6543, 0.3457],
        [0.6688, 0.3312],
        [0.6398, 0.3602],
        [0.6837, 0.3163],
        [0.6508, 0.3492],
        [0.6689, 0.3311],
        [0.6528, 0.3472],
        [0.6619, 0.3381],
        [0.6663, 0.3337],
        [0.6720, 0.3280],
        [0.6484, 0.3516],
        [0.6674, 0.3326],
        [0.6700, 0.3300],
        [0.6405, 0.3595],
        [0.6378, 0.3622],
        [0.6746, 0.3254],
        [0.6335, 0.3665],
        [0.6659, 0.3341],
        [0.7002, 0.2998],
        [0.6591, 0.3409],
        [0.6382, 0.3618],
        [0.6719, 0.3281],
        [0.6720, 0.3280],
        [0.6877, 0.3123]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0023 loss: 0.6639 acc_train: 0.6103 time: 0.1152s
tensor([[0.6726, 0.3274],
        [0.6567, 0.3433],
        [0.6792, 0.3208],
        [0.6678, 0.3322],
        [0.6919, 0.3081],
        [0.6512, 0.3488],
        [0.6623, 0.3377],
        [0.6642, 0.3358],
        [0.6506, 0.3494],
        [0.6591, 0.3409],
        [0.6578, 0.3422],
        [0.6828, 0.3172],
        [0.6633, 0.3367],
        [0.6522, 0.3478],
        [0.6689, 0.3311],
        [0.6310, 0.3690],
        [0.6751, 0.3249],
        [0.6737, 0.3263],
        [0.6366, 0.3634],
        [0.6467, 0.3533],
        [0.6640, 0.3360],
        [0.6627, 0.3373],
        [0.6738, 0.3262],
        [0.6801, 0.3199],
        [0.6645, 0.3355],
        [0.6275, 0.3725],
        [0.6442, 0.3558],
        [0.6674, 0.3326],
        [0.6471, 0.3529],
        [0.6383, 0.3617],
        [0.6435, 0.3565],
        [0.6486, 0.3514],
        [0.6736, 0.3264],
        [0.6721, 0.3279],
        [0.6647, 0.3353],
        [0.6535, 0.3465],
        [0.6418, 0.3582],
        [0.6399, 0.3601],
        [0.6658, 0.3342],
        [0.6675, 0.3325],
        [0.6697, 0.3303],
        [0.6451, 0.3549],
        [0.6314, 0.3686],
        [0.6604, 0.3396],
        [0.6849, 0.3151],
        [0.6596, 0.3404],
        [0.6889, 0.3111],
        [0.6751, 0.3249],
        [0.6546, 0.3454],
        [0.6743, 0.3257],
        [0.6680, 0.3320],
        [0.6717, 0.3283],
        [0.6610, 0.3390],
        [0.6585, 0.3415],
        [0.6459, 0.3541],
        [0.6839, 0.3161],
        [0.6492, 0.3508],
        [0.6546, 0.3454],
        [0.6802, 0.3198],
        [0.6593, 0.3407],
        [0.6293, 0.3707],
        [0.6474, 0.3526],
        [0.6820, 0.3180],
        [0.6766, 0.3234],
        [0.6516, 0.3484],
        [0.6522, 0.3478],
        [0.6535, 0.3465],
        [0.6361, 0.3639],
        [0.6570, 0.3430],
        [0.6574, 0.3426],
        [0.6526, 0.3474],
        [0.6709, 0.3291],
        [0.6777, 0.3223],
        [0.6748, 0.3252],
        [0.6473, 0.3527],
        [0.6522, 0.3478],
        [0.6766, 0.3234],
        [0.6689, 0.3311],
        [0.6416, 0.3584],
        [0.6641, 0.3359],
        [0.6640, 0.3360],
        [0.6759, 0.3241],
        [0.6377, 0.3623],
        [0.6606, 0.3394],
        [0.6487, 0.3513],
        [0.6411, 0.3589],
        [0.6529, 0.3471],
        [0.6655, 0.3345],
        [0.6721, 0.3279],
        [0.6650, 0.3350],
        [0.6753, 0.3247],
        [0.6691, 0.3309],
        [0.6756, 0.3244],
        [0.6362, 0.3638],
        [0.6607, 0.3393],
        [0.6879, 0.3121],
        [0.6842, 0.3158],
        [0.6283, 0.3717],
        [0.6864, 0.3136],
        [0.6500, 0.3500],
        [0.6801, 0.3199],
        [0.6688, 0.3312],
        [0.6313, 0.3687],
        [0.6465, 0.3535],
        [0.6564, 0.3436],
        [0.6713, 0.3287],
        [0.6668, 0.3332],
        [0.6782, 0.3218],
        [0.6457, 0.3543],
        [0.6909, 0.3091],
        [0.6449, 0.3551],
        [0.6450, 0.3550],
        [0.6688, 0.3312],
        [0.6715, 0.3285],
        [0.6454, 0.3546],
        [0.6665, 0.3335],
        [0.6808, 0.3192],
        [0.6717, 0.3283],
        [0.6649, 0.3351],
        [0.6691, 0.3309],
        [0.6359, 0.3641],
        [0.6320, 0.3680],
        [0.6799, 0.3201],
        [0.6690, 0.3310],
        [0.6457, 0.3543],
        [0.6612, 0.3388],
        [0.6229, 0.3771],
        [0.6803, 0.3197],
        [0.6470, 0.3530],
        [0.6735, 0.3265],
        [0.6666, 0.3334],
        [0.6424, 0.3576],
        [0.6567, 0.3433],
        [0.6629, 0.3371],
        [0.6745, 0.3255],
        [0.6405, 0.3595],
        [0.6359, 0.3641],
        [0.6497, 0.3503],
        [0.6682, 0.3318],
        [0.6616, 0.3384],
        [0.6317, 0.3683],
        [0.6603, 0.3397],
        [0.6700, 0.3300],
        [0.6756, 0.3244],
        [0.6225, 0.3775],
        [0.6642, 0.3358],
        [0.6440, 0.3560],
        [0.6613, 0.3387],
        [0.6702, 0.3298],
        [0.6878, 0.3122],
        [0.6688, 0.3312],
        [0.6824, 0.3176],
        [0.6675, 0.3325],
        [0.6882, 0.3118],
        [0.6794, 0.3206],
        [0.6408, 0.3592],
        [0.6815, 0.3185],
        [0.6688, 0.3312],
        [0.6531, 0.3469],
        [0.6539, 0.3461],
        [0.6639, 0.3361],
        [0.6678, 0.3322],
        [0.6538, 0.3462],
        [0.6364, 0.3636],
        [0.6596, 0.3404],
        [0.6647, 0.3353],
        [0.6529, 0.3471],
        [0.6591, 0.3409],
        [0.6683, 0.3317],
        [0.6650, 0.3350],
        [0.6591, 0.3409],
        [0.6437, 0.3563],
        [0.6572, 0.3428],
        [0.6830, 0.3170],
        [0.6743, 0.3257],
        [0.6463, 0.3537],
        [0.6671, 0.3329],
        [0.6709, 0.3291],
        [0.6610, 0.3390],
        [0.6642, 0.3358],
        [0.6772, 0.3228],
        [0.6420, 0.3580],
        [0.6399, 0.3601],
        [0.6261, 0.3739],
        [0.6864, 0.3136],
        [0.6800, 0.3200],
        [0.6622, 0.3378],
        [0.6446, 0.3554],
        [0.6303, 0.3697],
        [0.6514, 0.3486],
        [0.6882, 0.3118],
        [0.6681, 0.3319],
        [0.6551, 0.3449],
        [0.6525, 0.3475],
        [0.6591, 0.3409],
        [0.6506, 0.3494],
        [0.6695, 0.3305],
        [0.6300, 0.3700],
        [0.6936, 0.3064],
        [0.6939, 0.3061],
        [0.6503, 0.3497],
        [0.6883, 0.3117],
        [0.6865, 0.3135],
        [0.6372, 0.3628],
        [0.6578, 0.3422],
        [0.6504, 0.3496],
        [0.6889, 0.3111],
        [0.6944, 0.3056],
        [0.6704, 0.3296],
        [0.6777, 0.3223],
        [0.6637, 0.3363],
        [0.6666, 0.3334],
        [0.6700, 0.3300],
        [0.6396, 0.3604],
        [0.6714, 0.3286],
        [0.6583, 0.3417],
        [0.6471, 0.3529],
        [0.6607, 0.3393],
        [0.6767, 0.3233],
        [0.6739, 0.3261],
        [0.6549, 0.3451],
        [0.6791, 0.3209],
        [0.6258, 0.3742],
        [0.6499, 0.3501],
        [0.6888, 0.3112],
        [0.6828, 0.3172],
        [0.6595, 0.3405],
        [0.6607, 0.3393],
        [0.6523, 0.3477],
        [0.6724, 0.3276],
        [0.6351, 0.3649],
        [0.6858, 0.3142],
        [0.6629, 0.3371],
        [0.6607, 0.3393],
        [0.6751, 0.3249],
        [0.6865, 0.3135],
        [0.6649, 0.3351],
        [0.6550, 0.3450],
        [0.6649, 0.3351],
        [0.6436, 0.3564],
        [0.6804, 0.3196],
        [0.6785, 0.3215],
        [0.6576, 0.3424],
        [0.6712, 0.3288],
        [0.6354, 0.3646],
        [0.6582, 0.3418],
        [0.6819, 0.3181],
        [0.6732, 0.3268],
        [0.6553, 0.3447],
        [0.6670, 0.3330],
        [0.6425, 0.3575],
        [0.6794, 0.3206],
        [0.6519, 0.3481],
        [0.6676, 0.3324],
        [0.6546, 0.3454],
        [0.6620, 0.3380],
        [0.6654, 0.3346],
        [0.6705, 0.3295],
        [0.6505, 0.3495],
        [0.6665, 0.3335],
        [0.6688, 0.3312],
        [0.6435, 0.3565],
        [0.6413, 0.3587],
        [0.6724, 0.3276],
        [0.6373, 0.3627],
        [0.6641, 0.3359],
        [0.6945, 0.3055],
        [0.6596, 0.3404],
        [0.6405, 0.3595],
        [0.6703, 0.3297],
        [0.6703, 0.3297],
        [0.6839, 0.3161]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0024 loss: 0.6649 acc_train: 0.6103 time: 0.1165s
tensor([[0.6708, 0.3292],
        [0.6573, 0.3427],
        [0.6767, 0.3233],
        [0.6666, 0.3334],
        [0.6876, 0.3124],
        [0.6522, 0.3478],
        [0.6620, 0.3380],
        [0.6636, 0.3364],
        [0.6515, 0.3485],
        [0.6594, 0.3406],
        [0.6581, 0.3419],
        [0.6797, 0.3203],
        [0.6627, 0.3373],
        [0.6533, 0.3467],
        [0.6677, 0.3323],
        [0.6350, 0.3650],
        [0.6732, 0.3268],
        [0.6713, 0.3287],
        [0.6401, 0.3599],
        [0.6481, 0.3519],
        [0.6640, 0.3360],
        [0.6616, 0.3384],
        [0.6716, 0.3284],
        [0.6773, 0.3227],
        [0.6631, 0.3369],
        [0.6320, 0.3680],
        [0.6466, 0.3534],
        [0.6655, 0.3345],
        [0.6488, 0.3512],
        [0.6416, 0.3584],
        [0.6460, 0.3540],
        [0.6498, 0.3502],
        [0.6717, 0.3283],
        [0.6707, 0.3293],
        [0.6642, 0.3358],
        [0.6524, 0.3476],
        [0.6447, 0.3553],
        [0.6432, 0.3568],
        [0.6649, 0.3351],
        [0.6670, 0.3330],
        [0.6683, 0.3317],
        [0.6479, 0.3521],
        [0.6339, 0.3661],
        [0.6599, 0.3401],
        [0.6807, 0.3193],
        [0.6590, 0.3410],
        [0.6849, 0.3151],
        [0.6733, 0.3267],
        [0.6555, 0.3445],
        [0.6727, 0.3273],
        [0.6667, 0.3333],
        [0.6699, 0.3301],
        [0.6611, 0.3389],
        [0.6584, 0.3416],
        [0.6473, 0.3527],
        [0.6803, 0.3197],
        [0.6510, 0.3490],
        [0.6555, 0.3445],
        [0.6774, 0.3226],
        [0.6595, 0.3405],
        [0.6334, 0.3666],
        [0.6486, 0.3514],
        [0.6788, 0.3212],
        [0.6742, 0.3258],
        [0.6532, 0.3468],
        [0.6533, 0.3467],
        [0.6548, 0.3452],
        [0.6403, 0.3597],
        [0.6576, 0.3424],
        [0.6583, 0.3417],
        [0.6534, 0.3466],
        [0.6697, 0.3303],
        [0.6753, 0.3247],
        [0.6722, 0.3278],
        [0.6495, 0.3505],
        [0.6533, 0.3467],
        [0.6739, 0.3261],
        [0.6674, 0.3326],
        [0.6447, 0.3553],
        [0.6637, 0.3363],
        [0.6634, 0.3366],
        [0.6734, 0.3266],
        [0.6413, 0.3587],
        [0.6605, 0.3395],
        [0.6500, 0.3500],
        [0.6439, 0.3561],
        [0.6537, 0.3463],
        [0.6642, 0.3358],
        [0.6705, 0.3295],
        [0.6642, 0.3358],
        [0.6730, 0.3270],
        [0.6678, 0.3322],
        [0.6732, 0.3268],
        [0.6399, 0.3601],
        [0.6598, 0.3402],
        [0.6836, 0.3164],
        [0.6815, 0.3185],
        [0.6327, 0.3673],
        [0.6832, 0.3168],
        [0.6516, 0.3484],
        [0.6774, 0.3226],
        [0.6679, 0.3321],
        [0.6353, 0.3647],
        [0.6485, 0.3515],
        [0.6569, 0.3431],
        [0.6694, 0.3306],
        [0.6657, 0.3343],
        [0.6753, 0.3247],
        [0.6479, 0.3521],
        [0.6864, 0.3136],
        [0.6457, 0.3543],
        [0.6476, 0.3524],
        [0.6678, 0.3322],
        [0.6700, 0.3300],
        [0.6467, 0.3533],
        [0.6643, 0.3357],
        [0.6775, 0.3225],
        [0.6701, 0.3299],
        [0.6645, 0.3355],
        [0.6677, 0.3323],
        [0.6389, 0.3611],
        [0.6360, 0.3640],
        [0.6772, 0.3228],
        [0.6675, 0.3325],
        [0.6477, 0.3523],
        [0.6608, 0.3392],
        [0.6287, 0.3713],
        [0.6777, 0.3223],
        [0.6486, 0.3514],
        [0.6717, 0.3283],
        [0.6657, 0.3343],
        [0.6449, 0.3551],
        [0.6575, 0.3425],
        [0.6624, 0.3376],
        [0.6723, 0.3277],
        [0.6433, 0.3567],
        [0.6391, 0.3609],
        [0.6518, 0.3482],
        [0.6674, 0.3326],
        [0.6610, 0.3390],
        [0.6355, 0.3645],
        [0.6603, 0.3397],
        [0.6689, 0.3311],
        [0.6734, 0.3266],
        [0.6281, 0.3719],
        [0.6635, 0.3365],
        [0.6463, 0.3537],
        [0.6613, 0.3387],
        [0.6684, 0.3316],
        [0.6840, 0.3160],
        [0.6672, 0.3328],
        [0.6793, 0.3207],
        [0.6666, 0.3334],
        [0.6839, 0.3161],
        [0.6772, 0.3228],
        [0.6437, 0.3563],
        [0.6783, 0.3217],
        [0.6679, 0.3321],
        [0.6541, 0.3459],
        [0.6538, 0.3462],
        [0.6637, 0.3363],
        [0.6666, 0.3334],
        [0.6549, 0.3451],
        [0.6397, 0.3603],
        [0.6577, 0.3423],
        [0.6640, 0.3360],
        [0.6541, 0.3459],
        [0.6591, 0.3409],
        [0.6669, 0.3331],
        [0.6645, 0.3355],
        [0.6582, 0.3418],
        [0.6456, 0.3544],
        [0.6567, 0.3433],
        [0.6796, 0.3204],
        [0.6719, 0.3281],
        [0.6486, 0.3514],
        [0.6659, 0.3341],
        [0.6687, 0.3313],
        [0.6613, 0.3387],
        [0.6637, 0.3363],
        [0.6745, 0.3255],
        [0.6447, 0.3553],
        [0.6424, 0.3576],
        [0.6308, 0.3692],
        [0.6831, 0.3169],
        [0.6773, 0.3227],
        [0.6624, 0.3376],
        [0.6466, 0.3534],
        [0.6346, 0.3654],
        [0.6529, 0.3471],
        [0.6836, 0.3164],
        [0.6668, 0.3332],
        [0.6555, 0.3445],
        [0.6535, 0.3465],
        [0.6592, 0.3408],
        [0.6521, 0.3479],
        [0.6678, 0.3322],
        [0.6346, 0.3654],
        [0.6889, 0.3111],
        [0.6895, 0.3105],
        [0.6518, 0.3482],
        [0.6843, 0.3157],
        [0.6828, 0.3172],
        [0.6403, 0.3597],
        [0.6583, 0.3417],
        [0.6521, 0.3479],
        [0.6846, 0.3154],
        [0.6897, 0.3103],
        [0.6687, 0.3313],
        [0.6753, 0.3247],
        [0.6636, 0.3364],
        [0.6654, 0.3346],
        [0.6685, 0.3315],
        [0.6427, 0.3573],
        [0.6702, 0.3298],
        [0.6585, 0.3415],
        [0.6488, 0.3512],
        [0.6600, 0.3400],
        [0.6734, 0.3266],
        [0.6720, 0.3280],
        [0.6559, 0.3441],
        [0.6767, 0.3233],
        [0.6305, 0.3695],
        [0.6517, 0.3483],
        [0.6847, 0.3153],
        [0.6802, 0.3198],
        [0.6581, 0.3419],
        [0.6609, 0.3391],
        [0.6529, 0.3471],
        [0.6705, 0.3295],
        [0.6388, 0.3612],
        [0.6826, 0.3174],
        [0.6628, 0.3372],
        [0.6607, 0.3393],
        [0.6725, 0.3275],
        [0.6830, 0.3170],
        [0.6646, 0.3354],
        [0.6556, 0.3444],
        [0.6642, 0.3358],
        [0.6457, 0.3543],
        [0.6779, 0.3221],
        [0.6757, 0.3243],
        [0.6576, 0.3424],
        [0.6691, 0.3309],
        [0.6391, 0.3609],
        [0.6585, 0.3415],
        [0.6788, 0.3212],
        [0.6712, 0.3288],
        [0.6561, 0.3439],
        [0.6658, 0.3342],
        [0.6448, 0.3552],
        [0.6759, 0.3241],
        [0.6530, 0.3470],
        [0.6665, 0.3335],
        [0.6561, 0.3439],
        [0.6619, 0.3381],
        [0.6644, 0.3356],
        [0.6692, 0.3308],
        [0.6521, 0.3479],
        [0.6656, 0.3344],
        [0.6676, 0.3324],
        [0.6461, 0.3539],
        [0.6442, 0.3558],
        [0.6705, 0.3295],
        [0.6405, 0.3595],
        [0.6626, 0.3374],
        [0.6896, 0.3104],
        [0.6600, 0.3400],
        [0.6427, 0.3573],
        [0.6690, 0.3310],
        [0.6687, 0.3313],
        [0.6807, 0.3193]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0025 loss: 0.6658 acc_train: 0.6103 time: 0.1254s
tensor([[0.6694, 0.3306],
        [0.6577, 0.3423],
        [0.6746, 0.3254],
        [0.6656, 0.3344],
        [0.6841, 0.3159],
        [0.6530, 0.3470],
        [0.6618, 0.3382],
        [0.6632, 0.3368],
        [0.6524, 0.3476],
        [0.6599, 0.3401],
        [0.6583, 0.3417],
        [0.6770, 0.3230],
        [0.6622, 0.3378],
        [0.6542, 0.3458],
        [0.6665, 0.3335],
        [0.6385, 0.3615],
        [0.6714, 0.3286],
        [0.6693, 0.3307],
        [0.6430, 0.3570],
        [0.6494, 0.3506],
        [0.6638, 0.3362],
        [0.6610, 0.3390],
        [0.6697, 0.3303],
        [0.6749, 0.3251],
        [0.6617, 0.3383],
        [0.6359, 0.3641],
        [0.6486, 0.3514],
        [0.6641, 0.3359],
        [0.6501, 0.3499],
        [0.6444, 0.3556],
        [0.6482, 0.3518],
        [0.6508, 0.3492],
        [0.6701, 0.3299],
        [0.6694, 0.3306],
        [0.6637, 0.3363],
        [0.6516, 0.3484],
        [0.6470, 0.3530],
        [0.6458, 0.3542],
        [0.6641, 0.3359],
        [0.6666, 0.3334],
        [0.6671, 0.3329],
        [0.6501, 0.3499],
        [0.6359, 0.3641],
        [0.6594, 0.3406],
        [0.6772, 0.3228],
        [0.6586, 0.3414],
        [0.6815, 0.3185],
        [0.6717, 0.3283],
        [0.6562, 0.3438],
        [0.6713, 0.3287],
        [0.6657, 0.3343],
        [0.6686, 0.3314],
        [0.6611, 0.3389],
        [0.6582, 0.3418],
        [0.6486, 0.3514],
        [0.6772, 0.3228],
        [0.6524, 0.3476],
        [0.6561, 0.3439],
        [0.6751, 0.3249],
        [0.6597, 0.3403],
        [0.6369, 0.3631],
        [0.6498, 0.3502],
        [0.6763, 0.3237],
        [0.6722, 0.3278],
        [0.6544, 0.3456],
        [0.6541, 0.3459],
        [0.6558, 0.3442],
        [0.6437, 0.3563],
        [0.6580, 0.3420],
        [0.6592, 0.3408],
        [0.6542, 0.3458],
        [0.6687, 0.3313],
        [0.6733, 0.3267],
        [0.6703, 0.3297],
        [0.6513, 0.3487],
        [0.6541, 0.3459],
        [0.6717, 0.3283],
        [0.6661, 0.3339],
        [0.6474, 0.3526],
        [0.6633, 0.3367],
        [0.6629, 0.3371],
        [0.6715, 0.3285],
        [0.6443, 0.3557],
        [0.6604, 0.3396],
        [0.6512, 0.3488],
        [0.6463, 0.3537],
        [0.6546, 0.3454],
        [0.6632, 0.3368],
        [0.6691, 0.3309],
        [0.6635, 0.3365],
        [0.6710, 0.3290],
        [0.6669, 0.3331],
        [0.6712, 0.3288],
        [0.6429, 0.3571],
        [0.6592, 0.3408],
        [0.6801, 0.3199],
        [0.6791, 0.3209],
        [0.6364, 0.3636],
        [0.6803, 0.3197],
        [0.6529, 0.3471],
        [0.6751, 0.3249],
        [0.6672, 0.3328],
        [0.6387, 0.3613],
        [0.6503, 0.3497],
        [0.6573, 0.3427],
        [0.6678, 0.3322],
        [0.6648, 0.3352],
        [0.6727, 0.3273],
        [0.6496, 0.3504],
        [0.6827, 0.3173],
        [0.6462, 0.3538],
        [0.6499, 0.3501],
        [0.6668, 0.3332],
        [0.6687, 0.3313],
        [0.6479, 0.3521],
        [0.6626, 0.3374],
        [0.6747, 0.3253],
        [0.6686, 0.3314],
        [0.6640, 0.3360],
        [0.6668, 0.3332],
        [0.6415, 0.3585],
        [0.6392, 0.3608],
        [0.6750, 0.3250],
        [0.6663, 0.3337],
        [0.6493, 0.3507],
        [0.6606, 0.3394],
        [0.6336, 0.3664],
        [0.6757, 0.3243],
        [0.6502, 0.3498],
        [0.6701, 0.3299],
        [0.6651, 0.3349],
        [0.6470, 0.3530],
        [0.6580, 0.3420],
        [0.6620, 0.3380],
        [0.6705, 0.3295],
        [0.6456, 0.3544],
        [0.6418, 0.3582],
        [0.6534, 0.3466],
        [0.6665, 0.3335],
        [0.6605, 0.3395],
        [0.6387, 0.3613],
        [0.6602, 0.3398],
        [0.6679, 0.3321],
        [0.6715, 0.3285],
        [0.6327, 0.3673],
        [0.6630, 0.3370],
        [0.6482, 0.3518],
        [0.6614, 0.3386],
        [0.6670, 0.3330],
        [0.6809, 0.3191],
        [0.6661, 0.3339],
        [0.6765, 0.3235],
        [0.6658, 0.3342],
        [0.6805, 0.3195],
        [0.6752, 0.3248],
        [0.6461, 0.3539],
        [0.6758, 0.3242],
        [0.6671, 0.3329],
        [0.6551, 0.3449],
        [0.6537, 0.3463],
        [0.6636, 0.3364],
        [0.6658, 0.3342],
        [0.6559, 0.3441],
        [0.6425, 0.3575],
        [0.6562, 0.3438],
        [0.6635, 0.3365],
        [0.6551, 0.3449],
        [0.6593, 0.3407],
        [0.6656, 0.3344],
        [0.6640, 0.3360],
        [0.6574, 0.3426],
        [0.6472, 0.3528],
        [0.6562, 0.3438],
        [0.6769, 0.3231],
        [0.6700, 0.3300],
        [0.6507, 0.3493],
        [0.6650, 0.3350],
        [0.6668, 0.3332],
        [0.6614, 0.3386],
        [0.6633, 0.3367],
        [0.6720, 0.3280],
        [0.6469, 0.3531],
        [0.6444, 0.3556],
        [0.6348, 0.3652],
        [0.6803, 0.3197],
        [0.6750, 0.3250],
        [0.6625, 0.3375],
        [0.6484, 0.3516],
        [0.6381, 0.3619],
        [0.6539, 0.3461],
        [0.6797, 0.3203],
        [0.6656, 0.3344],
        [0.6558, 0.3442],
        [0.6544, 0.3456],
        [0.6591, 0.3409],
        [0.6534, 0.3466],
        [0.6666, 0.3334],
        [0.6384, 0.3616],
        [0.6850, 0.3150],
        [0.6857, 0.3143],
        [0.6530, 0.3470],
        [0.6809, 0.3191],
        [0.6797, 0.3203],
        [0.6430, 0.3570],
        [0.6586, 0.3414],
        [0.6533, 0.3467],
        [0.6810, 0.3190],
        [0.6859, 0.3141],
        [0.6674, 0.3326],
        [0.6733, 0.3267],
        [0.6635, 0.3365],
        [0.6642, 0.3358],
        [0.6673, 0.3327],
        [0.6451, 0.3549],
        [0.6692, 0.3308],
        [0.6585, 0.3415],
        [0.6501, 0.3499],
        [0.6597, 0.3403],
        [0.6705, 0.3295],
        [0.6705, 0.3295],
        [0.6566, 0.3434],
        [0.6744, 0.3256],
        [0.6346, 0.3654],
        [0.6532, 0.3468],
        [0.6813, 0.3187],
        [0.6779, 0.3221],
        [0.6572, 0.3428],
        [0.6610, 0.3390],
        [0.6535, 0.3465],
        [0.6688, 0.3312],
        [0.6420, 0.3580],
        [0.6798, 0.3202],
        [0.6626, 0.3374],
        [0.6607, 0.3393],
        [0.6703, 0.3297],
        [0.6801, 0.3199],
        [0.6642, 0.3358],
        [0.6560, 0.3440],
        [0.6636, 0.3364],
        [0.6474, 0.3526],
        [0.6756, 0.3244],
        [0.6733, 0.3267],
        [0.6577, 0.3423],
        [0.6675, 0.3325],
        [0.6423, 0.3577],
        [0.6586, 0.3414],
        [0.6760, 0.3240],
        [0.6695, 0.3305],
        [0.6568, 0.3432],
        [0.6651, 0.3349],
        [0.6469, 0.3531],
        [0.6730, 0.3270],
        [0.6541, 0.3459],
        [0.6656, 0.3344],
        [0.6572, 0.3428],
        [0.6617, 0.3383],
        [0.6636, 0.3364],
        [0.6681, 0.3319],
        [0.6534, 0.3466],
        [0.6649, 0.3351],
        [0.6665, 0.3335],
        [0.6484, 0.3516],
        [0.6467, 0.3533],
        [0.6689, 0.3311],
        [0.6432, 0.3568],
        [0.6616, 0.3384],
        [0.6857, 0.3143],
        [0.6601, 0.3399],
        [0.6447, 0.3553],
        [0.6679, 0.3321],
        [0.6672, 0.3328],
        [0.6780, 0.3220]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0026 loss: 0.6666 acc_train: 0.6103 time: 0.1297s
tensor([[0.6686, 0.3314],
        [0.6582, 0.3418],
        [0.6729, 0.3271],
        [0.6649, 0.3351],
        [0.6814, 0.3186],
        [0.6540, 0.3460],
        [0.6617, 0.3383],
        [0.6633, 0.3367],
        [0.6533, 0.3467],
        [0.6606, 0.3394],
        [0.6587, 0.3413],
        [0.6749, 0.3251],
        [0.6619, 0.3381],
        [0.6551, 0.3449],
        [0.6658, 0.3342],
        [0.6418, 0.3582],
        [0.6699, 0.3301],
        [0.6677, 0.3323],
        [0.6458, 0.3542],
        [0.6508, 0.3492],
        [0.6635, 0.3365],
        [0.6608, 0.3392],
        [0.6684, 0.3316],
        [0.6731, 0.3269],
        [0.6607, 0.3393],
        [0.6393, 0.3607],
        [0.6504, 0.3496],
        [0.6634, 0.3366],
        [0.6513, 0.3487],
        [0.6469, 0.3531],
        [0.6502, 0.3498],
        [0.6519, 0.3481],
        [0.6689, 0.3311],
        [0.6683, 0.3317],
        [0.6634, 0.3366],
        [0.6512, 0.3488],
        [0.6489, 0.3511],
        [0.6479, 0.3521],
        [0.6636, 0.3364],
        [0.6665, 0.3335],
        [0.6663, 0.3337],
        [0.6520, 0.3480],
        [0.6377, 0.3623],
        [0.6592, 0.3408],
        [0.6744, 0.3256],
        [0.6588, 0.3412],
        [0.6788, 0.3212],
        [0.6705, 0.3295],
        [0.6569, 0.3431],
        [0.6703, 0.3297],
        [0.6653, 0.3347],
        [0.6679, 0.3321],
        [0.6613, 0.3387],
        [0.6582, 0.3418],
        [0.6500, 0.3500],
        [0.6750, 0.3250],
        [0.6537, 0.3463],
        [0.6568, 0.3432],
        [0.6734, 0.3266],
        [0.6600, 0.3400],
        [0.6399, 0.3601],
        [0.6510, 0.3490],
        [0.6743, 0.3257],
        [0.6706, 0.3294],
        [0.6556, 0.3444],
        [0.6549, 0.3451],
        [0.6569, 0.3431],
        [0.6466, 0.3534],
        [0.6583, 0.3417],
        [0.6600, 0.3400],
        [0.6550, 0.3450],
        [0.6681, 0.3319],
        [0.6718, 0.3282],
        [0.6693, 0.3307],
        [0.6528, 0.3472],
        [0.6550, 0.3450],
        [0.6702, 0.3298],
        [0.6651, 0.3349],
        [0.6498, 0.3502],
        [0.6630, 0.3370],
        [0.6626, 0.3374],
        [0.6700, 0.3300],
        [0.6469, 0.3531],
        [0.6606, 0.3394],
        [0.6526, 0.3474],
        [0.6483, 0.3517],
        [0.6555, 0.3445],
        [0.6626, 0.3374],
        [0.6680, 0.3320],
        [0.6630, 0.3370],
        [0.6695, 0.3305],
        [0.6663, 0.3337],
        [0.6697, 0.3303],
        [0.6453, 0.3547],
        [0.6592, 0.3408],
        [0.6776, 0.3224],
        [0.6774, 0.3226],
        [0.6396, 0.3604],
        [0.6781, 0.3219],
        [0.6541, 0.3459],
        [0.6734, 0.3266],
        [0.6668, 0.3332],
        [0.6418, 0.3582],
        [0.6519, 0.3481],
        [0.6579, 0.3421],
        [0.6665, 0.3335],
        [0.6641, 0.3359],
        [0.6706, 0.3294],
        [0.6512, 0.3488],
        [0.6797, 0.3203],
        [0.6466, 0.3534],
        [0.6520, 0.3480],
        [0.6661, 0.3339],
        [0.6679, 0.3321],
        [0.6494, 0.3506],
        [0.6614, 0.3386],
        [0.6726, 0.3274],
        [0.6675, 0.3325],
        [0.6638, 0.3362],
        [0.6665, 0.3335],
        [0.6438, 0.3562],
        [0.6420, 0.3580],
        [0.6732, 0.3268],
        [0.6655, 0.3345],
        [0.6508, 0.3492],
        [0.6607, 0.3393],
        [0.6378, 0.3622],
        [0.6743, 0.3257],
        [0.6518, 0.3482],
        [0.6690, 0.3310],
        [0.6649, 0.3351],
        [0.6488, 0.3512],
        [0.6584, 0.3416],
        [0.6619, 0.3381],
        [0.6690, 0.3310],
        [0.6475, 0.3525],
        [0.6443, 0.3557],
        [0.6548, 0.3452],
        [0.6659, 0.3341],
        [0.6601, 0.3399],
        [0.6416, 0.3584],
        [0.6602, 0.3398],
        [0.6671, 0.3329],
        [0.6701, 0.3299],
        [0.6368, 0.3632],
        [0.6628, 0.3372],
        [0.6501, 0.3499],
        [0.6617, 0.3383],
        [0.6662, 0.3338],
        [0.6786, 0.3214],
        [0.6654, 0.3346],
        [0.6743, 0.3257],
        [0.6652, 0.3348],
        [0.6779, 0.3221],
        [0.6736, 0.3264],
        [0.6482, 0.3518],
        [0.6740, 0.3260],
        [0.6666, 0.3334],
        [0.6559, 0.3441],
        [0.6538, 0.3462],
        [0.6636, 0.3364],
        [0.6654, 0.3346],
        [0.6569, 0.3431],
        [0.6450, 0.3550],
        [0.6553, 0.3447],
        [0.6634, 0.3366],
        [0.6561, 0.3439],
        [0.6598, 0.3402],
        [0.6646, 0.3354],
        [0.6636, 0.3364],
        [0.6570, 0.3430],
        [0.6486, 0.3514],
        [0.6563, 0.3437],
        [0.6748, 0.3252],
        [0.6686, 0.3314],
        [0.6526, 0.3474],
        [0.6645, 0.3355],
        [0.6658, 0.3342],
        [0.6615, 0.3385],
        [0.6629, 0.3371],
        [0.6702, 0.3298],
        [0.6488, 0.3512],
        [0.6464, 0.3536],
        [0.6383, 0.3617],
        [0.6782, 0.3218],
        [0.6733, 0.3267],
        [0.6628, 0.3372],
        [0.6500, 0.3500],
        [0.6409, 0.3591],
        [0.6548, 0.3452],
        [0.6766, 0.3234],
        [0.6648, 0.3352],
        [0.6564, 0.3436],
        [0.6553, 0.3447],
        [0.6592, 0.3408],
        [0.6547, 0.3453],
        [0.6660, 0.3340],
        [0.6417, 0.3583],
        [0.6819, 0.3181],
        [0.6827, 0.3173],
        [0.6539, 0.3461],
        [0.6781, 0.3219],
        [0.6772, 0.3228],
        [0.6455, 0.3545],
        [0.6590, 0.3410],
        [0.6543, 0.3457],
        [0.6784, 0.3216],
        [0.6829, 0.3171],
        [0.6665, 0.3335],
        [0.6718, 0.3282],
        [0.6635, 0.3365],
        [0.6635, 0.3365],
        [0.6665, 0.3335],
        [0.6473, 0.3527],
        [0.6686, 0.3314],
        [0.6587, 0.3413],
        [0.6513, 0.3487],
        [0.6599, 0.3401],
        [0.6682, 0.3318],
        [0.6694, 0.3306],
        [0.6573, 0.3427],
        [0.6725, 0.3275],
        [0.6382, 0.3618],
        [0.6545, 0.3455],
        [0.6788, 0.3212],
        [0.6761, 0.3239],
        [0.6568, 0.3432],
        [0.6612, 0.3388],
        [0.6544, 0.3456],
        [0.6677, 0.3323],
        [0.6448, 0.3552],
        [0.6777, 0.3223],
        [0.6625, 0.3375],
        [0.6610, 0.3390],
        [0.6687, 0.3313],
        [0.6778, 0.3222],
        [0.6640, 0.3360],
        [0.6564, 0.3436],
        [0.6632, 0.3368],
        [0.6491, 0.3509],
        [0.6739, 0.3261],
        [0.6716, 0.3284],
        [0.6580, 0.3420],
        [0.6664, 0.3336],
        [0.6452, 0.3548],
        [0.6588, 0.3412],
        [0.6739, 0.3261],
        [0.6683, 0.3317],
        [0.6574, 0.3426],
        [0.6649, 0.3351],
        [0.6489, 0.3511],
        [0.6708, 0.3292],
        [0.6554, 0.3446],
        [0.6651, 0.3349],
        [0.6581, 0.3419],
        [0.6616, 0.3384],
        [0.6630, 0.3370],
        [0.6673, 0.3327],
        [0.6545, 0.3455],
        [0.6643, 0.3357],
        [0.6658, 0.3342],
        [0.6506, 0.3494],
        [0.6491, 0.3509],
        [0.6678, 0.3322],
        [0.6457, 0.3543],
        [0.6612, 0.3388],
        [0.6825, 0.3175],
        [0.6604, 0.3396],
        [0.6466, 0.3534],
        [0.6673, 0.3327],
        [0.6661, 0.3339],
        [0.6759, 0.3241]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0027 loss: 0.6671 acc_train: 0.6103 time: 0.1271s
tensor([[0.6682, 0.3318],
        [0.6586, 0.3414],
        [0.6719, 0.3281],
        [0.6646, 0.3354],
        [0.6795, 0.3205],
        [0.6551, 0.3449],
        [0.6618, 0.3382],
        [0.6635, 0.3365],
        [0.6543, 0.3457],
        [0.6614, 0.3386],
        [0.6593, 0.3407],
        [0.6733, 0.3267],
        [0.6618, 0.3382],
        [0.6558, 0.3442],
        [0.6654, 0.3346],
        [0.6447, 0.3553],
        [0.6687, 0.3313],
        [0.6665, 0.3335],
        [0.6482, 0.3518],
        [0.6523, 0.3477],
        [0.6633, 0.3367],
        [0.6610, 0.3390],
        [0.6674, 0.3326],
        [0.6718, 0.3282],
        [0.6602, 0.3398],
        [0.6423, 0.3577],
        [0.6518, 0.3482],
        [0.6631, 0.3369],
        [0.6524, 0.3476],
        [0.6490, 0.3510],
        [0.6522, 0.3478],
        [0.6529, 0.3471],
        [0.6681, 0.3319],
        [0.6677, 0.3323],
        [0.6636, 0.3364],
        [0.6510, 0.3490],
        [0.6505, 0.3495],
        [0.6498, 0.3502],
        [0.6635, 0.3365],
        [0.6664, 0.3336],
        [0.6658, 0.3342],
        [0.6536, 0.3464],
        [0.6394, 0.3606],
        [0.6591, 0.3409],
        [0.6723, 0.3277],
        [0.6593, 0.3407],
        [0.6769, 0.3231],
        [0.6698, 0.3302],
        [0.6577, 0.3423],
        [0.6697, 0.3303],
        [0.6652, 0.3348],
        [0.6676, 0.3324],
        [0.6617, 0.3383],
        [0.6582, 0.3418],
        [0.6515, 0.3485],
        [0.6735, 0.3265],
        [0.6549, 0.3451],
        [0.6576, 0.3424],
        [0.6723, 0.3277],
        [0.6605, 0.3395],
        [0.6424, 0.3576],
        [0.6523, 0.3477],
        [0.6729, 0.3271],
        [0.6696, 0.3304],
        [0.6565, 0.3435],
        [0.6557, 0.3443],
        [0.6580, 0.3420],
        [0.6489, 0.3511],
        [0.6585, 0.3415],
        [0.6607, 0.3393],
        [0.6559, 0.3441],
        [0.6678, 0.3322],
        [0.6706, 0.3294],
        [0.6688, 0.3312],
        [0.6543, 0.3457],
        [0.6559, 0.3441],
        [0.6692, 0.3308],
        [0.6645, 0.3355],
        [0.6518, 0.3482],
        [0.6629, 0.3371],
        [0.6625, 0.3375],
        [0.6689, 0.3311],
        [0.6492, 0.3508],
        [0.6611, 0.3389],
        [0.6539, 0.3461],
        [0.6500, 0.3500],
        [0.6566, 0.3434],
        [0.6623, 0.3377],
        [0.6673, 0.3327],
        [0.6628, 0.3372],
        [0.6685, 0.3315],
        [0.6661, 0.3339],
        [0.6689, 0.3311],
        [0.6473, 0.3527],
        [0.6595, 0.3405],
        [0.6758, 0.3242],
        [0.6761, 0.3239],
        [0.6423, 0.3577],
        [0.6765, 0.3235],
        [0.6554, 0.3446],
        [0.6723, 0.3277],
        [0.6665, 0.3335],
        [0.6445, 0.3555],
        [0.6534, 0.3466],
        [0.6586, 0.3414],
        [0.6656, 0.3344],
        [0.6637, 0.3363],
        [0.6691, 0.3309],
        [0.6527, 0.3473],
        [0.6773, 0.3227],
        [0.6470, 0.3530],
        [0.6538, 0.3462],
        [0.6658, 0.3342],
        [0.6674, 0.3326],
        [0.6510, 0.3490],
        [0.6607, 0.3393],
        [0.6710, 0.3290],
        [0.6667, 0.3333],
        [0.6639, 0.3361],
        [0.6667, 0.3333],
        [0.6458, 0.3542],
        [0.6443, 0.3557],
        [0.6720, 0.3280],
        [0.6651, 0.3349],
        [0.6522, 0.3478],
        [0.6609, 0.3391],
        [0.6414, 0.3586],
        [0.6734, 0.3266],
        [0.6535, 0.3465],
        [0.6682, 0.3318],
        [0.6649, 0.3351],
        [0.6503, 0.3497],
        [0.6588, 0.3412],
        [0.6620, 0.3380],
        [0.6681, 0.3319],
        [0.6490, 0.3510],
        [0.6466, 0.3534],
        [0.6559, 0.3441],
        [0.6656, 0.3344],
        [0.6600, 0.3400],
        [0.6442, 0.3558],
        [0.6604, 0.3396],
        [0.6666, 0.3334],
        [0.6692, 0.3308],
        [0.6403, 0.3597],
        [0.6628, 0.3372],
        [0.6519, 0.3481],
        [0.6622, 0.3378],
        [0.6658, 0.3342],
        [0.6769, 0.3231],
        [0.6652, 0.3348],
        [0.6726, 0.3274],
        [0.6647, 0.3353],
        [0.6760, 0.3240],
        [0.6724, 0.3276],
        [0.6498, 0.3502],
        [0.6729, 0.3271],
        [0.6664, 0.3336],
        [0.6568, 0.3432],
        [0.6541, 0.3459],
        [0.6637, 0.3363],
        [0.6653, 0.3347],
        [0.6577, 0.3423],
        [0.6473, 0.3527],
        [0.6549, 0.3451],
        [0.6636, 0.3364],
        [0.6572, 0.3428],
        [0.6603, 0.3397],
        [0.6639, 0.3361],
        [0.6632, 0.3368],
        [0.6568, 0.3432],
        [0.6499, 0.3501],
        [0.6567, 0.3433],
        [0.6732, 0.3268],
        [0.6677, 0.3323],
        [0.6543, 0.3457],
        [0.6644, 0.3356],
        [0.6652, 0.3348],
        [0.6617, 0.3383],
        [0.6627, 0.3373],
        [0.6690, 0.3310],
        [0.6505, 0.3495],
        [0.6481, 0.3519],
        [0.6415, 0.3585],
        [0.6766, 0.3234],
        [0.6722, 0.3278],
        [0.6632, 0.3368],
        [0.6514, 0.3486],
        [0.6433, 0.3567],
        [0.6557, 0.3443],
        [0.6743, 0.3257],
        [0.6643, 0.3357],
        [0.6571, 0.3429],
        [0.6562, 0.3438],
        [0.6594, 0.3406],
        [0.6561, 0.3439],
        [0.6658, 0.3342],
        [0.6444, 0.3556],
        [0.6796, 0.3204],
        [0.6803, 0.3197],
        [0.6548, 0.3452],
        [0.6761, 0.3239],
        [0.6753, 0.3247],
        [0.6479, 0.3521],
        [0.6595, 0.3405],
        [0.6552, 0.3448],
        [0.6765, 0.3235],
        [0.6806, 0.3194],
        [0.6660, 0.3340],
        [0.6708, 0.3292],
        [0.6637, 0.3363],
        [0.6632, 0.3368],
        [0.6660, 0.3340],
        [0.6491, 0.3509],
        [0.6682, 0.3318],
        [0.6589, 0.3411],
        [0.6524, 0.3476],
        [0.6604, 0.3396],
        [0.6665, 0.3335],
        [0.6688, 0.3312],
        [0.6580, 0.3420],
        [0.6710, 0.3290],
        [0.6414, 0.3586],
        [0.6556, 0.3444],
        [0.6769, 0.3231],
        [0.6747, 0.3253],
        [0.6566, 0.3434],
        [0.6614, 0.3386],
        [0.6553, 0.3447],
        [0.6669, 0.3331],
        [0.6473, 0.3527],
        [0.6762, 0.3238],
        [0.6626, 0.3374],
        [0.6612, 0.3388],
        [0.6676, 0.3324],
        [0.6761, 0.3239],
        [0.6639, 0.3361],
        [0.6569, 0.3431],
        [0.6631, 0.3369],
        [0.6508, 0.3492],
        [0.6726, 0.3274],
        [0.6702, 0.3298],
        [0.6585, 0.3415],
        [0.6659, 0.3341],
        [0.6478, 0.3522],
        [0.6590, 0.3410],
        [0.6723, 0.3277],
        [0.6675, 0.3325],
        [0.6581, 0.3419],
        [0.6651, 0.3349],
        [0.6508, 0.3492],
        [0.6693, 0.3307],
        [0.6568, 0.3432],
        [0.6648, 0.3352],
        [0.6590, 0.3410],
        [0.6617, 0.3383],
        [0.6627, 0.3373],
        [0.6669, 0.3331],
        [0.6556, 0.3444],
        [0.6641, 0.3359],
        [0.6655, 0.3345],
        [0.6526, 0.3474],
        [0.6511, 0.3489],
        [0.6670, 0.3330],
        [0.6478, 0.3522],
        [0.6611, 0.3389],
        [0.6802, 0.3198],
        [0.6608, 0.3392],
        [0.6485, 0.3515],
        [0.6671, 0.3329],
        [0.6654, 0.3346],
        [0.6744, 0.3256]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0028 loss: 0.6676 acc_train: 0.6103 time: 0.1236s
tensor([[0.6680, 0.3320],
        [0.6590, 0.3410],
        [0.6711, 0.3289],
        [0.6644, 0.3356],
        [0.6780, 0.3220],
        [0.6559, 0.3441],
        [0.6620, 0.3380],
        [0.6637, 0.3363],
        [0.6553, 0.3447],
        [0.6619, 0.3381],
        [0.6599, 0.3401],
        [0.6720, 0.3280],
        [0.6618, 0.3382],
        [0.6564, 0.3436],
        [0.6652, 0.3348],
        [0.6472, 0.3528],
        [0.6678, 0.3322],
        [0.6658, 0.3342],
        [0.6503, 0.3497],
        [0.6536, 0.3464],
        [0.6629, 0.3371],
        [0.6614, 0.3386],
        [0.6668, 0.3332],
        [0.6709, 0.3291],
        [0.6600, 0.3400],
        [0.6449, 0.3551],
        [0.6529, 0.3471],
        [0.6631, 0.3369],
        [0.6533, 0.3467],
        [0.6506, 0.3494],
        [0.6538, 0.3462],
        [0.6537, 0.3463],
        [0.6675, 0.3325],
        [0.6673, 0.3327],
        [0.6638, 0.3362],
        [0.6511, 0.3489],
        [0.6519, 0.3481],
        [0.6513, 0.3487],
        [0.6636, 0.3364],
        [0.6664, 0.3336],
        [0.6655, 0.3345],
        [0.6546, 0.3454],
        [0.6408, 0.3592],
        [0.6590, 0.3410],
        [0.6708, 0.3292],
        [0.6599, 0.3401],
        [0.6755, 0.3245],
        [0.6693, 0.3307],
        [0.6585, 0.3415],
        [0.6692, 0.3308],
        [0.6652, 0.3348],
        [0.6675, 0.3325],
        [0.6620, 0.3380],
        [0.6583, 0.3417],
        [0.6529, 0.3471],
        [0.6725, 0.3275],
        [0.6559, 0.3441],
        [0.6585, 0.3415],
        [0.6714, 0.3286],
        [0.6608, 0.3392],
        [0.6445, 0.3555],
        [0.6534, 0.3466],
        [0.6718, 0.3282],
        [0.6689, 0.3311],
        [0.6573, 0.3427],
        [0.6565, 0.3435],
        [0.6589, 0.3411],
        [0.6507, 0.3493],
        [0.6586, 0.3414],
        [0.6613, 0.3387],
        [0.6567, 0.3433],
        [0.6675, 0.3325],
        [0.6697, 0.3303],
        [0.6686, 0.3314],
        [0.6555, 0.3445],
        [0.6567, 0.3433],
        [0.6685, 0.3315],
        [0.6640, 0.3360],
        [0.6535, 0.3465],
        [0.6628, 0.3372],
        [0.6624, 0.3376],
        [0.6680, 0.3320],
        [0.6510, 0.3490],
        [0.6615, 0.3385],
        [0.6551, 0.3449],
        [0.6514, 0.3486],
        [0.6577, 0.3423],
        [0.6622, 0.3378],
        [0.6669, 0.3331],
        [0.6626, 0.3374],
        [0.6678, 0.3322],
        [0.6660, 0.3340],
        [0.6684, 0.3316],
        [0.6490, 0.3510],
        [0.6600, 0.3400],
        [0.6745, 0.3255],
        [0.6752, 0.3248],
        [0.6446, 0.3554],
        [0.6754, 0.3246],
        [0.6565, 0.3435],
        [0.6714, 0.3286],
        [0.6663, 0.3337],
        [0.6467, 0.3533],
        [0.6546, 0.3454],
        [0.6591, 0.3409],
        [0.6650, 0.3350],
        [0.6634, 0.3366],
        [0.6679, 0.3321],
        [0.6539, 0.3461],
        [0.6756, 0.3244],
        [0.6472, 0.3528],
        [0.6554, 0.3446],
        [0.6657, 0.3343],
        [0.6672, 0.3328],
        [0.6525, 0.3475],
        [0.6601, 0.3399],
        [0.6700, 0.3300],
        [0.6661, 0.3339],
        [0.6641, 0.3359],
        [0.6669, 0.3331],
        [0.6474, 0.3526],
        [0.6462, 0.3538],
        [0.6710, 0.3290],
        [0.6650, 0.3350],
        [0.6535, 0.3465],
        [0.6614, 0.3386],
        [0.6443, 0.3557],
        [0.6727, 0.3273],
        [0.6548, 0.3452],
        [0.6675, 0.3325],
        [0.6650, 0.3350],
        [0.6515, 0.3485],
        [0.6590, 0.3410],
        [0.6621, 0.3379],
        [0.6675, 0.3325],
        [0.6501, 0.3499],
        [0.6486, 0.3514],
        [0.6568, 0.3432],
        [0.6655, 0.3345],
        [0.6601, 0.3399],
        [0.6465, 0.3535],
        [0.6605, 0.3395],
        [0.6662, 0.3338],
        [0.6687, 0.3313],
        [0.6433, 0.3567],
        [0.6629, 0.3371],
        [0.6534, 0.3466],
        [0.6627, 0.3373],
        [0.6657, 0.3343],
        [0.6756, 0.3244],
        [0.6651, 0.3349],
        [0.6714, 0.3286],
        [0.6644, 0.3356],
        [0.6747, 0.3253],
        [0.6715, 0.3285],
        [0.6511, 0.3489],
        [0.6721, 0.3279],
        [0.6663, 0.3337],
        [0.6574, 0.3426],
        [0.6545, 0.3455],
        [0.6641, 0.3359],
        [0.6655, 0.3345],
        [0.6583, 0.3417],
        [0.6492, 0.3508],
        [0.6547, 0.3453],
        [0.6639, 0.3361],
        [0.6581, 0.3419],
        [0.6608, 0.3392],
        [0.6634, 0.3366],
        [0.6629, 0.3371],
        [0.6568, 0.3432],
        [0.6511, 0.3489],
        [0.6573, 0.3427],
        [0.6721, 0.3279],
        [0.6673, 0.3327],
        [0.6557, 0.3443],
        [0.6645, 0.3355],
        [0.6650, 0.3350],
        [0.6618, 0.3382],
        [0.6625, 0.3375],
        [0.6682, 0.3318],
        [0.6520, 0.3480],
        [0.6495, 0.3505],
        [0.6441, 0.3559],
        [0.6755, 0.3245],
        [0.6714, 0.3286],
        [0.6635, 0.3365],
        [0.6526, 0.3474],
        [0.6451, 0.3549],
        [0.6565, 0.3435],
        [0.6725, 0.3275],
        [0.6641, 0.3359],
        [0.6579, 0.3421],
        [0.6569, 0.3431],
        [0.6596, 0.3404],
        [0.6572, 0.3428],
        [0.6659, 0.3341],
        [0.6464, 0.3536],
        [0.6778, 0.3222],
        [0.6785, 0.3215],
        [0.6555, 0.3445],
        [0.6746, 0.3254],
        [0.6739, 0.3261],
        [0.6499, 0.3501],
        [0.6599, 0.3401],
        [0.6559, 0.3441],
        [0.6751, 0.3249],
        [0.6789, 0.3211],
        [0.6656, 0.3344],
        [0.6699, 0.3301],
        [0.6639, 0.3361],
        [0.6632, 0.3368],
        [0.6657, 0.3343],
        [0.6507, 0.3493],
        [0.6678, 0.3322],
        [0.6592, 0.3408],
        [0.6533, 0.3467],
        [0.6612, 0.3388],
        [0.6654, 0.3346],
        [0.6685, 0.3315],
        [0.6587, 0.3413],
        [0.6698, 0.3302],
        [0.6440, 0.3560],
        [0.6565, 0.3435],
        [0.6755, 0.3245],
        [0.6736, 0.3264],
        [0.6564, 0.3436],
        [0.6618, 0.3382],
        [0.6561, 0.3439],
        [0.6665, 0.3335],
        [0.6494, 0.3506],
        [0.6750, 0.3250],
        [0.6627, 0.3373],
        [0.6614, 0.3386],
        [0.6669, 0.3331],
        [0.6748, 0.3252],
        [0.6640, 0.3360],
        [0.6573, 0.3427],
        [0.6632, 0.3368],
        [0.6524, 0.3476],
        [0.6715, 0.3285],
        [0.6693, 0.3307],
        [0.6590, 0.3410],
        [0.6655, 0.3345],
        [0.6499, 0.3501],
        [0.6592, 0.3408],
        [0.6711, 0.3289],
        [0.6668, 0.3332],
        [0.6586, 0.3414],
        [0.6653, 0.3347],
        [0.6525, 0.3475],
        [0.6683, 0.3317],
        [0.6580, 0.3420],
        [0.6646, 0.3354],
        [0.6597, 0.3403],
        [0.6619, 0.3381],
        [0.6627, 0.3373],
        [0.6665, 0.3335],
        [0.6565, 0.3435],
        [0.6640, 0.3360],
        [0.6654, 0.3346],
        [0.6543, 0.3457],
        [0.6529, 0.3471],
        [0.6665, 0.3335],
        [0.6497, 0.3503],
        [0.6612, 0.3388],
        [0.6784, 0.3216],
        [0.6612, 0.3388],
        [0.6502, 0.3498],
        [0.6670, 0.3330],
        [0.6650, 0.3350],
        [0.6734, 0.3266]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0029 loss: 0.6680 acc_train: 0.6103 time: 0.1251s
tensor([[0.6680, 0.3320],
        [0.6594, 0.3406],
        [0.6708, 0.3292],
        [0.6644, 0.3356],
        [0.6771, 0.3229],
        [0.6566, 0.3434],
        [0.6624, 0.3376],
        [0.6641, 0.3359],
        [0.6563, 0.3437],
        [0.6624, 0.3376],
        [0.6606, 0.3394],
        [0.6711, 0.3289],
        [0.6619, 0.3381],
        [0.6570, 0.3430],
        [0.6653, 0.3347],
        [0.6492, 0.3508],
        [0.6673, 0.3327],
        [0.6655, 0.3345],
        [0.6519, 0.3481],
        [0.6550, 0.3450],
        [0.6628, 0.3372],
        [0.6619, 0.3381],
        [0.6664, 0.3336],
        [0.6704, 0.3296],
        [0.6601, 0.3399],
        [0.6469, 0.3531],
        [0.6539, 0.3461],
        [0.6633, 0.3367],
        [0.6543, 0.3457],
        [0.6520, 0.3480],
        [0.6552, 0.3448],
        [0.6546, 0.3454],
        [0.6671, 0.3329],
        [0.6671, 0.3329],
        [0.6642, 0.3358],
        [0.6514, 0.3486],
        [0.6531, 0.3469],
        [0.6526, 0.3474],
        [0.6639, 0.3361],
        [0.6665, 0.3335],
        [0.6656, 0.3344],
        [0.6554, 0.3446],
        [0.6421, 0.3579],
        [0.6591, 0.3409],
        [0.6697, 0.3303],
        [0.6606, 0.3394],
        [0.6746, 0.3254],
        [0.6691, 0.3309],
        [0.6594, 0.3406],
        [0.6689, 0.3311],
        [0.6654, 0.3346],
        [0.6676, 0.3324],
        [0.6624, 0.3376],
        [0.6584, 0.3416],
        [0.6543, 0.3457],
        [0.6720, 0.3280],
        [0.6569, 0.3431],
        [0.6593, 0.3407],
        [0.6710, 0.3290],
        [0.6612, 0.3388],
        [0.6463, 0.3537],
        [0.6544, 0.3456],
        [0.6711, 0.3289],
        [0.6684, 0.3316],
        [0.6580, 0.3420],
        [0.6572, 0.3428],
        [0.6596, 0.3404],
        [0.6522, 0.3478],
        [0.6586, 0.3414],
        [0.6618, 0.3382],
        [0.6574, 0.3426],
        [0.6674, 0.3326],
        [0.6691, 0.3309],
        [0.6687, 0.3313],
        [0.6566, 0.3434],
        [0.6576, 0.3424],
        [0.6681, 0.3319],
        [0.6640, 0.3360],
        [0.6549, 0.3451],
        [0.6628, 0.3372],
        [0.6626, 0.3374],
        [0.6675, 0.3325],
        [0.6526, 0.3474],
        [0.6621, 0.3379],
        [0.6561, 0.3439],
        [0.6526, 0.3474],
        [0.6586, 0.3414],
        [0.6622, 0.3378],
        [0.6668, 0.3332],
        [0.6627, 0.3373],
        [0.6676, 0.3324],
        [0.6661, 0.3339],
        [0.6682, 0.3318],
        [0.6503, 0.3497],
        [0.6605, 0.3395],
        [0.6737, 0.3263],
        [0.6744, 0.3256],
        [0.6466, 0.3534],
        [0.6748, 0.3252],
        [0.6573, 0.3427],
        [0.6707, 0.3293],
        [0.6663, 0.3337],
        [0.6485, 0.3515],
        [0.6556, 0.3444],
        [0.6597, 0.3403],
        [0.6648, 0.3352],
        [0.6634, 0.3366],
        [0.6671, 0.3329],
        [0.6550, 0.3450],
        [0.6744, 0.3256],
        [0.6475, 0.3525],
        [0.6567, 0.3433],
        [0.6659, 0.3341],
        [0.6672, 0.3328],
        [0.6538, 0.3462],
        [0.6599, 0.3401],
        [0.6694, 0.3306],
        [0.6659, 0.3341],
        [0.6644, 0.3356],
        [0.6674, 0.3326],
        [0.6488, 0.3512],
        [0.6478, 0.3522],
        [0.6705, 0.3295],
        [0.6650, 0.3350],
        [0.6546, 0.3454],
        [0.6620, 0.3380],
        [0.6467, 0.3533],
        [0.6722, 0.3278],
        [0.6560, 0.3440],
        [0.6672, 0.3328],
        [0.6651, 0.3349],
        [0.6524, 0.3476],
        [0.6593, 0.3407],
        [0.6624, 0.3376],
        [0.6672, 0.3328],
        [0.6511, 0.3489],
        [0.6503, 0.3497],
        [0.6576, 0.3424],
        [0.6655, 0.3345],
        [0.6603, 0.3397],
        [0.6485, 0.3515],
        [0.6607, 0.3393],
        [0.6660, 0.3340],
        [0.6684, 0.3316],
        [0.6456, 0.3544],
        [0.6631, 0.3369],
        [0.6548, 0.3452],
        [0.6632, 0.3368],
        [0.6658, 0.3342],
        [0.6747, 0.3253],
        [0.6651, 0.3349],
        [0.6706, 0.3294],
        [0.6643, 0.3357],
        [0.6739, 0.3261],
        [0.6709, 0.3291],
        [0.6522, 0.3478],
        [0.6718, 0.3282],
        [0.6663, 0.3337],
        [0.6580, 0.3420],
        [0.6552, 0.3448],
        [0.6645, 0.3355],
        [0.6657, 0.3343],
        [0.6588, 0.3412],
        [0.6507, 0.3493],
        [0.6548, 0.3452],
        [0.6643, 0.3357],
        [0.6590, 0.3410],
        [0.6613, 0.3387],
        [0.6632, 0.3368],
        [0.6628, 0.3372],
        [0.6569, 0.3431],
        [0.6522, 0.3478],
        [0.6581, 0.3419],
        [0.6714, 0.3286],
        [0.6672, 0.3328],
        [0.6569, 0.3431],
        [0.6648, 0.3352],
        [0.6650, 0.3350],
        [0.6620, 0.3380],
        [0.6625, 0.3375],
        [0.6677, 0.3323],
        [0.6532, 0.3468],
        [0.6507, 0.3493],
        [0.6463, 0.3537],
        [0.6747, 0.3253],
        [0.6709, 0.3291],
        [0.6638, 0.3362],
        [0.6537, 0.3463],
        [0.6467, 0.3533],
        [0.6572, 0.3428],
        [0.6714, 0.3286],
        [0.6641, 0.3359],
        [0.6588, 0.3412],
        [0.6576, 0.3424],
        [0.6600, 0.3400],
        [0.6583, 0.3417],
        [0.6663, 0.3337],
        [0.6480, 0.3520],
        [0.6767, 0.3233],
        [0.6772, 0.3228],
        [0.6563, 0.3437],
        [0.6736, 0.3264],
        [0.6730, 0.3270],
        [0.6517, 0.3483],
        [0.6603, 0.3397],
        [0.6565, 0.3435],
        [0.6742, 0.3258],
        [0.6777, 0.3223],
        [0.6656, 0.3344],
        [0.6694, 0.3306],
        [0.6643, 0.3357],
        [0.6634, 0.3366],
        [0.6657, 0.3343],
        [0.6521, 0.3479],
        [0.6675, 0.3325],
        [0.6596, 0.3404],
        [0.6541, 0.3459],
        [0.6619, 0.3381],
        [0.6647, 0.3353],
        [0.6684, 0.3316],
        [0.6594, 0.3406],
        [0.6691, 0.3309],
        [0.6462, 0.3538],
        [0.6573, 0.3427],
        [0.6746, 0.3254],
        [0.6727, 0.3273],
        [0.6565, 0.3435],
        [0.6623, 0.3377],
        [0.6569, 0.3431],
        [0.6664, 0.3336],
        [0.6512, 0.3488],
        [0.6743, 0.3257],
        [0.6629, 0.3371],
        [0.6618, 0.3382],
        [0.6666, 0.3334],
        [0.6740, 0.3260],
        [0.6642, 0.3358],
        [0.6579, 0.3421],
        [0.6635, 0.3365],
        [0.6537, 0.3463],
        [0.6709, 0.3291],
        [0.6688, 0.3312],
        [0.6596, 0.3404],
        [0.6653, 0.3347],
        [0.6516, 0.3484],
        [0.6596, 0.3404],
        [0.6704, 0.3296],
        [0.6663, 0.3337],
        [0.6590, 0.3410],
        [0.6656, 0.3344],
        [0.6541, 0.3459],
        [0.6678, 0.3322],
        [0.6590, 0.3410],
        [0.6646, 0.3354],
        [0.6603, 0.3397],
        [0.6621, 0.3379],
        [0.6628, 0.3372],
        [0.6663, 0.3337],
        [0.6574, 0.3426],
        [0.6642, 0.3358],
        [0.6654, 0.3346],
        [0.6557, 0.3443],
        [0.6543, 0.3457],
        [0.6663, 0.3337],
        [0.6513, 0.3487],
        [0.6615, 0.3385],
        [0.6773, 0.3227],
        [0.6616, 0.3384],
        [0.6517, 0.3483],
        [0.6670, 0.3330],
        [0.6649, 0.3351],
        [0.6727, 0.3273]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0030 loss: 0.6682 acc_train: 0.6103 time: 0.1221s
tensor([[0.6681, 0.3319],
        [0.6598, 0.3402],
        [0.6707, 0.3293],
        [0.6648, 0.3352],
        [0.6767, 0.3233],
        [0.6572, 0.3428],
        [0.6628, 0.3372],
        [0.6646, 0.3354],
        [0.6572, 0.3428],
        [0.6627, 0.3373],
        [0.6615, 0.3385],
        [0.6707, 0.3293],
        [0.6623, 0.3377],
        [0.6577, 0.3423],
        [0.6656, 0.3344],
        [0.6509, 0.3491],
        [0.6671, 0.3329],
        [0.6657, 0.3343],
        [0.6533, 0.3467],
        [0.6562, 0.3438],
        [0.6629, 0.3371],
        [0.6625, 0.3375],
        [0.6663, 0.3337],
        [0.6703, 0.3297],
        [0.6604, 0.3396],
        [0.6487, 0.3513],
        [0.6547, 0.3453],
        [0.6637, 0.3363],
        [0.6553, 0.3447],
        [0.6531, 0.3469],
        [0.6564, 0.3436],
        [0.6556, 0.3444],
        [0.6671, 0.3329],
        [0.6672, 0.3328],
        [0.6646, 0.3354],
        [0.6519, 0.3481],
        [0.6541, 0.3459],
        [0.6539, 0.3461],
        [0.6645, 0.3355],
        [0.6668, 0.3332],
        [0.6658, 0.3342],
        [0.6560, 0.3440],
        [0.6433, 0.3567],
        [0.6594, 0.3406],
        [0.6690, 0.3310],
        [0.6615, 0.3385],
        [0.6742, 0.3258],
        [0.6691, 0.3309],
        [0.6602, 0.3398],
        [0.6689, 0.3311],
        [0.6657, 0.3343],
        [0.6679, 0.3321],
        [0.6629, 0.3371],
        [0.6586, 0.3414],
        [0.6556, 0.3444],
        [0.6719, 0.3281],
        [0.6579, 0.3421],
        [0.6601, 0.3399],
        [0.6708, 0.3292],
        [0.6616, 0.3384],
        [0.6478, 0.3522],
        [0.6553, 0.3447],
        [0.6707, 0.3293],
        [0.6684, 0.3316],
        [0.6586, 0.3414],
        [0.6580, 0.3420],
        [0.6603, 0.3397],
        [0.6534, 0.3466],
        [0.6587, 0.3413],
        [0.6623, 0.3377],
        [0.6581, 0.3419],
        [0.6675, 0.3325],
        [0.6688, 0.3312],
        [0.6691, 0.3309],
        [0.6576, 0.3424],
        [0.6584, 0.3416],
        [0.6680, 0.3320],
        [0.6642, 0.3358],
        [0.6561, 0.3439],
        [0.6629, 0.3371],
        [0.6629, 0.3371],
        [0.6674, 0.3326],
        [0.6539, 0.3461],
        [0.6628, 0.3372],
        [0.6571, 0.3429],
        [0.6536, 0.3464],
        [0.6595, 0.3405],
        [0.6624, 0.3376],
        [0.6668, 0.3332],
        [0.6630, 0.3370],
        [0.6677, 0.3323],
        [0.6663, 0.3337],
        [0.6684, 0.3316],
        [0.6516, 0.3484],
        [0.6611, 0.3389],
        [0.6732, 0.3268],
        [0.6740, 0.3260],
        [0.6481, 0.3519],
        [0.6745, 0.3255],
        [0.6581, 0.3419],
        [0.6703, 0.3297],
        [0.6663, 0.3337],
        [0.6500, 0.3500],
        [0.6564, 0.3436],
        [0.6601, 0.3399],
        [0.6647, 0.3353],
        [0.6636, 0.3364],
        [0.6666, 0.3334],
        [0.6560, 0.3440],
        [0.6738, 0.3262],
        [0.6478, 0.3522],
        [0.6577, 0.3423],
        [0.6661, 0.3339],
        [0.6674, 0.3326],
        [0.6550, 0.3450],
        [0.6600, 0.3400],
        [0.6692, 0.3308],
        [0.6660, 0.3340],
        [0.6648, 0.3352],
        [0.6679, 0.3321],
        [0.6500, 0.3500],
        [0.6491, 0.3509],
        [0.6703, 0.3297],
        [0.6652, 0.3348],
        [0.6557, 0.3443],
        [0.6628, 0.3372],
        [0.6487, 0.3513],
        [0.6720, 0.3280],
        [0.6570, 0.3430],
        [0.6672, 0.3328],
        [0.6653, 0.3347],
        [0.6533, 0.3467],
        [0.6596, 0.3404],
        [0.6627, 0.3373],
        [0.6673, 0.3327],
        [0.6519, 0.3481],
        [0.6519, 0.3481],
        [0.6583, 0.3417],
        [0.6658, 0.3342],
        [0.6607, 0.3393],
        [0.6502, 0.3498],
        [0.6611, 0.3389],
        [0.6660, 0.3340],
        [0.6684, 0.3316],
        [0.6476, 0.3524],
        [0.6636, 0.3364],
        [0.6561, 0.3439],
        [0.6637, 0.3363],
        [0.6661, 0.3339],
        [0.6743, 0.3257],
        [0.6653, 0.3347],
        [0.6703, 0.3297],
        [0.6644, 0.3356],
        [0.6736, 0.3264],
        [0.6706, 0.3294],
        [0.6531, 0.3469],
        [0.6719, 0.3281],
        [0.6664, 0.3336],
        [0.6586, 0.3414],
        [0.6559, 0.3441],
        [0.6650, 0.3350],
        [0.6662, 0.3338],
        [0.6593, 0.3407],
        [0.6520, 0.3480],
        [0.6552, 0.3448],
        [0.6648, 0.3352],
        [0.6597, 0.3403],
        [0.6617, 0.3383],
        [0.6633, 0.3367],
        [0.6628, 0.3372],
        [0.6572, 0.3428],
        [0.6533, 0.3467],
        [0.6589, 0.3411],
        [0.6712, 0.3288],
        [0.6673, 0.3327],
        [0.6577, 0.3423],
        [0.6654, 0.3346],
        [0.6653, 0.3347],
        [0.6623, 0.3377],
        [0.6627, 0.3373],
        [0.6676, 0.3324],
        [0.6542, 0.3458],
        [0.6518, 0.3482],
        [0.6482, 0.3518],
        [0.6743, 0.3257],
        [0.6707, 0.3293],
        [0.6641, 0.3359],
        [0.6548, 0.3452],
        [0.6480, 0.3520],
        [0.6579, 0.3421],
        [0.6709, 0.3291],
        [0.6642, 0.3358],
        [0.6597, 0.3403],
        [0.6585, 0.3415],
        [0.6605, 0.3395],
        [0.6592, 0.3408],
        [0.6668, 0.3332],
        [0.6493, 0.3507],
        [0.6760, 0.3240],
        [0.6765, 0.3235],
        [0.6571, 0.3429],
        [0.6731, 0.3269],
        [0.6726, 0.3274],
        [0.6532, 0.3468],
        [0.6607, 0.3393],
        [0.6571, 0.3429],
        [0.6738, 0.3262],
        [0.6772, 0.3228],
        [0.6658, 0.3342],
        [0.6691, 0.3309],
        [0.6648, 0.3352],
        [0.6638, 0.3362],
        [0.6658, 0.3342],
        [0.6533, 0.3467],
        [0.6674, 0.3326],
        [0.6602, 0.3398],
        [0.6548, 0.3452],
        [0.6628, 0.3372],
        [0.6645, 0.3355],
        [0.6685, 0.3315],
        [0.6601, 0.3399],
        [0.6688, 0.3312],
        [0.6479, 0.3521],
        [0.6580, 0.3420],
        [0.6741, 0.3259],
        [0.6721, 0.3279],
        [0.6567, 0.3433],
        [0.6629, 0.3371],
        [0.6578, 0.3422],
        [0.6666, 0.3334],
        [0.6527, 0.3473],
        [0.6740, 0.3260],
        [0.6632, 0.3368],
        [0.6622, 0.3378],
        [0.6667, 0.3333],
        [0.6735, 0.3265],
        [0.6646, 0.3354],
        [0.6586, 0.3414],
        [0.6639, 0.3361],
        [0.6550, 0.3450],
        [0.6706, 0.3294],
        [0.6687, 0.3313],
        [0.6603, 0.3397],
        [0.6653, 0.3347],
        [0.6531, 0.3469],
        [0.6601, 0.3399],
        [0.6702, 0.3298],
        [0.6661, 0.3339],
        [0.6595, 0.3405],
        [0.6659, 0.3341],
        [0.6555, 0.3445],
        [0.6677, 0.3323],
        [0.6599, 0.3401],
        [0.6649, 0.3351],
        [0.6608, 0.3392],
        [0.6624, 0.3376],
        [0.6631, 0.3369],
        [0.6663, 0.3337],
        [0.6582, 0.3418],
        [0.6645, 0.3355],
        [0.6656, 0.3344],
        [0.6569, 0.3431],
        [0.6554, 0.3446],
        [0.6664, 0.3336],
        [0.6527, 0.3473],
        [0.6619, 0.3381],
        [0.6766, 0.3234],
        [0.6622, 0.3378],
        [0.6531, 0.3469],
        [0.6672, 0.3328],
        [0.6649, 0.3351],
        [0.6725, 0.3275]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0031 loss: 0.6684 acc_train: 0.6103 time: 0.1451s
tensor([[0.6683, 0.3317],
        [0.6603, 0.3397],
        [0.6709, 0.3291],
        [0.6653, 0.3347],
        [0.6765, 0.3235],
        [0.6577, 0.3423],
        [0.6634, 0.3366],
        [0.6650, 0.3350],
        [0.6582, 0.3418],
        [0.6630, 0.3370],
        [0.6623, 0.3377],
        [0.6705, 0.3295],
        [0.6627, 0.3373],
        [0.6584, 0.3416],
        [0.6660, 0.3340],
        [0.6523, 0.3477],
        [0.6673, 0.3327],
        [0.6661, 0.3339],
        [0.6544, 0.3456],
        [0.6574, 0.3426],
        [0.6631, 0.3369],
        [0.6632, 0.3368],
        [0.6664, 0.3336],
        [0.6704, 0.3296],
        [0.6608, 0.3392],
        [0.6502, 0.3498],
        [0.6553, 0.3447],
        [0.6642, 0.3358],
        [0.6563, 0.3437],
        [0.6541, 0.3459],
        [0.6574, 0.3426],
        [0.6564, 0.3436],
        [0.6673, 0.3327],
        [0.6674, 0.3326],
        [0.6650, 0.3350],
        [0.6525, 0.3475],
        [0.6551, 0.3449],
        [0.6549, 0.3451],
        [0.6652, 0.3348],
        [0.6671, 0.3329],
        [0.6663, 0.3337],
        [0.6566, 0.3434],
        [0.6443, 0.3557],
        [0.6598, 0.3402],
        [0.6687, 0.3313],
        [0.6625, 0.3375],
        [0.6740, 0.3260],
        [0.6694, 0.3306],
        [0.6610, 0.3390],
        [0.6690, 0.3310],
        [0.6661, 0.3339],
        [0.6682, 0.3318],
        [0.6634, 0.3366],
        [0.6589, 0.3411],
        [0.6567, 0.3433],
        [0.6721, 0.3279],
        [0.6588, 0.3412],
        [0.6609, 0.3391],
        [0.6709, 0.3291],
        [0.6620, 0.3380],
        [0.6490, 0.3510],
        [0.6561, 0.3439],
        [0.6706, 0.3294],
        [0.6685, 0.3315],
        [0.6592, 0.3408],
        [0.6587, 0.3413],
        [0.6608, 0.3392],
        [0.6545, 0.3455],
        [0.6590, 0.3410],
        [0.6628, 0.3372],
        [0.6588, 0.3412],
        [0.6676, 0.3324],
        [0.6689, 0.3311],
        [0.6695, 0.3305],
        [0.6584, 0.3416],
        [0.6593, 0.3407],
        [0.6683, 0.3317],
        [0.6646, 0.3354],
        [0.6570, 0.3430],
        [0.6631, 0.3369],
        [0.6633, 0.3367],
        [0.6675, 0.3325],
        [0.6550, 0.3450],
        [0.6634, 0.3366],
        [0.6580, 0.3420],
        [0.6544, 0.3456],
        [0.6603, 0.3397],
        [0.6628, 0.3372],
        [0.6670, 0.3330],
        [0.6634, 0.3366],
        [0.6680, 0.3320],
        [0.6666, 0.3334],
        [0.6686, 0.3314],
        [0.6527, 0.3473],
        [0.6616, 0.3384],
        [0.6731, 0.3269],
        [0.6738, 0.3262],
        [0.6494, 0.3506],
        [0.6745, 0.3255],
        [0.6587, 0.3413],
        [0.6702, 0.3298],
        [0.6664, 0.3336],
        [0.6512, 0.3488],
        [0.6571, 0.3429],
        [0.6607, 0.3393],
        [0.6648, 0.3352],
        [0.6640, 0.3360],
        [0.6664, 0.3336],
        [0.6569, 0.3431],
        [0.6736, 0.3264],
        [0.6483, 0.3517],
        [0.6586, 0.3414],
        [0.6666, 0.3334],
        [0.6677, 0.3323],
        [0.6560, 0.3440],
        [0.6602, 0.3398],
        [0.6692, 0.3308],
        [0.6663, 0.3337],
        [0.6653, 0.3347],
        [0.6684, 0.3316],
        [0.6510, 0.3490],
        [0.6502, 0.3498],
        [0.6704, 0.3296],
        [0.6656, 0.3344],
        [0.6566, 0.3434],
        [0.6635, 0.3365],
        [0.6502, 0.3498],
        [0.6720, 0.3280],
        [0.6579, 0.3421],
        [0.6674, 0.3326],
        [0.6656, 0.3344],
        [0.6541, 0.3459],
        [0.6599, 0.3401],
        [0.6631, 0.3369],
        [0.6674, 0.3326],
        [0.6527, 0.3473],
        [0.6532, 0.3468],
        [0.6590, 0.3410],
        [0.6662, 0.3338],
        [0.6611, 0.3389],
        [0.6516, 0.3484],
        [0.6615, 0.3385],
        [0.6661, 0.3339],
        [0.6686, 0.3314],
        [0.6491, 0.3509],
        [0.6641, 0.3359],
        [0.6572, 0.3428],
        [0.6642, 0.3358],
        [0.6665, 0.3335],
        [0.6740, 0.3260],
        [0.6656, 0.3344],
        [0.6703, 0.3297],
        [0.6647, 0.3353],
        [0.6737, 0.3263],
        [0.6705, 0.3295],
        [0.6539, 0.3461],
        [0.6722, 0.3278],
        [0.6667, 0.3333],
        [0.6591, 0.3409],
        [0.6566, 0.3434],
        [0.6656, 0.3344],
        [0.6667, 0.3333],
        [0.6597, 0.3403],
        [0.6531, 0.3469],
        [0.6558, 0.3442],
        [0.6652, 0.3348],
        [0.6603, 0.3397],
        [0.6622, 0.3378],
        [0.6637, 0.3363],
        [0.6629, 0.3371],
        [0.6575, 0.3425],
        [0.6544, 0.3456],
        [0.6598, 0.3402],
        [0.6712, 0.3288],
        [0.6677, 0.3323],
        [0.6585, 0.3415],
        [0.6660, 0.3340],
        [0.6656, 0.3344],
        [0.6627, 0.3373],
        [0.6631, 0.3369],
        [0.6677, 0.3323],
        [0.6551, 0.3449],
        [0.6526, 0.3474],
        [0.6498, 0.3502],
        [0.6742, 0.3258],
        [0.6706, 0.3294],
        [0.6645, 0.3355],
        [0.6558, 0.3442],
        [0.6490, 0.3510],
        [0.6586, 0.3414],
        [0.6707, 0.3293],
        [0.6644, 0.3356],
        [0.6605, 0.3395],
        [0.6592, 0.3408],
        [0.6611, 0.3389],
        [0.6600, 0.3400],
        [0.6673, 0.3327],
        [0.6502, 0.3498],
        [0.6758, 0.3242],
        [0.6761, 0.3239],
        [0.6579, 0.3421],
        [0.6729, 0.3271],
        [0.6726, 0.3274],
        [0.6545, 0.3455],
        [0.6613, 0.3387],
        [0.6578, 0.3422],
        [0.6737, 0.3263],
        [0.6770, 0.3230],
        [0.6662, 0.3338],
        [0.6691, 0.3309],
        [0.6654, 0.3346],
        [0.6643, 0.3357],
        [0.6661, 0.3339],
        [0.6544, 0.3456],
        [0.6674, 0.3326],
        [0.6608, 0.3392],
        [0.6556, 0.3444],
        [0.6636, 0.3364],
        [0.6646, 0.3354],
        [0.6688, 0.3312],
        [0.6608, 0.3392],
        [0.6687, 0.3313],
        [0.6492, 0.3508],
        [0.6587, 0.3413],
        [0.6739, 0.3261],
        [0.6718, 0.3282],
        [0.6571, 0.3429],
        [0.6635, 0.3365],
        [0.6585, 0.3415],
        [0.6670, 0.3330],
        [0.6540, 0.3460],
        [0.6741, 0.3259],
        [0.6635, 0.3365],
        [0.6627, 0.3373],
        [0.6670, 0.3330],
        [0.6733, 0.3267],
        [0.6650, 0.3350],
        [0.6593, 0.3407],
        [0.6643, 0.3357],
        [0.6562, 0.3438],
        [0.6706, 0.3294],
        [0.6689, 0.3311],
        [0.6609, 0.3391],
        [0.6655, 0.3345],
        [0.6543, 0.3457],
        [0.6607, 0.3393],
        [0.6703, 0.3297],
        [0.6661, 0.3339],
        [0.6600, 0.3400],
        [0.6662, 0.3338],
        [0.6568, 0.3432],
        [0.6679, 0.3321],
        [0.6606, 0.3394],
        [0.6651, 0.3349],
        [0.6614, 0.3386],
        [0.6628, 0.3372],
        [0.6635, 0.3365],
        [0.6663, 0.3337],
        [0.6591, 0.3409],
        [0.6649, 0.3351],
        [0.6660, 0.3340],
        [0.6578, 0.3422],
        [0.6564, 0.3436],
        [0.6667, 0.3333],
        [0.6539, 0.3461],
        [0.6624, 0.3376],
        [0.6763, 0.3237],
        [0.6627, 0.3373],
        [0.6543, 0.3457],
        [0.6675, 0.3325],
        [0.6652, 0.3348],
        [0.6725, 0.3275]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0032 loss: 0.6685 acc_train: 0.6103 time: 0.1356s
tensor([[0.6686, 0.3314],
        [0.6608, 0.3392],
        [0.6711, 0.3289],
        [0.6658, 0.3342],
        [0.6765, 0.3235],
        [0.6581, 0.3419],
        [0.6639, 0.3361],
        [0.6655, 0.3345],
        [0.6590, 0.3410],
        [0.6635, 0.3365],
        [0.6631, 0.3369],
        [0.6706, 0.3294],
        [0.6631, 0.3369],
        [0.6591, 0.3409],
        [0.6665, 0.3335],
        [0.6534, 0.3466],
        [0.6676, 0.3324],
        [0.6667, 0.3333],
        [0.6554, 0.3446],
        [0.6585, 0.3415],
        [0.6634, 0.3366],
        [0.6639, 0.3361],
        [0.6666, 0.3334],
        [0.6706, 0.3294],
        [0.6614, 0.3386],
        [0.6515, 0.3485],
        [0.6560, 0.3440],
        [0.6648, 0.3352],
        [0.6572, 0.3428],
        [0.6550, 0.3450],
        [0.6583, 0.3417],
        [0.6572, 0.3428],
        [0.6677, 0.3323],
        [0.6677, 0.3323],
        [0.6655, 0.3345],
        [0.6533, 0.3467],
        [0.6560, 0.3440],
        [0.6558, 0.3442],
        [0.6659, 0.3341],
        [0.6674, 0.3326],
        [0.6668, 0.3332],
        [0.6572, 0.3428],
        [0.6452, 0.3548],
        [0.6603, 0.3397],
        [0.6687, 0.3313],
        [0.6634, 0.3366],
        [0.6741, 0.3259],
        [0.6697, 0.3303],
        [0.6618, 0.3382],
        [0.6692, 0.3308],
        [0.6666, 0.3334],
        [0.6686, 0.3314],
        [0.6640, 0.3360],
        [0.6594, 0.3406],
        [0.6578, 0.3422],
        [0.6724, 0.3276],
        [0.6596, 0.3404],
        [0.6616, 0.3384],
        [0.6711, 0.3289],
        [0.6624, 0.3376],
        [0.6502, 0.3498],
        [0.6567, 0.3433],
        [0.6708, 0.3292],
        [0.6687, 0.3313],
        [0.6598, 0.3402],
        [0.6594, 0.3406],
        [0.6613, 0.3387],
        [0.6555, 0.3445],
        [0.6593, 0.3407],
        [0.6632, 0.3368],
        [0.6595, 0.3405],
        [0.6678, 0.3322],
        [0.6691, 0.3309],
        [0.6699, 0.3301],
        [0.6592, 0.3408],
        [0.6601, 0.3399],
        [0.6687, 0.3313],
        [0.6651, 0.3349],
        [0.6578, 0.3422],
        [0.6634, 0.3366],
        [0.6638, 0.3362],
        [0.6678, 0.3322],
        [0.6558, 0.3442],
        [0.6641, 0.3359],
        [0.6589, 0.3411],
        [0.6552, 0.3448],
        [0.6610, 0.3390],
        [0.6632, 0.3368],
        [0.6673, 0.3327],
        [0.6640, 0.3360],
        [0.6683, 0.3317],
        [0.6670, 0.3330],
        [0.6690, 0.3310],
        [0.6537, 0.3463],
        [0.6622, 0.3378],
        [0.6732, 0.3268],
        [0.6738, 0.3262],
        [0.6505, 0.3495],
        [0.6747, 0.3253],
        [0.6593, 0.3407],
        [0.6704, 0.3296],
        [0.6667, 0.3333],
        [0.6522, 0.3478],
        [0.6577, 0.3423],
        [0.6612, 0.3388],
        [0.6650, 0.3350],
        [0.6645, 0.3355],
        [0.6666, 0.3334],
        [0.6577, 0.3423],
        [0.6735, 0.3265],
        [0.6488, 0.3512],
        [0.6593, 0.3407],
        [0.6671, 0.3329],
        [0.6681, 0.3319],
        [0.6570, 0.3430],
        [0.6605, 0.3395],
        [0.6695, 0.3305],
        [0.6668, 0.3332],
        [0.6658, 0.3342],
        [0.6689, 0.3311],
        [0.6518, 0.3482],
        [0.6512, 0.3488],
        [0.6706, 0.3294],
        [0.6660, 0.3340],
        [0.6574, 0.3426],
        [0.6643, 0.3357],
        [0.6514, 0.3486],
        [0.6720, 0.3280],
        [0.6586, 0.3414],
        [0.6676, 0.3324],
        [0.6660, 0.3340],
        [0.6549, 0.3451],
        [0.6603, 0.3397],
        [0.6635, 0.3365],
        [0.6677, 0.3323],
        [0.6535, 0.3465],
        [0.6544, 0.3456],
        [0.6597, 0.3403],
        [0.6666, 0.3334],
        [0.6616, 0.3384],
        [0.6529, 0.3471],
        [0.6620, 0.3380],
        [0.6664, 0.3336],
        [0.6689, 0.3311],
        [0.6503, 0.3497],
        [0.6647, 0.3353],
        [0.6582, 0.3418],
        [0.6647, 0.3353],
        [0.6670, 0.3330],
        [0.6740, 0.3260],
        [0.6660, 0.3340],
        [0.6707, 0.3293],
        [0.6651, 0.3349],
        [0.6739, 0.3261],
        [0.6707, 0.3293],
        [0.6546, 0.3454],
        [0.6725, 0.3275],
        [0.6670, 0.3330],
        [0.6596, 0.3404],
        [0.6574, 0.3426],
        [0.6661, 0.3339],
        [0.6672, 0.3328],
        [0.6602, 0.3398],
        [0.6540, 0.3460],
        [0.6565, 0.3435],
        [0.6657, 0.3343],
        [0.6609, 0.3391],
        [0.6628, 0.3372],
        [0.6644, 0.3356],
        [0.6633, 0.3367],
        [0.6579, 0.3421],
        [0.6553, 0.3447],
        [0.6607, 0.3393],
        [0.6713, 0.3287],
        [0.6682, 0.3318],
        [0.6591, 0.3409],
        [0.6666, 0.3334],
        [0.6661, 0.3339],
        [0.6633, 0.3367],
        [0.6635, 0.3365],
        [0.6680, 0.3320],
        [0.6559, 0.3441],
        [0.6534, 0.3466],
        [0.6511, 0.3489],
        [0.6743, 0.3257],
        [0.6707, 0.3293],
        [0.6649, 0.3351],
        [0.6567, 0.3433],
        [0.6500, 0.3500],
        [0.6593, 0.3407],
        [0.6709, 0.3291],
        [0.6648, 0.3352],
        [0.6612, 0.3388],
        [0.6600, 0.3400],
        [0.6618, 0.3382],
        [0.6607, 0.3393],
        [0.6678, 0.3322],
        [0.6510, 0.3490],
        [0.6758, 0.3242],
        [0.6759, 0.3241],
        [0.6588, 0.3412],
        [0.6730, 0.3270],
        [0.6727, 0.3273],
        [0.6556, 0.3444],
        [0.6618, 0.3382],
        [0.6584, 0.3416],
        [0.6738, 0.3262],
        [0.6771, 0.3229],
        [0.6666, 0.3334],
        [0.6693, 0.3307],
        [0.6661, 0.3339],
        [0.6649, 0.3351],
        [0.6666, 0.3334],
        [0.6554, 0.3446],
        [0.6675, 0.3325],
        [0.6614, 0.3386],
        [0.6563, 0.3437],
        [0.6644, 0.3356],
        [0.6650, 0.3350],
        [0.6692, 0.3308],
        [0.6615, 0.3385],
        [0.6688, 0.3312],
        [0.6503, 0.3497],
        [0.6592, 0.3408],
        [0.6739, 0.3261],
        [0.6718, 0.3282],
        [0.6576, 0.3424],
        [0.6641, 0.3359],
        [0.6592, 0.3408],
        [0.6674, 0.3326],
        [0.6550, 0.3450],
        [0.6743, 0.3257],
        [0.6640, 0.3360],
        [0.6633, 0.3367],
        [0.6674, 0.3326],
        [0.6733, 0.3267],
        [0.6655, 0.3345],
        [0.6600, 0.3400],
        [0.6648, 0.3352],
        [0.6572, 0.3428],
        [0.6709, 0.3291],
        [0.6692, 0.3308],
        [0.6616, 0.3384],
        [0.6658, 0.3342],
        [0.6552, 0.3448],
        [0.6614, 0.3386],
        [0.6705, 0.3295],
        [0.6662, 0.3338],
        [0.6606, 0.3394],
        [0.6666, 0.3334],
        [0.6580, 0.3420],
        [0.6684, 0.3316],
        [0.6613, 0.3387],
        [0.6655, 0.3345],
        [0.6619, 0.3381],
        [0.6634, 0.3366],
        [0.6640, 0.3360],
        [0.6666, 0.3334],
        [0.6599, 0.3401],
        [0.6655, 0.3345],
        [0.6664, 0.3336],
        [0.6586, 0.3414],
        [0.6572, 0.3428],
        [0.6671, 0.3329],
        [0.6549, 0.3451],
        [0.6629, 0.3371],
        [0.6762, 0.3238],
        [0.6633, 0.3367],
        [0.6553, 0.3447],
        [0.6678, 0.3322],
        [0.6656, 0.3344],
        [0.6727, 0.3273]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0033 loss: 0.6685 acc_train: 0.6103 time: 0.1079s
tensor([[0.6690, 0.3310],
        [0.6614, 0.3386],
        [0.6715, 0.3285],
        [0.6665, 0.3335],
        [0.6767, 0.3233],
        [0.6586, 0.3414],
        [0.6645, 0.3355],
        [0.6660, 0.3340],
        [0.6599, 0.3401],
        [0.6640, 0.3360],
        [0.6638, 0.3362],
        [0.6709, 0.3291],
        [0.6636, 0.3364],
        [0.6599, 0.3401],
        [0.6670, 0.3330],
        [0.6543, 0.3457],
        [0.6682, 0.3318],
        [0.6673, 0.3327],
        [0.6562, 0.3438],
        [0.6594, 0.3406],
        [0.6638, 0.3362],
        [0.6645, 0.3355],
        [0.6670, 0.3330],
        [0.6710, 0.3290],
        [0.6620, 0.3380],
        [0.6526, 0.3474],
        [0.6566, 0.3434],
        [0.6653, 0.3347],
        [0.6580, 0.3420],
        [0.6559, 0.3441],
        [0.6590, 0.3410],
        [0.6580, 0.3420],
        [0.6683, 0.3317],
        [0.6682, 0.3318],
        [0.6661, 0.3339],
        [0.6542, 0.3458],
        [0.6568, 0.3432],
        [0.6566, 0.3434],
        [0.6666, 0.3334],
        [0.6678, 0.3322],
        [0.6672, 0.3328],
        [0.6578, 0.3422],
        [0.6460, 0.3540],
        [0.6607, 0.3393],
        [0.6690, 0.3310],
        [0.6643, 0.3357],
        [0.6743, 0.3257],
        [0.6701, 0.3299],
        [0.6626, 0.3374],
        [0.6694, 0.3306],
        [0.6672, 0.3328],
        [0.6690, 0.3310],
        [0.6646, 0.3354],
        [0.6599, 0.3401],
        [0.6587, 0.3413],
        [0.6729, 0.3271],
        [0.6604, 0.3396],
        [0.6623, 0.3377],
        [0.6713, 0.3287],
        [0.6629, 0.3371],
        [0.6512, 0.3488],
        [0.6573, 0.3427],
        [0.6711, 0.3289],
        [0.6691, 0.3309],
        [0.6604, 0.3396],
        [0.6601, 0.3399],
        [0.6617, 0.3383],
        [0.6563, 0.3437],
        [0.6598, 0.3402],
        [0.6637, 0.3363],
        [0.6602, 0.3398],
        [0.6681, 0.3319],
        [0.6694, 0.3306],
        [0.6702, 0.3298],
        [0.6598, 0.3402],
        [0.6609, 0.3391],
        [0.6692, 0.3308],
        [0.6658, 0.3342],
        [0.6584, 0.3416],
        [0.6639, 0.3361],
        [0.6644, 0.3356],
        [0.6682, 0.3318],
        [0.6566, 0.3434],
        [0.6647, 0.3353],
        [0.6597, 0.3403],
        [0.6560, 0.3440],
        [0.6616, 0.3384],
        [0.6637, 0.3363],
        [0.6677, 0.3323],
        [0.6646, 0.3354],
        [0.6688, 0.3312],
        [0.6674, 0.3326],
        [0.6694, 0.3306],
        [0.6546, 0.3454],
        [0.6628, 0.3372],
        [0.6734, 0.3266],
        [0.6740, 0.3260],
        [0.6514, 0.3486],
        [0.6750, 0.3250],
        [0.6598, 0.3402],
        [0.6708, 0.3292],
        [0.6670, 0.3330],
        [0.6530, 0.3470],
        [0.6582, 0.3418],
        [0.6619, 0.3381],
        [0.6653, 0.3347],
        [0.6651, 0.3349],
        [0.6670, 0.3330],
        [0.6584, 0.3416],
        [0.6737, 0.3263],
        [0.6493, 0.3507],
        [0.6599, 0.3401],
        [0.6676, 0.3324],
        [0.6686, 0.3314],
        [0.6579, 0.3421],
        [0.6609, 0.3391],
        [0.6700, 0.3300],
        [0.6674, 0.3326],
        [0.6663, 0.3337],
        [0.6693, 0.3307],
        [0.6526, 0.3474],
        [0.6521, 0.3479],
        [0.6709, 0.3291],
        [0.6664, 0.3336],
        [0.6582, 0.3418],
        [0.6651, 0.3349],
        [0.6525, 0.3475],
        [0.6723, 0.3277],
        [0.6594, 0.3406],
        [0.6680, 0.3320],
        [0.6664, 0.3336],
        [0.6557, 0.3443],
        [0.6608, 0.3392],
        [0.6641, 0.3359],
        [0.6681, 0.3319],
        [0.6542, 0.3458],
        [0.6554, 0.3446],
        [0.6604, 0.3396],
        [0.6672, 0.3328],
        [0.6623, 0.3377],
        [0.6540, 0.3460],
        [0.6625, 0.3375],
        [0.6667, 0.3333],
        [0.6693, 0.3307],
        [0.6514, 0.3486],
        [0.6653, 0.3347],
        [0.6591, 0.3409],
        [0.6652, 0.3348],
        [0.6675, 0.3325],
        [0.6742, 0.3258],
        [0.6665, 0.3335],
        [0.6712, 0.3288],
        [0.6655, 0.3345],
        [0.6743, 0.3257],
        [0.6710, 0.3290],
        [0.6552, 0.3448],
        [0.6729, 0.3271],
        [0.6674, 0.3326],
        [0.6602, 0.3398],
        [0.6583, 0.3417],
        [0.6668, 0.3332],
        [0.6678, 0.3322],
        [0.6606, 0.3394],
        [0.6549, 0.3451],
        [0.6574, 0.3426],
        [0.6661, 0.3339],
        [0.6615, 0.3385],
        [0.6634, 0.3366],
        [0.6651, 0.3349],
        [0.6638, 0.3362],
        [0.6583, 0.3417],
        [0.6562, 0.3438],
        [0.6615, 0.3385],
        [0.6715, 0.3285],
        [0.6687, 0.3313],
        [0.6597, 0.3403],
        [0.6673, 0.3327],
        [0.6666, 0.3334],
        [0.6639, 0.3361],
        [0.6640, 0.3360],
        [0.6684, 0.3316],
        [0.6567, 0.3433],
        [0.6541, 0.3459],
        [0.6522, 0.3478],
        [0.6745, 0.3255],
        [0.6709, 0.3291],
        [0.6654, 0.3346],
        [0.6575, 0.3425],
        [0.6508, 0.3492],
        [0.6600, 0.3400],
        [0.6712, 0.3288],
        [0.6653, 0.3347],
        [0.6620, 0.3380],
        [0.6607, 0.3393],
        [0.6627, 0.3373],
        [0.6613, 0.3387],
        [0.6682, 0.3318],
        [0.6518, 0.3482],
        [0.6760, 0.3240],
        [0.6760, 0.3240],
        [0.6596, 0.3404],
        [0.6734, 0.3266],
        [0.6731, 0.3269],
        [0.6566, 0.3434],
        [0.6624, 0.3376],
        [0.6591, 0.3409],
        [0.6741, 0.3259],
        [0.6773, 0.3227],
        [0.6671, 0.3329],
        [0.6695, 0.3305],
        [0.6667, 0.3333],
        [0.6656, 0.3344],
        [0.6671, 0.3329],
        [0.6564, 0.3436],
        [0.6677, 0.3323],
        [0.6621, 0.3379],
        [0.6570, 0.3430],
        [0.6652, 0.3348],
        [0.6655, 0.3345],
        [0.6697, 0.3303],
        [0.6621, 0.3379],
        [0.6691, 0.3309],
        [0.6512, 0.3488],
        [0.6598, 0.3402],
        [0.6740, 0.3260],
        [0.6719, 0.3281],
        [0.6581, 0.3419],
        [0.6648, 0.3352],
        [0.6599, 0.3401],
        [0.6679, 0.3321],
        [0.6559, 0.3441],
        [0.6747, 0.3253],
        [0.6644, 0.3356],
        [0.6638, 0.3362],
        [0.6679, 0.3321],
        [0.6735, 0.3265],
        [0.6660, 0.3340],
        [0.6607, 0.3393],
        [0.6654, 0.3346],
        [0.6581, 0.3419],
        [0.6713, 0.3287],
        [0.6697, 0.3303],
        [0.6622, 0.3378],
        [0.6662, 0.3338],
        [0.6561, 0.3439],
        [0.6621, 0.3379],
        [0.6710, 0.3290],
        [0.6664, 0.3336],
        [0.6611, 0.3389],
        [0.6671, 0.3329],
        [0.6590, 0.3410],
        [0.6690, 0.3310],
        [0.6619, 0.3381],
        [0.6659, 0.3341],
        [0.6624, 0.3376],
        [0.6640, 0.3360],
        [0.6646, 0.3354],
        [0.6669, 0.3331],
        [0.6606, 0.3394],
        [0.6660, 0.3340],
        [0.6670, 0.3330],
        [0.6592, 0.3408],
        [0.6579, 0.3421],
        [0.6676, 0.3324],
        [0.6559, 0.3441],
        [0.6634, 0.3366],
        [0.6763, 0.3237],
        [0.6639, 0.3361],
        [0.6563, 0.3437],
        [0.6682, 0.3318],
        [0.6661, 0.3339],
        [0.6730, 0.3270]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0034 loss: 0.6685 acc_train: 0.6103 time: 0.1192s
tensor([[0.6694, 0.3306],
        [0.6620, 0.3380],
        [0.6719, 0.3281],
        [0.6671, 0.3329],
        [0.6769, 0.3231],
        [0.6590, 0.3410],
        [0.6651, 0.3349],
        [0.6664, 0.3336],
        [0.6606, 0.3394],
        [0.6645, 0.3355],
        [0.6644, 0.3356],
        [0.6712, 0.3288],
        [0.6640, 0.3360],
        [0.6607, 0.3393],
        [0.6675, 0.3325],
        [0.6552, 0.3448],
        [0.6687, 0.3313],
        [0.6679, 0.3321],
        [0.6569, 0.3431],
        [0.6601, 0.3399],
        [0.6643, 0.3357],
        [0.6651, 0.3349],
        [0.6675, 0.3325],
        [0.6714, 0.3286],
        [0.6626, 0.3374],
        [0.6535, 0.3465],
        [0.6573, 0.3427],
        [0.6658, 0.3342],
        [0.6588, 0.3412],
        [0.6566, 0.3434],
        [0.6596, 0.3404],
        [0.6587, 0.3413],
        [0.6689, 0.3311],
        [0.6686, 0.3314],
        [0.6665, 0.3335],
        [0.6550, 0.3450],
        [0.6576, 0.3424],
        [0.6573, 0.3427],
        [0.6672, 0.3328],
        [0.6681, 0.3319],
        [0.6676, 0.3324],
        [0.6586, 0.3414],
        [0.6467, 0.3533],
        [0.6612, 0.3388],
        [0.6695, 0.3305],
        [0.6651, 0.3349],
        [0.6746, 0.3254],
        [0.6705, 0.3295],
        [0.6633, 0.3367],
        [0.6697, 0.3303],
        [0.6677, 0.3323],
        [0.6693, 0.3307],
        [0.6652, 0.3348],
        [0.6604, 0.3396],
        [0.6594, 0.3406],
        [0.6733, 0.3267],
        [0.6611, 0.3389],
        [0.6630, 0.3370],
        [0.6716, 0.3284],
        [0.6633, 0.3367],
        [0.6521, 0.3479],
        [0.6579, 0.3421],
        [0.6714, 0.3286],
        [0.6695, 0.3305],
        [0.6609, 0.3391],
        [0.6607, 0.3393],
        [0.6622, 0.3378],
        [0.6571, 0.3429],
        [0.6603, 0.3397],
        [0.6642, 0.3358],
        [0.6608, 0.3392],
        [0.6684, 0.3316],
        [0.6698, 0.3302],
        [0.6704, 0.3296],
        [0.6604, 0.3396],
        [0.6616, 0.3384],
        [0.6697, 0.3303],
        [0.6663, 0.3337],
        [0.6590, 0.3410],
        [0.6643, 0.3357],
        [0.6648, 0.3352],
        [0.6686, 0.3314],
        [0.6573, 0.3427],
        [0.6652, 0.3348],
        [0.6605, 0.3395],
        [0.6567, 0.3433],
        [0.6621, 0.3379],
        [0.6642, 0.3358],
        [0.6681, 0.3319],
        [0.6652, 0.3348],
        [0.6692, 0.3308],
        [0.6678, 0.3322],
        [0.6698, 0.3302],
        [0.6553, 0.3447],
        [0.6632, 0.3368],
        [0.6737, 0.3263],
        [0.6743, 0.3257],
        [0.6521, 0.3479],
        [0.6753, 0.3247],
        [0.6603, 0.3397],
        [0.6713, 0.3287],
        [0.6674, 0.3326],
        [0.6537, 0.3463],
        [0.6587, 0.3413],
        [0.6625, 0.3375],
        [0.6657, 0.3343],
        [0.6657, 0.3343],
        [0.6675, 0.3325],
        [0.6591, 0.3409],
        [0.6739, 0.3261],
        [0.6499, 0.3501],
        [0.6604, 0.3396],
        [0.6681, 0.3319],
        [0.6691, 0.3309],
        [0.6587, 0.3413],
        [0.6613, 0.3387],
        [0.6704, 0.3296],
        [0.6680, 0.3320],
        [0.6668, 0.3332],
        [0.6696, 0.3304],
        [0.6533, 0.3467],
        [0.6529, 0.3471],
        [0.6712, 0.3288],
        [0.6669, 0.3331],
        [0.6589, 0.3411],
        [0.6658, 0.3342],
        [0.6533, 0.3467],
        [0.6725, 0.3275],
        [0.6600, 0.3400],
        [0.6684, 0.3316],
        [0.6668, 0.3332],
        [0.6564, 0.3436],
        [0.6614, 0.3386],
        [0.6646, 0.3354],
        [0.6684, 0.3316],
        [0.6550, 0.3450],
        [0.6563, 0.3437],
        [0.6610, 0.3390],
        [0.6677, 0.3323],
        [0.6629, 0.3371],
        [0.6549, 0.3451],
        [0.6630, 0.3370],
        [0.6671, 0.3329],
        [0.6697, 0.3303],
        [0.6523, 0.3477],
        [0.6659, 0.3341],
        [0.6599, 0.3401],
        [0.6656, 0.3344],
        [0.6680, 0.3320],
        [0.6744, 0.3256],
        [0.6669, 0.3331],
        [0.6718, 0.3282],
        [0.6659, 0.3341],
        [0.6747, 0.3253],
        [0.6714, 0.3286],
        [0.6559, 0.3441],
        [0.6733, 0.3267],
        [0.6678, 0.3322],
        [0.6608, 0.3392],
        [0.6591, 0.3409],
        [0.6673, 0.3327],
        [0.6683, 0.3317],
        [0.6611, 0.3389],
        [0.6557, 0.3443],
        [0.6583, 0.3417],
        [0.6665, 0.3335],
        [0.6620, 0.3380],
        [0.6639, 0.3361],
        [0.6658, 0.3342],
        [0.6644, 0.3356],
        [0.6587, 0.3413],
        [0.6570, 0.3430],
        [0.6622, 0.3378],
        [0.6717, 0.3283],
        [0.6693, 0.3307],
        [0.6602, 0.3398],
        [0.6679, 0.3321],
        [0.6670, 0.3330],
        [0.6645, 0.3355],
        [0.6645, 0.3355],
        [0.6689, 0.3311],
        [0.6574, 0.3426],
        [0.6546, 0.3454],
        [0.6532, 0.3468],
        [0.6748, 0.3252],
        [0.6711, 0.3289],
        [0.6658, 0.3342],
        [0.6582, 0.3418],
        [0.6516, 0.3484],
        [0.6606, 0.3394],
        [0.6716, 0.3284],
        [0.6657, 0.3343],
        [0.6626, 0.3374],
        [0.6613, 0.3387],
        [0.6635, 0.3365],
        [0.6618, 0.3382],
        [0.6686, 0.3314],
        [0.6526, 0.3474],
        [0.6762, 0.3238],
        [0.6761, 0.3239],
        [0.6605, 0.3395],
        [0.6737, 0.3263],
        [0.6735, 0.3265],
        [0.6573, 0.3427],
        [0.6630, 0.3370],
        [0.6598, 0.3402],
        [0.6744, 0.3256],
        [0.6776, 0.3224],
        [0.6676, 0.3324],
        [0.6698, 0.3302],
        [0.6672, 0.3328],
        [0.6662, 0.3338],
        [0.6675, 0.3325],
        [0.6572, 0.3428],
        [0.6680, 0.3320],
        [0.6627, 0.3373],
        [0.6577, 0.3423],
        [0.6657, 0.3343],
        [0.6661, 0.3339],
        [0.6701, 0.3299],
        [0.6627, 0.3373],
        [0.6694, 0.3306],
        [0.6520, 0.3480],
        [0.6603, 0.3397],
        [0.6742, 0.3258],
        [0.6722, 0.3278],
        [0.6587, 0.3413],
        [0.6653, 0.3347],
        [0.6605, 0.3395],
        [0.6683, 0.3317],
        [0.6567, 0.3433],
        [0.6751, 0.3249],
        [0.6649, 0.3351],
        [0.6643, 0.3357],
        [0.6683, 0.3317],
        [0.6737, 0.3263],
        [0.6664, 0.3336],
        [0.6613, 0.3387],
        [0.6660, 0.3340],
        [0.6589, 0.3411],
        [0.6717, 0.3283],
        [0.6701, 0.3299],
        [0.6628, 0.3372],
        [0.6667, 0.3333],
        [0.6568, 0.3432],
        [0.6628, 0.3372],
        [0.6715, 0.3285],
        [0.6667, 0.3333],
        [0.6617, 0.3383],
        [0.6675, 0.3325],
        [0.6599, 0.3401],
        [0.6696, 0.3304],
        [0.6624, 0.3376],
        [0.6663, 0.3337],
        [0.6629, 0.3371],
        [0.6646, 0.3354],
        [0.6651, 0.3349],
        [0.6673, 0.3327],
        [0.6613, 0.3387],
        [0.6666, 0.3334],
        [0.6675, 0.3325],
        [0.6598, 0.3402],
        [0.6585, 0.3415],
        [0.6682, 0.3318],
        [0.6567, 0.3433],
        [0.6640, 0.3360],
        [0.6764, 0.3236],
        [0.6644, 0.3356],
        [0.6571, 0.3429],
        [0.6685, 0.3315],
        [0.6665, 0.3335],
        [0.6734, 0.3266]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0035 loss: 0.6686 acc_train: 0.6103 time: 0.1053s
tensor([[0.6696, 0.3304],
        [0.6625, 0.3375],
        [0.6721, 0.3279],
        [0.6676, 0.3324],
        [0.6771, 0.3229],
        [0.6594, 0.3406],
        [0.6655, 0.3345],
        [0.6667, 0.3333],
        [0.6612, 0.3388],
        [0.6650, 0.3350],
        [0.6650, 0.3350],
        [0.6714, 0.3286],
        [0.6644, 0.3356],
        [0.6614, 0.3386],
        [0.6679, 0.3321],
        [0.6558, 0.3442],
        [0.6693, 0.3307],
        [0.6683, 0.3317],
        [0.6575, 0.3425],
        [0.6607, 0.3393],
        [0.6649, 0.3351],
        [0.6655, 0.3345],
        [0.6679, 0.3321],
        [0.6717, 0.3283],
        [0.6630, 0.3370],
        [0.6543, 0.3457],
        [0.6579, 0.3421],
        [0.6662, 0.3338],
        [0.6594, 0.3406],
        [0.6572, 0.3428],
        [0.6601, 0.3399],
        [0.6594, 0.3406],
        [0.6695, 0.3305],
        [0.6690, 0.3310],
        [0.6669, 0.3331],
        [0.6559, 0.3441],
        [0.6582, 0.3418],
        [0.6579, 0.3421],
        [0.6677, 0.3323],
        [0.6684, 0.3316],
        [0.6679, 0.3321],
        [0.6593, 0.3407],
        [0.6475, 0.3525],
        [0.6617, 0.3383],
        [0.6700, 0.3300],
        [0.6657, 0.3343],
        [0.6748, 0.3252],
        [0.6708, 0.3292],
        [0.6640, 0.3360],
        [0.6700, 0.3300],
        [0.6681, 0.3319],
        [0.6696, 0.3304],
        [0.6656, 0.3344],
        [0.6610, 0.3390],
        [0.6601, 0.3399],
        [0.6736, 0.3264],
        [0.6618, 0.3382],
        [0.6635, 0.3365],
        [0.6718, 0.3282],
        [0.6637, 0.3363],
        [0.6528, 0.3472],
        [0.6583, 0.3417],
        [0.6716, 0.3284],
        [0.6699, 0.3301],
        [0.6614, 0.3386],
        [0.6612, 0.3388],
        [0.6626, 0.3374],
        [0.6577, 0.3423],
        [0.6609, 0.3391],
        [0.6646, 0.3354],
        [0.6614, 0.3386],
        [0.6686, 0.3314],
        [0.6701, 0.3299],
        [0.6706, 0.3294],
        [0.6608, 0.3392],
        [0.6622, 0.3378],
        [0.6701, 0.3299],
        [0.6668, 0.3332],
        [0.6594, 0.3406],
        [0.6648, 0.3352],
        [0.6653, 0.3347],
        [0.6690, 0.3310],
        [0.6579, 0.3421],
        [0.6657, 0.3343],
        [0.6611, 0.3389],
        [0.6573, 0.3427],
        [0.6624, 0.3376],
        [0.6647, 0.3353],
        [0.6684, 0.3316],
        [0.6657, 0.3343],
        [0.6695, 0.3305],
        [0.6682, 0.3318],
        [0.6701, 0.3299],
        [0.6560, 0.3440],
        [0.6636, 0.3364],
        [0.6739, 0.3261],
        [0.6746, 0.3254],
        [0.6528, 0.3472],
        [0.6755, 0.3245],
        [0.6608, 0.3392],
        [0.6717, 0.3283],
        [0.6677, 0.3323],
        [0.6543, 0.3457],
        [0.6592, 0.3408],
        [0.6631, 0.3369],
        [0.6660, 0.3340],
        [0.6662, 0.3338],
        [0.6680, 0.3320],
        [0.6598, 0.3402],
        [0.6740, 0.3260],
        [0.6505, 0.3495],
        [0.6608, 0.3392],
        [0.6685, 0.3315],
        [0.6695, 0.3305],
        [0.6593, 0.3407],
        [0.6617, 0.3383],
        [0.6707, 0.3293],
        [0.6685, 0.3315],
        [0.6673, 0.3327],
        [0.6698, 0.3302],
        [0.6540, 0.3460],
        [0.6536, 0.3464],
        [0.6715, 0.3285],
        [0.6673, 0.3327],
        [0.6595, 0.3405],
        [0.6664, 0.3336],
        [0.6540, 0.3460],
        [0.6727, 0.3273],
        [0.6605, 0.3395],
        [0.6687, 0.3313],
        [0.6672, 0.3328],
        [0.6571, 0.3429],
        [0.6619, 0.3381],
        [0.6650, 0.3350],
        [0.6687, 0.3313],
        [0.6556, 0.3444],
        [0.6570, 0.3430],
        [0.6616, 0.3384],
        [0.6682, 0.3318],
        [0.6634, 0.3366],
        [0.6556, 0.3444],
        [0.6635, 0.3365],
        [0.6674, 0.3326],
        [0.6700, 0.3300],
        [0.6531, 0.3469],
        [0.6664, 0.3336],
        [0.6605, 0.3395],
        [0.6659, 0.3341],
        [0.6683, 0.3317],
        [0.6746, 0.3254],
        [0.6673, 0.3327],
        [0.6724, 0.3276],
        [0.6662, 0.3338],
        [0.6750, 0.3250],
        [0.6719, 0.3281],
        [0.6565, 0.3435],
        [0.6735, 0.3265],
        [0.6681, 0.3319],
        [0.6613, 0.3387],
        [0.6598, 0.3402],
        [0.6678, 0.3322],
        [0.6686, 0.3314],
        [0.6616, 0.3384],
        [0.6563, 0.3437],
        [0.6590, 0.3410],
        [0.6669, 0.3331],
        [0.6625, 0.3375],
        [0.6644, 0.3356],
        [0.6665, 0.3335],
        [0.6649, 0.3351],
        [0.6592, 0.3408],
        [0.6577, 0.3423],
        [0.6628, 0.3372],
        [0.6719, 0.3281],
        [0.6697, 0.3303],
        [0.6606, 0.3394],
        [0.6683, 0.3317],
        [0.6674, 0.3326],
        [0.6651, 0.3349],
        [0.6649, 0.3351],
        [0.6693, 0.3307],
        [0.6579, 0.3421],
        [0.6552, 0.3448],
        [0.6540, 0.3460],
        [0.6751, 0.3249],
        [0.6713, 0.3287],
        [0.6662, 0.3338],
        [0.6588, 0.3412],
        [0.6522, 0.3478],
        [0.6612, 0.3388],
        [0.6720, 0.3280],
        [0.6662, 0.3338],
        [0.6630, 0.3370],
        [0.6618, 0.3382],
        [0.6643, 0.3357],
        [0.6622, 0.3378],
        [0.6688, 0.3312],
        [0.6533, 0.3467],
        [0.6764, 0.3236],
        [0.6762, 0.3238],
        [0.6612, 0.3388],
        [0.6741, 0.3259],
        [0.6738, 0.3262],
        [0.6579, 0.3421],
        [0.6635, 0.3365],
        [0.6604, 0.3396],
        [0.6747, 0.3253],
        [0.6778, 0.3222],
        [0.6680, 0.3320],
        [0.6700, 0.3300],
        [0.6677, 0.3323],
        [0.6667, 0.3333],
        [0.6680, 0.3320],
        [0.6579, 0.3421],
        [0.6682, 0.3318],
        [0.6634, 0.3366],
        [0.6584, 0.3416],
        [0.6662, 0.3338],
        [0.6667, 0.3333],
        [0.6705, 0.3295],
        [0.6631, 0.3369],
        [0.6697, 0.3303],
        [0.6526, 0.3474],
        [0.6608, 0.3392],
        [0.6744, 0.3256],
        [0.6726, 0.3274],
        [0.6592, 0.3408],
        [0.6658, 0.3342],
        [0.6610, 0.3390],
        [0.6686, 0.3314],
        [0.6574, 0.3426],
        [0.6754, 0.3246],
        [0.6653, 0.3347],
        [0.6647, 0.3353],
        [0.6687, 0.3313],
        [0.6739, 0.3261],
        [0.6668, 0.3332],
        [0.6618, 0.3382],
        [0.6665, 0.3335],
        [0.6595, 0.3405],
        [0.6721, 0.3279],
        [0.6705, 0.3295],
        [0.6632, 0.3368],
        [0.6670, 0.3330],
        [0.6575, 0.3425],
        [0.6634, 0.3366],
        [0.6719, 0.3281],
        [0.6670, 0.3330],
        [0.6622, 0.3378],
        [0.6679, 0.3321],
        [0.6606, 0.3394],
        [0.6702, 0.3298],
        [0.6628, 0.3372],
        [0.6667, 0.3333],
        [0.6634, 0.3366],
        [0.6651, 0.3349],
        [0.6656, 0.3344],
        [0.6677, 0.3323],
        [0.6619, 0.3381],
        [0.6671, 0.3329],
        [0.6680, 0.3320],
        [0.6602, 0.3398],
        [0.6590, 0.3410],
        [0.6686, 0.3314],
        [0.6574, 0.3426],
        [0.6644, 0.3356],
        [0.6766, 0.3234],
        [0.6649, 0.3351],
        [0.6578, 0.3422],
        [0.6688, 0.3312],
        [0.6669, 0.3331],
        [0.6737, 0.3263]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0036 loss: 0.6686 acc_train: 0.6103 time: 0.1197s
tensor([[0.6698, 0.3302],
        [0.6630, 0.3370],
        [0.6722, 0.3278],
        [0.6679, 0.3321],
        [0.6771, 0.3229],
        [0.6596, 0.3404],
        [0.6658, 0.3342],
        [0.6669, 0.3331],
        [0.6617, 0.3383],
        [0.6653, 0.3347],
        [0.6653, 0.3347],
        [0.6715, 0.3285],
        [0.6646, 0.3354],
        [0.6619, 0.3381],
        [0.6682, 0.3318],
        [0.6563, 0.3437],
        [0.6698, 0.3302],
        [0.6685, 0.3315],
        [0.6580, 0.3420],
        [0.6610, 0.3390],
        [0.6654, 0.3346],
        [0.6656, 0.3344],
        [0.6682, 0.3318],
        [0.6718, 0.3282],
        [0.6634, 0.3366],
        [0.6548, 0.3452],
        [0.6584, 0.3416],
        [0.6664, 0.3336],
        [0.6599, 0.3401],
        [0.6576, 0.3424],
        [0.6604, 0.3396],
        [0.6599, 0.3401],
        [0.6699, 0.3301],
        [0.6693, 0.3307],
        [0.6671, 0.3329],
        [0.6566, 0.3434],
        [0.6587, 0.3413],
        [0.6583, 0.3417],
        [0.6680, 0.3320],
        [0.6685, 0.3315],
        [0.6681, 0.3319],
        [0.6599, 0.3401],
        [0.6482, 0.3518],
        [0.6620, 0.3380],
        [0.6705, 0.3295],
        [0.6660, 0.3340],
        [0.6749, 0.3251],
        [0.6709, 0.3291],
        [0.6644, 0.3356],
        [0.6701, 0.3299],
        [0.6683, 0.3317],
        [0.6696, 0.3304],
        [0.6659, 0.3341],
        [0.6616, 0.3384],
        [0.6605, 0.3395],
        [0.6738, 0.3262],
        [0.6623, 0.3377],
        [0.6639, 0.3361],
        [0.6719, 0.3281],
        [0.6640, 0.3360],
        [0.6534, 0.3466],
        [0.6586, 0.3414],
        [0.6718, 0.3282],
        [0.6701, 0.3299],
        [0.6618, 0.3382],
        [0.6616, 0.3384],
        [0.6630, 0.3370],
        [0.6582, 0.3418],
        [0.6613, 0.3387],
        [0.6648, 0.3352],
        [0.6617, 0.3383],
        [0.6688, 0.3312],
        [0.6703, 0.3297],
        [0.6706, 0.3294],
        [0.6611, 0.3389],
        [0.6626, 0.3374],
        [0.6703, 0.3297],
        [0.6672, 0.3328],
        [0.6598, 0.3402],
        [0.6650, 0.3350],
        [0.6655, 0.3345],
        [0.6692, 0.3308],
        [0.6583, 0.3417],
        [0.6660, 0.3340],
        [0.6616, 0.3384],
        [0.6578, 0.3422],
        [0.6627, 0.3373],
        [0.6650, 0.3350],
        [0.6686, 0.3314],
        [0.6661, 0.3339],
        [0.6697, 0.3303],
        [0.6684, 0.3316],
        [0.6702, 0.3298],
        [0.6564, 0.3436],
        [0.6638, 0.3362],
        [0.6739, 0.3261],
        [0.6748, 0.3252],
        [0.6532, 0.3468],
        [0.6755, 0.3245],
        [0.6611, 0.3389],
        [0.6720, 0.3280],
        [0.6679, 0.3321],
        [0.6548, 0.3452],
        [0.6595, 0.3405],
        [0.6635, 0.3365],
        [0.6662, 0.3338],
        [0.6665, 0.3335],
        [0.6685, 0.3315],
        [0.6602, 0.3398],
        [0.6741, 0.3259],
        [0.6511, 0.3489],
        [0.6611, 0.3389],
        [0.6687, 0.3313],
        [0.6698, 0.3302],
        [0.6598, 0.3402],
        [0.6620, 0.3380],
        [0.6709, 0.3291],
        [0.6688, 0.3312],
        [0.6676, 0.3324],
        [0.6699, 0.3301],
        [0.6545, 0.3455],
        [0.6542, 0.3458],
        [0.6716, 0.3284],
        [0.6675, 0.3325],
        [0.6599, 0.3401],
        [0.6668, 0.3332],
        [0.6545, 0.3455],
        [0.6727, 0.3273],
        [0.6607, 0.3393],
        [0.6688, 0.3312],
        [0.6674, 0.3326],
        [0.6577, 0.3423],
        [0.6623, 0.3377],
        [0.6653, 0.3347],
        [0.6688, 0.3312],
        [0.6561, 0.3439],
        [0.6576, 0.3424],
        [0.6621, 0.3379],
        [0.6684, 0.3316],
        [0.6637, 0.3363],
        [0.6561, 0.3439],
        [0.6638, 0.3362],
        [0.6676, 0.3324],
        [0.6702, 0.3298],
        [0.6536, 0.3464],
        [0.6667, 0.3333],
        [0.6609, 0.3391],
        [0.6661, 0.3339],
        [0.6686, 0.3314],
        [0.6748, 0.3252],
        [0.6676, 0.3324],
        [0.6728, 0.3272],
        [0.6664, 0.3336],
        [0.6752, 0.3248],
        [0.6721, 0.3279],
        [0.6570, 0.3430],
        [0.6736, 0.3264],
        [0.6683, 0.3317],
        [0.6616, 0.3384],
        [0.6604, 0.3396],
        [0.6682, 0.3318],
        [0.6689, 0.3311],
        [0.6619, 0.3381],
        [0.6569, 0.3431],
        [0.6596, 0.3404],
        [0.6670, 0.3330],
        [0.6628, 0.3372],
        [0.6648, 0.3352],
        [0.6670, 0.3330],
        [0.6653, 0.3347],
        [0.6596, 0.3404],
        [0.6582, 0.3418],
        [0.6632, 0.3368],
        [0.6719, 0.3281],
        [0.6699, 0.3301],
        [0.6609, 0.3391],
        [0.6686, 0.3314],
        [0.6676, 0.3324],
        [0.6655, 0.3345],
        [0.6653, 0.3347],
        [0.6695, 0.3305],
        [0.6583, 0.3417],
        [0.6556, 0.3444],
        [0.6545, 0.3455],
        [0.6752, 0.3248],
        [0.6714, 0.3286],
        [0.6664, 0.3336],
        [0.6593, 0.3407],
        [0.6528, 0.3472],
        [0.6616, 0.3384],
        [0.6722, 0.3278],
        [0.6665, 0.3335],
        [0.6632, 0.3368],
        [0.6621, 0.3379],
        [0.6649, 0.3351],
        [0.6625, 0.3375],
        [0.6688, 0.3312],
        [0.6539, 0.3461],
        [0.6765, 0.3235],
        [0.6762, 0.3238],
        [0.6617, 0.3383],
        [0.6743, 0.3257],
        [0.6740, 0.3260],
        [0.6583, 0.3417],
        [0.6638, 0.3362],
        [0.6608, 0.3392],
        [0.6748, 0.3252],
        [0.6780, 0.3220],
        [0.6682, 0.3318],
        [0.6702, 0.3298],
        [0.6681, 0.3319],
        [0.6670, 0.3330],
        [0.6682, 0.3318],
        [0.6584, 0.3416],
        [0.6684, 0.3316],
        [0.6638, 0.3362],
        [0.6589, 0.3411],
        [0.6664, 0.3336],
        [0.6670, 0.3330],
        [0.6706, 0.3294],
        [0.6634, 0.3366],
        [0.6698, 0.3302],
        [0.6531, 0.3469],
        [0.6611, 0.3389],
        [0.6744, 0.3256],
        [0.6728, 0.3272],
        [0.6597, 0.3403],
        [0.6660, 0.3340],
        [0.6613, 0.3387],
        [0.6687, 0.3313],
        [0.6579, 0.3421],
        [0.6755, 0.3245],
        [0.6656, 0.3344],
        [0.6649, 0.3351],
        [0.6689, 0.3311],
        [0.6740, 0.3260],
        [0.6671, 0.3329],
        [0.6622, 0.3378],
        [0.6669, 0.3331],
        [0.6599, 0.3401],
        [0.6724, 0.3276],
        [0.6707, 0.3293],
        [0.6635, 0.3365],
        [0.6673, 0.3327],
        [0.6579, 0.3421],
        [0.6639, 0.3361],
        [0.6721, 0.3279],
        [0.6673, 0.3327],
        [0.6625, 0.3375],
        [0.6680, 0.3320],
        [0.6611, 0.3389],
        [0.6706, 0.3294],
        [0.6630, 0.3370],
        [0.6670, 0.3330],
        [0.6637, 0.3363],
        [0.6654, 0.3346],
        [0.6659, 0.3341],
        [0.6679, 0.3321],
        [0.6623, 0.3377],
        [0.6674, 0.3326],
        [0.6683, 0.3317],
        [0.6605, 0.3395],
        [0.6593, 0.3407],
        [0.6688, 0.3312],
        [0.6579, 0.3421],
        [0.6646, 0.3354],
        [0.6766, 0.3234],
        [0.6652, 0.3348],
        [0.6584, 0.3416],
        [0.6689, 0.3311],
        [0.6672, 0.3328],
        [0.6739, 0.3261]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0037 loss: 0.6686 acc_train: 0.6103 time: 0.1132s
tensor([[0.6698, 0.3302],
        [0.6633, 0.3367],
        [0.6722, 0.3278],
        [0.6681, 0.3319],
        [0.6770, 0.3230],
        [0.6596, 0.3404],
        [0.6660, 0.3340],
        [0.6669, 0.3331],
        [0.6621, 0.3379],
        [0.6655, 0.3345],
        [0.6656, 0.3344],
        [0.6716, 0.3284],
        [0.6647, 0.3353],
        [0.6621, 0.3379],
        [0.6683, 0.3317],
        [0.6566, 0.3434],
        [0.6702, 0.3298],
        [0.6686, 0.3314],
        [0.6583, 0.3417],
        [0.6611, 0.3389],
        [0.6658, 0.3342],
        [0.6656, 0.3344],
        [0.6684, 0.3316],
        [0.6719, 0.3281],
        [0.6637, 0.3363],
        [0.6552, 0.3448],
        [0.6588, 0.3412],
        [0.6666, 0.3334],
        [0.6601, 0.3399],
        [0.6578, 0.3422],
        [0.6605, 0.3395],
        [0.6602, 0.3398],
        [0.6701, 0.3299],
        [0.6694, 0.3306],
        [0.6671, 0.3329],
        [0.6571, 0.3429],
        [0.6591, 0.3409],
        [0.6586, 0.3414],
        [0.6682, 0.3318],
        [0.6685, 0.3315],
        [0.6681, 0.3319],
        [0.6604, 0.3396],
        [0.6488, 0.3512],
        [0.6624, 0.3376],
        [0.6708, 0.3292],
        [0.6661, 0.3339],
        [0.6749, 0.3251],
        [0.6709, 0.3291],
        [0.6647, 0.3353],
        [0.6701, 0.3299],
        [0.6684, 0.3316],
        [0.6697, 0.3303],
        [0.6660, 0.3340],
        [0.6620, 0.3380],
        [0.6607, 0.3393],
        [0.6738, 0.3262],
        [0.6626, 0.3374],
        [0.6640, 0.3360],
        [0.6719, 0.3281],
        [0.6642, 0.3358],
        [0.6539, 0.3461],
        [0.6588, 0.3412],
        [0.6717, 0.3283],
        [0.6702, 0.3298],
        [0.6620, 0.3380],
        [0.6619, 0.3381],
        [0.6632, 0.3368],
        [0.6586, 0.3414],
        [0.6617, 0.3383],
        [0.6650, 0.3350],
        [0.6619, 0.3381],
        [0.6688, 0.3312],
        [0.6704, 0.3296],
        [0.6705, 0.3295],
        [0.6612, 0.3388],
        [0.6628, 0.3372],
        [0.6705, 0.3295],
        [0.6673, 0.3327],
        [0.6600, 0.3400],
        [0.6652, 0.3348],
        [0.6656, 0.3344],
        [0.6693, 0.3307],
        [0.6586, 0.3414],
        [0.6661, 0.3339],
        [0.6619, 0.3381],
        [0.6582, 0.3418],
        [0.6629, 0.3371],
        [0.6652, 0.3348],
        [0.6687, 0.3313],
        [0.6664, 0.3336],
        [0.6698, 0.3302],
        [0.6684, 0.3316],
        [0.6702, 0.3298],
        [0.6567, 0.3433],
        [0.6639, 0.3361],
        [0.6739, 0.3261],
        [0.6748, 0.3252],
        [0.6535, 0.3465],
        [0.6755, 0.3245],
        [0.6613, 0.3387],
        [0.6722, 0.3278],
        [0.6679, 0.3321],
        [0.6552, 0.3448],
        [0.6598, 0.3402],
        [0.6639, 0.3361],
        [0.6663, 0.3337],
        [0.6667, 0.3333],
        [0.6688, 0.3312],
        [0.6605, 0.3395],
        [0.6742, 0.3258],
        [0.6516, 0.3484],
        [0.6613, 0.3387],
        [0.6687, 0.3313],
        [0.6699, 0.3301],
        [0.6600, 0.3400],
        [0.6623, 0.3377],
        [0.6709, 0.3291],
        [0.6689, 0.3311],
        [0.6677, 0.3323],
        [0.6699, 0.3301],
        [0.6548, 0.3452],
        [0.6546, 0.3454],
        [0.6716, 0.3284],
        [0.6676, 0.3324],
        [0.6602, 0.3398],
        [0.6669, 0.3331],
        [0.6549, 0.3451],
        [0.6727, 0.3273],
        [0.6609, 0.3391],
        [0.6689, 0.3311],
        [0.6675, 0.3325],
        [0.6582, 0.3418],
        [0.6627, 0.3373],
        [0.6654, 0.3346],
        [0.6688, 0.3312],
        [0.6565, 0.3435],
        [0.6579, 0.3421],
        [0.6624, 0.3376],
        [0.6685, 0.3315],
        [0.6639, 0.3361],
        [0.6565, 0.3435],
        [0.6640, 0.3360],
        [0.6677, 0.3323],
        [0.6702, 0.3298],
        [0.6541, 0.3459],
        [0.6669, 0.3331],
        [0.6612, 0.3388],
        [0.6661, 0.3339],
        [0.6687, 0.3313],
        [0.6748, 0.3252],
        [0.6677, 0.3323],
        [0.6729, 0.3271],
        [0.6665, 0.3335],
        [0.6752, 0.3248],
        [0.6723, 0.3277],
        [0.6573, 0.3427],
        [0.6736, 0.3264],
        [0.6683, 0.3317],
        [0.6618, 0.3382],
        [0.6609, 0.3391],
        [0.6683, 0.3317],
        [0.6689, 0.3311],
        [0.6620, 0.3380],
        [0.6572, 0.3428],
        [0.6601, 0.3399],
        [0.6671, 0.3329],
        [0.6630, 0.3370],
        [0.6650, 0.3350],
        [0.6673, 0.3327],
        [0.6655, 0.3345],
        [0.6600, 0.3400],
        [0.6586, 0.3414],
        [0.6633, 0.3367],
        [0.6719, 0.3281],
        [0.6701, 0.3299],
        [0.6611, 0.3389],
        [0.6688, 0.3312],
        [0.6677, 0.3323],
        [0.6657, 0.3343],
        [0.6655, 0.3345],
        [0.6697, 0.3303],
        [0.6586, 0.3414],
        [0.6559, 0.3441],
        [0.6549, 0.3451],
        [0.6752, 0.3248],
        [0.6714, 0.3286],
        [0.6664, 0.3336],
        [0.6596, 0.3404],
        [0.6533, 0.3467],
        [0.6619, 0.3381],
        [0.6724, 0.3276],
        [0.6668, 0.3332],
        [0.6631, 0.3369],
        [0.6623, 0.3377],
        [0.6653, 0.3347],
        [0.6626, 0.3374],
        [0.6687, 0.3313],
        [0.6544, 0.3456],
        [0.6765, 0.3235],
        [0.6761, 0.3239],
        [0.6620, 0.3380],
        [0.6743, 0.3257],
        [0.6741, 0.3259],
        [0.6585, 0.3415],
        [0.6641, 0.3359],
        [0.6612, 0.3388],
        [0.6748, 0.3252],
        [0.6780, 0.3220],
        [0.6682, 0.3318],
        [0.6703, 0.3297],
        [0.6683, 0.3317],
        [0.6671, 0.3329],
        [0.6684, 0.3316],
        [0.6587, 0.3413],
        [0.6686, 0.3314],
        [0.6642, 0.3358],
        [0.6592, 0.3408],
        [0.6665, 0.3335],
        [0.6673, 0.3327],
        [0.6706, 0.3294],
        [0.6635, 0.3365],
        [0.6699, 0.3301],
        [0.6533, 0.3467],
        [0.6614, 0.3386],
        [0.6744, 0.3256],
        [0.6730, 0.3270],
        [0.6601, 0.3399],
        [0.6661, 0.3339],
        [0.6615, 0.3385],
        [0.6687, 0.3313],
        [0.6582, 0.3418],
        [0.6756, 0.3244],
        [0.6658, 0.3342],
        [0.6651, 0.3349],
        [0.6689, 0.3311],
        [0.6740, 0.3260],
        [0.6671, 0.3329],
        [0.6625, 0.3375],
        [0.6672, 0.3328],
        [0.6602, 0.3398],
        [0.6726, 0.3274],
        [0.6709, 0.3291],
        [0.6636, 0.3364],
        [0.6674, 0.3326],
        [0.6583, 0.3417],
        [0.6643, 0.3357],
        [0.6723, 0.3277],
        [0.6674, 0.3326],
        [0.6628, 0.3372],
        [0.6681, 0.3319],
        [0.6613, 0.3387],
        [0.6708, 0.3292],
        [0.6630, 0.3370],
        [0.6672, 0.3328],
        [0.6640, 0.3360],
        [0.6657, 0.3343],
        [0.6661, 0.3339],
        [0.6680, 0.3320],
        [0.6626, 0.3374],
        [0.6676, 0.3324],
        [0.6684, 0.3316],
        [0.6607, 0.3393],
        [0.6594, 0.3406],
        [0.6690, 0.3310],
        [0.6582, 0.3418],
        [0.6648, 0.3352],
        [0.6765, 0.3235],
        [0.6654, 0.3346],
        [0.6587, 0.3413],
        [0.6689, 0.3311],
        [0.6673, 0.3327],
        [0.6739, 0.3261]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0038 loss: 0.6686 acc_train: 0.6103 time: 0.1199s
tensor([[0.6697, 0.3303],
        [0.6635, 0.3365],
        [0.6721, 0.3279],
        [0.6681, 0.3319],
        [0.6769, 0.3231],
        [0.6596, 0.3404],
        [0.6660, 0.3340],
        [0.6669, 0.3331],
        [0.6624, 0.3376],
        [0.6656, 0.3344],
        [0.6657, 0.3343],
        [0.6715, 0.3285],
        [0.6647, 0.3353],
        [0.6622, 0.3378],
        [0.6683, 0.3317],
        [0.6568, 0.3432],
        [0.6705, 0.3295],
        [0.6685, 0.3315],
        [0.6586, 0.3414],
        [0.6612, 0.3388],
        [0.6660, 0.3340],
        [0.6655, 0.3345],
        [0.6686, 0.3314],
        [0.6718, 0.3282],
        [0.6639, 0.3361],
        [0.6554, 0.3446],
        [0.6591, 0.3409],
        [0.6666, 0.3334],
        [0.6602, 0.3398],
        [0.6579, 0.3421],
        [0.6606, 0.3394],
        [0.6604, 0.3396],
        [0.6702, 0.3298],
        [0.6694, 0.3306],
        [0.6671, 0.3329],
        [0.6575, 0.3425],
        [0.6592, 0.3408],
        [0.6588, 0.3412],
        [0.6682, 0.3318],
        [0.6684, 0.3316],
        [0.6681, 0.3319],
        [0.6608, 0.3392],
        [0.6493, 0.3507],
        [0.6627, 0.3373],
        [0.6710, 0.3290],
        [0.6662, 0.3338],
        [0.6749, 0.3251],
        [0.6708, 0.3292],
        [0.6648, 0.3352],
        [0.6701, 0.3299],
        [0.6683, 0.3317],
        [0.6696, 0.3304],
        [0.6659, 0.3341],
        [0.6623, 0.3377],
        [0.6608, 0.3392],
        [0.6737, 0.3263],
        [0.6628, 0.3372],
        [0.6641, 0.3359],
        [0.6718, 0.3282],
        [0.6643, 0.3357],
        [0.6542, 0.3458],
        [0.6589, 0.3411],
        [0.6716, 0.3284],
        [0.6702, 0.3298],
        [0.6621, 0.3379],
        [0.6621, 0.3379],
        [0.6633, 0.3367],
        [0.6588, 0.3412],
        [0.6621, 0.3379],
        [0.6650, 0.3350],
        [0.6620, 0.3380],
        [0.6688, 0.3312],
        [0.6704, 0.3296],
        [0.6704, 0.3296],
        [0.6612, 0.3388],
        [0.6629, 0.3371],
        [0.6705, 0.3295],
        [0.6672, 0.3328],
        [0.6601, 0.3399],
        [0.6652, 0.3348],
        [0.6656, 0.3344],
        [0.6693, 0.3307],
        [0.6589, 0.3411],
        [0.6661, 0.3339],
        [0.6620, 0.3380],
        [0.6584, 0.3416],
        [0.6630, 0.3370],
        [0.6652, 0.3348],
        [0.6687, 0.3313],
        [0.6665, 0.3335],
        [0.6697, 0.3303],
        [0.6683, 0.3317],
        [0.6701, 0.3299],
        [0.6569, 0.3431],
        [0.6639, 0.3361],
        [0.6738, 0.3262],
        [0.6748, 0.3252],
        [0.6536, 0.3464],
        [0.6754, 0.3246],
        [0.6615, 0.3385],
        [0.6723, 0.3277],
        [0.6679, 0.3321],
        [0.6554, 0.3446],
        [0.6601, 0.3399],
        [0.6641, 0.3359],
        [0.6663, 0.3337],
        [0.6668, 0.3332],
        [0.6690, 0.3310],
        [0.6607, 0.3393],
        [0.6742, 0.3258],
        [0.6522, 0.3478],
        [0.6614, 0.3386],
        [0.6686, 0.3314],
        [0.6699, 0.3301],
        [0.6600, 0.3400],
        [0.6626, 0.3374],
        [0.6708, 0.3292],
        [0.6689, 0.3311],
        [0.6678, 0.3322],
        [0.6697, 0.3303],
        [0.6551, 0.3449],
        [0.6549, 0.3451],
        [0.6715, 0.3285],
        [0.6676, 0.3324],
        [0.6604, 0.3396],
        [0.6669, 0.3331],
        [0.6551, 0.3449],
        [0.6726, 0.3274],
        [0.6608, 0.3392],
        [0.6688, 0.3312],
        [0.6675, 0.3325],
        [0.6586, 0.3414],
        [0.6630, 0.3370],
        [0.6655, 0.3345],
        [0.6688, 0.3312],
        [0.6567, 0.3433],
        [0.6581, 0.3419],
        [0.6627, 0.3373],
        [0.6684, 0.3316],
        [0.6640, 0.3360],
        [0.6566, 0.3434],
        [0.6640, 0.3360],
        [0.6677, 0.3323],
        [0.6702, 0.3298],
        [0.6543, 0.3457],
        [0.6669, 0.3331],
        [0.6613, 0.3387],
        [0.6660, 0.3340],
        [0.6687, 0.3313],
        [0.6747, 0.3253],
        [0.6677, 0.3323],
        [0.6729, 0.3271],
        [0.6666, 0.3334],
        [0.6751, 0.3249],
        [0.6723, 0.3277],
        [0.6576, 0.3424],
        [0.6734, 0.3266],
        [0.6683, 0.3317],
        [0.6619, 0.3381],
        [0.6611, 0.3389],
        [0.6684, 0.3316],
        [0.6689, 0.3311],
        [0.6621, 0.3379],
        [0.6575, 0.3425],
        [0.6604, 0.3396],
        [0.6671, 0.3329],
        [0.6631, 0.3369],
        [0.6651, 0.3349],
        [0.6674, 0.3326],
        [0.6655, 0.3345],
        [0.6604, 0.3396],
        [0.6588, 0.3412],
        [0.6634, 0.3366],
        [0.6718, 0.3282],
        [0.6701, 0.3299],
        [0.6612, 0.3388],
        [0.6688, 0.3312],
        [0.6677, 0.3323],
        [0.6657, 0.3343],
        [0.6657, 0.3343],
        [0.6697, 0.3303],
        [0.6587, 0.3413],
        [0.6562, 0.3438],
        [0.6551, 0.3449],
        [0.6751, 0.3249],
        [0.6713, 0.3287],
        [0.6662, 0.3338],
        [0.6598, 0.3402],
        [0.6536, 0.3464],
        [0.6621, 0.3379],
        [0.6726, 0.3274],
        [0.6669, 0.3331],
        [0.6630, 0.3370],
        [0.6624, 0.3376],
        [0.6655, 0.3345],
        [0.6627, 0.3373],
        [0.6686, 0.3314],
        [0.6547, 0.3453],
        [0.6764, 0.3236],
        [0.6760, 0.3240],
        [0.6621, 0.3379],
        [0.6742, 0.3258],
        [0.6740, 0.3260],
        [0.6585, 0.3415],
        [0.6644, 0.3356],
        [0.6614, 0.3386],
        [0.6748, 0.3252],
        [0.6780, 0.3220],
        [0.6682, 0.3318],
        [0.6703, 0.3297],
        [0.6684, 0.3316],
        [0.6671, 0.3329],
        [0.6685, 0.3315],
        [0.6589, 0.3411],
        [0.6686, 0.3314],
        [0.6644, 0.3356],
        [0.6594, 0.3406],
        [0.6665, 0.3335],
        [0.6675, 0.3325],
        [0.6705, 0.3295],
        [0.6636, 0.3364],
        [0.6699, 0.3301],
        [0.6535, 0.3465],
        [0.6616, 0.3384],
        [0.6743, 0.3257],
        [0.6730, 0.3270],
        [0.6605, 0.3395],
        [0.6660, 0.3340],
        [0.6615, 0.3385],
        [0.6686, 0.3314],
        [0.6584, 0.3416],
        [0.6755, 0.3245],
        [0.6660, 0.3340],
        [0.6651, 0.3349],
        [0.6689, 0.3311],
        [0.6739, 0.3261],
        [0.6671, 0.3329],
        [0.6627, 0.3373],
        [0.6673, 0.3327],
        [0.6604, 0.3396],
        [0.6726, 0.3274],
        [0.6709, 0.3291],
        [0.6636, 0.3364],
        [0.6675, 0.3325],
        [0.6585, 0.3415],
        [0.6645, 0.3355],
        [0.6723, 0.3277],
        [0.6675, 0.3325],
        [0.6630, 0.3370],
        [0.6681, 0.3319],
        [0.6615, 0.3385],
        [0.6709, 0.3291],
        [0.6630, 0.3370],
        [0.6673, 0.3327],
        [0.6641, 0.3359],
        [0.6658, 0.3342],
        [0.6663, 0.3337],
        [0.6681, 0.3319],
        [0.6628, 0.3372],
        [0.6678, 0.3322],
        [0.6685, 0.3315],
        [0.6608, 0.3392],
        [0.6595, 0.3405],
        [0.6690, 0.3310],
        [0.6583, 0.3417],
        [0.6649, 0.3351],
        [0.6764, 0.3236],
        [0.6654, 0.3346],
        [0.6588, 0.3412],
        [0.6687, 0.3313],
        [0.6673, 0.3327],
        [0.6739, 0.3261]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0039 loss: 0.6686 acc_train: 0.6103 time: 0.1327s
tensor([[0.6696, 0.3304],
        [0.6636, 0.3364],
        [0.6719, 0.3281],
        [0.6680, 0.3320],
        [0.6767, 0.3233],
        [0.6596, 0.3404],
        [0.6660, 0.3340],
        [0.6668, 0.3332],
        [0.6626, 0.3374],
        [0.6655, 0.3345],
        [0.6658, 0.3342],
        [0.6715, 0.3285],
        [0.6647, 0.3353],
        [0.6622, 0.3378],
        [0.6683, 0.3317],
        [0.6569, 0.3431],
        [0.6707, 0.3293],
        [0.6684, 0.3316],
        [0.6588, 0.3412],
        [0.6612, 0.3388],
        [0.6663, 0.3337],
        [0.6653, 0.3347],
        [0.6686, 0.3314],
        [0.6718, 0.3282],
        [0.6639, 0.3361],
        [0.6556, 0.3444],
        [0.6593, 0.3407],
        [0.6667, 0.3333],
        [0.6603, 0.3397],
        [0.6580, 0.3420],
        [0.6607, 0.3393],
        [0.6605, 0.3395],
        [0.6703, 0.3297],
        [0.6693, 0.3307],
        [0.6670, 0.3330],
        [0.6578, 0.3422],
        [0.6594, 0.3406],
        [0.6590, 0.3410],
        [0.6681, 0.3319],
        [0.6682, 0.3318],
        [0.6682, 0.3318],
        [0.6610, 0.3390],
        [0.6498, 0.3502],
        [0.6630, 0.3370],
        [0.6712, 0.3288],
        [0.6661, 0.3339],
        [0.6748, 0.3252],
        [0.6708, 0.3292],
        [0.6648, 0.3352],
        [0.6700, 0.3300],
        [0.6682, 0.3318],
        [0.6696, 0.3304],
        [0.6658, 0.3342],
        [0.6627, 0.3373],
        [0.6608, 0.3392],
        [0.6736, 0.3264],
        [0.6629, 0.3371],
        [0.6641, 0.3359],
        [0.6716, 0.3284],
        [0.6643, 0.3357],
        [0.6544, 0.3456],
        [0.6591, 0.3409],
        [0.6715, 0.3285],
        [0.6702, 0.3298],
        [0.6622, 0.3378],
        [0.6622, 0.3378],
        [0.6634, 0.3366],
        [0.6589, 0.3411],
        [0.6624, 0.3376],
        [0.6650, 0.3350],
        [0.6621, 0.3379],
        [0.6686, 0.3314],
        [0.6703, 0.3297],
        [0.6702, 0.3298],
        [0.6612, 0.3388],
        [0.6630, 0.3370],
        [0.6704, 0.3296],
        [0.6671, 0.3329],
        [0.6603, 0.3397],
        [0.6652, 0.3348],
        [0.6656, 0.3344],
        [0.6692, 0.3308],
        [0.6590, 0.3410],
        [0.6660, 0.3340],
        [0.6620, 0.3380],
        [0.6586, 0.3414],
        [0.6631, 0.3369],
        [0.6652, 0.3348],
        [0.6687, 0.3313],
        [0.6665, 0.3335],
        [0.6696, 0.3304],
        [0.6681, 0.3319],
        [0.6700, 0.3300],
        [0.6571, 0.3429],
        [0.6639, 0.3361],
        [0.6737, 0.3263],
        [0.6746, 0.3254],
        [0.6538, 0.3462],
        [0.6752, 0.3248],
        [0.6616, 0.3384],
        [0.6722, 0.3278],
        [0.6678, 0.3322],
        [0.6556, 0.3444],
        [0.6603, 0.3397],
        [0.6643, 0.3357],
        [0.6663, 0.3337],
        [0.6668, 0.3332],
        [0.6692, 0.3308],
        [0.6608, 0.3392],
        [0.6742, 0.3258],
        [0.6527, 0.3473],
        [0.6614, 0.3386],
        [0.6685, 0.3315],
        [0.6699, 0.3301],
        [0.6599, 0.3401],
        [0.6629, 0.3371],
        [0.6707, 0.3293],
        [0.6689, 0.3311],
        [0.6678, 0.3322],
        [0.6696, 0.3304],
        [0.6553, 0.3447],
        [0.6552, 0.3448],
        [0.6714, 0.3286],
        [0.6675, 0.3325],
        [0.6606, 0.3394],
        [0.6668, 0.3332],
        [0.6552, 0.3448],
        [0.6724, 0.3276],
        [0.6608, 0.3392],
        [0.6686, 0.3314],
        [0.6674, 0.3326],
        [0.6590, 0.3410],
        [0.6633, 0.3367],
        [0.6654, 0.3346],
        [0.6687, 0.3313],
        [0.6568, 0.3432],
        [0.6582, 0.3418],
        [0.6628, 0.3372],
        [0.6683, 0.3317],
        [0.6640, 0.3360],
        [0.6568, 0.3432],
        [0.6641, 0.3359],
        [0.6676, 0.3324],
        [0.6701, 0.3299],
        [0.6545, 0.3455],
        [0.6669, 0.3331],
        [0.6615, 0.3385],
        [0.6660, 0.3340],
        [0.6687, 0.3313],
        [0.6745, 0.3255],
        [0.6677, 0.3323],
        [0.6729, 0.3271],
        [0.6667, 0.3333],
        [0.6749, 0.3251],
        [0.6723, 0.3277],
        [0.6579, 0.3421],
        [0.6733, 0.3267],
        [0.6682, 0.3318],
        [0.6619, 0.3381],
        [0.6614, 0.3386],
        [0.6685, 0.3315],
        [0.6690, 0.3310],
        [0.6622, 0.3378],
        [0.6576, 0.3424],
        [0.6607, 0.3393],
        [0.6671, 0.3329],
        [0.6632, 0.3368],
        [0.6651, 0.3349],
        [0.6674, 0.3326],
        [0.6655, 0.3345],
        [0.6607, 0.3393],
        [0.6590, 0.3410],
        [0.6634, 0.3366],
        [0.6716, 0.3284],
        [0.6701, 0.3299],
        [0.6614, 0.3386],
        [0.6687, 0.3313],
        [0.6677, 0.3323],
        [0.6657, 0.3343],
        [0.6658, 0.3342],
        [0.6697, 0.3303],
        [0.6589, 0.3411],
        [0.6566, 0.3434],
        [0.6552, 0.3448],
        [0.6750, 0.3250],
        [0.6712, 0.3288],
        [0.6660, 0.3340],
        [0.6600, 0.3400],
        [0.6538, 0.3462],
        [0.6622, 0.3378],
        [0.6727, 0.3273],
        [0.6671, 0.3329],
        [0.6629, 0.3371],
        [0.6624, 0.3376],
        [0.6656, 0.3344],
        [0.6628, 0.3372],
        [0.6685, 0.3315],
        [0.6550, 0.3450],
        [0.6763, 0.3237],
        [0.6758, 0.3242],
        [0.6621, 0.3379],
        [0.6740, 0.3260],
        [0.6739, 0.3261],
        [0.6586, 0.3414],
        [0.6646, 0.3354],
        [0.6617, 0.3383],
        [0.6748, 0.3252],
        [0.6779, 0.3221],
        [0.6680, 0.3320],
        [0.6703, 0.3297],
        [0.6685, 0.3315],
        [0.6671, 0.3329],
        [0.6685, 0.3315],
        [0.6591, 0.3409],
        [0.6686, 0.3314],
        [0.6646, 0.3354],
        [0.6596, 0.3404],
        [0.6665, 0.3335],
        [0.6677, 0.3323],
        [0.6704, 0.3296],
        [0.6636, 0.3364],
        [0.6699, 0.3301],
        [0.6536, 0.3464],
        [0.6618, 0.3382],
        [0.6742, 0.3258],
        [0.6731, 0.3269],
        [0.6607, 0.3393],
        [0.6659, 0.3341],
        [0.6616, 0.3384],
        [0.6685, 0.3315],
        [0.6586, 0.3414],
        [0.6753, 0.3247],
        [0.6661, 0.3339],
        [0.6651, 0.3349],
        [0.6689, 0.3311],
        [0.6738, 0.3262],
        [0.6670, 0.3330],
        [0.6629, 0.3371],
        [0.6675, 0.3325],
        [0.6605, 0.3395],
        [0.6725, 0.3275],
        [0.6708, 0.3292],
        [0.6636, 0.3364],
        [0.6675, 0.3325],
        [0.6587, 0.3413],
        [0.6647, 0.3353],
        [0.6722, 0.3278],
        [0.6676, 0.3324],
        [0.6632, 0.3368],
        [0.6680, 0.3320],
        [0.6616, 0.3384],
        [0.6710, 0.3290],
        [0.6629, 0.3371],
        [0.6674, 0.3326],
        [0.6642, 0.3358],
        [0.6658, 0.3342],
        [0.6663, 0.3337],
        [0.6681, 0.3319],
        [0.6629, 0.3371],
        [0.6679, 0.3321],
        [0.6685, 0.3315],
        [0.6609, 0.3391],
        [0.6596, 0.3404],
        [0.6690, 0.3310],
        [0.6584, 0.3416],
        [0.6650, 0.3350],
        [0.6763, 0.3237],
        [0.6655, 0.3345],
        [0.6590, 0.3410],
        [0.6686, 0.3314],
        [0.6673, 0.3327],
        [0.6739, 0.3261]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0040 loss: 0.6686 acc_train: 0.6103 time: 0.1230s
tensor([[0.6695, 0.3305],
        [0.6638, 0.3362],
        [0.6718, 0.3282],
        [0.6680, 0.3320],
        [0.6765, 0.3235],
        [0.6597, 0.3403],
        [0.6660, 0.3340],
        [0.6668, 0.3332],
        [0.6629, 0.3371],
        [0.6655, 0.3345],
        [0.6659, 0.3341],
        [0.6714, 0.3286],
        [0.6647, 0.3353],
        [0.6623, 0.3377],
        [0.6683, 0.3316],
        [0.6570, 0.3430],
        [0.6709, 0.3291],
        [0.6683, 0.3317],
        [0.6591, 0.3409],
        [0.6613, 0.3387],
        [0.6665, 0.3335],
        [0.6652, 0.3348],
        [0.6687, 0.3313],
        [0.6717, 0.3283],
        [0.6640, 0.3360],
        [0.6559, 0.3441],
        [0.6595, 0.3405],
        [0.6669, 0.3331],
        [0.6604, 0.3396],
        [0.6582, 0.3418],
        [0.6609, 0.3391],
        [0.6606, 0.3394],
        [0.6703, 0.3297],
        [0.6693, 0.3307],
        [0.6670, 0.3330],
        [0.6580, 0.3420],
        [0.6596, 0.3404],
        [0.6592, 0.3408],
        [0.6681, 0.3319],
        [0.6681, 0.3319],
        [0.6682, 0.3318],
        [0.6612, 0.3388],
        [0.6502, 0.3498],
        [0.6633, 0.3367],
        [0.6713, 0.3287],
        [0.6660, 0.3340],
        [0.6747, 0.3253],
        [0.6708, 0.3292],
        [0.6649, 0.3351],
        [0.6700, 0.3300],
        [0.6681, 0.3319],
        [0.6697, 0.3303],
        [0.6658, 0.3342],
        [0.6630, 0.3370],
        [0.6609, 0.3391],
        [0.6736, 0.3264],
        [0.6631, 0.3369],
        [0.6642, 0.3358],
        [0.6715, 0.3285],
        [0.6643, 0.3357],
        [0.6547, 0.3453],
        [0.6593, 0.3407],
        [0.6713, 0.3287],
        [0.6701, 0.3299],
        [0.6623, 0.3377],
        [0.6622, 0.3378],
        [0.6636, 0.3364],
        [0.6591, 0.3409],
        [0.6627, 0.3373],
        [0.6650, 0.3350],
        [0.6622, 0.3378],
        [0.6686, 0.3314],
        [0.6703, 0.3297],
        [0.6702, 0.3298],
        [0.6613, 0.3387],
        [0.6631, 0.3369],
        [0.6704, 0.3296],
        [0.6670, 0.3330],
        [0.6605, 0.3395],
        [0.6652, 0.3348],
        [0.6656, 0.3344],
        [0.6691, 0.3309],
        [0.6592, 0.3408],
        [0.6661, 0.3339],
        [0.6621, 0.3379],
        [0.6588, 0.3412],
        [0.6633, 0.3367],
        [0.6652, 0.3348],
        [0.6687, 0.3313],
        [0.6666, 0.3334],
        [0.6695, 0.3305],
        [0.6680, 0.3320],
        [0.6699, 0.3301],
        [0.6573, 0.3427],
        [0.6640, 0.3360],
        [0.6736, 0.3264],
        [0.6745, 0.3255],
        [0.6540, 0.3460],
        [0.6751, 0.3249],
        [0.6619, 0.3381],
        [0.6722, 0.3278],
        [0.6677, 0.3323],
        [0.6559, 0.3441],
        [0.6606, 0.3394],
        [0.6646, 0.3354],
        [0.6663, 0.3337],
        [0.6668, 0.3332],
        [0.6693, 0.3307],
        [0.6609, 0.3391],
        [0.6742, 0.3258],
        [0.6533, 0.3467],
        [0.6616, 0.3384],
        [0.6685, 0.3315],
        [0.6699, 0.3301],
        [0.6599, 0.3401],
        [0.6631, 0.3369],
        [0.6706, 0.3294],
        [0.6688, 0.3312],
        [0.6679, 0.3321],
        [0.6695, 0.3305],
        [0.6555, 0.3445],
        [0.6555, 0.3445],
        [0.6714, 0.3286],
        [0.6674, 0.3326],
        [0.6608, 0.3392],
        [0.6667, 0.3333],
        [0.6554, 0.3446],
        [0.6723, 0.3277],
        [0.6609, 0.3391],
        [0.6685, 0.3315],
        [0.6674, 0.3326],
        [0.6593, 0.3407],
        [0.6636, 0.3364],
        [0.6654, 0.3346],
        [0.6687, 0.3313],
        [0.6570, 0.3430],
        [0.6583, 0.3417],
        [0.6630, 0.3370],
        [0.6682, 0.3318],
        [0.6640, 0.3360],
        [0.6570, 0.3430],
        [0.6642, 0.3358],
        [0.6675, 0.3325],
        [0.6701, 0.3299],
        [0.6548, 0.3452],
        [0.6669, 0.3331],
        [0.6617, 0.3383],
        [0.6661, 0.3339],
        [0.6688, 0.3312],
        [0.6744, 0.3256],
        [0.6678, 0.3322],
        [0.6728, 0.3272],
        [0.6669, 0.3331],
        [0.6748, 0.3252],
        [0.6723, 0.3277],
        [0.6581, 0.3419],
        [0.6733, 0.3267],
        [0.6681, 0.3319],
        [0.6620, 0.3380],
        [0.6616, 0.3384],
        [0.6685, 0.3315],
        [0.6690, 0.3310],
        [0.6623, 0.3377],
        [0.6579, 0.3421],
        [0.6609, 0.3391],
        [0.6671, 0.3329],
        [0.6634, 0.3366],
        [0.6651, 0.3349],
        [0.6673, 0.3327],
        [0.6654, 0.3346],
        [0.6611, 0.3389],
        [0.6592, 0.3408],
        [0.6634, 0.3366],
        [0.6715, 0.3285],
        [0.6701, 0.3299],
        [0.6616, 0.3384],
        [0.6688, 0.3312],
        [0.6678, 0.3322],
        [0.6657, 0.3343],
        [0.6660, 0.3340],
        [0.6698, 0.3302],
        [0.6590, 0.3410],
        [0.6570, 0.3430],
        [0.6554, 0.3446],
        [0.6748, 0.3252],
        [0.6711, 0.3289],
        [0.6659, 0.3341],
        [0.6602, 0.3398],
        [0.6542, 0.3458],
        [0.6623, 0.3377],
        [0.6729, 0.3271],
        [0.6672, 0.3328],
        [0.6628, 0.3372],
        [0.6624, 0.3376],
        [0.6657, 0.3343],
        [0.6630, 0.3370],
        [0.6685, 0.3315],
        [0.6553, 0.3447],
        [0.6762, 0.3238],
        [0.6756, 0.3244],
        [0.6621, 0.3379],
        [0.6739, 0.3261],
        [0.6738, 0.3262],
        [0.6587, 0.3413],
        [0.6648, 0.3352],
        [0.6619, 0.3381],
        [0.6748, 0.3252],
        [0.6778, 0.3222],
        [0.6680, 0.3320],
        [0.6703, 0.3297],
        [0.6686, 0.3314],
        [0.6670, 0.3330],
        [0.6686, 0.3314],
        [0.6593, 0.3407],
        [0.6686, 0.3314],
        [0.6648, 0.3352],
        [0.6598, 0.3402],
        [0.6665, 0.3335],
        [0.6678, 0.3322],
        [0.6704, 0.3296],
        [0.6637, 0.3363],
        [0.6699, 0.3301],
        [0.6539, 0.3461],
        [0.6620, 0.3380],
        [0.6741, 0.3259],
        [0.6731, 0.3269],
        [0.6610, 0.3390],
        [0.6658, 0.3342],
        [0.6616, 0.3384],
        [0.6684, 0.3316],
        [0.6588, 0.3412],
        [0.6751, 0.3249],
        [0.6662, 0.3338],
        [0.6652, 0.3348],
        [0.6689, 0.3311],
        [0.6737, 0.3263],
        [0.6670, 0.3330],
        [0.6630, 0.3370],
        [0.6676, 0.3324],
        [0.6607, 0.3393],
        [0.6724, 0.3276],
        [0.6708, 0.3292],
        [0.6636, 0.3364],
        [0.6675, 0.3325],
        [0.6590, 0.3410],
        [0.6649, 0.3351],
        [0.6722, 0.3278],
        [0.6677, 0.3323],
        [0.6634, 0.3366],
        [0.6680, 0.3320],
        [0.6617, 0.3383],
        [0.6710, 0.3290],
        [0.6628, 0.3372],
        [0.6674, 0.3326],
        [0.6643, 0.3357],
        [0.6659, 0.3341],
        [0.6664, 0.3336],
        [0.6682, 0.3318],
        [0.6631, 0.3369],
        [0.6679, 0.3321],
        [0.6685, 0.3315],
        [0.6610, 0.3390],
        [0.6597, 0.3403],
        [0.6691, 0.3309],
        [0.6585, 0.3415],
        [0.6651, 0.3349],
        [0.6762, 0.3238],
        [0.6655, 0.3345],
        [0.6591, 0.3409],
        [0.6686, 0.3314],
        [0.6674, 0.3326],
        [0.6738, 0.3262]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0041 loss: 0.6686 acc_train: 0.6103 time: 0.1254s
tensor([[0.6695, 0.3305],
        [0.6640, 0.3360],
        [0.6718, 0.3282],
        [0.6679, 0.3321],
        [0.6764, 0.3236],
        [0.6599, 0.3401],
        [0.6660, 0.3340],
        [0.6669, 0.3331],
        [0.6631, 0.3369],
        [0.6654, 0.3346],
        [0.6660, 0.3340],
        [0.6713, 0.3287],
        [0.6648, 0.3352],
        [0.6624, 0.3376],
        [0.6684, 0.3316],
        [0.6572, 0.3428],
        [0.6710, 0.3290],
        [0.6683, 0.3317],
        [0.6594, 0.3406],
        [0.6614, 0.3386],
        [0.6666, 0.3334],
        [0.6652, 0.3348],
        [0.6688, 0.3312],
        [0.6717, 0.3283],
        [0.6641, 0.3359],
        [0.6561, 0.3439],
        [0.6598, 0.3402],
        [0.6671, 0.3329],
        [0.6605, 0.3395],
        [0.6583, 0.3417],
        [0.6611, 0.3389],
        [0.6608, 0.3392],
        [0.6703, 0.3297],
        [0.6693, 0.3307],
        [0.6670, 0.3330],
        [0.6583, 0.3417],
        [0.6598, 0.3402],
        [0.6594, 0.3406],
        [0.6682, 0.3318],
        [0.6681, 0.3319],
        [0.6682, 0.3318],
        [0.6614, 0.3386],
        [0.6507, 0.3493],
        [0.6636, 0.3364],
        [0.6714, 0.3286],
        [0.6660, 0.3340],
        [0.6746, 0.3254],
        [0.6708, 0.3292],
        [0.6649, 0.3351],
        [0.6700, 0.3300],
        [0.6681, 0.3319],
        [0.6698, 0.3302],
        [0.6658, 0.3342],
        [0.6634, 0.3366],
        [0.6611, 0.3389],
        [0.6736, 0.3264],
        [0.6633, 0.3367],
        [0.6643, 0.3357],
        [0.6714, 0.3286],
        [0.6644, 0.3356],
        [0.6551, 0.3449],
        [0.6596, 0.3404],
        [0.6712, 0.3288],
        [0.6701, 0.3299],
        [0.6624, 0.3376],
        [0.6623, 0.3377],
        [0.6638, 0.3362],
        [0.6593, 0.3407],
        [0.6630, 0.3370],
        [0.6650, 0.3350],
        [0.6623, 0.3377],
        [0.6685, 0.3315],
        [0.6702, 0.3298],
        [0.6702, 0.3298],
        [0.6614, 0.3386],
        [0.6632, 0.3368],
        [0.6704, 0.3296],
        [0.6670, 0.3330],
        [0.6608, 0.3392],
        [0.6652, 0.3348],
        [0.6657, 0.3343],
        [0.6690, 0.3310],
        [0.6595, 0.3405],
        [0.6662, 0.3338],
        [0.6623, 0.3377],
        [0.6590, 0.3410],
        [0.6636, 0.3364],
        [0.6653, 0.3347],
        [0.6687, 0.3313],
        [0.6667, 0.3333],
        [0.6694, 0.3306],
        [0.6680, 0.3320],
        [0.6698, 0.3302],
        [0.6575, 0.3425],
        [0.6642, 0.3358],
        [0.6736, 0.3264],
        [0.6744, 0.3256],
        [0.6543, 0.3457],
        [0.6750, 0.3250],
        [0.6621, 0.3379],
        [0.6721, 0.3279],
        [0.6677, 0.3323],
        [0.6561, 0.3439],
        [0.6610, 0.3390],
        [0.6648, 0.3352],
        [0.6664, 0.3336],
        [0.6669, 0.3331],
        [0.6695, 0.3305],
        [0.6611, 0.3389],
        [0.6742, 0.3258],
        [0.6539, 0.3461],
        [0.6618, 0.3382],
        [0.6684, 0.3316],
        [0.6698, 0.3302],
        [0.6599, 0.3401],
        [0.6634, 0.3366],
        [0.6706, 0.3294],
        [0.6688, 0.3312],
        [0.6680, 0.3320],
        [0.6694, 0.3306],
        [0.6558, 0.3442],
        [0.6559, 0.3441],
        [0.6714, 0.3286],
        [0.6674, 0.3326],
        [0.6611, 0.3389],
        [0.6666, 0.3334],
        [0.6557, 0.3443],
        [0.6722, 0.3278],
        [0.6611, 0.3389],
        [0.6684, 0.3316],
        [0.6675, 0.3325],
        [0.6596, 0.3404],
        [0.6638, 0.3362],
        [0.6655, 0.3345],
        [0.6687, 0.3313],
        [0.6572, 0.3428],
        [0.6585, 0.3415],
        [0.6631, 0.3369],
        [0.6681, 0.3319],
        [0.6641, 0.3359],
        [0.6573, 0.3427],
        [0.6643, 0.3357],
        [0.6674, 0.3326],
        [0.6700, 0.3300],
        [0.6551, 0.3449],
        [0.6669, 0.3331],
        [0.6619, 0.3381],
        [0.6663, 0.3337],
        [0.6689, 0.3311],
        [0.6742, 0.3258],
        [0.6678, 0.3322],
        [0.6727, 0.3273],
        [0.6670, 0.3330],
        [0.6747, 0.3253],
        [0.6723, 0.3277],
        [0.6583, 0.3417],
        [0.6733, 0.3267],
        [0.6681, 0.3319],
        [0.6621, 0.3379],
        [0.6618, 0.3382],
        [0.6685, 0.3315],
        [0.6692, 0.3308],
        [0.6625, 0.3375],
        [0.6581, 0.3419],
        [0.6611, 0.3389],
        [0.6672, 0.3328],
        [0.6636, 0.3364],
        [0.6651, 0.3349],
        [0.6672, 0.3328],
        [0.6655, 0.3345],
        [0.6615, 0.3385],
        [0.6595, 0.3405],
        [0.6635, 0.3365],
        [0.6715, 0.3285],
        [0.6702, 0.3298],
        [0.6618, 0.3382],
        [0.6688, 0.3312],
        [0.6679, 0.3321],
        [0.6656, 0.3344],
        [0.6661, 0.3339],
        [0.6698, 0.3302],
        [0.6592, 0.3408],
        [0.6574, 0.3426],
        [0.6556, 0.3444],
        [0.6747, 0.3253],
        [0.6712, 0.3288],
        [0.6658, 0.3342],
        [0.6603, 0.3397],
        [0.6545, 0.3455],
        [0.6625, 0.3375],
        [0.6730, 0.3270],
        [0.6673, 0.3327],
        [0.6628, 0.3372],
        [0.6625, 0.3375],
        [0.6658, 0.3342],
        [0.6631, 0.3369],
        [0.6686, 0.3314],
        [0.6556, 0.3444],
        [0.6761, 0.3239],
        [0.6754, 0.3246],
        [0.6621, 0.3379],
        [0.6737, 0.3263],
        [0.6738, 0.3262],
        [0.6588, 0.3412],
        [0.6651, 0.3349],
        [0.6621, 0.3379],
        [0.6748, 0.3252],
        [0.6777, 0.3223],
        [0.6680, 0.3320],
        [0.6703, 0.3297],
        [0.6687, 0.3313],
        [0.6670, 0.3330],
        [0.6687, 0.3313],
        [0.6595, 0.3405],
        [0.6687, 0.3313],
        [0.6649, 0.3351],
        [0.6600, 0.3400],
        [0.6665, 0.3335],
        [0.6680, 0.3320],
        [0.6703, 0.3297],
        [0.6638, 0.3362],
        [0.6700, 0.3300],
        [0.6542, 0.3458],
        [0.6622, 0.3378],
        [0.6741, 0.3259],
        [0.6731, 0.3269],
        [0.6613, 0.3387],
        [0.6658, 0.3342],
        [0.6617, 0.3383],
        [0.6685, 0.3315],
        [0.6590, 0.3410],
        [0.6749, 0.3251],
        [0.6664, 0.3336],
        [0.6652, 0.3348],
        [0.6691, 0.3309],
        [0.6736, 0.3264],
        [0.6669, 0.3331],
        [0.6632, 0.3368],
        [0.6677, 0.3323],
        [0.6609, 0.3391],
        [0.6723, 0.3277],
        [0.6707, 0.3293],
        [0.6637, 0.3363],
        [0.6675, 0.3325],
        [0.6593, 0.3407],
        [0.6651, 0.3349],
        [0.6722, 0.3278],
        [0.6678, 0.3322],
        [0.6636, 0.3364],
        [0.6680, 0.3320],
        [0.6619, 0.3381],
        [0.6710, 0.3290],
        [0.6628, 0.3372],
        [0.6675, 0.3325],
        [0.6644, 0.3356],
        [0.6659, 0.3341],
        [0.6666, 0.3334],
        [0.6683, 0.3317],
        [0.6633, 0.3367],
        [0.6681, 0.3319],
        [0.6685, 0.3315],
        [0.6613, 0.3387],
        [0.6600, 0.3400],
        [0.6691, 0.3309],
        [0.6587, 0.3413],
        [0.6653, 0.3347],
        [0.6762, 0.3238],
        [0.6656, 0.3344],
        [0.6592, 0.3408],
        [0.6686, 0.3314],
        [0.6674, 0.3326],
        [0.6738, 0.3262]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0042 loss: 0.6686 acc_train: 0.6103 time: 0.1229s
tensor([[0.6695, 0.3305],
        [0.6642, 0.3358],
        [0.6718, 0.3282],
        [0.6679, 0.3321],
        [0.6764, 0.3236],
        [0.6602, 0.3398],
        [0.6660, 0.3340],
        [0.6669, 0.3331],
        [0.6633, 0.3367],
        [0.6654, 0.3346],
        [0.6661, 0.3339],
        [0.6713, 0.3287],
        [0.6649, 0.3351],
        [0.6625, 0.3375],
        [0.6685, 0.3315],
        [0.6574, 0.3426],
        [0.6710, 0.3290],
        [0.6683, 0.3317],
        [0.6596, 0.3404],
        [0.6616, 0.3384],
        [0.6668, 0.3332],
        [0.6652, 0.3348],
        [0.6689, 0.3311],
        [0.6718, 0.3282],
        [0.6642, 0.3358],
        [0.6563, 0.3437],
        [0.6600, 0.3400],
        [0.6673, 0.3327],
        [0.6606, 0.3394],
        [0.6585, 0.3415],
        [0.6613, 0.3387],
        [0.6609, 0.3391],
        [0.6702, 0.3298],
        [0.6693, 0.3307],
        [0.6671, 0.3329],
        [0.6585, 0.3415],
        [0.6601, 0.3399],
        [0.6596, 0.3404],
        [0.6682, 0.3318],
        [0.6681, 0.3319],
        [0.6683, 0.3317],
        [0.6616, 0.3384],
        [0.6511, 0.3489],
        [0.6639, 0.3361],
        [0.6715, 0.3285],
        [0.6659, 0.3341],
        [0.6746, 0.3254],
        [0.6708, 0.3292],
        [0.6649, 0.3351],
        [0.6700, 0.3300],
        [0.6681, 0.3319],
        [0.6700, 0.3300],
        [0.6658, 0.3342],
        [0.6636, 0.3364],
        [0.6612, 0.3388],
        [0.6736, 0.3264],
        [0.6634, 0.3366],
        [0.6644, 0.3356],
        [0.6713, 0.3287],
        [0.6645, 0.3355],
        [0.6554, 0.3446],
        [0.6599, 0.3401],
        [0.6712, 0.3288],
        [0.6702, 0.3298],
        [0.6625, 0.3375],
        [0.6624, 0.3376],
        [0.6639, 0.3361],
        [0.6595, 0.3405],
        [0.6633, 0.3367],
        [0.6650, 0.3350],
        [0.6624, 0.3376],
        [0.6685, 0.3315],
        [0.6702, 0.3298],
        [0.6702, 0.3298],
        [0.6615, 0.3385],
        [0.6633, 0.3367],
        [0.6705, 0.3295],
        [0.6670, 0.3330],
        [0.6610, 0.3390],
        [0.6653, 0.3347],
        [0.6657, 0.3343],
        [0.6689, 0.3311],
        [0.6597, 0.3403],
        [0.6663, 0.3337],
        [0.6624, 0.3376],
        [0.6593, 0.3407],
        [0.6638, 0.3362],
        [0.6654, 0.3346],
        [0.6687, 0.3313],
        [0.6667, 0.3333],
        [0.6693, 0.3307],
        [0.6679, 0.3321],
        [0.6697, 0.3303],
        [0.6577, 0.3423],
        [0.6644, 0.3356],
        [0.6736, 0.3264],
        [0.6743, 0.3257],
        [0.6546, 0.3454],
        [0.6749, 0.3251],
        [0.6623, 0.3377],
        [0.6721, 0.3279],
        [0.6677, 0.3323],
        [0.6564, 0.3436],
        [0.6613, 0.3387],
        [0.6650, 0.3350],
        [0.6665, 0.3335],
        [0.6669, 0.3331],
        [0.6696, 0.3304],
        [0.6612, 0.3388],
        [0.6743, 0.3257],
        [0.6544, 0.3456],
        [0.6620, 0.3380],
        [0.6684, 0.3316],
        [0.6698, 0.3302],
        [0.6600, 0.3400],
        [0.6637, 0.3363],
        [0.6706, 0.3294],
        [0.6688, 0.3312],
        [0.6681, 0.3319],
        [0.6694, 0.3306],
        [0.6561, 0.3439],
        [0.6562, 0.3438],
        [0.6714, 0.3286],
        [0.6674, 0.3326],
        [0.6613, 0.3387],
        [0.6665, 0.3335],
        [0.6559, 0.3441],
        [0.6722, 0.3278],
        [0.6613, 0.3387],
        [0.6683, 0.3317],
        [0.6676, 0.3324],
        [0.6599, 0.3401],
        [0.6641, 0.3359],
        [0.6656, 0.3344],
        [0.6688, 0.3312],
        [0.6574, 0.3426],
        [0.6587, 0.3413],
        [0.6633, 0.3367],
        [0.6680, 0.3320],
        [0.6642, 0.3358],
        [0.6575, 0.3425],
        [0.6645, 0.3355],
        [0.6674, 0.3326],
        [0.6700, 0.3300],
        [0.6553, 0.3447],
        [0.6670, 0.3330],
        [0.6620, 0.3380],
        [0.6664, 0.3336],
        [0.6690, 0.3310],
        [0.6742, 0.3258],
        [0.6679, 0.3321],
        [0.6726, 0.3274],
        [0.6672, 0.3328],
        [0.6746, 0.3254],
        [0.6722, 0.3278],
        [0.6586, 0.3414],
        [0.6733, 0.3267],
        [0.6681, 0.3319],
        [0.6623, 0.3377],
        [0.6620, 0.3380],
        [0.6685, 0.3315],
        [0.6693, 0.3307],
        [0.6627, 0.3373],
        [0.6583, 0.3417],
        [0.6613, 0.3387],
        [0.6673, 0.3327],
        [0.6638, 0.3362],
        [0.6651, 0.3349],
        [0.6671, 0.3329],
        [0.6655, 0.3345],
        [0.6619, 0.3381],
        [0.6597, 0.3403],
        [0.6635, 0.3365],
        [0.6714, 0.3286],
        [0.6702, 0.3298],
        [0.6620, 0.3380],
        [0.6689, 0.3311],
        [0.6680, 0.3320],
        [0.6656, 0.3344],
        [0.6663, 0.3337],
        [0.6699, 0.3301],
        [0.6594, 0.3406],
        [0.6578, 0.3422],
        [0.6558, 0.3442],
        [0.6747, 0.3253],
        [0.6712, 0.3288],
        [0.6657, 0.3343],
        [0.6605, 0.3395],
        [0.6548, 0.3452],
        [0.6626, 0.3374],
        [0.6732, 0.3268],
        [0.6673, 0.3327],
        [0.6629, 0.3371],
        [0.6627, 0.3373],
        [0.6658, 0.3342],
        [0.6633, 0.3367],
        [0.6687, 0.3313],
        [0.6559, 0.3441],
        [0.6761, 0.3239],
        [0.6754, 0.3246],
        [0.6621, 0.3379],
        [0.6737, 0.3263],
        [0.6737, 0.3263],
        [0.6590, 0.3410],
        [0.6653, 0.3347],
        [0.6623, 0.3377],
        [0.6748, 0.3252],
        [0.6776, 0.3224],
        [0.6680, 0.3320],
        [0.6702, 0.3298],
        [0.6687, 0.3313],
        [0.6670, 0.3330],
        [0.6687, 0.3313],
        [0.6597, 0.3403],
        [0.6688, 0.3312],
        [0.6651, 0.3349],
        [0.6602, 0.3398],
        [0.6666, 0.3334],
        [0.6681, 0.3319],
        [0.6703, 0.3297],
        [0.6640, 0.3360],
        [0.6700, 0.3300],
        [0.6545, 0.3455],
        [0.6625, 0.3375],
        [0.6741, 0.3259],
        [0.6731, 0.3269],
        [0.6615, 0.3385],
        [0.6658, 0.3342],
        [0.6617, 0.3383],
        [0.6686, 0.3314],
        [0.6593, 0.3407],
        [0.6747, 0.3253],
        [0.6666, 0.3334],
        [0.6653, 0.3347],
        [0.6692, 0.3308],
        [0.6735, 0.3265],
        [0.6669, 0.3331],
        [0.6633, 0.3367],
        [0.6678, 0.3322],
        [0.6611, 0.3389],
        [0.6722, 0.3278],
        [0.6707, 0.3293],
        [0.6638, 0.3362],
        [0.6676, 0.3324],
        [0.6596, 0.3404],
        [0.6652, 0.3348],
        [0.6722, 0.3278],
        [0.6680, 0.3320],
        [0.6638, 0.3362],
        [0.6681, 0.3319],
        [0.6620, 0.3380],
        [0.6710, 0.3290],
        [0.6629, 0.3371],
        [0.6676, 0.3324],
        [0.6646, 0.3354],
        [0.6659, 0.3341],
        [0.6667, 0.3333],
        [0.6684, 0.3316],
        [0.6635, 0.3365],
        [0.6682, 0.3318],
        [0.6686, 0.3314],
        [0.6615, 0.3385],
        [0.6602, 0.3398],
        [0.6692, 0.3308],
        [0.6588, 0.3412],
        [0.6655, 0.3345],
        [0.6761, 0.3239],
        [0.6656, 0.3344],
        [0.6593, 0.3407],
        [0.6686, 0.3314],
        [0.6675, 0.3325],
        [0.6738, 0.3262]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0043 loss: 0.6686 acc_train: 0.6103 time: 0.1235s
tensor([[0.6695, 0.3305],
        [0.6643, 0.3357],
        [0.6718, 0.3282],
        [0.6679, 0.3321],
        [0.6763, 0.3237],
        [0.6605, 0.3395],
        [0.6660, 0.3340],
        [0.6670, 0.3330],
        [0.6634, 0.3366],
        [0.6654, 0.3346],
        [0.6661, 0.3339],
        [0.6712, 0.3288],
        [0.6650, 0.3350],
        [0.6626, 0.3374],
        [0.6686, 0.3314],
        [0.6576, 0.3424],
        [0.6710, 0.3290],
        [0.6683, 0.3317],
        [0.6598, 0.3402],
        [0.6617, 0.3383],
        [0.6669, 0.3331],
        [0.6653, 0.3347],
        [0.6690, 0.3310],
        [0.6718, 0.3282],
        [0.6643, 0.3357],
        [0.6565, 0.3435],
        [0.6602, 0.3398],
        [0.6674, 0.3326],
        [0.6608, 0.3392],
        [0.6587, 0.3413],
        [0.6616, 0.3384],
        [0.6610, 0.3390],
        [0.6702, 0.3298],
        [0.6693, 0.3307],
        [0.6672, 0.3328],
        [0.6588, 0.3412],
        [0.6603, 0.3397],
        [0.6598, 0.3402],
        [0.6682, 0.3318],
        [0.6681, 0.3319],
        [0.6683, 0.3317],
        [0.6618, 0.3382],
        [0.6515, 0.3485],
        [0.6642, 0.3358],
        [0.6714, 0.3286],
        [0.6659, 0.3341],
        [0.6745, 0.3255],
        [0.6708, 0.3292],
        [0.6649, 0.3351],
        [0.6700, 0.3300],
        [0.6681, 0.3319],
        [0.6701, 0.3299],
        [0.6659, 0.3341],
        [0.6639, 0.3361],
        [0.6614, 0.3386],
        [0.6735, 0.3265],
        [0.6636, 0.3364],
        [0.6645, 0.3355],
        [0.6713, 0.3287],
        [0.6646, 0.3354],
        [0.6557, 0.3443],
        [0.6602, 0.3398],
        [0.6712, 0.3288],
        [0.6702, 0.3298],
        [0.6626, 0.3374],
        [0.6624, 0.3376],
        [0.6641, 0.3359],
        [0.6596, 0.3404],
        [0.6635, 0.3365],
        [0.6651, 0.3349],
        [0.6626, 0.3374],
        [0.6685, 0.3315],
        [0.6702, 0.3298],
        [0.6702, 0.3298],
        [0.6616, 0.3384],
        [0.6634, 0.3366],
        [0.6705, 0.3295],
        [0.6669, 0.3331],
        [0.6613, 0.3387],
        [0.6654, 0.3346],
        [0.6658, 0.3342],
        [0.6689, 0.3311],
        [0.6599, 0.3401],
        [0.6663, 0.3337],
        [0.6625, 0.3375],
        [0.6596, 0.3404],
        [0.6641, 0.3359],
        [0.6655, 0.3345],
        [0.6687, 0.3313],
        [0.6668, 0.3332],
        [0.6693, 0.3307],
        [0.6680, 0.3320],
        [0.6697, 0.3303],
        [0.6579, 0.3421],
        [0.6645, 0.3355],
        [0.6736, 0.3264],
        [0.6742, 0.3258],
        [0.6549, 0.3451],
        [0.6748, 0.3252],
        [0.6625, 0.3375],
        [0.6720, 0.3280],
        [0.6678, 0.3322],
        [0.6566, 0.3434],
        [0.6615, 0.3385],
        [0.6651, 0.3349],
        [0.6666, 0.3334],
        [0.6670, 0.3330],
        [0.6697, 0.3303],
        [0.6613, 0.3387],
        [0.6743, 0.3257],
        [0.6550, 0.3450],
        [0.6622, 0.3378],
        [0.6684, 0.3316],
        [0.6698, 0.3302],
        [0.6601, 0.3399],
        [0.6639, 0.3361],
        [0.6707, 0.3293],
        [0.6688, 0.3312],
        [0.6682, 0.3318],
        [0.6693, 0.3307],
        [0.6563, 0.3437],
        [0.6565, 0.3435],
        [0.6714, 0.3286],
        [0.6674, 0.3326],
        [0.6615, 0.3385],
        [0.6664, 0.3336],
        [0.6560, 0.3440],
        [0.6722, 0.3278],
        [0.6615, 0.3385],
        [0.6683, 0.3317],
        [0.6677, 0.3323],
        [0.6601, 0.3399],
        [0.6642, 0.3358],
        [0.6656, 0.3344],
        [0.6689, 0.3311],
        [0.6576, 0.3424],
        [0.6588, 0.3412],
        [0.6634, 0.3366],
        [0.6680, 0.3320],
        [0.6643, 0.3357],
        [0.6577, 0.3423],
        [0.6646, 0.3354],
        [0.6674, 0.3326],
        [0.6700, 0.3300],
        [0.6555, 0.3445],
        [0.6671, 0.3329],
        [0.6622, 0.3378],
        [0.6666, 0.3334],
        [0.6690, 0.3310],
        [0.6741, 0.3259],
        [0.6679, 0.3321],
        [0.6725, 0.3275],
        [0.6673, 0.3327],
        [0.6745, 0.3255],
        [0.6722, 0.3278],
        [0.6588, 0.3412],
        [0.6733, 0.3267],
        [0.6682, 0.3318],
        [0.6625, 0.3375],
        [0.6621, 0.3379],
        [0.6685, 0.3315],
        [0.6693, 0.3307],
        [0.6628, 0.3372],
        [0.6585, 0.3415],
        [0.6614, 0.3386],
        [0.6674, 0.3326],
        [0.6639, 0.3361],
        [0.6651, 0.3349],
        [0.6670, 0.3330],
        [0.6656, 0.3344],
        [0.6622, 0.3378],
        [0.6599, 0.3401],
        [0.6636, 0.3364],
        [0.6714, 0.3286],
        [0.6701, 0.3299],
        [0.6623, 0.3377],
        [0.6689, 0.3311],
        [0.6680, 0.3320],
        [0.6656, 0.3344],
        [0.6664, 0.3336],
        [0.6700, 0.3300],
        [0.6596, 0.3404],
        [0.6582, 0.3418],
        [0.6560, 0.3440],
        [0.6746, 0.3254],
        [0.6713, 0.3287],
        [0.6657, 0.3343],
        [0.6606, 0.3394],
        [0.6551, 0.3449],
        [0.6627, 0.3373],
        [0.6733, 0.3267],
        [0.6673, 0.3327],
        [0.6630, 0.3370],
        [0.6628, 0.3372],
        [0.6659, 0.3341],
        [0.6635, 0.3365],
        [0.6688, 0.3312],
        [0.6562, 0.3438],
        [0.6760, 0.3240],
        [0.6753, 0.3247],
        [0.6622, 0.3378],
        [0.6736, 0.3264],
        [0.6736, 0.3264],
        [0.6591, 0.3409],
        [0.6655, 0.3345],
        [0.6625, 0.3375],
        [0.6748, 0.3252],
        [0.6775, 0.3225],
        [0.6680, 0.3320],
        [0.6702, 0.3298],
        [0.6688, 0.3312],
        [0.6670, 0.3330],
        [0.6688, 0.3312],
        [0.6599, 0.3401],
        [0.6688, 0.3312],
        [0.6651, 0.3349],
        [0.6604, 0.3396],
        [0.6667, 0.3333],
        [0.6682, 0.3318],
        [0.6703, 0.3297],
        [0.6641, 0.3359],
        [0.6701, 0.3299],
        [0.6549, 0.3451],
        [0.6627, 0.3373],
        [0.6741, 0.3259],
        [0.6731, 0.3269],
        [0.6617, 0.3383],
        [0.6658, 0.3342],
        [0.6618, 0.3382],
        [0.6686, 0.3314],
        [0.6595, 0.3405],
        [0.6745, 0.3255],
        [0.6667, 0.3333],
        [0.6654, 0.3346],
        [0.6693, 0.3307],
        [0.6735, 0.3265],
        [0.6669, 0.3331],
        [0.6634, 0.3366],
        [0.6679, 0.3321],
        [0.6613, 0.3387],
        [0.6722, 0.3278],
        [0.6707, 0.3293],
        [0.6639, 0.3361],
        [0.6676, 0.3324],
        [0.6599, 0.3401],
        [0.6654, 0.3346],
        [0.6722, 0.3278],
        [0.6681, 0.3319],
        [0.6640, 0.3360],
        [0.6681, 0.3319],
        [0.6622, 0.3378],
        [0.6710, 0.3290],
        [0.6630, 0.3370],
        [0.6677, 0.3323],
        [0.6647, 0.3353],
        [0.6660, 0.3340],
        [0.6668, 0.3332],
        [0.6685, 0.3315],
        [0.6636, 0.3364],
        [0.6683, 0.3317],
        [0.6686, 0.3314],
        [0.6617, 0.3383],
        [0.6604, 0.3396],
        [0.6692, 0.3308],
        [0.6590, 0.3410],
        [0.6657, 0.3343],
        [0.6761, 0.3239],
        [0.6657, 0.3343],
        [0.6594, 0.3406],
        [0.6687, 0.3313],
        [0.6676, 0.3324],
        [0.6737, 0.3263]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0044 loss: 0.6687 acc_train: 0.6103 time: 0.1243s
tensor([[0.6695, 0.3305],
        [0.6645, 0.3355],
        [0.6718, 0.3282],
        [0.6678, 0.3322],
        [0.6762, 0.3238],
        [0.6608, 0.3392],
        [0.6660, 0.3340],
        [0.6670, 0.3330],
        [0.6635, 0.3365],
        [0.6654, 0.3346],
        [0.6661, 0.3339],
        [0.6712, 0.3288],
        [0.6652, 0.3348],
        [0.6627, 0.3373],
        [0.6687, 0.3313],
        [0.6577, 0.3423],
        [0.6709, 0.3291],
        [0.6683, 0.3317],
        [0.6600, 0.3400],
        [0.6618, 0.3382],
        [0.6670, 0.3330],
        [0.6654, 0.3346],
        [0.6690, 0.3310],
        [0.6717, 0.3283],
        [0.6644, 0.3356],
        [0.6566, 0.3434],
        [0.6604, 0.3396],
        [0.6675, 0.3325],
        [0.6609, 0.3391],
        [0.6589, 0.3411],
        [0.6617, 0.3383],
        [0.6611, 0.3389],
        [0.6701, 0.3299],
        [0.6692, 0.3308],
        [0.6673, 0.3327],
        [0.6590, 0.3410],
        [0.6605, 0.3395],
        [0.6599, 0.3401],
        [0.6682, 0.3318],
        [0.6681, 0.3319],
        [0.6683, 0.3317],
        [0.6619, 0.3381],
        [0.6518, 0.3482],
        [0.6643, 0.3357],
        [0.6713, 0.3287],
        [0.6658, 0.3342],
        [0.6744, 0.3256],
        [0.6708, 0.3292],
        [0.6649, 0.3351],
        [0.6700, 0.3300],
        [0.6680, 0.3320],
        [0.6701, 0.3299],
        [0.6660, 0.3340],
        [0.6640, 0.3360],
        [0.6615, 0.3385],
        [0.6735, 0.3265],
        [0.6637, 0.3363],
        [0.6645, 0.3355],
        [0.6713, 0.3287],
        [0.6646, 0.3354],
        [0.6559, 0.3441],
        [0.6604, 0.3396],
        [0.6712, 0.3288],
        [0.6702, 0.3298],
        [0.6628, 0.3372],
        [0.6625, 0.3375],
        [0.6642, 0.3358],
        [0.6598, 0.3402],
        [0.6637, 0.3363],
        [0.6652, 0.3348],
        [0.6627, 0.3373],
        [0.6685, 0.3315],
        [0.6702, 0.3298],
        [0.6702, 0.3298],
        [0.6617, 0.3383],
        [0.6634, 0.3366],
        [0.6704, 0.3296],
        [0.6669, 0.3331],
        [0.6615, 0.3385],
        [0.6655, 0.3345],
        [0.6659, 0.3341],
        [0.6688, 0.3312],
        [0.6600, 0.3400],
        [0.6664, 0.3336],
        [0.6626, 0.3374],
        [0.6598, 0.3402],
        [0.6642, 0.3358],
        [0.6656, 0.3344],
        [0.6687, 0.3313],
        [0.6668, 0.3332],
        [0.6692, 0.3308],
        [0.6680, 0.3320],
        [0.6697, 0.3303],
        [0.6581, 0.3419],
        [0.6646, 0.3354],
        [0.6736, 0.3264],
        [0.6741, 0.3259],
        [0.6551, 0.3449],
        [0.6747, 0.3253],
        [0.6627, 0.3373],
        [0.6719, 0.3281],
        [0.6678, 0.3322],
        [0.6568, 0.3432],
        [0.6616, 0.3384],
        [0.6652, 0.3348],
        [0.6667, 0.3333],
        [0.6670, 0.3330],
        [0.6698, 0.3302],
        [0.6614, 0.3386],
        [0.6743, 0.3257],
        [0.6554, 0.3446],
        [0.6624, 0.3376],
        [0.6685, 0.3315],
        [0.6697, 0.3303],
        [0.6602, 0.3398],
        [0.6641, 0.3359],
        [0.6707, 0.3293],
        [0.6687, 0.3313],
        [0.6683, 0.3317],
        [0.6693, 0.3307],
        [0.6564, 0.3436],
        [0.6568, 0.3432],
        [0.6713, 0.3287],
        [0.6675, 0.3325],
        [0.6616, 0.3384],
        [0.6664, 0.3336],
        [0.6561, 0.3439],
        [0.6722, 0.3278],
        [0.6616, 0.3384],
        [0.6682, 0.3318],
        [0.6677, 0.3323],
        [0.6602, 0.3398],
        [0.6644, 0.3356],
        [0.6656, 0.3344],
        [0.6689, 0.3311],
        [0.6578, 0.3422],
        [0.6589, 0.3411],
        [0.6635, 0.3365],
        [0.6679, 0.3321],
        [0.6644, 0.3356],
        [0.6579, 0.3421],
        [0.6647, 0.3353],
        [0.6674, 0.3326],
        [0.6700, 0.3300],
        [0.6557, 0.3443],
        [0.6672, 0.3328],
        [0.6623, 0.3377],
        [0.6666, 0.3334],
        [0.6690, 0.3310],
        [0.6740, 0.3260],
        [0.6679, 0.3321],
        [0.6725, 0.3275],
        [0.6674, 0.3326],
        [0.6744, 0.3256],
        [0.6721, 0.3279],
        [0.6590, 0.3410],
        [0.6732, 0.3268],
        [0.6683, 0.3317],
        [0.6626, 0.3374],
        [0.6622, 0.3378],
        [0.6684, 0.3316],
        [0.6693, 0.3307],
        [0.6629, 0.3371],
        [0.6586, 0.3414],
        [0.6615, 0.3385],
        [0.6674, 0.3326],
        [0.6641, 0.3359],
        [0.6651, 0.3349],
        [0.6669, 0.3331],
        [0.6656, 0.3344],
        [0.6625, 0.3375],
        [0.6600, 0.3400],
        [0.6637, 0.3363],
        [0.6714, 0.3286],
        [0.6701, 0.3299],
        [0.6624, 0.3376],
        [0.6689, 0.3311],
        [0.6680, 0.3320],
        [0.6655, 0.3345],
        [0.6665, 0.3335],
        [0.6700, 0.3300],
        [0.6598, 0.3402],
        [0.6584, 0.3416],
        [0.6562, 0.3438],
        [0.6745, 0.3255],
        [0.6713, 0.3287],
        [0.6658, 0.3342],
        [0.6606, 0.3394],
        [0.6554, 0.3446],
        [0.6628, 0.3372],
        [0.6733, 0.3267],
        [0.6673, 0.3327],
        [0.6632, 0.3368],
        [0.6629, 0.3371],
        [0.6658, 0.3342],
        [0.6636, 0.3364],
        [0.6689, 0.3311],
        [0.6564, 0.3436],
        [0.6759, 0.3241],
        [0.6752, 0.3248],
        [0.6622, 0.3378],
        [0.6736, 0.3264],
        [0.6735, 0.3265],
        [0.6592, 0.3408],
        [0.6656, 0.3344],
        [0.6625, 0.3375],
        [0.6747, 0.3253],
        [0.6773, 0.3227],
        [0.6681, 0.3319],
        [0.6702, 0.3298],
        [0.6687, 0.3313],
        [0.6669, 0.3331],
        [0.6688, 0.3312],
        [0.6600, 0.3400],
        [0.6689, 0.3311],
        [0.6652, 0.3348],
        [0.6606, 0.3394],
        [0.6667, 0.3333],
        [0.6682, 0.3318],
        [0.6702, 0.3298],
        [0.6642, 0.3358],
        [0.6702, 0.3298],
        [0.6552, 0.3448],
        [0.6628, 0.3372],
        [0.6741, 0.3259],
        [0.6730, 0.3270],
        [0.6618, 0.3382],
        [0.6659, 0.3341],
        [0.6619, 0.3381],
        [0.6686, 0.3314],
        [0.6596, 0.3404],
        [0.6743, 0.3257],
        [0.6668, 0.3332],
        [0.6655, 0.3345],
        [0.6693, 0.3307],
        [0.6735, 0.3265],
        [0.6669, 0.3331],
        [0.6635, 0.3365],
        [0.6679, 0.3321],
        [0.6615, 0.3385],
        [0.6721, 0.3279],
        [0.6707, 0.3293],
        [0.6639, 0.3361],
        [0.6676, 0.3324],
        [0.6601, 0.3399],
        [0.6654, 0.3346],
        [0.6721, 0.3279],
        [0.6682, 0.3318],
        [0.6641, 0.3359],
        [0.6682, 0.3318],
        [0.6623, 0.3377],
        [0.6709, 0.3291],
        [0.6631, 0.3369],
        [0.6677, 0.3323],
        [0.6649, 0.3351],
        [0.6660, 0.3340],
        [0.6669, 0.3331],
        [0.6685, 0.3315],
        [0.6637, 0.3363],
        [0.6683, 0.3317],
        [0.6686, 0.3314],
        [0.6619, 0.3381],
        [0.6606, 0.3394],
        [0.6693, 0.3307],
        [0.6591, 0.3409],
        [0.6658, 0.3342],
        [0.6761, 0.3239],
        [0.6658, 0.3342],
        [0.6595, 0.3405],
        [0.6687, 0.3313],
        [0.6677, 0.3323],
        [0.6736, 0.3264]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0045 loss: 0.6687 acc_train: 0.6103 time: 0.1176s
tensor([[0.6694, 0.3306],
        [0.6646, 0.3354],
        [0.6718, 0.3282],
        [0.6678, 0.3322],
        [0.6761, 0.3239],
        [0.6611, 0.3389],
        [0.6660, 0.3340],
        [0.6670, 0.3330],
        [0.6634, 0.3366],
        [0.6654, 0.3346],
        [0.6660, 0.3340],
        [0.6711, 0.3289],
        [0.6653, 0.3347],
        [0.6628, 0.3372],
        [0.6686, 0.3314],
        [0.6578, 0.3422],
        [0.6707, 0.3293],
        [0.6683, 0.3317],
        [0.6600, 0.3400],
        [0.6619, 0.3381],
        [0.6671, 0.3329],
        [0.6654, 0.3346],
        [0.6691, 0.3309],
        [0.6717, 0.3283],
        [0.6644, 0.3356],
        [0.6568, 0.3432],
        [0.6605, 0.3395],
        [0.6675, 0.3325],
        [0.6610, 0.3390],
        [0.6591, 0.3409],
        [0.6619, 0.3381],
        [0.6612, 0.3388],
        [0.6700, 0.3300],
        [0.6692, 0.3308],
        [0.6673, 0.3327],
        [0.6593, 0.3407],
        [0.6606, 0.3394],
        [0.6600, 0.3400],
        [0.6682, 0.3318],
        [0.6681, 0.3319],
        [0.6683, 0.3317],
        [0.6619, 0.3381],
        [0.6521, 0.3479],
        [0.6644, 0.3356],
        [0.6712, 0.3288],
        [0.6658, 0.3342],
        [0.6743, 0.3257],
        [0.6707, 0.3293],
        [0.6649, 0.3351],
        [0.6700, 0.3300],
        [0.6680, 0.3320],
        [0.6700, 0.3300],
        [0.6661, 0.3339],
        [0.6641, 0.3359],
        [0.6616, 0.3384],
        [0.6734, 0.3266],
        [0.6638, 0.3362],
        [0.6646, 0.3354],
        [0.6713, 0.3287],
        [0.6647, 0.3353],
        [0.6561, 0.3439],
        [0.6605, 0.3395],
        [0.6712, 0.3288],
        [0.6702, 0.3298],
        [0.6629, 0.3371],
        [0.6626, 0.3374],
        [0.6643, 0.3357],
        [0.6599, 0.3401],
        [0.6637, 0.3363],
        [0.6653, 0.3347],
        [0.6628, 0.3372],
        [0.6686, 0.3314],
        [0.6701, 0.3299],
        [0.6701, 0.3299],
        [0.6618, 0.3382],
        [0.6634, 0.3366],
        [0.6704, 0.3296],
        [0.6669, 0.3331],
        [0.6617, 0.3383],
        [0.6656, 0.3344],
        [0.6660, 0.3340],
        [0.6688, 0.3312],
        [0.6601, 0.3399],
        [0.6663, 0.3337],
        [0.6626, 0.3374],
        [0.6600, 0.3400],
        [0.6642, 0.3358],
        [0.6657, 0.3343],
        [0.6687, 0.3313],
        [0.6668, 0.3332],
        [0.6691, 0.3309],
        [0.6680, 0.3320],
        [0.6697, 0.3303],
        [0.6583, 0.3417],
        [0.6647, 0.3353],
        [0.6735, 0.3265],
        [0.6740, 0.3260],
        [0.6553, 0.3447],
        [0.6746, 0.3254],
        [0.6627, 0.3373],
        [0.6718, 0.3282],
        [0.6679, 0.3321],
        [0.6569, 0.3431],
        [0.6617, 0.3383],
        [0.6652, 0.3348],
        [0.6667, 0.3333],
        [0.6670, 0.3330],
        [0.6697, 0.3303],
        [0.6614, 0.3386],
        [0.6742, 0.3258],
        [0.6558, 0.3442],
        [0.6625, 0.3375],
        [0.6685, 0.3315],
        [0.6697, 0.3303],
        [0.6604, 0.3396],
        [0.6643, 0.3357],
        [0.6708, 0.3292],
        [0.6687, 0.3313],
        [0.6683, 0.3317],
        [0.6692, 0.3308],
        [0.6566, 0.3434],
        [0.6570, 0.3430],
        [0.6712, 0.3288],
        [0.6675, 0.3325],
        [0.6616, 0.3384],
        [0.6663, 0.3337],
        [0.6563, 0.3437],
        [0.6722, 0.3278],
        [0.6617, 0.3383],
        [0.6682, 0.3318],
        [0.6677, 0.3323],
        [0.6603, 0.3397],
        [0.6644, 0.3356],
        [0.6657, 0.3343],
        [0.6690, 0.3310],
        [0.6581, 0.3419],
        [0.6590, 0.3410],
        [0.6636, 0.3364],
        [0.6680, 0.3320],
        [0.6645, 0.3355],
        [0.6580, 0.3420],
        [0.6648, 0.3352],
        [0.6674, 0.3326],
        [0.6699, 0.3301],
        [0.6558, 0.3442],
        [0.6672, 0.3328],
        [0.6623, 0.3377],
        [0.6666, 0.3334],
        [0.6690, 0.3310],
        [0.6740, 0.3260],
        [0.6678, 0.3322],
        [0.6724, 0.3276],
        [0.6675, 0.3325],
        [0.6742, 0.3258],
        [0.6720, 0.3280],
        [0.6592, 0.3408],
        [0.6731, 0.3269],
        [0.6683, 0.3317],
        [0.6628, 0.3372],
        [0.6623, 0.3377],
        [0.6684, 0.3316],
        [0.6692, 0.3308],
        [0.6630, 0.3370],
        [0.6587, 0.3413],
        [0.6616, 0.3384],
        [0.6675, 0.3325],
        [0.6641, 0.3359],
        [0.6650, 0.3350],
        [0.6668, 0.3332],
        [0.6657, 0.3343],
        [0.6627, 0.3373],
        [0.6601, 0.3399],
        [0.6638, 0.3362],
        [0.6713, 0.3287],
        [0.6700, 0.3300],
        [0.6625, 0.3375],
        [0.6688, 0.3312],
        [0.6679, 0.3321],
        [0.6655, 0.3345],
        [0.6665, 0.3335],
        [0.6700, 0.3300],
        [0.6600, 0.3400],
        [0.6585, 0.3415],
        [0.6563, 0.3437],
        [0.6744, 0.3256],
        [0.6712, 0.3288],
        [0.6659, 0.3341],
        [0.6607, 0.3393],
        [0.6557, 0.3443],
        [0.6629, 0.3371],
        [0.6732, 0.3268],
        [0.6672, 0.3328],
        [0.6633, 0.3367],
        [0.6629, 0.3371],
        [0.6658, 0.3342],
        [0.6636, 0.3364],
        [0.6689, 0.3311],
        [0.6565, 0.3435],
        [0.6758, 0.3242],
        [0.6752, 0.3248],
        [0.6622, 0.3378],
        [0.6735, 0.3265],
        [0.6734, 0.3266],
        [0.6592, 0.3408],
        [0.6656, 0.3344],
        [0.6626, 0.3374],
        [0.6745, 0.3255],
        [0.6771, 0.3229],
        [0.6681, 0.3319],
        [0.6701, 0.3299],
        [0.6687, 0.3313],
        [0.6669, 0.3331],
        [0.6688, 0.3312],
        [0.6601, 0.3399],
        [0.6689, 0.3311],
        [0.6652, 0.3348],
        [0.6607, 0.3393],
        [0.6667, 0.3333],
        [0.6682, 0.3318],
        [0.6702, 0.3298],
        [0.6642, 0.3358],
        [0.6703, 0.3297],
        [0.6554, 0.3446],
        [0.6629, 0.3371],
        [0.6740, 0.3260],
        [0.6729, 0.3271],
        [0.6619, 0.3381],
        [0.6660, 0.3340],
        [0.6620, 0.3380],
        [0.6686, 0.3314],
        [0.6597, 0.3403],
        [0.6742, 0.3258],
        [0.6669, 0.3331],
        [0.6656, 0.3344],
        [0.6693, 0.3307],
        [0.6734, 0.3266],
        [0.6669, 0.3331],
        [0.6635, 0.3365],
        [0.6679, 0.3321],
        [0.6616, 0.3384],
        [0.6720, 0.3280],
        [0.6706, 0.3294],
        [0.6640, 0.3360],
        [0.6676, 0.3324],
        [0.6602, 0.3398],
        [0.6655, 0.3345],
        [0.6720, 0.3280],
        [0.6683, 0.3317],
        [0.6642, 0.3358],
        [0.6682, 0.3318],
        [0.6623, 0.3377],
        [0.6708, 0.3292],
        [0.6631, 0.3369],
        [0.6678, 0.3322],
        [0.6650, 0.3350],
        [0.6661, 0.3339],
        [0.6670, 0.3330],
        [0.6685, 0.3315],
        [0.6638, 0.3362],
        [0.6683, 0.3317],
        [0.6687, 0.3313],
        [0.6620, 0.3380],
        [0.6608, 0.3392],
        [0.6692, 0.3308],
        [0.6592, 0.3408],
        [0.6659, 0.3341],
        [0.6760, 0.3240],
        [0.6658, 0.3342],
        [0.6596, 0.3404],
        [0.6688, 0.3312],
        [0.6677, 0.3323],
        [0.6735, 0.3265]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0046 loss: 0.6687 acc_train: 0.6103 time: 0.1179s
tensor([[0.6694, 0.3306],
        [0.6646, 0.3354],
        [0.6717, 0.3283],
        [0.6678, 0.3322],
        [0.6759, 0.3241],
        [0.6613, 0.3387],
        [0.6660, 0.3340],
        [0.6670, 0.3330],
        [0.6634, 0.3366],
        [0.6654, 0.3346],
        [0.6658, 0.3342],
        [0.6711, 0.3289],
        [0.6654, 0.3346],
        [0.6629, 0.3371],
        [0.6686, 0.3314],
        [0.6579, 0.3421],
        [0.6705, 0.3295],
        [0.6682, 0.3318],
        [0.6600, 0.3400],
        [0.6619, 0.3381],
        [0.6670, 0.3330],
        [0.6654, 0.3346],
        [0.6690, 0.3310],
        [0.6716, 0.3284],
        [0.6645, 0.3355],
        [0.6569, 0.3431],
        [0.6606, 0.3394],
        [0.6675, 0.3325],
        [0.6611, 0.3389],
        [0.6592, 0.3408],
        [0.6620, 0.3380],
        [0.6613, 0.3387],
        [0.6699, 0.3301],
        [0.6692, 0.3308],
        [0.6673, 0.3327],
        [0.6595, 0.3405],
        [0.6608, 0.3392],
        [0.6600, 0.3400],
        [0.6681, 0.3319],
        [0.6680, 0.3320],
        [0.6682, 0.3318],
        [0.6620, 0.3380],
        [0.6524, 0.3476],
        [0.6644, 0.3356],
        [0.6709, 0.3291],
        [0.6658, 0.3342],
        [0.6742, 0.3258],
        [0.6706, 0.3294],
        [0.6649, 0.3351],
        [0.6700, 0.3300],
        [0.6679, 0.3321],
        [0.6699, 0.3301],
        [0.6661, 0.3339],
        [0.6640, 0.3360],
        [0.6616, 0.3384],
        [0.6732, 0.3268],
        [0.6638, 0.3362],
        [0.6646, 0.3354],
        [0.6712, 0.3288],
        [0.6648, 0.3352],
        [0.6563, 0.3437],
        [0.6605, 0.3395],
        [0.6712, 0.3288],
        [0.6703, 0.3297],
        [0.6630, 0.3370],
        [0.6626, 0.3374],
        [0.6643, 0.3357],
        [0.6601, 0.3399],
        [0.6637, 0.3363],
        [0.6653, 0.3347],
        [0.6629, 0.3371],
        [0.6686, 0.3314],
        [0.6700, 0.3300],
        [0.6701, 0.3299],
        [0.6620, 0.3380],
        [0.6634, 0.3366],
        [0.6703, 0.3297],
        [0.6669, 0.3331],
        [0.6619, 0.3381],
        [0.6657, 0.3343],
        [0.6660, 0.3340],
        [0.6687, 0.3313],
        [0.6601, 0.3399],
        [0.6663, 0.3337],
        [0.6626, 0.3374],
        [0.6601, 0.3399],
        [0.6643, 0.3357],
        [0.6657, 0.3343],
        [0.6687, 0.3313],
        [0.6668, 0.3332],
        [0.6691, 0.3309],
        [0.6680, 0.3320],
        [0.6698, 0.3302],
        [0.6584, 0.3416],
        [0.6647, 0.3353],
        [0.6734, 0.3266],
        [0.6738, 0.3262],
        [0.6555, 0.3445],
        [0.6744, 0.3256],
        [0.6628, 0.3372],
        [0.6717, 0.3283],
        [0.6679, 0.3321],
        [0.6570, 0.3430],
        [0.6617, 0.3383],
        [0.6651, 0.3349],
        [0.6667, 0.3333],
        [0.6670, 0.3330],
        [0.6696, 0.3304],
        [0.6615, 0.3385],
        [0.6740, 0.3260],
        [0.6561, 0.3439],
        [0.6626, 0.3374],
        [0.6685, 0.3315],
        [0.6696, 0.3304],
        [0.6605, 0.3395],
        [0.6645, 0.3355],
        [0.6708, 0.3292],
        [0.6687, 0.3313],
        [0.6682, 0.3318],
        [0.6691, 0.3309],
        [0.6567, 0.3433],
        [0.6571, 0.3429],
        [0.6711, 0.3289],
        [0.6676, 0.3324],
        [0.6616, 0.3384],
        [0.6663, 0.3337],
        [0.6564, 0.3436],
        [0.6721, 0.3279],
        [0.6618, 0.3382],
        [0.6681, 0.3319],
        [0.6677, 0.3323],
        [0.6603, 0.3397],
        [0.6644, 0.3356],
        [0.6657, 0.3343],
        [0.6690, 0.3310],
        [0.6583, 0.3417],
        [0.6591, 0.3409],
        [0.6637, 0.3363],
        [0.6680, 0.3320],
        [0.6645, 0.3355],
        [0.6581, 0.3419],
        [0.6649, 0.3351],
        [0.6675, 0.3325],
        [0.6698, 0.3302],
        [0.6559, 0.3441],
        [0.6673, 0.3327],
        [0.6624, 0.3376],
        [0.6666, 0.3334],
        [0.6689, 0.3311],
        [0.6739, 0.3261],
        [0.6677, 0.3323],
        [0.6722, 0.3278],
        [0.6675, 0.3325],
        [0.6741, 0.3259],
        [0.6719, 0.3281],
        [0.6593, 0.3407],
        [0.6729, 0.3271],
        [0.6683, 0.3317],
        [0.6630, 0.3370],
        [0.6622, 0.3378],
        [0.6684, 0.3316],
        [0.6691, 0.3309],
        [0.6631, 0.3369],
        [0.6587, 0.3413],
        [0.6617, 0.3383],
        [0.6675, 0.3325],
        [0.6642, 0.3358],
        [0.6650, 0.3350],
        [0.6667, 0.3333],
        [0.6657, 0.3343],
        [0.6629, 0.3371],
        [0.6602, 0.3398],
        [0.6639, 0.3361],
        [0.6712, 0.3288],
        [0.6699, 0.3301],
        [0.6626, 0.3374],
        [0.6687, 0.3313],
        [0.6677, 0.3323],
        [0.6655, 0.3345],
        [0.6665, 0.3335],
        [0.6700, 0.3300],
        [0.6601, 0.3399],
        [0.6586, 0.3414],
        [0.6564, 0.3436],
        [0.6743, 0.3257],
        [0.6711, 0.3289],
        [0.6659, 0.3341],
        [0.6607, 0.3393],
        [0.6560, 0.3440],
        [0.6630, 0.3370],
        [0.6730, 0.3270],
        [0.6671, 0.3329],
        [0.6635, 0.3365],
        [0.6630, 0.3370],
        [0.6657, 0.3343],
        [0.6637, 0.3363],
        [0.6688, 0.3312],
        [0.6567, 0.3433],
        [0.6757, 0.3243],
        [0.6751, 0.3249],
        [0.6623, 0.3377],
        [0.6735, 0.3265],
        [0.6733, 0.3267],
        [0.6593, 0.3407],
        [0.6656, 0.3344],
        [0.6626, 0.3374],
        [0.6743, 0.3257],
        [0.6768, 0.3232],
        [0.6681, 0.3319],
        [0.6700, 0.3300],
        [0.6686, 0.3314],
        [0.6669, 0.3331],
        [0.6687, 0.3313],
        [0.6602, 0.3398],
        [0.6688, 0.3312],
        [0.6651, 0.3349],
        [0.6608, 0.3392],
        [0.6667, 0.3333],
        [0.6681, 0.3319],
        [0.6701, 0.3299],
        [0.6643, 0.3357],
        [0.6703, 0.3297],
        [0.6557, 0.3443],
        [0.6629, 0.3371],
        [0.6739, 0.3261],
        [0.6726, 0.3274],
        [0.6620, 0.3380],
        [0.6662, 0.3338],
        [0.6620, 0.3380],
        [0.6685, 0.3314],
        [0.6598, 0.3402],
        [0.6741, 0.3259],
        [0.6669, 0.3331],
        [0.6656, 0.3344],
        [0.6692, 0.3308],
        [0.6734, 0.3266],
        [0.6669, 0.3331],
        [0.6635, 0.3365],
        [0.6678, 0.3322],
        [0.6616, 0.3384],
        [0.6719, 0.3281],
        [0.6706, 0.3294],
        [0.6640, 0.3360],
        [0.6676, 0.3324],
        [0.6603, 0.3397],
        [0.6655, 0.3345],
        [0.6719, 0.3281],
        [0.6683, 0.3317],
        [0.6643, 0.3357],
        [0.6681, 0.3319],
        [0.6624, 0.3376],
        [0.6707, 0.3293],
        [0.6632, 0.3368],
        [0.6679, 0.3321],
        [0.6650, 0.3350],
        [0.6661, 0.3339],
        [0.6670, 0.3330],
        [0.6685, 0.3315],
        [0.6638, 0.3362],
        [0.6683, 0.3317],
        [0.6687, 0.3313],
        [0.6622, 0.3378],
        [0.6609, 0.3391],
        [0.6692, 0.3308],
        [0.6592, 0.3408],
        [0.6659, 0.3341],
        [0.6758, 0.3242],
        [0.6659, 0.3341],
        [0.6597, 0.3403],
        [0.6688, 0.3312],
        [0.6678, 0.3322],
        [0.6733, 0.3267]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0047 loss: 0.6687 acc_train: 0.6103 time: 0.1201s
tensor([[0.6693, 0.3307],
        [0.6645, 0.3355],
        [0.6717, 0.3283],
        [0.6677, 0.3323],
        [0.6757, 0.3243],
        [0.6614, 0.3386],
        [0.6659, 0.3341],
        [0.6670, 0.3330],
        [0.6634, 0.3366],
        [0.6654, 0.3346],
        [0.6657, 0.3343],
        [0.6710, 0.3290],
        [0.6654, 0.3346],
        [0.6630, 0.3370],
        [0.6685, 0.3315],
        [0.6581, 0.3419],
        [0.6703, 0.3297],
        [0.6682, 0.3318],
        [0.6600, 0.3400],
        [0.6620, 0.3380],
        [0.6669, 0.3331],
        [0.6654, 0.3346],
        [0.6689, 0.3311],
        [0.6715, 0.3285],
        [0.6645, 0.3355],
        [0.6570, 0.3430],
        [0.6606, 0.3394],
        [0.6674, 0.3326],
        [0.6611, 0.3389],
        [0.6594, 0.3406],
        [0.6620, 0.3380],
        [0.6614, 0.3386],
        [0.6697, 0.3303],
        [0.6691, 0.3309],
        [0.6673, 0.3327],
        [0.6597, 0.3403],
        [0.6608, 0.3392],
        [0.6600, 0.3400],
        [0.6681, 0.3319],
        [0.6680, 0.3320],
        [0.6681, 0.3319],
        [0.6619, 0.3381],
        [0.6526, 0.3474],
        [0.6644, 0.3356],
        [0.6706, 0.3294],
        [0.6658, 0.3342],
        [0.6740, 0.3260],
        [0.6705, 0.3295],
        [0.6648, 0.3352],
        [0.6699, 0.3301],
        [0.6679, 0.3321],
        [0.6698, 0.3302],
        [0.6662, 0.3338],
        [0.6640, 0.3360],
        [0.6617, 0.3383],
        [0.6730, 0.3270],
        [0.6638, 0.3362],
        [0.6647, 0.3353],
        [0.6712, 0.3288],
        [0.6648, 0.3352],
        [0.6565, 0.3435],
        [0.6606, 0.3394],
        [0.6712, 0.3288],
        [0.6702, 0.3298],
        [0.6631, 0.3369],
        [0.6627, 0.3373],
        [0.6643, 0.3357],
        [0.6602, 0.3398],
        [0.6636, 0.3364],
        [0.6654, 0.3346],
        [0.6629, 0.3371],
        [0.6685, 0.3315],
        [0.6699, 0.3301],
        [0.6700, 0.3300],
        [0.6621, 0.3379],
        [0.6634, 0.3366],
        [0.6702, 0.3298],
        [0.6669, 0.3331],
        [0.6620, 0.3380],
        [0.6657, 0.3343],
        [0.6660, 0.3340],
        [0.6687, 0.3313],
        [0.6601, 0.3399],
        [0.6663, 0.3337],
        [0.6626, 0.3374],
        [0.6601, 0.3399],
        [0.6643, 0.3357],
        [0.6657, 0.3343],
        [0.6686, 0.3314],
        [0.6667, 0.3333],
        [0.6690, 0.3310],
        [0.6680, 0.3320],
        [0.6698, 0.3302],
        [0.6585, 0.3415],
        [0.6648, 0.3352],
        [0.6733, 0.3267],
        [0.6736, 0.3264],
        [0.6556, 0.3444],
        [0.6743, 0.3257],
        [0.6628, 0.3372],
        [0.6715, 0.3285],
        [0.6679, 0.3321],
        [0.6571, 0.3429],
        [0.6617, 0.3383],
        [0.6649, 0.3351],
        [0.6667, 0.3333],
        [0.6669, 0.3331],
        [0.6694, 0.3306],
        [0.6615, 0.3385],
        [0.6738, 0.3262],
        [0.6563, 0.3437],
        [0.6627, 0.3373],
        [0.6685, 0.3315],
        [0.6695, 0.3305],
        [0.6606, 0.3394],
        [0.6646, 0.3354],
        [0.6707, 0.3293],
        [0.6686, 0.3314],
        [0.6682, 0.3318],
        [0.6690, 0.3310],
        [0.6569, 0.3431],
        [0.6572, 0.3428],
        [0.6710, 0.3290],
        [0.6676, 0.3324],
        [0.6616, 0.3384],
        [0.6663, 0.3337],
        [0.6566, 0.3434],
        [0.6720, 0.3280],
        [0.6619, 0.3381],
        [0.6680, 0.3320],
        [0.6676, 0.3324],
        [0.6603, 0.3397],
        [0.6644, 0.3356],
        [0.6657, 0.3343],
        [0.6690, 0.3310],
        [0.6584, 0.3416],
        [0.6592, 0.3408],
        [0.6637, 0.3363],
        [0.6680, 0.3320],
        [0.6645, 0.3355],
        [0.6582, 0.3418],
        [0.6649, 0.3351],
        [0.6674, 0.3326],
        [0.6697, 0.3303],
        [0.6560, 0.3440],
        [0.6672, 0.3328],
        [0.6624, 0.3376],
        [0.6665, 0.3335],
        [0.6688, 0.3312],
        [0.6737, 0.3263],
        [0.6677, 0.3323],
        [0.6721, 0.3279],
        [0.6674, 0.3326],
        [0.6739, 0.3261],
        [0.6718, 0.3282],
        [0.6594, 0.3406],
        [0.6727, 0.3273],
        [0.6683, 0.3317],
        [0.6631, 0.3369],
        [0.6622, 0.3378],
        [0.6683, 0.3317],
        [0.6689, 0.3311],
        [0.6631, 0.3369],
        [0.6588, 0.3412],
        [0.6618, 0.3382],
        [0.6675, 0.3325],
        [0.6642, 0.3358],
        [0.6650, 0.3350],
        [0.6666, 0.3334],
        [0.6657, 0.3343],
        [0.6630, 0.3370],
        [0.6602, 0.3398],
        [0.6639, 0.3361],
        [0.6710, 0.3290],
        [0.6698, 0.3302],
        [0.6626, 0.3374],
        [0.6685, 0.3315],
        [0.6676, 0.3324],
        [0.6655, 0.3345],
        [0.6664, 0.3336],
        [0.6699, 0.3301],
        [0.6603, 0.3397],
        [0.6586, 0.3414],
        [0.6566, 0.3434],
        [0.6741, 0.3259],
        [0.6710, 0.3290],
        [0.6660, 0.3340],
        [0.6608, 0.3392],
        [0.6562, 0.3438],
        [0.6630, 0.3370],
        [0.6728, 0.3272],
        [0.6669, 0.3331],
        [0.6637, 0.3363],
        [0.6630, 0.3370],
        [0.6656, 0.3344],
        [0.6637, 0.3363],
        [0.6687, 0.3313],
        [0.6568, 0.3432],
        [0.6755, 0.3245],
        [0.6749, 0.3251],
        [0.6623, 0.3377],
        [0.6733, 0.3267],
        [0.6731, 0.3269],
        [0.6594, 0.3406],
        [0.6655, 0.3345],
        [0.6626, 0.3374],
        [0.6740, 0.3260],
        [0.6765, 0.3235],
        [0.6681, 0.3319],
        [0.6699, 0.3301],
        [0.6684, 0.3316],
        [0.6669, 0.3331],
        [0.6686, 0.3314],
        [0.6603, 0.3397],
        [0.6688, 0.3312],
        [0.6651, 0.3349],
        [0.6609, 0.3391],
        [0.6666, 0.3334],
        [0.6680, 0.3320],
        [0.6700, 0.3300],
        [0.6643, 0.3357],
        [0.6702, 0.3298],
        [0.6559, 0.3441],
        [0.6629, 0.3371],
        [0.6737, 0.3263],
        [0.6724, 0.3276],
        [0.6620, 0.3380],
        [0.6662, 0.3338],
        [0.6621, 0.3379],
        [0.6685, 0.3315],
        [0.6598, 0.3402],
        [0.6739, 0.3261],
        [0.6668, 0.3332],
        [0.6657, 0.3343],
        [0.6691, 0.3309],
        [0.6733, 0.3267],
        [0.6670, 0.3330],
        [0.6634, 0.3366],
        [0.6676, 0.3324],
        [0.6617, 0.3383],
        [0.6718, 0.3282],
        [0.6705, 0.3295],
        [0.6640, 0.3360],
        [0.6675, 0.3325],
        [0.6603, 0.3397],
        [0.6654, 0.3346],
        [0.6718, 0.3282],
        [0.6682, 0.3318],
        [0.6643, 0.3357],
        [0.6681, 0.3319],
        [0.6624, 0.3376],
        [0.6705, 0.3295],
        [0.6633, 0.3367],
        [0.6678, 0.3322],
        [0.6650, 0.3350],
        [0.6661, 0.3339],
        [0.6670, 0.3330],
        [0.6684, 0.3316],
        [0.6637, 0.3363],
        [0.6682, 0.3318],
        [0.6686, 0.3314],
        [0.6622, 0.3378],
        [0.6610, 0.3390],
        [0.6691, 0.3309],
        [0.6594, 0.3406],
        [0.6658, 0.3342],
        [0.6756, 0.3244],
        [0.6659, 0.3341],
        [0.6597, 0.3403],
        [0.6688, 0.3312],
        [0.6678, 0.3322],
        [0.6731, 0.3269]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0048 loss: 0.6687 acc_train: 0.6103 time: 0.1218s
tensor([[0.6692, 0.3308],
        [0.6644, 0.3356],
        [0.6715, 0.3285],
        [0.6676, 0.3324],
        [0.6754, 0.3246],
        [0.6615, 0.3385],
        [0.6659, 0.3341],
        [0.6669, 0.3331],
        [0.6633, 0.3367],
        [0.6653, 0.3347],
        [0.6655, 0.3345],
        [0.6708, 0.3292],
        [0.6654, 0.3346],
        [0.6631, 0.3369],
        [0.6683, 0.3317],
        [0.6581, 0.3419],
        [0.6701, 0.3299],
        [0.6681, 0.3319],
        [0.6600, 0.3400],
        [0.6620, 0.3380],
        [0.6668, 0.3332],
        [0.6654, 0.3346],
        [0.6688, 0.3312],
        [0.6713, 0.3287],
        [0.6645, 0.3355],
        [0.6571, 0.3429],
        [0.6606, 0.3394],
        [0.6672, 0.3328],
        [0.6611, 0.3389],
        [0.6595, 0.3405],
        [0.6620, 0.3380],
        [0.6614, 0.3386],
        [0.6696, 0.3304],
        [0.6690, 0.3310],
        [0.6673, 0.3327],
        [0.6599, 0.3401],
        [0.6609, 0.3391],
        [0.6600, 0.3400],
        [0.6679, 0.3321],
        [0.6680, 0.3320],
        [0.6679, 0.3321],
        [0.6618, 0.3382],
        [0.6529, 0.3471],
        [0.6643, 0.3357],
        [0.6703, 0.3297],
        [0.6658, 0.3342],
        [0.6738, 0.3262],
        [0.6703, 0.3297],
        [0.6648, 0.3352],
        [0.6697, 0.3303],
        [0.6678, 0.3322],
        [0.6696, 0.3304],
        [0.6661, 0.3339],
        [0.6639, 0.3361],
        [0.6617, 0.3383],
        [0.6728, 0.3272],
        [0.6637, 0.3363],
        [0.6646, 0.3354],
        [0.6710, 0.3290],
        [0.6647, 0.3353],
        [0.6566, 0.3434],
        [0.6606, 0.3394],
        [0.6711, 0.3289],
        [0.6701, 0.3299],
        [0.6631, 0.3369],
        [0.6627, 0.3373],
        [0.6643, 0.3357],
        [0.6602, 0.3398],
        [0.6635, 0.3365],
        [0.6654, 0.3346],
        [0.6629, 0.3371],
        [0.6685, 0.3315],
        [0.6698, 0.3302],
        [0.6699, 0.3301],
        [0.6622, 0.3378],
        [0.6634, 0.3366],
        [0.6700, 0.3300],
        [0.6668, 0.3332],
        [0.6620, 0.3380],
        [0.6657, 0.3343],
        [0.6660, 0.3340],
        [0.6686, 0.3314],
        [0.6601, 0.3399],
        [0.6662, 0.3338],
        [0.6625, 0.3375],
        [0.6601, 0.3399],
        [0.6642, 0.3358],
        [0.6657, 0.3343],
        [0.6685, 0.3315],
        [0.6666, 0.3334],
        [0.6689, 0.3311],
        [0.6679, 0.3321],
        [0.6698, 0.3302],
        [0.6586, 0.3414],
        [0.6647, 0.3353],
        [0.6731, 0.3269],
        [0.6733, 0.3267],
        [0.6557, 0.3443],
        [0.6740, 0.3260],
        [0.6628, 0.3372],
        [0.6712, 0.3288],
        [0.6679, 0.3321],
        [0.6572, 0.3428],
        [0.6616, 0.3384],
        [0.6647, 0.3353],
        [0.6667, 0.3333],
        [0.6668, 0.3332],
        [0.6692, 0.3308],
        [0.6615, 0.3385],
        [0.6735, 0.3265],
        [0.6564, 0.3436],
        [0.6627, 0.3373],
        [0.6685, 0.3315],
        [0.6694, 0.3306],
        [0.6607, 0.3393],
        [0.6646, 0.3354],
        [0.6705, 0.3295],
        [0.6685, 0.3315],
        [0.6680, 0.3320],
        [0.6689, 0.3311],
        [0.6570, 0.3430],
        [0.6572, 0.3428],
        [0.6708, 0.3292],
        [0.6676, 0.3324],
        [0.6616, 0.3384],
        [0.6663, 0.3337],
        [0.6567, 0.3433],
        [0.6718, 0.3282],
        [0.6619, 0.3381],
        [0.6680, 0.3320],
        [0.6675, 0.3325],
        [0.6602, 0.3398],
        [0.6643, 0.3357],
        [0.6657, 0.3343],
        [0.6689, 0.3311],
        [0.6585, 0.3415],
        [0.6593, 0.3407],
        [0.6636, 0.3364],
        [0.6680, 0.3320],
        [0.6645, 0.3355],
        [0.6583, 0.3417],
        [0.6648, 0.3352],
        [0.6674, 0.3326],
        [0.6696, 0.3304],
        [0.6561, 0.3439],
        [0.6671, 0.3329],
        [0.6623, 0.3377],
        [0.6664, 0.3336],
        [0.6687, 0.3313],
        [0.6735, 0.3265],
        [0.6675, 0.3325],
        [0.6719, 0.3281],
        [0.6672, 0.3328],
        [0.6737, 0.3263],
        [0.6716, 0.3284],
        [0.6594, 0.3406],
        [0.6725, 0.3275],
        [0.6682, 0.3318],
        [0.6632, 0.3368],
        [0.6621, 0.3379],
        [0.6682, 0.3318],
        [0.6687, 0.3313],
        [0.6631, 0.3369],
        [0.6588, 0.3412],
        [0.6618, 0.3382],
        [0.6674, 0.3326],
        [0.6641, 0.3359],
        [0.6649, 0.3351],
        [0.6665, 0.3335],
        [0.6657, 0.3343],
        [0.6631, 0.3369],
        [0.6602, 0.3398],
        [0.6639, 0.3361],
        [0.6709, 0.3291],
        [0.6696, 0.3304],
        [0.6626, 0.3374],
        [0.6684, 0.3316],
        [0.6674, 0.3326],
        [0.6655, 0.3345],
        [0.6662, 0.3338],
        [0.6698, 0.3302],
        [0.6604, 0.3396],
        [0.6586, 0.3414],
        [0.6567, 0.3433],
        [0.6738, 0.3262],
        [0.6708, 0.3292],
        [0.6661, 0.3339],
        [0.6608, 0.3392],
        [0.6563, 0.3437],
        [0.6630, 0.3370],
        [0.6725, 0.3275],
        [0.6667, 0.3333],
        [0.6638, 0.3362],
        [0.6630, 0.3370],
        [0.6654, 0.3346],
        [0.6637, 0.3363],
        [0.6685, 0.3315],
        [0.6569, 0.3431],
        [0.6752, 0.3248],
        [0.6747, 0.3253],
        [0.6624, 0.3376],
        [0.6731, 0.3269],
        [0.6729, 0.3271],
        [0.6595, 0.3405],
        [0.6653, 0.3347],
        [0.6625, 0.3375],
        [0.6738, 0.3262],
        [0.6761, 0.3239],
        [0.6681, 0.3319],
        [0.6697, 0.3303],
        [0.6682, 0.3318],
        [0.6668, 0.3332],
        [0.6684, 0.3316],
        [0.6604, 0.3396],
        [0.6687, 0.3313],
        [0.6650, 0.3350],
        [0.6609, 0.3391],
        [0.6665, 0.3335],
        [0.6678, 0.3322],
        [0.6699, 0.3301],
        [0.6643, 0.3357],
        [0.6700, 0.3300],
        [0.6560, 0.3440],
        [0.6628, 0.3372],
        [0.6735, 0.3265],
        [0.6721, 0.3279],
        [0.6620, 0.3380],
        [0.6663, 0.3337],
        [0.6622, 0.3378],
        [0.6684, 0.3316],
        [0.6598, 0.3402],
        [0.6737, 0.3263],
        [0.6667, 0.3333],
        [0.6656, 0.3344],
        [0.6689, 0.3311],
        [0.6731, 0.3269],
        [0.6670, 0.3330],
        [0.6634, 0.3366],
        [0.6674, 0.3326],
        [0.6617, 0.3383],
        [0.6716, 0.3284],
        [0.6704, 0.3296],
        [0.6640, 0.3360],
        [0.6674, 0.3326],
        [0.6603, 0.3397],
        [0.6653, 0.3347],
        [0.6716, 0.3284],
        [0.6681, 0.3319],
        [0.6642, 0.3358],
        [0.6680, 0.3320],
        [0.6624, 0.3376],
        [0.6703, 0.3297],
        [0.6633, 0.3367],
        [0.6677, 0.3323],
        [0.6650, 0.3350],
        [0.6661, 0.3339],
        [0.6669, 0.3331],
        [0.6683, 0.3317],
        [0.6637, 0.3363],
        [0.6680, 0.3320],
        [0.6685, 0.3315],
        [0.6622, 0.3378],
        [0.6610, 0.3390],
        [0.6689, 0.3311],
        [0.6595, 0.3405],
        [0.6657, 0.3343],
        [0.6754, 0.3246],
        [0.6659, 0.3341],
        [0.6598, 0.3402],
        [0.6687, 0.3313],
        [0.6677, 0.3323],
        [0.6729, 0.3271]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0049 loss: 0.6688 acc_train: 0.6103 time: 0.1268s
tensor([[0.6690, 0.3310],
        [0.6643, 0.3357],
        [0.6712, 0.3288],
        [0.6675, 0.3325],
        [0.6751, 0.3249],
        [0.6615, 0.3385],
        [0.6658, 0.3342],
        [0.6668, 0.3332],
        [0.6632, 0.3368],
        [0.6652, 0.3348],
        [0.6653, 0.3347],
        [0.6706, 0.3294],
        [0.6653, 0.3347],
        [0.6630, 0.3370],
        [0.6681, 0.3319],
        [0.6582, 0.3418],
        [0.6698, 0.3302],
        [0.6679, 0.3321],
        [0.6600, 0.3400],
        [0.6620, 0.3380],
        [0.6666, 0.3334],
        [0.6653, 0.3347],
        [0.6686, 0.3314],
        [0.6711, 0.3289],
        [0.6645, 0.3355],
        [0.6572, 0.3428],
        [0.6605, 0.3395],
        [0.6670, 0.3330],
        [0.6611, 0.3389],
        [0.6596, 0.3404],
        [0.6620, 0.3380],
        [0.6613, 0.3387],
        [0.6694, 0.3306],
        [0.6688, 0.3312],
        [0.6672, 0.3328],
        [0.6599, 0.3401],
        [0.6609, 0.3391],
        [0.6600, 0.3400],
        [0.6678, 0.3322],
        [0.6679, 0.3321],
        [0.6677, 0.3323],
        [0.6617, 0.3383],
        [0.6530, 0.3470],
        [0.6641, 0.3359],
        [0.6699, 0.3301],
        [0.6658, 0.3342],
        [0.6735, 0.3265],
        [0.6701, 0.3299],
        [0.6647, 0.3353],
        [0.6695, 0.3305],
        [0.6677, 0.3323],
        [0.6693, 0.3307],
        [0.6660, 0.3340],
        [0.6638, 0.3362],
        [0.6617, 0.3383],
        [0.6725, 0.3275],
        [0.6636, 0.3364],
        [0.6645, 0.3355],
        [0.6709, 0.3291],
        [0.6646, 0.3354],
        [0.6566, 0.3434],
        [0.6606, 0.3394],
        [0.6709, 0.3291],
        [0.6699, 0.3301],
        [0.6631, 0.3369],
        [0.6626, 0.3374],
        [0.6641, 0.3359],
        [0.6602, 0.3398],
        [0.6633, 0.3367],
        [0.6653, 0.3347],
        [0.6628, 0.3372],
        [0.6683, 0.3317],
        [0.6697, 0.3303],
        [0.6697, 0.3303],
        [0.6623, 0.3377],
        [0.6634, 0.3366],
        [0.6698, 0.3302],
        [0.6668, 0.3332],
        [0.6620, 0.3380],
        [0.6657, 0.3343],
        [0.6659, 0.3341],
        [0.6685, 0.3315],
        [0.6601, 0.3399],
        [0.6661, 0.3339],
        [0.6624, 0.3376],
        [0.6601, 0.3399],
        [0.6641, 0.3359],
        [0.6656, 0.3344],
        [0.6683, 0.3317],
        [0.6665, 0.3335],
        [0.6688, 0.3312],
        [0.6678, 0.3322],
        [0.6697, 0.3303],
        [0.6587, 0.3413],
        [0.6647, 0.3353],
        [0.6729, 0.3271],
        [0.6729, 0.3271],
        [0.6558, 0.3442],
        [0.6737, 0.3263],
        [0.6628, 0.3372],
        [0.6709, 0.3291],
        [0.6678, 0.3322],
        [0.6572, 0.3428],
        [0.6616, 0.3384],
        [0.6645, 0.3355],
        [0.6666, 0.3334],
        [0.6667, 0.3333],
        [0.6689, 0.3311],
        [0.6614, 0.3386],
        [0.6731, 0.3269],
        [0.6564, 0.3436],
        [0.6626, 0.3374],
        [0.6684, 0.3316],
        [0.6692, 0.3308],
        [0.6608, 0.3392],
        [0.6646, 0.3354],
        [0.6703, 0.3297],
        [0.6684, 0.3316],
        [0.6678, 0.3322],
        [0.6688, 0.3312],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6706, 0.3294],
        [0.6675, 0.3325],
        [0.6615, 0.3385],
        [0.6663, 0.3337],
        [0.6568, 0.3432],
        [0.6716, 0.3284],
        [0.6619, 0.3381],
        [0.6679, 0.3321],
        [0.6674, 0.3326],
        [0.6602, 0.3398],
        [0.6641, 0.3359],
        [0.6656, 0.3344],
        [0.6687, 0.3313],
        [0.6586, 0.3414],
        [0.6593, 0.3407],
        [0.6635, 0.3365],
        [0.6679, 0.3321],
        [0.6645, 0.3355],
        [0.6583, 0.3417],
        [0.6647, 0.3353],
        [0.6673, 0.3327],
        [0.6694, 0.3306],
        [0.6561, 0.3439],
        [0.6670, 0.3330],
        [0.6622, 0.3378],
        [0.6663, 0.3337],
        [0.6685, 0.3315],
        [0.6733, 0.3267],
        [0.6674, 0.3326],
        [0.6716, 0.3284],
        [0.6670, 0.3330],
        [0.6734, 0.3266],
        [0.6713, 0.3287],
        [0.6594, 0.3406],
        [0.6722, 0.3278],
        [0.6681, 0.3319],
        [0.6631, 0.3369],
        [0.6620, 0.3380],
        [0.6681, 0.3319],
        [0.6685, 0.3315],
        [0.6631, 0.3369],
        [0.6588, 0.3412],
        [0.6619, 0.3381],
        [0.6672, 0.3328],
        [0.6640, 0.3360],
        [0.6649, 0.3351],
        [0.6665, 0.3335],
        [0.6656, 0.3344],
        [0.6630, 0.3370],
        [0.6602, 0.3398],
        [0.6639, 0.3361],
        [0.6706, 0.3294],
        [0.6694, 0.3306],
        [0.6625, 0.3375],
        [0.6682, 0.3318],
        [0.6671, 0.3329],
        [0.6654, 0.3346],
        [0.6660, 0.3340],
        [0.6696, 0.3304],
        [0.6604, 0.3396],
        [0.6586, 0.3414],
        [0.6568, 0.3432],
        [0.6735, 0.3265],
        [0.6706, 0.3294],
        [0.6661, 0.3339],
        [0.6608, 0.3392],
        [0.6564, 0.3436],
        [0.6630, 0.3370],
        [0.6721, 0.3279],
        [0.6666, 0.3334],
        [0.6638, 0.3362],
        [0.6630, 0.3370],
        [0.6653, 0.3347],
        [0.6636, 0.3364],
        [0.6683, 0.3317],
        [0.6569, 0.3431],
        [0.6748, 0.3252],
        [0.6744, 0.3256],
        [0.6624, 0.3376],
        [0.6729, 0.3271],
        [0.6726, 0.3274],
        [0.6595, 0.3405],
        [0.6651, 0.3349],
        [0.6625, 0.3375],
        [0.6734, 0.3266],
        [0.6757, 0.3243],
        [0.6680, 0.3320],
        [0.6695, 0.3305],
        [0.6680, 0.3320],
        [0.6667, 0.3333],
        [0.6682, 0.3318],
        [0.6604, 0.3396],
        [0.6685, 0.3315],
        [0.6649, 0.3351],
        [0.6609, 0.3391],
        [0.6664, 0.3336],
        [0.6676, 0.3324],
        [0.6697, 0.3303],
        [0.6642, 0.3358],
        [0.6698, 0.3302],
        [0.6561, 0.3439],
        [0.6627, 0.3373],
        [0.6732, 0.3268],
        [0.6717, 0.3283],
        [0.6620, 0.3380],
        [0.6662, 0.3338],
        [0.6623, 0.3377],
        [0.6682, 0.3318],
        [0.6598, 0.3402],
        [0.6735, 0.3265],
        [0.6665, 0.3335],
        [0.6656, 0.3344],
        [0.6688, 0.3312],
        [0.6728, 0.3272],
        [0.6669, 0.3331],
        [0.6633, 0.3367],
        [0.6672, 0.3328],
        [0.6616, 0.3384],
        [0.6714, 0.3286],
        [0.6702, 0.3298],
        [0.6639, 0.3361],
        [0.6672, 0.3328],
        [0.6603, 0.3397],
        [0.6652, 0.3348],
        [0.6713, 0.3287],
        [0.6679, 0.3321],
        [0.6641, 0.3359],
        [0.6678, 0.3322],
        [0.6623, 0.3377],
        [0.6701, 0.3299],
        [0.6633, 0.3367],
        [0.6676, 0.3324],
        [0.6649, 0.3351],
        [0.6660, 0.3340],
        [0.6667, 0.3333],
        [0.6681, 0.3319],
        [0.6636, 0.3364],
        [0.6678, 0.3322],
        [0.6684, 0.3316],
        [0.6622, 0.3378],
        [0.6610, 0.3390],
        [0.6687, 0.3313],
        [0.6595, 0.3405],
        [0.6656, 0.3344],
        [0.6750, 0.3250],
        [0.6658, 0.3342],
        [0.6598, 0.3402],
        [0.6686, 0.3314],
        [0.6675, 0.3325],
        [0.6726, 0.3274]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0050 loss: 0.6688 acc_train: 0.6103 time: 0.1301s
tensor([[0.6688, 0.3312],
        [0.6641, 0.3359],
        [0.6709, 0.3291],
        [0.6674, 0.3326],
        [0.6747, 0.3253],
        [0.6615, 0.3385],
        [0.6657, 0.3343],
        [0.6666, 0.3334],
        [0.6632, 0.3368],
        [0.6651, 0.3349],
        [0.6652, 0.3348],
        [0.6704, 0.3296],
        [0.6652, 0.3348],
        [0.6630, 0.3370],
        [0.6679, 0.3321],
        [0.6583, 0.3417],
        [0.6695, 0.3305],
        [0.6677, 0.3323],
        [0.6599, 0.3401],
        [0.6620, 0.3380],
        [0.6664, 0.3336],
        [0.6652, 0.3348],
        [0.6683, 0.3317],
        [0.6707, 0.3293],
        [0.6643, 0.3357],
        [0.6573, 0.3427],
        [0.6605, 0.3395],
        [0.6668, 0.3332],
        [0.6611, 0.3389],
        [0.6596, 0.3404],
        [0.6619, 0.3381],
        [0.6613, 0.3387],
        [0.6692, 0.3308],
        [0.6686, 0.3314],
        [0.6670, 0.3330],
        [0.6600, 0.3400],
        [0.6608, 0.3392],
        [0.6600, 0.3400],
        [0.6675, 0.3325],
        [0.6677, 0.3323],
        [0.6676, 0.3324],
        [0.6615, 0.3385],
        [0.6532, 0.3468],
        [0.6639, 0.3361],
        [0.6695, 0.3305],
        [0.6658, 0.3342],
        [0.6732, 0.3268],
        [0.6698, 0.3302],
        [0.6646, 0.3354],
        [0.6693, 0.3307],
        [0.6675, 0.3325],
        [0.6690, 0.3310],
        [0.6659, 0.3341],
        [0.6636, 0.3364],
        [0.6616, 0.3384],
        [0.6722, 0.3278],
        [0.6635, 0.3365],
        [0.6644, 0.3356],
        [0.6706, 0.3294],
        [0.6645, 0.3355],
        [0.6567, 0.3433],
        [0.6605, 0.3395],
        [0.6706, 0.3294],
        [0.6697, 0.3303],
        [0.6630, 0.3370],
        [0.6625, 0.3375],
        [0.6640, 0.3360],
        [0.6602, 0.3398],
        [0.6630, 0.3370],
        [0.6652, 0.3348],
        [0.6627, 0.3373],
        [0.6682, 0.3318],
        [0.6695, 0.3305],
        [0.6695, 0.3305],
        [0.6622, 0.3378],
        [0.6633, 0.3367],
        [0.6695, 0.3305],
        [0.6666, 0.3334],
        [0.6619, 0.3381],
        [0.6655, 0.3345],
        [0.6658, 0.3342],
        [0.6683, 0.3317],
        [0.6601, 0.3399],
        [0.6659, 0.3341],
        [0.6624, 0.3376],
        [0.6600, 0.3400],
        [0.6640, 0.3360],
        [0.6654, 0.3346],
        [0.6681, 0.3319],
        [0.6663, 0.3337],
        [0.6686, 0.3314],
        [0.6676, 0.3324],
        [0.6695, 0.3305],
        [0.6588, 0.3412],
        [0.6646, 0.3354],
        [0.6725, 0.3275],
        [0.6725, 0.3275],
        [0.6559, 0.3441],
        [0.6734, 0.3266],
        [0.6627, 0.3373],
        [0.6706, 0.3294],
        [0.6676, 0.3324],
        [0.6572, 0.3428],
        [0.6615, 0.3385],
        [0.6642, 0.3358],
        [0.6664, 0.3336],
        [0.6666, 0.3334],
        [0.6685, 0.3315],
        [0.6614, 0.3386],
        [0.6727, 0.3273],
        [0.6564, 0.3436],
        [0.6625, 0.3375],
        [0.6682, 0.3318],
        [0.6689, 0.3311],
        [0.6608, 0.3392],
        [0.6645, 0.3355],
        [0.6701, 0.3299],
        [0.6682, 0.3318],
        [0.6675, 0.3325],
        [0.6686, 0.3314],
        [0.6571, 0.3429],
        [0.6573, 0.3427],
        [0.6703, 0.3297],
        [0.6674, 0.3326],
        [0.6615, 0.3385],
        [0.6662, 0.3338],
        [0.6569, 0.3431],
        [0.6713, 0.3287],
        [0.6619, 0.3381],
        [0.6677, 0.3323],
        [0.6672, 0.3328],
        [0.6601, 0.3399],
        [0.6639, 0.3361],
        [0.6655, 0.3345],
        [0.6685, 0.3315],
        [0.6586, 0.3414],
        [0.6594, 0.3406],
        [0.6634, 0.3366],
        [0.6678, 0.3322],
        [0.6643, 0.3357],
        [0.6583, 0.3417],
        [0.6646, 0.3354],
        [0.6671, 0.3329],
        [0.6692, 0.3308],
        [0.6562, 0.3438],
        [0.6668, 0.3332],
        [0.6621, 0.3379],
        [0.6661, 0.3339],
        [0.6683, 0.3317],
        [0.6729, 0.3271],
        [0.6672, 0.3328],
        [0.6713, 0.3287],
        [0.6668, 0.3332],
        [0.6731, 0.3269],
        [0.6710, 0.3290],
        [0.6594, 0.3406],
        [0.6718, 0.3282],
        [0.6679, 0.3321],
        [0.6631, 0.3369],
        [0.6619, 0.3381],
        [0.6678, 0.3322],
        [0.6682, 0.3318],
        [0.6631, 0.3369],
        [0.6588, 0.3412],
        [0.6619, 0.3381],
        [0.6670, 0.3330],
        [0.6638, 0.3362],
        [0.6648, 0.3352],
        [0.6663, 0.3337],
        [0.6655, 0.3345],
        [0.6629, 0.3371],
        [0.6602, 0.3398],
        [0.6638, 0.3362],
        [0.6704, 0.3296],
        [0.6692, 0.3308],
        [0.6624, 0.3376],
        [0.6679, 0.3321],
        [0.6669, 0.3331],
        [0.6653, 0.3347],
        [0.6658, 0.3342],
        [0.6694, 0.3306],
        [0.6604, 0.3396],
        [0.6585, 0.3415],
        [0.6569, 0.3431],
        [0.6732, 0.3268],
        [0.6703, 0.3297],
        [0.6660, 0.3340],
        [0.6608, 0.3392],
        [0.6565, 0.3435],
        [0.6629, 0.3371],
        [0.6717, 0.3283],
        [0.6664, 0.3336],
        [0.6637, 0.3363],
        [0.6629, 0.3371],
        [0.6652, 0.3348],
        [0.6635, 0.3365],
        [0.6681, 0.3319],
        [0.6570, 0.3430],
        [0.6744, 0.3256],
        [0.6740, 0.3260],
        [0.6624, 0.3376],
        [0.6726, 0.3274],
        [0.6723, 0.3277],
        [0.6596, 0.3404],
        [0.6649, 0.3351],
        [0.6624, 0.3376],
        [0.6731, 0.3269],
        [0.6753, 0.3247],
        [0.6678, 0.3322],
        [0.6693, 0.3307],
        [0.6678, 0.3322],
        [0.6665, 0.3335],
        [0.6680, 0.3320],
        [0.6604, 0.3396],
        [0.6682, 0.3318],
        [0.6648, 0.3352],
        [0.6609, 0.3391],
        [0.6662, 0.3338],
        [0.6673, 0.3327],
        [0.6695, 0.3305],
        [0.6641, 0.3359],
        [0.6695, 0.3305],
        [0.6562, 0.3438],
        [0.6626, 0.3374],
        [0.6728, 0.3272],
        [0.6713, 0.3287],
        [0.6619, 0.3381],
        [0.6661, 0.3339],
        [0.6623, 0.3377],
        [0.6680, 0.3320],
        [0.6597, 0.3403],
        [0.6732, 0.3268],
        [0.6663, 0.3337],
        [0.6654, 0.3346],
        [0.6686, 0.3314],
        [0.6725, 0.3275],
        [0.6668, 0.3332],
        [0.6632, 0.3368],
        [0.6669, 0.3331],
        [0.6616, 0.3384],
        [0.6712, 0.3288],
        [0.6700, 0.3300],
        [0.6638, 0.3362],
        [0.6670, 0.3330],
        [0.6602, 0.3398],
        [0.6650, 0.3350],
        [0.6710, 0.3290],
        [0.6677, 0.3323],
        [0.6639, 0.3361],
        [0.6676, 0.3324],
        [0.6622, 0.3378],
        [0.6698, 0.3302],
        [0.6632, 0.3368],
        [0.6674, 0.3326],
        [0.6647, 0.3353],
        [0.6658, 0.3342],
        [0.6665, 0.3335],
        [0.6679, 0.3321],
        [0.6634, 0.3366],
        [0.6676, 0.3324],
        [0.6682, 0.3318],
        [0.6621, 0.3379],
        [0.6610, 0.3390],
        [0.6685, 0.3315],
        [0.6596, 0.3404],
        [0.6654, 0.3346],
        [0.6746, 0.3254],
        [0.6656, 0.3344],
        [0.6598, 0.3402],
        [0.6684, 0.3316],
        [0.6673, 0.3327],
        [0.6722, 0.3278]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0051 loss: 0.6689 acc_train: 0.6103 time: 0.1199s
[Epoch 50] Loss: 0.66887 Forward: 0.064s Backward: 0.055s Train Accuracy: 61.03 Test Accuracy: 66.18
Training is complete!
(0, tensor(12917, device='cuda:7'))
12917
tensor(indices=tensor([[12917],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  301,   301,   301,  ..., 22447, 22447, 22447],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([4.8810e-05, 1.0460e-04, 2.8626e-04,  ...,
                      1.4401e-04, 4.1898e-04, 2.9264e-06]),
       size=(22540, 50), nnz=2942, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.9335e-05, -2.3724e-06,  5.2691e-06,  ...,
                       5.0245e-06, -2.0110e-05, -2.1811e-06]),
       size=(22540, 50), nnz=21650, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(1, tensor(21950, device='cuda:7'))
21950
tensor(indices=tensor([[21950],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1004,  1004,  1004,  ..., 22400, 22400, 22400],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([1.1159e-04, 1.3210e-04, 6.4430e-04,  ...,
                      4.2100e-05, 2.3577e-04, 6.4941e-06]),
       size=(22540, 50), nnz=3108, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.8296e-05, -2.2449e-06,  4.9859e-06,  ...,
                       4.7544e-06, -1.9029e-05, -2.0639e-06]),
       size=(22540, 50), nnz=21800, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(2, tensor(3144, device='cuda:7'))
3144
tensor(indices=tensor([[3144],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  888,   888,   888,  ..., 22146, 22146, 22146],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([1.0908e-04, 2.0298e-04, 5.9221e-04,  ...,
                      9.1732e-05, 2.9971e-05, 2.0869e-04]),
       size=(22540, 50), nnz=2177, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.1389e-05, -2.6244e-06,  5.8288e-06,  ...,
                       5.5581e-06, -2.2246e-05, -2.4128e-06]),
       size=(22540, 50), nnz=20850, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(3, tensor(20225, device='cuda:7'))
20225
tensor(indices=tensor([[20225],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  169,   169,   169,  ..., 22530, 22530, 22530],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([1.8753e-05, 3.4383e-05, 9.4299e-05,  ...,
                      5.6178e-05, 2.0363e-04, 1.4268e-06]),
       size=(22540, 50), nnz=10991, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.8264e-05, -2.2410e-06,  4.9773e-06,  ...,
                       4.7462e-06, -1.8996e-05, -2.0603e-06]),
       size=(22540, 50), nnz=30700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(4, tensor(7271, device='cuda:7'))
7271
tensor(indices=tensor([[7271],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  406,   406,   406,  ..., 22441, 22441, 22441],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 6.6480e-05,  7.5698e-05,  3.8042e-04,  ...,
                       1.8211e-04,  2.3070e-04, -8.6899e-05]),
       size=(22540, 50), nnz=4525, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.9148e-05, -2.3495e-06,  5.2183e-06,  ...,
                       4.9760e-06, -1.9916e-05, -2.1601e-06]),
       size=(22540, 50), nnz=23650, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(5, tensor(10768, device='cuda:7'))
10768
tensor(indices=tensor([[10768],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  604,   604,   604,  ..., 21768, 21768, 21768],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([1.5239e-04, 3.0270e-04, 8.8971e-04,  ...,
                      1.0583e-04, 4.2059e-05, 1.2225e-04]),
       size=(22540, 50), nnz=1450, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.8949e-05, -2.3250e-06,  5.1638e-06,  ...,
                       4.9241e-06, -1.9708e-05, -2.1375e-06]),
       size=(22540, 50), nnz=19900, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
1
1
(6, tensor(11934, device='cuda:7'))
11934
tensor(indices=tensor([[11934],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1570,  1570,  1570,  ..., 22510, 22510, 22510],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 6.4497e-05,  1.2918e-04,  5.2555e-04,  ...,
                       2.5465e-04,  3.3059e-04, -7.8550e-05]),
       size=(22540, 50), nnz=1980, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.1685e-05, -2.6608e-06,  5.9096e-06,  ...,
                       5.6352e-06, -2.2554e-05, -2.4462e-06]),
       size=(22540, 50), nnz=20550, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(7, tensor(4336, device='cuda:7'))
4336
tensor(indices=tensor([[4336],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   93,    93,    93,  ..., 22478, 22478, 22478],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([1.6572e-04, 1.8786e-04, 8.1233e-04,  ...,
                      2.6275e-04, 9.1508e-04, 8.3574e-06]),
       size=(22540, 50), nnz=2518, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.9551e-05, -2.3989e-06,  5.3280e-06,  ...,
                       5.0806e-06, -2.0335e-05, -2.2055e-06]),
       size=(22540, 50), nnz=21700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(8, tensor(10172, device='cuda:7'))
10172
tensor(indices=tensor([[10172],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  154,   154,   154,  ..., 22502, 22502, 22502],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([8.7248e-05, 1.3259e-04, 5.3841e-04,  ...,
                      6.4982e-05, 2.5539e-04, 6.3565e-06]),
       size=(22540, 50), nnz=3345, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.9430e-05, -2.3841e-06,  5.2951e-06,  ...,
                       5.0493e-06, -2.0209e-05, -2.1919e-06]),
       size=(22540, 50), nnz=21950, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
2
(9, tensor(13510, device='cuda:7'))
13510
tensor(indices=tensor([[13510],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   42,    42,    42,  ..., 22429, 22429, 22429],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([6.2303e-05, 7.6720e-05, 2.7877e-04,  ...,
                      1.3276e-04, 3.2900e-04, 8.3746e-06]),
       size=(22540, 50), nnz=3213, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   42,    42,    42,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 8.1297e-03,  8.5636e-03,  3.2139e-03,  ...,
                       5.0504e-06, -2.0214e-05, -2.1924e-06]),
       size=(22540, 50), nnz=21950, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(10, tensor(19233, device='cuda:7'))
19233
tensor(indices=tensor([[19233],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1667,  1667,  1667,  ..., 21474, 21474, 21474],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1229e-04,  4.5208e-04, -2.8392e-04,  ...,
                       4.8072e-05,  2.1313e-05,  5.7436e-05]),
       size=(22540, 50), nnz=2992, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.8867e-05, -2.3150e-06,  5.1416e-06,  ...,
                       4.9029e-06, -1.9623e-05, -2.1283e-06]),
       size=(22540, 50), nnz=21650, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(11, tensor(19260, device='cuda:7'))
19260
tensor(indices=tensor([[19260],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  112,   112,   112,  ..., 22455, 22455, 22455],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([5.4805e-05, 7.0747e-05, 2.0421e-04,  ...,
                      3.8033e-05, 1.4235e-04, 5.1204e-06]),
       size=(22540, 50), nnz=4243, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.0837e-05, -2.5568e-06,  5.6786e-06,  ...,
                       5.4149e-06, -2.1673e-05, -2.3506e-06]),
       size=(22540, 50), nnz=23450, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(12, tensor(7860, device='cuda:7'))
7860
tensor(indices=tensor([[7860],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  206,   206,   206,  ..., 22444, 22444, 22444],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([6.4465e-05, 7.6769e-05, 2.3965e-04,  ...,
                      7.8363e-05, 3.3164e-04, 3.3690e-06]),
       size=(22540, 50), nnz=4755, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.3350e-05, -2.8650e-06,  6.3633e-06,  ...,
                       6.0678e-06, -2.4286e-05, -2.6340e-06]),
       size=(22540, 50), nnz=23750, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(13, tensor(9637, device='cuda:7'))
9637
tensor(indices=tensor([[9637],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   16,    16,    16,  ..., 22208, 22208, 22208],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([6.6826e-05, 1.0067e-04, 4.8088e-04,  ...,
                      5.7679e-05, 2.3590e-05, 8.6248e-05]),
       size=(22540, 50), nnz=3181, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   16,    16,    16,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.7523e-04,  2.8395e-04, -7.3237e-05,  ...,
                       5.4355e-06, -2.1755e-05, -2.3595e-06]),
       size=(22540, 50), nnz=21950, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
3
2
(14, tensor(7315, device='cuda:7'))
7315
tensor(indices=tensor([[7315],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  135,   135,   135,  ..., 21920, 21920, 21920],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.1863e-04,  5.3194e-04, -4.5765e-04,  ...,
                       8.8228e-05,  3.2423e-05,  2.3163e-04]),
       size=(22540, 50), nnz=2179, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.0286e-05, -2.4891e-06,  5.5283e-06,  ...,
                       5.2716e-06, -2.1099e-05, -2.2884e-06]),
       size=(22540, 50), nnz=21000, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(15, tensor(21185, device='cuda:7'))
21185
tensor(indices=tensor([[21185],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 2547,  2547,  2547,  ..., 22453, 22453, 22453],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([1.4076e-04, 2.2260e-04, 7.1799e-04,  ...,
                      8.8114e-05, 4.7889e-04, 1.2528e-05]),
       size=(22540, 50), nnz=1632, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.1339e-05, -2.6183e-06,  5.8153e-06,  ...,
                       5.5453e-06, -2.2194e-05, -2.4072e-06]),
       size=(22540, 50), nnz=20050, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
4
3
(16, tensor(9704, device='cuda:7'))
9704
tensor(indices=tensor([[9704],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   44,    44,    44,  ..., 21806, 21806, 21806],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([2.2912e-05, 5.8013e-05, 3.2954e-04,  ...,
                      2.9746e-04, 8.9727e-04, 1.3378e-05]),
       size=(22540, 50), nnz=2279, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   44,    44,    44,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-8.1778e-04, -1.1019e-03, -7.0776e-05,  ...,
                       5.4684e-06, -2.1887e-05, -2.3738e-06]),
       size=(22540, 50), nnz=21000, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(17, tensor(15542, device='cuda:7'))
15542
tensor(indices=tensor([[15542],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1508,  1508,  1508,  ..., 22413, 22413, 22413],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.1355e-04,  7.2465e-04, -4.6932e-04,  ...,
                       1.8728e-04,  7.9415e-05,  8.3262e-05]),
       size=(22540, 50), nnz=1256, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.2278e-05, -2.7336e-06,  6.0713e-06,  ...,
                       5.7894e-06, -2.3171e-05, -2.5131e-06]),
       size=(22540, 50), nnz=19650, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
5
4
(18, tensor(1543, device='cuda:7'))
1543
tensor(indices=tensor([[1543],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  170,   170,   170,  ..., 22535, 22535, 22535],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([7.8898e-05, 7.5555e-05, 4.3979e-04,  ...,
                      1.6734e-04, 5.1750e-04, 8.8597e-06]),
       size=(22540, 50), nnz=3502, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22535, 22535, 22535],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.1369e-05, -2.6220e-06,  5.8236e-06,  ...,
                       1.9145e-04,  5.2026e-04, -1.1522e-04]),
       size=(22540, 50), nnz=22300, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(19, tensor(9956, device='cuda:7'))
9956
tensor(indices=tensor([[9956],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   77,    77,    77,  ..., 22356, 22356, 22356],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([1.5808e-04, 2.4649e-04, 6.5015e-04,  ...,
                      2.4869e-04, 6.0967e-04, 1.8855e-05]),
       size=(22540, 50), nnz=1989, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.0541e-05, -2.5204e-06,  5.5978e-06,  ...,
                       5.3379e-06, -2.1364e-05, -2.3172e-06]),
       size=(22540, 50), nnz=20800, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(20, tensor(19946, device='cuda:7'))
19946
tensor(indices=tensor([[19946],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  104,   104,   104,  ..., 21864, 21864, 21864],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([3.4971e-05, 4.2462e-05, 2.2101e-04,  ...,
                      4.8152e-05, 1.7052e-05, 1.3182e-04]),
       size=(22540, 50), nnz=3742, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.8355e-05, -2.2522e-06,  5.0021e-06,  ...,
                       4.7698e-06, -1.9091e-05, -2.0706e-06]),
       size=(22540, 50), nnz=22700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(21, tensor(2144, device='cuda:7'))
2144
tensor(indices=tensor([[2144],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   29,    29,    29,  ..., 22515, 22515, 22515],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([1.0203e-04, 1.0866e-04, 3.4728e-04,  ...,
                      6.0307e-05, 2.3191e-05, 4.5864e-05]),
       size=(22540, 50), nnz=3064, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   29,    29,    29,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.0768e-04,  2.9073e-07, -2.9246e-03,  ...,
                       5.5092e-06, -2.2050e-05, -2.3915e-06]),
       size=(22540, 50), nnz=22050, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(22, tensor(17777, device='cuda:7'))
17777
tensor(indices=tensor([[17777],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  977,   977,   977,  ..., 21095, 21095, 21095],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([2.0322e-04, 2.4259e-04, 1.1563e-03,  ...,
                      2.2796e-04, 8.3910e-04, 2.0802e-05]),
       size=(22540, 50), nnz=1631, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.3278e-05, -2.8563e-06,  6.3438e-06,  ...,
                       6.0493e-06, -2.4211e-05, -2.6259e-06]),
       size=(22540, 50), nnz=20250, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(23, tensor(13745, device='cuda:7'))
13745
tensor(indices=tensor([[13745],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  839,   839,   839,  ..., 22233, 22233, 22233],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.4729e-04,  1.4017e-03, -7.9717e-04,  ...,
                       2.0894e-04,  7.7056e-04,  7.4001e-07]),
       size=(22540, 50), nnz=1647, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.8832e-05, -2.3107e-06,  5.1321e-06,  ...,
                       4.8939e-06, -1.9587e-05, -2.1244e-06]),
       size=(22540, 50), nnz=20250, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
6
(24, tensor(5234, device='cuda:7'))
5234
tensor(indices=tensor([[5234],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  397,   397,   397,  ..., 22290, 22290, 22290],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([4.0826e-05, 1.3910e-04, 5.1261e-04,  ...,
                      9.2607e-05, 3.1360e-05, 1.5935e-04]),
       size=(22540, 50), nnz=2066, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.1921e-05, -2.6897e-06,  5.9737e-06,  ...,
                       5.6964e-06, -2.2799e-05, -2.4728e-06]),
       size=(22540, 50), nnz=20950, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(25, tensor(20943, device='cuda:7'))
20943
tensor(indices=tensor([[20943],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   10,    10,    10,  ..., 22483, 22483, 22483],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([1.3309e-05, 2.1783e-05, 5.9857e-05,  ...,
                      1.0469e-05, 4.0877e-06, 1.1414e-05]),
       size=(22540, 50), nnz=16184, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   10,    10,    10,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.0520e-04, -1.7992e-05,  1.0538e-04,  ...,
                       5.2386e-06, -2.0967e-05, -2.2741e-06]),
       size=(22540, 50), nnz=35150, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(26, tensor(3410, device='cuda:7'))
3410
tensor(indices=tensor([[3410],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  160,   160,   160,  ..., 22330, 22330, 22330],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([1.1330e-04, 1.6500e-04, 4.9540e-04,  ...,
                      3.6782e-04, 1.0289e-03, 2.2424e-05]),
       size=(22540, 50), nnz=1878, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.1808e-05, -2.6758e-06,  5.9430e-06,  ...,
                       5.6671e-06, -2.2682e-05, -2.4600e-06]),
       size=(22540, 50), nnz=20500, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
7
5
(27, tensor(5643, device='cuda:7'))
5643
tensor(indices=tensor([[5643],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  577,   577,   577,  ..., 22279, 22279, 22279],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 9.2957e-05,  2.2195e-04, -2.3527e-04,  ...,
                       9.7280e-05,  3.0776e-04,  4.5023e-06]),
       size=(22540, 50), nnz=5412, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.1255e-05, -2.6080e-06,  5.7923e-06,  ...,
                       5.5234e-06, -2.2107e-05, -2.3977e-06]),
       size=(22540, 50), nnz=24600, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(28, tensor(211, device='cuda:7'))
211
tensor(indices=tensor([[211],
                       [  0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  211,   211,   211,  ..., 22270, 22270, 22270],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-0.0005,  0.0071,  0.0020,  ...,  0.0015,  0.0017,
                      -0.0003]),
       size=(22540, 50), nnz=1351, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.0412e-05, -2.5046e-06,  5.5627e-06,  ...,
                       5.3045e-06, -2.1231e-05, -2.3026e-06]),
       size=(22540, 50), nnz=19700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(29, tensor(3969, device='cuda:7'))
3969
tensor(indices=tensor([[3969],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1274,  1274,  1274,  ..., 21527, 21527, 21527],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([9.6581e-05, 1.5780e-04, 4.4391e-04,  ...,
                      6.7291e-05, 2.3163e-05, 1.4455e-04]),
       size=(22540, 50), nnz=2820, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.0401e-05, -2.5031e-06,  5.5595e-06,  ...,
                       5.3014e-06, -2.1218e-05, -2.3013e-06]),
       size=(22540, 50), nnz=21500, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(30, tensor(11213, device='cuda:7'))
11213
tensor(indices=tensor([[11213],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[    1,     1,     1,  ..., 22191, 22191, 22191],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([4.3617e-05, 7.1779e-05, 3.0752e-04,  ...,
                      9.8058e-05, 2.7203e-04, 2.9861e-06]),
       size=(22540, 50), nnz=4625, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[    1,     1,     1,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.6867e-03, -4.7628e-04,  6.1721e-04,  ...,
                       4.6463e-06, -1.8596e-05, -2.0169e-06]),
       size=(22540, 50), nnz=23550, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([ 0.0000, -0.0027,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
       grad_fn=<SumBackward1>)
(31, tensor(10620, device='cuda:7'))
10620
tensor(indices=tensor([[10620],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   20,    20,    20,  ..., 22527, 22527, 22527],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([8.7320e-05, 1.1416e-04, 4.9076e-04,  ...,
                      6.8144e-05, 2.3677e-05, 1.3388e-04]),
       size=(22540, 50), nnz=3011, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   20,    20,    20,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 7.5012e-04, -2.6620e-04, -4.2432e-04,  ...,
                       5.0944e-06, -2.0390e-05, -2.2114e-06]),
       size=(22540, 50), nnz=22000, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(32, tensor(11150, device='cuda:7'))
11150
tensor(indices=tensor([[11150],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  410,   410,   410,  ..., 22484, 22484, 22484],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 6.8683e-05,  1.2448e-04,  4.3772e-04,  ...,
                       1.6660e-04,  3.2425e-04, -1.2709e-04]),
       size=(22540, 50), nnz=2137, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.8110e-05, -2.2221e-06,  4.9353e-06,  ...,
                       4.7061e-06, -1.8836e-05, -2.0429e-06]),
       size=(22540, 50), nnz=20950, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(33, tensor(10248, device='cuda:7'))
10248
tensor(indices=tensor([[10248],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1484,  1484,  1484,  ..., 22397, 22397, 22397],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([2.1658e-04, 2.9963e-04, 8.9267e-04,  ...,
                      2.1025e-04, 9.1737e-04, 1.9547e-05]),
       size=(22540, 50), nnz=1165, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.0267e-05, -2.4868e-06,  5.5232e-06,  ...,
                       5.2668e-06, -2.1080e-05, -2.2863e-06]),
       size=(22540, 50), nnz=19650, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(34, tensor(19890, device='cuda:7'))
19890
tensor(indices=tensor([[19890],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   23,    23,    23,  ..., 22079, 22079, 22079],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([1.5905e-04, 1.8668e-04, 6.0854e-04,  ...,
                      1.1473e-04, 4.4221e-05, 3.4177e-04]),
       size=(22540, 50), nnz=1498, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   23,    23,    23,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-5.5117e-04, -1.4942e-03, -1.1784e-03,  ...,
                       5.0430e-06, -2.0184e-05, -2.1891e-06]),
       size=(22540, 50), nnz=20000, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(35, tensor(18276, device='cuda:7'))
18276
tensor(indices=tensor([[18276],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1296,  1296,  1296,  ..., 22095, 22095, 22095],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([1.3406e-04, 2.5541e-04, 9.7486e-04,  ...,
                      7.6050e-05, 6.8008e-04, 2.5552e-05]),
       size=(22540, 50), nnz=1555, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.0915e-05, -2.5663e-06,  5.6998e-06,  ...,
                       5.4352e-06, -2.1754e-05, -2.3594e-06]),
       size=(22540, 50), nnz=20200, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(36, tensor(1166, device='cuda:7'))
1166
tensor(indices=tensor([[1166],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  593,   593,   593,  ..., 20686, 20686, 20686],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([1.6152e-04, 1.9083e-04, 8.7916e-04,  ...,
                      8.7210e-05, 3.2319e-04, 1.3180e-05]),
       size=(22540, 50), nnz=2283, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.8625e-05, -2.2853e-06,  5.0756e-06,  ...,
                       4.8400e-06, -1.9372e-05, -2.1010e-06]),
       size=(22540, 50), nnz=21000, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
8
6
(37, tensor(10336, device='cuda:7'))
10336
tensor(indices=tensor([[10336],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  201,   201,   201,  ..., 22311, 22311, 22311],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([8.9731e-05, 1.2571e-04, 5.6342e-04,  ...,
                      6.3868e-05, 2.6559e-04, 9.5952e-06]),
       size=(22540, 50), nnz=3353, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.9287e-05, -2.3665e-06,  5.2561e-06,  ...,
                       5.0120e-06, -2.0060e-05, -2.1757e-06]),
       size=(22540, 50), nnz=22050, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(38, tensor(4256, device='cuda:7'))
4256
tensor(indices=tensor([[4256],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  486,   486,   486,  ..., 20095, 20095, 20095],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([1.3255e-04, 2.1160e-04, 6.2099e-04,  ...,
                      3.0797e-04, 1.0345e-03, 1.1900e-05]),
       size=(22540, 50), nnz=2137, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.8464e-05, -2.2655e-06,  5.0317e-06,  ...,
                       4.7981e-06, -1.9204e-05, -2.0828e-06]),
       size=(22540, 50), nnz=21100, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
9
(39, tensor(963, device='cuda:7'))
963
tensor(indices=tensor([[963],
                       [  0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  347,   347,   347,  ..., 21723, 21723, 21723],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 6.7378e-05,  1.0711e-04,  5.6448e-04,  ...,
                       5.5211e-04,  7.2956e-04, -2.0831e-04]),
       size=(22540, 50), nnz=1400, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.0752e-05, -2.5463e-06,  5.6553e-06,  ...,
                       5.3927e-06, -2.1584e-05, -2.3410e-06]),
       size=(22540, 50), nnz=19850, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(40, tensor(4369, device='cuda:7'))
4369
tensor(indices=tensor([[4369],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  517,   517,   517,  ..., 22472, 22472, 22472],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([5.7147e-05, 1.0897e-04, 2.9335e-04,  ...,
                      1.4874e-04, 4.0968e-04, 1.0817e-05]),
       size=(22540, 50), nnz=3445, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.9732e-05, -2.4211e-06,  5.3773e-06,  ...,
                       5.1276e-06, -2.0523e-05, -2.2259e-06]),
       size=(22540, 50), nnz=22650, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(41, tensor(6785, device='cuda:7'))
6785
tensor(indices=tensor([[6785],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1074,  1074,  1074,  ..., 22522, 22522, 22522],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([8.5149e-05, 9.5508e-05, 4.2075e-04,  ...,
                      1.4912e-04, 4.7126e-04, 7.7064e-06]),
       size=(22540, 50), nnz=3970, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.3036e-05, -2.8265e-06,  6.2777e-06,  ...,
                       5.9862e-06, -2.3959e-05, -2.5986e-06]),
       size=(22540, 50), nnz=23050, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(42, tensor(2579, device='cuda:7'))
2579
tensor(indices=tensor([[2579],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  278,   278,   278,  ..., 21657, 21657, 21657],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([8.9871e-05, 1.4925e-04, 3.7973e-04,  ...,
                      1.1200e-04, 5.2896e-04, 1.3530e-05]),
       size=(22540, 50), nnz=2962, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.1569e-05, -2.6466e-06,  5.8780e-06,  ...,
                       5.6051e-06, -2.2434e-05, -2.4332e-06]),
       size=(22540, 50), nnz=21700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(43, tensor(17531, device='cuda:7'))
17531
tensor(indices=tensor([[17531],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   91,    91,    91,  ..., 22300, 22300, 22300],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([2.7272e-05, 4.4804e-05, 2.0264e-04,  ...,
                      1.2611e-04, 3.5179e-04, 4.1802e-06]),
       size=(22540, 50), nnz=4855, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.1215e-05, -2.6030e-06,  5.7814e-06,  ...,
                       5.5129e-06, -2.2065e-05, -2.3931e-06]),
       size=(22540, 50), nnz=24200, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(44, tensor(541, device='cuda:7'))
541
tensor(indices=tensor([[541],
                       [  0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  541,   541,   541,  ..., 21195, 21195, 21195],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-0.0005,  0.0079,  0.0022,  ...,  0.0005,  0.0005,
                      -0.0001]),
       size=(22540, 50), nnz=1486, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.2159e-05, -2.7189e-06,  6.0387e-06,  ...,
                       5.7583e-06, -2.3047e-05, -2.4997e-06]),
       size=(22540, 50), nnz=20000, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(45, tensor(13333, device='cuda:7'))
13333
tensor(indices=tensor([[13333],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  222,   222,   222,  ..., 22334, 22334, 22334],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([4.7961e-05, 8.0686e-05, 2.6733e-04,  ...,
                      1.9012e-04, 5.4650e-04, 9.0710e-06]),
       size=(22540, 50), nnz=3661, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.9786e-05, -2.4278e-06,  5.3921e-06,  ...,
                       5.1417e-06, -2.0579e-05, -2.2320e-06]),
       size=(22540, 50), nnz=22550, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(46, tensor(19769, device='cuda:7'))
19769
tensor(indices=tensor([[19769],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  848,   848,   848,   848,   848,   848,   848,   848,
                          848,   848,   848,   848,   848,   848,   848,   848,
                          848,   848,   848,   848,   848,   848,   848,   848,
                          848,   848,   848,   848,   848,   848,   848,   848,
                          848,   848,   848,   848,   848,   848,   848,   848,
                          848,   848,   848,   848,   848,   848,   848,   848,
                         3369,  3369,  3369,  3369,  3369,  3369,  3369,  3369,
                         3369,  3369,  3369,  3369,  3369,  3369,  3369,  3369,
                         3369,  3369,  3369,  3369,  3369,  3369,  3369,  3369,
                         3369,  3369,  3369,  3369,  3369,  3369,  3369,  3369,
                         3369,  3369,  3369,  3369,  3369,  3369,  3369,  3369,
                         3369,  3369,  3369,  3369,  3369,  3369,  3369,  3369,
                         3369,  4374,  4374,  4374,  4374,  4374,  4374,  4374,
                         4374,  4374,  4374,  4374,  4374,  4374,  4374,  4374,
                         4374,  4374,  4374,  4374,  4374,  4374,  4374,  4374,
                         4374,  4374,  4374,  4374,  4374,  4374,  4374,  4374,
                         4374,  4374,  4374,  4374,  4374,  4374,  4374,  4374,
                         4374,  4374,  4374,  4374,  4374,  4374,  4374,  4374,
                         4374,  4374, 13556, 13556, 13556, 13556, 13556, 13556,
                        13556, 13556, 13556, 13556, 13556, 13556, 13556, 13556,
                        13556, 13556, 13556, 13556, 13556, 13556, 13556, 13556,
                        13556, 13556, 13556, 13556, 13556, 13556, 13556, 13556,
                        13556, 13556, 13556, 13556, 13556, 13556, 13556, 13556,
                        13556, 13556, 13556, 13556, 13556, 13556, 13556, 13556,
                        13556, 13556, 15665, 15665, 15665, 15665, 15665, 15665,
                        15665, 15665, 15665, 15665, 15665, 15665, 15665, 15665,
                        15665, 15665, 15665, 15665, 15665, 15665, 15665, 15665,
                        15665, 15665, 15665, 15665, 15665, 15665, 15665, 15665,
                        15665, 15665, 15665, 15665, 15665, 15665, 15665, 15665,
                        15665, 15665, 15665, 15665, 15665, 15665, 15665, 15665,
                        15665, 17492, 17492, 17492, 17492, 17492, 17492, 17492,
                        17492, 17492, 17492, 17492, 17492, 17492, 17492, 17492,
                        17492, 17492, 17492, 17492, 17492, 17492, 17492, 17492,
                        17492, 17492, 17492, 17492, 17492, 17492, 17492, 17492,
                        17492, 17492, 17492, 17492, 17492, 17492, 17492, 17492,
                        17492, 17492, 17492, 17492, 17492, 17492, 17492, 17492,
                        17492, 17492, 19769, 19769, 19769, 19769, 19769, 19769,
                        19769, 19769, 19769, 19769, 19769, 19769, 19769, 19769,
                        19769, 19769, 19769, 19769, 19769, 19769, 19769, 19769,
                        19769, 19769, 19769, 19769, 19769, 19769, 19769, 19769,
                        19769, 19769, 19769, 19769, 19769, 19769, 19769, 19769,
                        19769, 19769, 19769, 19769, 19769, 19769, 19769, 19769,
                        19769, 19769, 20523, 20523, 20523, 20523, 20523, 20523,
                        20523, 20523, 20523, 20523, 20523, 20523, 20523, 20523,
                        20523, 20523, 20523, 20523, 20523, 20523, 20523, 20523,
                        20523, 20523, 20523, 20523, 20523, 20523, 20523, 20523,
                        20523, 20523, 20523, 20523, 20523, 20523, 20523, 20523,
                        20523, 20523, 20523, 20523, 20523, 20523, 20523, 20523,
                        20523, 20523, 21110, 21110, 21110, 21110, 21110, 21110,
                        21110, 21110, 21110, 21110, 21110, 21110, 21110, 21110,
                        21110, 21110, 21110, 21110, 21110, 21110, 21110, 21110,
                        21110, 21110, 21110, 21110, 21110, 21110, 21110, 21110,
                        21110, 21110, 21110, 21110, 21110, 21110, 21110, 21110,
                        21110, 21110, 21110, 21110, 21110, 21110, 21110, 21110,
                        21110, 21110, 21110],
                       [    0,     1,     2,     3,     4,     5,     6,     7,
                            8,     9,    10,    11,    12,    13,    14,    15,
                           16,    17,    18,    19,    20,    21,    22,    23,
                           24,    25,    26,    27,    28,    30,    31,    32,
                           33,    34,    35,    36,    37,    39,    40,    41,
                           42,    43,    44,    45,    46,    47,    48,    49,
                            0,     1,     2,     3,     4,     5,     6,     7,
                            8,     9,    10,    11,    12,    13,    14,    15,
                           16,    17,    18,    19,    20,    21,    22,    23,
                           24,    25,    26,    27,    28,    30,    31,    32,
                           33,    34,    35,    36,    37,    38,    39,    40,
                           41,    42,    43,    44,    45,    46,    47,    48,
                           49,     0,     1,     2,     3,     4,     5,     6,
                            7,     8,     9,    10,    11,    12,    13,    14,
                           15,    16,    17,    18,    19,    20,    21,    22,
                           23,    24,    25,    26,    27,    28,    30,    31,
                           32,    33,    34,    35,    36,    37,    38,    39,
                           40,    41,    42,    43,    44,    45,    46,    47,
                           48,    49,     0,     1,     2,     3,     4,     5,
                            6,     7,     8,     9,    10,    11,    12,    13,
                           14,    15,    16,    17,    18,    19,    20,    21,
                           22,    23,    24,    25,    26,    27,    28,    30,
                           31,    32,    33,    34,    35,    36,    37,    39,
                           40,    41,    42,    43,    44,    45,    46,    47,
                           48,    49,     0,     1,     2,     3,     4,     5,
                            6,     7,     8,     9,    10,    11,    12,    13,
                           14,    15,    16,    17,    18,    19,    20,    21,
                           22,    23,    24,    26,    27,    28,    30,    31,
                           32,    33,    34,    35,    36,    37,    38,    39,
                           40,    41,    42,    43,    44,    45,    47,    48,
                           49,     0,     1,     2,     3,     4,     5,     6,
                            7,     8,     9,    10,    11,    12,    13,    14,
                           15,    16,    17,    18,    19,    20,    21,    22,
                           23,    24,    25,    26,    27,    28,    30,    31,
                           32,    33,    34,    35,    36,    37,    38,    39,
                           40,    41,    42,    43,    44,    45,    46,    47,
                           48,    49,     0,     1,     2,     3,     4,     5,
                            6,     7,     8,     9,    10,    11,    12,    13,
                           14,    15,    16,    17,    18,    19,    20,    21,
                           22,    23,    24,    25,    26,    27,    28,    30,
                           31,    32,    33,    34,    35,    36,    37,    39,
                           40,    41,    42,    43,    44,    45,    46,    47,
                           48,    49,     0,     1,     2,     3,     4,     5,
                            6,     7,     8,     9,    10,    11,    12,    13,
                           14,    15,    16,    17,    18,    19,    20,    21,
                           22,    23,    24,    25,    26,    27,    28,    30,
                           31,    32,    33,    34,    35,    36,    37,    38,
                           39,    40,    41,    42,    44,    45,    46,    47,
                           48,    49,     0,     1,     2,     3,     4,     5,
                            6,     7,     8,     9,    10,    11,    12,    13,
                           14,    15,    16,    17,    18,    19,    20,    21,
                           22,    23,    24,    25,    26,    27,    28,    30,
                           31,    32,    33,    34,    35,    36,    37,    38,
                           39,    40,    41,    42,    43,    44,    45,    46,
                           47,    48,    49]]),
       values=tensor([ 4.2755e-04,  6.9517e-04,  2.7539e-03,  4.3365e-04,
                      -1.1564e-05,  2.5262e-03,  3.3889e-04,  3.8820e-03,
                       2.5318e-03,  1.0747e-03,  3.7372e-04,  2.5908e-03,
                       5.9710e-04,  1.8309e-03,  3.1732e-05,  2.8418e-03,
                       5.1408e-04,  1.9336e-03,  1.0103e-02,  1.7207e-03,
                       3.0742e-05,  1.1257e-03,  1.2018e-03,  1.7009e-03,
                       8.3164e-05,  7.7422e-05,  1.0990e-04,  1.2694e-03,
                       1.1510e-03,  3.5330e-03,  7.6437e-04,  6.6033e-04,
                       1.2040e-03, -1.0570e-04,  1.4808e-03,  3.2362e-04,
                       9.4389e-05,  9.5242e-04,  2.7223e-03,  1.7052e-03,
                       1.6581e-03, -6.5128e-06,  4.3461e-04,  6.6566e-04,
                       5.1553e-05,  8.9380e-04,  2.7952e-03,  4.4823e-05,
                       5.4267e-04,  5.1530e-04,  2.9128e-03,  2.9299e-04,
                      -2.6695e-05,  2.2498e-03,  3.9072e-04,  3.5595e-03,
                       2.5347e-03,  1.0385e-03,  2.7944e-04,  2.2655e-03,
                       4.9758e-04,  1.3371e-03,  7.3433e-06,  2.5409e-03,
                       4.6350e-04,  1.4951e-03,  8.8439e-03,  1.5898e-03,
                       1.7967e-05,  7.2480e-04,  7.4214e-04,  1.4858e-03,
                       1.1696e-04,  8.5229e-05,  8.9678e-05,  1.1669e-03,
                       1.2611e-03,  2.8957e-03,  5.7563e-04,  6.2737e-04,
                       1.2071e-03, -3.5411e-05,  1.1783e-03,  2.0583e-04,
                       7.1807e-05, -3.4710e-05,  9.4964e-04,  2.5967e-03,
                       1.2820e-03,  1.3625e-03, -1.2022e-05,  4.3244e-04,
                       3.3379e-04,  3.7363e-05,  7.5759e-04,  2.3220e-03,
                       6.9916e-05,  3.0110e-04,  1.0166e-03,  2.2115e-03,
                       6.5829e-04,  9.5193e-04,  2.3599e-03,  3.5496e-04,
                       7.1582e-03,  3.2572e-03,  6.8029e-04,  2.7760e-03,
                       7.7139e-03, -1.7663e-04,  3.2102e-03, -2.5223e-04,
                       2.3355e-03,  1.4406e-04,  3.0782e-03,  4.5773e-03,
                       1.5937e-03,  4.4275e-04, -2.6355e-04, -8.5728e-04,
                       1.7723e-03,  1.4540e-06, -4.0950e-05,  1.1492e-03,
                       2.4508e-03,  4.1048e-04, -1.0830e-04,  2.0033e-03,
                       7.6134e-05,  1.3372e-03, -5.2751e-04,  2.6831e-03,
                       9.9857e-04, -2.9537e-04,  2.8929e-05,  3.5130e-03,
                       1.9641e-03,  3.2689e-03,  4.4955e-03, -3.0574e-05,
                       9.8369e-04, -1.1039e-04,  1.8272e-04,  1.9355e-04,
                       1.0535e-04,  1.5796e-03,  7.6190e-04,  1.4369e-03,
                       3.5356e-03,  5.5941e-04,  1.1609e-03,  3.5298e-03,
                       3.7920e-04,  9.9199e-03,  4.6397e-03,  1.2259e-03,
                       3.5866e-03,  9.7304e-03, -4.5486e-04,  3.2899e-03,
                      -3.4746e-04,  3.1865e-03,  2.1367e-04,  4.0185e-03,
                       7.7967e-03,  2.1677e-03,  4.9415e-04, -7.5465e-04,
                      -1.2991e-03,  2.7367e-03,  8.4660e-06, -1.3805e-04,
                       1.0533e-03,  3.1938e-03,  9.4761e-04, -1.7173e-04,
                       2.4300e-03,  1.0257e-04,  1.9772e-03, -8.4536e-04,
                       3.6447e-03,  2.1342e-03, -5.5583e-04,  4.7485e-03,
                       3.0973e-03,  5.3223e-03,  5.8290e-03, -6.8541e-06,
                       1.2230e-03, -1.3881e-04,  1.6081e-04,  6.5489e-04,
                       2.6573e-04,  8.9996e-04,  2.7053e-03, -4.4250e-03,
                       2.0007e-02, -1.1815e-03,  2.9762e-03,  4.2761e-03,
                       1.3629e-03,  1.8255e-02,  9.8603e-04,  3.6248e-03,
                       2.3082e-03,  9.5070e-03,  1.5461e-03,  3.1034e-03,
                       2.5814e-04,  8.2406e-03,  4.1870e-04,  1.4027e-02,
                       1.8482e-02,  7.0271e-03,  5.2239e-03,  1.1714e-02,
                       5.5151e-03,  6.8484e-03, -1.3134e-04,  6.1937e-03,
                      -1.0010e-03, -2.2509e-03,  6.2200e-03,  2.2851e-02,
                      -3.9296e-04,  1.5190e-03,  1.1510e-02,  3.2842e-02,
                       1.3118e-03,  9.0956e-03, -8.3238e-06, -2.2155e-04,
                      -1.4528e-03,  2.0431e-02,  1.9463e-02,  9.3324e-04,
                       3.4819e-03,  1.3865e-03,  7.4612e-03,  4.0543e-03,
                       4.1034e-05,  6.1542e-04,  1.1074e-03,  2.8450e-03,
                       4.8482e-04,  1.0445e-03,  3.1147e-03,  2.6408e-04,
                       7.4507e-03,  3.5340e-03,  9.3512e-04,  3.1709e-03,
                       8.4558e-03, -3.4651e-04,  3.1931e-03, -1.5973e-04,
                       2.7679e-03,  1.7414e-04,  3.5068e-03,  5.9737e-03,
                       1.7867e-03,  4.1080e-04, -5.4350e-04, -1.2519e-03,
                       2.1528e-03,  4.3406e-06, -1.3001e-04,  9.2773e-04,
                       2.9041e-03,  7.6790e-04, -1.3788e-04,  2.1802e-03,
                       4.5855e-05,  1.6362e-03, -7.4893e-04,  3.1266e-03,
                       1.6071e-03, -4.4651e-04,  1.1773e-05,  4.2642e-03,
                       2.3477e-03,  4.2982e-03,  5.0721e-03, -2.0014e-05,
                       8.2848e-04, -1.5162e-04,  1.5770e-04,  4.8094e-04,
                       1.8003e-04,  7.3706e-04, -2.8509e-04,  9.1769e-03,
                       2.1178e-03,  9.2234e-03,  4.4115e-04,  1.8459e-03,
                      -3.2882e-06,  1.2089e-02,  8.4204e-04,  1.9193e-03,
                       8.0378e-03,  1.7287e-02,  5.9134e-04,  1.1195e-02,
                       1.8578e-03,  8.9000e-03,  7.5328e-03,  1.4270e-02,
                       7.7940e-03,  3.0981e-03,  1.7412e-03,  1.4901e-03,
                       6.5548e-03,  3.6311e-03, -5.1372e-06, -3.7620e-05,
                       3.5374e-03,  1.9239e-03, -5.5237e-04,  7.2899e-03,
                       9.1395e-03,  1.1666e-03,  6.2300e-04,  3.9649e-03,
                       2.4120e-02,  1.7547e-04,  4.2970e-04,  1.8048e-03,
                       2.7918e-03,  3.0277e-03,  1.2647e-02,  2.3624e-04,
                      -5.0925e-05,  8.8259e-03,  2.9713e-05,  8.1037e-04,
                      -4.9355e-05,  1.7632e-03,  4.4799e-04,  6.7501e-04,
                       2.9242e-03,  3.9821e-04, -3.4817e-05,  2.4362e-03,
                       3.5416e-04,  3.8242e-03,  2.5184e-03,  1.1283e-03,
                       3.4116e-04,  2.6151e-03,  5.4576e-04,  1.7549e-03,
                       2.2374e-05,  2.8541e-03,  5.3616e-04,  1.8935e-03,
                       9.5489e-03,  1.7054e-03,  2.8245e-05,  9.7483e-04,
                       9.4387e-04,  1.7337e-03,  1.3088e-04,  1.1267e-04,
                       1.0438e-04,  1.3803e-03,  1.2826e-03,  3.4941e-03,
                       7.5547e-04,  6.5072e-04,  1.2947e-03, -1.1734e-04,
                       1.4416e-03,  3.5248e-04,  5.3755e-05, -4.8254e-05,
                       1.0600e-03,  2.6862e-03,  1.5473e-03,  1.7793e-03,
                       5.4410e-04,  5.7645e-04,  3.6428e-05,  7.6718e-04,
                       3.1568e-03,  5.7578e-05,  4.4756e-04,  7.6835e-04,
                       3.2265e-03,  4.8417e-04, -3.7110e-05,  2.6850e-03,
                       3.2446e-04,  3.8719e-03,  2.5786e-03,  1.2355e-03,
                       3.6570e-04,  3.0553e-03,  5.3817e-04,  1.9443e-03,
                       3.6374e-05,  3.1508e-03,  6.0312e-04,  2.1045e-03,
                       1.0124e-02,  1.7805e-03,  2.6774e-05,  1.1052e-03,
                       1.0356e-03,  1.7839e-03,  7.1875e-05,  8.7841e-05,
                       1.1165e-04,  1.3668e-03,  1.1535e-03,  3.7676e-03,
                       8.9157e-04,  6.5576e-04,  1.2654e-03, -1.2608e-04,
                       1.5940e-03,  2.9719e-04,  8.0033e-05, -1.6768e-05,
                       1.1019e-03,  2.7994e-03,  1.5295e-03,  1.8350e-03,
                      -6.7783e-06,  4.9716e-04,  6.8557e-04,  6.4277e-05,
                       7.5717e-04,  2.8644e-03,  6.6680e-05]),
       size=(22540, 50), nnz=435, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.0211e-05, -2.4799e-06,  5.5079e-06,  ...,
                       5.2521e-06, -2.1021e-05, -2.2799e-06]),
       size=(22540, 50), nnz=18750, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(47, tensor(16980, device='cuda:7'))
16980
tensor(indices=tensor([[16980],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   73,    73,    73,  ..., 22209, 22209, 22209],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.3247e-04,  2.8777e-04, -2.6882e-04,  ...,
                       5.1351e-05,  1.6305e-04,  6.4030e-06]),
       size=(22540, 50), nnz=3301, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.9195e-05, -2.3553e-06,  5.2310e-06,  ...,
                       4.9881e-06, -1.9965e-05, -2.1653e-06]),
       size=(22540, 50), nnz=22550, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(48, tensor(14021, device='cuda:7'))
14021
tensor(indices=tensor([[14021],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  370,   370,   370,  ..., 22418, 22418, 22418],
                       [    0,     1,     2,  ...,    46,    47,    48]]),
       values=tensor([1.2354e-05, 2.8773e-05, 8.1784e-05,  ...,
                      2.6557e-06, 1.4758e-05, 5.8312e-06]),
       size=(22540, 50), nnz=10556, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.3450e-05, -2.8773e-06,  6.3905e-06,  ...,
                       6.0938e-06, -2.4390e-05, -2.6453e-06]),
       size=(22540, 50), nnz=30250, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(49, tensor(9082, device='cuda:7'))
9082
tensor(indices=tensor([[9082],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   94,    94,    94,  ..., 22128, 22128, 22128],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([5.7316e-05, 8.5659e-05, 3.4985e-04,  ...,
                      1.1182e-04, 3.0297e-04, 1.3575e-05]),
       size=(22540, 50), nnz=3418, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.1847e-05, -2.6807e-06,  5.9538e-06,  ...,
                       5.6773e-06, -2.2723e-05, -2.4645e-06]),
       size=(22540, 50), nnz=22700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(50, tensor(15956, device='cuda:7'))
15956
tensor(indices=tensor([[15956],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  121,   121,   121,  ..., 21697, 21697, 21697],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([7.4788e-05, 1.0402e-04, 3.2579e-04,  ...,
                      5.1402e-05, 2.0614e-05, 5.6977e-05]),
       size=(22540, 50), nnz=2677, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.7596e-05, -2.1591e-06,  4.7953e-06,  ...,
                       4.5727e-06, -1.8302e-05, -1.9850e-06]),
       size=(22540, 50), nnz=21350, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(51, tensor(19216, device='cuda:7'))
19216
tensor(indices=tensor([[19216],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  242,   242,   242,  ..., 22516, 22516, 22516],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([4.5869e-06, 2.4484e-05, 5.6222e-05,  ...,
                      1.2377e-05, 6.0377e-06, 1.6621e-06]),
       size=(22540, 50), nnz=9761, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.1399e-05, -2.6257e-06,  5.8317e-06,  ...,
                       5.5609e-06, -2.2257e-05, -2.4140e-06]),
       size=(22540, 50), nnz=29350, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(52, tensor(18218, device='cuda:7'))
18218
tensor(indices=tensor([[18218],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   38,    38,    38,  ..., 22531, 22531, 22531],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([3.7146e-05, 4.0241e-05, 2.1058e-04,  ...,
                      9.7328e-06, 4.4148e-05, 3.0586e-06]),
       size=(22540, 50), nnz=7600, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   38,    38,    38,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 3.6931e-04,  5.7382e-04,  2.4704e-04,  ...,
                       5.9411e-06, -2.3779e-05, -2.5790e-06]),
       size=(22540, 50), nnz=26800, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
10
7
(53, tensor(101, device='cuda:7'))
101
tensor(indices=tensor([[101],
                       [  0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  101,   101,   101,  ..., 22479, 22479, 22479],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-6.1282e-04,  7.6023e-03,  2.0502e-03,  ...,
                       3.4460e-05,  1.7022e-04,  1.5828e-05]),
       size=(22540, 50), nnz=2460, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.0825e-05, -2.5552e-06,  5.6752e-06,  ...,
                       5.4117e-06, -2.1660e-05, -2.3492e-06]),
       size=(22540, 50), nnz=21350, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(54, tensor(5170, device='cuda:7'))
5170
tensor(indices=tensor([[5170],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1324,  1324,  1324,  ..., 22331, 22331, 22331],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([2.0177e-04, 2.3686e-04, 1.1297e-03,  ...,
                      3.4000e-04, 1.2265e-03, 1.3328e-05]),
       size=(22540, 50), nnz=1752, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.8788e-05, -2.3053e-06,  5.1200e-06,  ...,
                       4.8823e-06, -1.9541e-05, -2.1194e-06]),
       size=(22540, 50), nnz=20450, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(55, tensor(6744, device='cuda:7'))
6744
tensor(indices=tensor([[6744],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  539,   539,   539,  ..., 22480, 22480, 22480],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 0.0001,  0.0002,  0.0007,  ...,  0.0005,  0.0005,
                      -0.0002]),
       size=(22540, 50), nnz=2016, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.1677e-05, -2.6598e-06,  5.9074e-06,  ...,
                       5.6331e-06, -2.2546e-05, -2.4453e-06]),
       size=(22540, 50), nnz=20750, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(56, tensor(10582, device='cuda:7'))
10582
tensor(indices=tensor([[10582],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  337,   337,   337,  ..., 22391, 22391, 22391],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([5.0643e-05, 1.0417e-04, 4.0076e-04,  ...,
                      7.2512e-05, 2.4380e-04, 3.3794e-06]),
       size=(22540, 50), nnz=4968, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.0042e-05, -2.4591e-06,  5.4617e-06,  ...,
                       5.2081e-06, -2.0845e-05, -2.2608e-06]),
       size=(22540, 50), nnz=24200, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(57, tensor(7417, device='cuda:7'))
7417
tensor(indices=tensor([[7417],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  349,   349,   349,  ..., 21585, 21585, 21585],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([1.2721e-04, 1.7269e-04, 7.8028e-04,  ...,
                      9.8766e-05, 3.2347e-05, 1.7366e-04]),
       size=(22540, 50), nnz=2365, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.2319e-05, -2.7386e-06,  6.0824e-06,  ...,
                       5.8000e-06, -2.3214e-05, -2.5178e-06]),
       size=(22540, 50), nnz=21300, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
11
8
(58, tensor(15108, device='cuda:7'))
15108
tensor(indices=tensor([[15108],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  905,   905,   905,  ..., 21522, 21522, 21522],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 8.0031e-05,  1.3667e-04,  3.8590e-04,  ...,
                       2.5422e-04,  4.9396e-04, -9.9314e-05]),
       size=(22540, 50), nnz=2233, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.8569e-05, -2.2784e-06,  5.0604e-06,  ...,
                       4.8255e-06, -1.9313e-05, -2.0947e-06]),
       size=(22540, 50), nnz=20900, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(59, tensor(22241, device='cuda:7'))
22241
tensor(indices=tensor([[22241],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  340,   340,   340,  ..., 22488, 22488, 22488],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([6.4904e-05, 8.9718e-05, 4.1230e-04,  ...,
                      3.6769e-05, 1.9064e-04, 3.3843e-06]),
       size=(22540, 50), nnz=4513, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.8743e-05, -2.2998e-06,  5.1079e-06,  ...,
                       4.8707e-06, -1.9495e-05, -2.1144e-06]),
       size=(22540, 50), nnz=23350, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(60, tensor(21863, device='cuda:7'))
21863
tensor(indices=tensor([[21863],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   49,    49,    49,  ..., 22495, 22495, 22495],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([1.4207e-04, 2.0393e-04, 9.8177e-04,  ...,
                      4.9353e-04, 1.4302e-03, 3.1044e-05]),
       size=(22540, 50), nnz=1105, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   49,    49,    49,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-5.2909e-03,  4.7892e-03, -2.4930e-03,  ...,
                       5.6178e-06, -2.2484e-05, -2.4386e-06]),
       size=(22540, 50), nnz=19550, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(61, tensor(2846, device='cuda:7'))
2846
tensor(indices=tensor([[2846],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  645,   645,   645,  ..., 22102, 22102, 22102],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([7.9026e-05, 1.2200e-04, 6.1784e-04,  ...,
                      3.3656e-05, 2.4379e-05, 2.1532e-04]),
       size=(22540, 50), nnz=1846, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.0588e-05, -2.5262e-06,  5.6107e-06,  ...,
                       5.3502e-06, -2.1414e-05, -2.3225e-06]),
       size=(22540, 50), nnz=20550, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(62, tensor(6607, device='cuda:7'))
6607
tensor(indices=tensor([[6607],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  285,   285,   285,  ..., 22448, 22448, 22448],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([5.3055e-05, 1.0557e-04, 2.7701e-04,  ...,
                      2.1545e-05, 6.9934e-05, 9.4053e-06]),
       size=(22540, 50), nnz=4232, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.2255e-05, -2.7307e-06,  6.0649e-06,  ...,
                       5.7833e-06, -2.3147e-05, -2.5105e-06]),
       size=(22540, 50), nnz=23350, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(63, tensor(22189, device='cuda:7'))
22189
tensor(indices=tensor([[22189],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  840,   840,   840,  ..., 22189, 22189, 22189],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 5.3656e-05,  1.0442e-04,  2.9465e-04,  ...,
                       6.2759e-04, -5.4823e-05,  1.5452e-03]),
       size=(22540, 50), nnz=4248, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   25,    25,    25,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 9.5147e-05,  2.4571e-07,  3.0575e-04,  ...,
                       5.2812e-06, -2.1137e-05, -2.2925e-06]),
       size=(22540, 50), nnz=23200, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(64, tensor(8783, device='cuda:7'))
8783
tensor(indices=tensor([[8783],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   26,    26,    26,  ..., 22463, 22463, 22463],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([2.8464e-05, 6.2671e-05, 1.1026e-04,  ...,
                      4.9331e-05, 1.7311e-05, 7.1949e-06]),
       size=(22540, 50), nnz=3428, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   26,    26,    26,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.1499e-03, -1.9585e-04, -4.8043e-04,  ...,
                       5.6164e-06, -2.2479e-05, -2.4380e-06]),
       size=(22540, 50), nnz=22350, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(65, tensor(9376, device='cuda:7'))
9376
tensor(indices=tensor([[9376],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  745,   745,   745,  ..., 22492, 22492, 22492],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 3.3743e-05,  7.0512e-05,  1.7813e-04,  ...,
                       1.3593e-04,  2.7819e-04, -6.6484e-05]),
       size=(22540, 50), nnz=3713, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.9814e-05, -2.4312e-06,  5.3997e-06,  ...,
                       5.1490e-06, -2.0608e-05, -2.2351e-06]),
       size=(22540, 50), nnz=22650, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(66, tensor(12544, device='cuda:7'))
12544
tensor(indices=tensor([[12544],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  799,   799,   799,  ..., 22462, 22462, 22462],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([1.2179e-04, 1.4741e-04, 7.2054e-04,  ...,
                      6.8147e-05, 2.6475e-04, 8.8255e-06]),
       size=(22540, 50), nnz=2520, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.8670e-05, -2.2908e-06,  5.0879e-06,  ...,
                       4.8517e-06, -1.9418e-05, -2.1061e-06]),
       size=(22540, 50), nnz=21600, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(67, tensor(20261, device='cuda:7'))
20261
tensor(indices=tensor([[20261],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   41,    41,    41,  ..., 21504, 21504, 21504],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([6.7573e-05, 8.5637e-05, 2.7629e-04,  ...,
                      4.1214e-05, 1.5980e-05, 5.1568e-05]),
       size=(22540, 50), nnz=3611, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   41,    41,    41,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-4.1380e-04,  2.2789e-04, -5.3973e-04,  ...,
                       5.3397e-06, -2.1372e-05, -2.3179e-06]),
       size=(22540, 50), nnz=22700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
11213
torch.Size([2, 149304])
tensor(indices=tensor([[11213],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[    1,     1,     1,  ..., 22191, 22191, 22191],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([4.3617e-05, 7.1779e-05, 3.0752e-04,  ...,
                      9.8058e-05, 2.7203e-04, 2.9861e-06]),
       size=(22540, 50), nnz=4625, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[    1,     1,     1,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.6867e-03, -4.7628e-04,  6.1721e-04,  ...,
                       4.6463e-06, -1.8596e-05, -2.0169e-06]),
       size=(22540, 50), nnz=23550, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
2579
torch.Size([2, 149304])
tensor(indices=tensor([[2579],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[    8,     8,     8,  ..., 21657, 21657, 21657],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([1.4432e-04, 1.9782e-04, 6.2421e-04,  ...,
                      1.1144e-04, 5.2633e-04, 1.3462e-05]),
       size=(22540, 50), nnz=2962, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[    8,     8,     8,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-6.4544e-05, -9.3346e-06, -6.7810e-05,  ...,
                       5.5773e-06, -2.2322e-05, -2.4211e-06]),
       size=(22540, 50), nnz=21950, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
10248
torch.Size([2, 149304])
tensor(indices=tensor([[10248],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1484,  1484,  1484,  ..., 22397, 22397, 22397],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([2.1658e-04, 2.9963e-04, 8.9267e-04,  ...,
                      2.1025e-04, 9.1737e-04, 1.9547e-05]),
       size=(22540, 50), nnz=1165, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.0267e-05, -2.4868e-06,  5.5232e-06,  ...,
                       5.2668e-06, -2.1080e-05, -2.2863e-06]),
       size=(22540, 50), nnz=19650, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
11213
tensor(indices=tensor([[11213],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[    1,     1,     1,  ..., 22191, 22191, 22191],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([4.3617e-05, 7.1779e-05, 3.0752e-04,  ...,
                      9.8058e-05, 2.7203e-04, 2.9861e-06]),
       size=(22540, 50), nnz=4625, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[    1,     1,     1,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.6867e-03, -4.7628e-04,  6.1721e-04,  ...,
                       4.6463e-06, -1.8596e-05, -2.0169e-06]),
       size=(22540, 50), nnz=23550, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
2579
tensor(indices=tensor([[2579],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  278,   278,   278,  ..., 21657, 21657, 21657],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([8.9805e-05, 1.4914e-04, 3.7945e-04,  ...,
                      1.1192e-04, 5.2858e-04, 1.3520e-05]),
       size=(22540, 50), nnz=2962, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.1554e-05, -2.6446e-06,  5.8737e-06,  ...,
                       5.6010e-06, -2.2417e-05, -2.4314e-06]),
       size=(22540, 50), nnz=21700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
10248
tensor(indices=tensor([[10248],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1484,  1484,  1484,  ..., 22397, 22397, 22397],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([2.1658e-04, 2.9963e-04, 8.9267e-04,  ...,
                      2.1025e-04, 9.1737e-04, 1.9547e-05]),
       size=(22540, 50), nnz=1165, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.0267e-05, -2.4868e-06,  5.5232e-06,  ...,
                       5.2668e-06, -2.1080e-05, -2.2863e-06]),
       size=(22540, 50), nnz=19650, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
11213
tensor(indices=tensor([[11213],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[    1,     1,     1,  ..., 22191, 22191, 22191],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([4.3640e-05, 7.1817e-05, 3.0769e-04,  ...,
                      9.8110e-05, 2.7217e-04, 2.9877e-06]),
       size=(22540, 50), nnz=4625, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[    1,     1,     1,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.6881e-03, -4.7654e-04,  6.1754e-04,  ...,
                       4.6488e-06, -1.8606e-05, -2.0180e-06]),
       size=(22540, 50), nnz=23550, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
3410
tensor(indices=tensor([[3410],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  160,   160,   160,  ..., 22330, 22330, 22330],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([1.2136e-04, 1.7675e-04, 5.3065e-04,  ...,
                      3.9399e-04, 1.1022e-03, 2.4019e-05]),
       size=(22540, 50), nnz=1879, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.8230e-05, -2.1526e-06,  4.9054e-06,  ...,
                       4.8722e-06, -1.8867e-05, -2.0676e-06]),
       size=(22540, 50), nnz=20500, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
2579
tensor(indices=tensor([[2579],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  278,   278,   278,  ..., 21657, 21657, 21657],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([8.9871e-05, 1.4925e-04, 3.7973e-04,  ...,
                      1.1200e-04, 5.2896e-04, 1.3530e-05]),
       size=(22540, 50), nnz=2962, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.1569e-05, -2.6466e-06,  5.8780e-06,  ...,
                       5.6051e-06, -2.2434e-05, -2.4332e-06]),
       size=(22540, 50), nnz=21700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
11213
torch.Size([2, 149304])
tensor(indices=tensor([[11213],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[    1,     1,     1,  ..., 22191, 22191, 22191],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([4.3649e-05, 7.1831e-05, 3.0775e-04,  ...,
                      9.8129e-05, 2.7222e-04, 2.9882e-06]),
       size=(22540, 50), nnz=4626, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[    1,     1,     1,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.6944e-03, -4.7689e-04,  6.1593e-04,  ...,
                       4.6497e-06, -1.8610e-05, -2.0184e-06]),
       size=(22540, 50), nnz=23750, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
3410
torch.Size([2, 149304])
tensor(indices=tensor([[3410],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   12,    12,    12,  ..., 22330, 22330, 22330],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 3.3070e-03, -5.7108e-03,  2.4776e-02,  ...,
                       3.8332e-04,  1.0723e-03,  2.3368e-05]),
       size=(22540, 50), nnz=1880, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   12,    12,    12,  ..., 22330, 22330, 22330],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 6.6373e-03, -5.4803e-03,  1.4459e-04,  ...,
                       1.8285e-04, -5.3317e-05,  1.5142e-05]),
       size=(22540, 50), nnz=2700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
2579
torch.Size([2, 149304])
tensor(indices=tensor([[2579],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  278,   278,   278,  ..., 21657, 21657, 21657],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([8.9871e-05, 1.4925e-04, 3.7973e-04,  ...,
                      1.1200e-04, 5.2896e-04, 1.3530e-05]),
       size=(22540, 50), nnz=2962, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.1569e-05, -2.6466e-06,  5.8780e-06,  ...,
                       5.6051e-06, -2.2434e-05, -2.4332e-06]),
       size=(22540, 50), nnz=21700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
count_nodes_self:  11
count_edges_self:  8
Starting evaluation...
[Evaluation] Test Accuracy: 66.18
emb_type:  DistMult
Labels loaded.
RDF loaded.
Graph loaded.
cuda:  True
shape edges:  torch.Size([63382, 3])
test_idx:  tensor([12917, 21950,  3144, 20225,  7271, 10768, 11934,  4336, 10172, 13510,
        19233, 19260,  7860,  9637,  7315, 21185,  9704, 15542,  1543,  9956,
        19946,  2144, 17777, 13745,  5234, 20943,  3410,  5643,   211,  3969,
        11213, 10620, 11150, 10248, 19890, 18276,  1166, 10336,  4256,   963,
         4369,  6785,  2579, 17531,   541, 13333, 19769, 16980, 14021,  9082,
        15956, 19216, 18218,   101,  5170,  6744, 10582,  7417, 15108, 22241,
        21863,  2846,  6607, 22189,  8783,  9376, 12544, 20261],
       device='cuda:7')
num_classes:  2
num_nodes:  22540
num_relations:  9
tensor([[0.4689, 0.5311],
        [0.4999, 0.5001],
        [0.4702, 0.5298],
        [0.4947, 0.5053],
        [0.4748, 0.5252],
        [0.4546, 0.5454],
        [0.4915, 0.5085],
        [0.4606, 0.5394],
        [0.4759, 0.5241],
        [0.4590, 0.5410],
        [0.4905, 0.5095],
        [0.4800, 0.5200],
        [0.4810, 0.5190],
        [0.4897, 0.5103],
        [0.4453, 0.5547],
        [0.4603, 0.5397],
        [0.5031, 0.4969],
        [0.4926, 0.5074],
        [0.4779, 0.5221],
        [0.4744, 0.5256],
        [0.4763, 0.5237],
        [0.4615, 0.5385],
        [0.4905, 0.5095],
        [0.4845, 0.5155],
        [0.4711, 0.5289],
        [0.4818, 0.5182],
        [0.5207, 0.4793],
        [0.4824, 0.5176],
        [0.4523, 0.5477],
        [0.4663, 0.5337],
        [0.4706, 0.5294],
        [0.4701, 0.5299],
        [0.4518, 0.5482],
        [0.4786, 0.5214],
        [0.4918, 0.5082],
        [0.4338, 0.5662],
        [0.4857, 0.5143],
        [0.4573, 0.5427],
        [0.4623, 0.5377],
        [0.4711, 0.5289],
        [0.4712, 0.5288],
        [0.4762, 0.5238],
        [0.4453, 0.5547],
        [0.4724, 0.5276],
        [0.4841, 0.5159],
        [0.5077, 0.4923],
        [0.4661, 0.5339],
        [0.4667, 0.5333],
        [0.4787, 0.5213],
        [0.4693, 0.5307],
        [0.4709, 0.5291],
        [0.4448, 0.5552],
        [0.4530, 0.5470],
        [0.4591, 0.5409],
        [0.4892, 0.5108],
        [0.4646, 0.5354],
        [0.4754, 0.5246],
        [0.4823, 0.5177],
        [0.4772, 0.5228],
        [0.5229, 0.4771],
        [0.4955, 0.5045],
        [0.4827, 0.5173],
        [0.4579, 0.5421],
        [0.4624, 0.5376],
        [0.4536, 0.5464],
        [0.4711, 0.5289],
        [0.4634, 0.5366],
        [0.4829, 0.5171],
        [0.4725, 0.5275],
        [0.4624, 0.5376],
        [0.4996, 0.5004],
        [0.4937, 0.5063],
        [0.5035, 0.4965],
        [0.4700, 0.5300],
        [0.4613, 0.5387],
        [0.4897, 0.5103],
        [0.4337, 0.5663],
        [0.5051, 0.4949],
        [0.5052, 0.4948],
        [0.4969, 0.5031],
        [0.4716, 0.5284],
        [0.4931, 0.5069],
        [0.4393, 0.5607],
        [0.4597, 0.5403],
        [0.4660, 0.5340],
        [0.4596, 0.5404],
        [0.4683, 0.5317],
        [0.4624, 0.5376],
        [0.4638, 0.5362],
        [0.4563, 0.5437],
        [0.4673, 0.5327],
        [0.4713, 0.5287],
        [0.4678, 0.5322],
        [0.4950, 0.5050],
        [0.4823, 0.5177],
        [0.4695, 0.5305],
        [0.4838, 0.5162],
        [0.4797, 0.5203],
        [0.4981, 0.5019],
        [0.4569, 0.5431],
        [0.4673, 0.5327],
        [0.4858, 0.5142],
        [0.4747, 0.5253],
        [0.4812, 0.5188],
        [0.4695, 0.5305],
        [0.4976, 0.5024],
        [0.4504, 0.5496],
        [0.4666, 0.5334],
        [0.5128, 0.4872],
        [0.4946, 0.5054],
        [0.4941, 0.5059],
        [0.4396, 0.5604],
        [0.4718, 0.5282],
        [0.4664, 0.5336],
        [0.4702, 0.5298],
        [0.4907, 0.5093],
        [0.4940, 0.5060],
        [0.4808, 0.5192],
        [0.5127, 0.4873],
        [0.4393, 0.5607],
        [0.4950, 0.5050],
        [0.4902, 0.5098],
        [0.4870, 0.5130],
        [0.4651, 0.5349],
        [0.4826, 0.5174],
        [0.4550, 0.5450],
        [0.4838, 0.5162],
        [0.4703, 0.5297],
        [0.4713, 0.5287],
        [0.4831, 0.5169],
        [0.4650, 0.5350],
        [0.5125, 0.4875],
        [0.4750, 0.5250],
        [0.4563, 0.5437],
        [0.5069, 0.4931],
        [0.4573, 0.5427],
        [0.4534, 0.5466],
        [0.4889, 0.5111],
        [0.4742, 0.5258],
        [0.5001, 0.4999],
        [0.4858, 0.5142],
        [0.4603, 0.5397],
        [0.4923, 0.5077],
        [0.4718, 0.5282],
        [0.4865, 0.5135],
        [0.4822, 0.5178],
        [0.4793, 0.5207],
        [0.4896, 0.5104],
        [0.4650, 0.5350],
        [0.4772, 0.5228],
        [0.4778, 0.5222],
        [0.4829, 0.5171],
        [0.4581, 0.5419],
        [0.4795, 0.5205],
        [0.4526, 0.5474],
        [0.4946, 0.5054],
        [0.4630, 0.5370],
        [0.4515, 0.5485],
        [0.4319, 0.5681],
        [0.4817, 0.5183],
        [0.4722, 0.5278],
        [0.4504, 0.5496],
        [0.4483, 0.5517],
        [0.4745, 0.5255],
        [0.4546, 0.5454],
        [0.4661, 0.5339],
        [0.5010, 0.4990],
        [0.4652, 0.5348],
        [0.4895, 0.5105],
        [0.4730, 0.5270],
        [0.4887, 0.5113],
        [0.4342, 0.5658],
        [0.4745, 0.5255],
        [0.4835, 0.5165],
        [0.4833, 0.5167],
        [0.5021, 0.4979],
        [0.4599, 0.5401],
        [0.4531, 0.5469],
        [0.4858, 0.5142],
        [0.4854, 0.5146],
        [0.4764, 0.5236],
        [0.4320, 0.5680],
        [0.4886, 0.5114],
        [0.5093, 0.4907],
        [0.4774, 0.5226],
        [0.4697, 0.5303],
        [0.4743, 0.5257],
        [0.4796, 0.5204],
        [0.4877, 0.5123],
        [0.4816, 0.5184],
        [0.4906, 0.5094],
        [0.4930, 0.5070],
        [0.4988, 0.5012],
        [0.4939, 0.5061],
        [0.4863, 0.5137],
        [0.4950, 0.5050],
        [0.4870, 0.5130],
        [0.4712, 0.5288],
        [0.4724, 0.5276],
        [0.5004, 0.4996],
        [0.4861, 0.5139],
        [0.4927, 0.5073],
        [0.4738, 0.5262],
        [0.4510, 0.5490],
        [0.5009, 0.4991],
        [0.4620, 0.5380],
        [0.4928, 0.5072],
        [0.4719, 0.5281],
        [0.4883, 0.5117],
        [0.4778, 0.5222],
        [0.4961, 0.5039],
        [0.4847, 0.5153],
        [0.4620, 0.5380],
        [0.4682, 0.5318],
        [0.4858, 0.5142],
        [0.4716, 0.5284],
        [0.4766, 0.5234],
        [0.4461, 0.5539],
        [0.4777, 0.5223],
        [0.4982, 0.5018],
        [0.4537, 0.5463],
        [0.4892, 0.5108],
        [0.4951, 0.5049],
        [0.4775, 0.5225],
        [0.4553, 0.5447],
        [0.4714, 0.5286],
        [0.4696, 0.5304],
        [0.4709, 0.5291],
        [0.4512, 0.5488],
        [0.4721, 0.5279],
        [0.4833, 0.5167],
        [0.4652, 0.5348],
        [0.4575, 0.5425],
        [0.4724, 0.5276],
        [0.4739, 0.5261],
        [0.4930, 0.5070],
        [0.4682, 0.5318],
        [0.4858, 0.5142],
        [0.4758, 0.5242],
        [0.4707, 0.5293],
        [0.4986, 0.5014],
        [0.4615, 0.5385],
        [0.4510, 0.5490],
        [0.5143, 0.4857],
        [0.4969, 0.5031],
        [0.4972, 0.5028],
        [0.4525, 0.5475],
        [0.4633, 0.5367],
        [0.4572, 0.5428],
        [0.4995, 0.5005],
        [0.4866, 0.5134],
        [0.4272, 0.5728],
        [0.4684, 0.5316],
        [0.4478, 0.5522],
        [0.4475, 0.5525],
        [0.4652, 0.5348],
        [0.4678, 0.5322],
        [0.4583, 0.5417],
        [0.4760, 0.5240],
        [0.4602, 0.5398],
        [0.4722, 0.5278],
        [0.4745, 0.5255],
        [0.4919, 0.5081],
        [0.4916, 0.5084],
        [0.4758, 0.5242],
        [0.5032, 0.4968],
        [0.4986, 0.5014],
        [0.4902, 0.5098],
        [0.4864, 0.5136],
        [0.4516, 0.5484],
        [0.4652, 0.5348],
        [0.4962, 0.5038]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0002 loss: 0.7001 acc_train: 0.4007 time: 0.1054s
tensor([[0.6167, 0.3833],
        [0.6412, 0.3588],
        [0.6490, 0.3510],
        [0.6309, 0.3691],
        [0.6218, 0.3782],
        [0.5938, 0.4062],
        [0.6243, 0.3757],
        [0.6066, 0.3934],
        [0.6244, 0.3756],
        [0.5995, 0.4005],
        [0.6524, 0.3476],
        [0.6072, 0.3928],
        [0.6251, 0.3749],
        [0.6380, 0.3620],
        [0.6157, 0.3843],
        [0.6148, 0.3852],
        [0.6426, 0.3574],
        [0.6240, 0.3760],
        [0.6361, 0.3639],
        [0.6108, 0.3892],
        [0.6188, 0.3812],
        [0.6248, 0.3752],
        [0.6412, 0.3588],
        [0.6532, 0.3468],
        [0.6290, 0.3710],
        [0.6124, 0.3876],
        [0.6474, 0.3526],
        [0.6210, 0.3790],
        [0.6099, 0.3901],
        [0.6107, 0.3893],
        [0.6188, 0.3812],
        [0.6061, 0.3939],
        [0.6089, 0.3911],
        [0.6208, 0.3792],
        [0.6307, 0.3693],
        [0.5542, 0.4458],
        [0.6241, 0.3759],
        [0.6097, 0.3903],
        [0.6194, 0.3806],
        [0.6172, 0.3828],
        [0.6194, 0.3806],
        [0.6221, 0.3779],
        [0.5981, 0.4019],
        [0.6126, 0.3874],
        [0.6094, 0.3906],
        [0.6347, 0.3653],
        [0.6280, 0.3720],
        [0.6335, 0.3665],
        [0.6130, 0.3870],
        [0.6070, 0.3930],
        [0.6183, 0.3817],
        [0.5994, 0.4006],
        [0.6027, 0.3973],
        [0.6244, 0.3756],
        [0.6450, 0.3550],
        [0.6298, 0.3702],
        [0.6201, 0.3799],
        [0.6233, 0.3767],
        [0.6166, 0.3834],
        [0.6571, 0.3429],
        [0.6306, 0.3694],
        [0.6311, 0.3689],
        [0.6081, 0.3919],
        [0.6261, 0.3739],
        [0.5991, 0.4009],
        [0.6170, 0.3830],
        [0.6160, 0.3840],
        [0.6199, 0.3801],
        [0.6403, 0.3597],
        [0.6167, 0.3833],
        [0.6267, 0.3733],
        [0.6271, 0.3729],
        [0.6390, 0.3610],
        [0.6081, 0.3919],
        [0.6016, 0.3984],
        [0.6413, 0.3587],
        [0.6080, 0.3920],
        [0.6473, 0.3527],
        [0.6289, 0.3711],
        [0.6377, 0.3623],
        [0.6269, 0.3731],
        [0.6430, 0.3570],
        [0.5898, 0.4102],
        [0.6100, 0.3900],
        [0.6344, 0.3656],
        [0.6012, 0.3988],
        [0.6136, 0.3864],
        [0.6206, 0.3794],
        [0.5964, 0.4036],
        [0.6020, 0.3980],
        [0.6189, 0.3811],
        [0.6136, 0.3864],
        [0.6316, 0.3684],
        [0.6228, 0.3772],
        [0.6308, 0.3692],
        [0.6101, 0.3899],
        [0.6414, 0.3586],
        [0.6190, 0.3810],
        [0.6381, 0.3619],
        [0.5975, 0.4025],
        [0.6101, 0.3899],
        [0.6349, 0.3651],
        [0.6283, 0.3717],
        [0.6038, 0.3962],
        [0.6225, 0.3775],
        [0.6304, 0.3696],
        [0.6116, 0.3884],
        [0.6087, 0.3913],
        [0.6383, 0.3617],
        [0.6233, 0.3767],
        [0.6213, 0.3787],
        [0.5839, 0.4161],
        [0.6194, 0.3806],
        [0.6190, 0.3810],
        [0.6244, 0.3756],
        [0.6144, 0.3856],
        [0.6477, 0.3523],
        [0.6422, 0.3578],
        [0.6466, 0.3534],
        [0.5935, 0.4065],
        [0.6463, 0.3537],
        [0.6174, 0.3826],
        [0.6276, 0.3724],
        [0.6150, 0.3850],
        [0.6367, 0.3633],
        [0.6181, 0.3819],
        [0.6199, 0.3801],
        [0.6158, 0.3842],
        [0.6188, 0.3812],
        [0.6249, 0.3751],
        [0.6182, 0.3818],
        [0.6597, 0.3403],
        [0.6246, 0.3754],
        [0.6099, 0.3901],
        [0.6400, 0.3600],
        [0.5971, 0.4029],
        [0.5956, 0.4044],
        [0.6277, 0.3723],
        [0.6170, 0.3830],
        [0.6317, 0.3683],
        [0.6199, 0.3801],
        [0.6155, 0.3845],
        [0.6283, 0.3717],
        [0.6087, 0.3913],
        [0.6219, 0.3781],
        [0.6361, 0.3639],
        [0.6340, 0.3660],
        [0.6223, 0.3777],
        [0.6128, 0.3872],
        [0.6240, 0.3760],
        [0.6261, 0.3739],
        [0.6394, 0.3606],
        [0.6128, 0.3872],
        [0.6361, 0.3639],
        [0.6267, 0.3733],
        [0.6266, 0.3734],
        [0.6290, 0.3710],
        [0.6076, 0.3924],
        [0.5924, 0.4076],
        [0.6180, 0.3820],
        [0.6153, 0.3847],
        [0.6104, 0.3896],
        [0.6084, 0.3916],
        [0.6200, 0.3800],
        [0.5845, 0.4155],
        [0.6027, 0.3973],
        [0.6350, 0.3650],
        [0.6119, 0.3881],
        [0.6374, 0.3626],
        [0.6230, 0.3770],
        [0.6085, 0.3915],
        [0.5994, 0.4006],
        [0.6217, 0.3783],
        [0.6283, 0.3717],
        [0.6181, 0.3819],
        [0.6403, 0.3597],
        [0.6180, 0.3820],
        [0.6016, 0.3984],
        [0.6209, 0.3791],
        [0.6337, 0.3663],
        [0.6388, 0.3612],
        [0.5945, 0.4055],
        [0.6212, 0.3788],
        [0.6446, 0.3554],
        [0.6089, 0.3911],
        [0.6138, 0.3862],
        [0.6087, 0.3913],
        [0.6295, 0.3705],
        [0.6167, 0.3833],
        [0.6381, 0.3619],
        [0.6325, 0.3675],
        [0.6330, 0.3670],
        [0.6289, 0.3711],
        [0.6273, 0.3727],
        [0.6357, 0.3643],
        [0.6508, 0.3492],
        [0.6461, 0.3539],
        [0.6118, 0.3882],
        [0.6351, 0.3649],
        [0.6430, 0.3570],
        [0.6298, 0.3702],
        [0.6472, 0.3528],
        [0.6271, 0.3729],
        [0.5979, 0.4021],
        [0.6393, 0.3607],
        [0.6164, 0.3836],
        [0.6349, 0.3651],
        [0.6345, 0.3655],
        [0.6352, 0.3648],
        [0.6037, 0.3963],
        [0.6316, 0.3684],
        [0.6171, 0.3829],
        [0.6238, 0.3762],
        [0.6164, 0.3836],
        [0.6305, 0.3695],
        [0.6246, 0.3754],
        [0.6222, 0.3778],
        [0.5965, 0.4035],
        [0.6329, 0.3671],
        [0.6250, 0.3750],
        [0.6082, 0.3918],
        [0.6461, 0.3539],
        [0.6327, 0.3673],
        [0.6389, 0.3611],
        [0.6134, 0.3866],
        [0.6244, 0.3756],
        [0.5968, 0.4032],
        [0.6226, 0.3774],
        [0.6155, 0.3845],
        [0.6218, 0.3782],
        [0.6287, 0.3713],
        [0.6326, 0.3674],
        [0.6188, 0.3812],
        [0.6128, 0.3872],
        [0.6289, 0.3711],
        [0.6485, 0.3515],
        [0.6115, 0.3885],
        [0.6280, 0.3720],
        [0.6006, 0.3994],
        [0.6096, 0.3904],
        [0.6282, 0.3718],
        [0.6142, 0.3858],
        [0.6071, 0.3929],
        [0.6430, 0.3570],
        [0.6424, 0.3576],
        [0.6398, 0.3602],
        [0.6119, 0.3881],
        [0.6212, 0.3788],
        [0.6080, 0.3920],
        [0.6411, 0.3589],
        [0.6212, 0.3788],
        [0.6231, 0.3769],
        [0.6194, 0.3806],
        [0.6161, 0.3839],
        [0.6078, 0.3922],
        [0.6322, 0.3678],
        [0.6146, 0.3854],
        [0.6279, 0.3721],
        [0.6196, 0.3804],
        [0.6160, 0.3840],
        [0.6283, 0.3717],
        [0.6143, 0.3857],
        [0.6379, 0.3621],
        [0.6368, 0.3632],
        [0.6195, 0.3805],
        [0.6300, 0.3700],
        [0.6356, 0.3644],
        [0.6323, 0.3677],
        [0.6220, 0.3780],
        [0.6022, 0.3978],
        [0.6365, 0.3635],
        [0.6263, 0.3737]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0003 loss: 0.6713 acc_train: 0.6103 time: 0.1182s
tensor([[0.6724, 0.3276],
        [0.6942, 0.3058],
        [0.7172, 0.2828],
        [0.6830, 0.3170],
        [0.6885, 0.3115],
        [0.6507, 0.3493],
        [0.6692, 0.3308],
        [0.6651, 0.3349],
        [0.6803, 0.3197],
        [0.6528, 0.3472],
        [0.7094, 0.2906],
        [0.6585, 0.3415],
        [0.6817, 0.3183],
        [0.6880, 0.3120],
        [0.6870, 0.3130],
        [0.6776, 0.3224],
        [0.6931, 0.3069],
        [0.6660, 0.3340],
        [0.6925, 0.3075],
        [0.6614, 0.3386],
        [0.6777, 0.3223],
        [0.6787, 0.3213],
        [0.6995, 0.3005],
        [0.7151, 0.2849],
        [0.6891, 0.3109],
        [0.6658, 0.3342],
        [0.6840, 0.3160],
        [0.6776, 0.3224],
        [0.6675, 0.3325],
        [0.6680, 0.3320],
        [0.6787, 0.3213],
        [0.6615, 0.3385],
        [0.6795, 0.3205],
        [0.6740, 0.3260],
        [0.6840, 0.3160],
        [0.6220, 0.3780],
        [0.6806, 0.3194],
        [0.6742, 0.3258],
        [0.6857, 0.3143],
        [0.6673, 0.3327],
        [0.6763, 0.3237],
        [0.6850, 0.3150],
        [0.6627, 0.3373],
        [0.6707, 0.3293],
        [0.6623, 0.3377],
        [0.6737, 0.3263],
        [0.6931, 0.3069],
        [0.7015, 0.2985],
        [0.6582, 0.3418],
        [0.6700, 0.3300],
        [0.6749, 0.3251],
        [0.6688, 0.3312],
        [0.6661, 0.3339],
        [0.6891, 0.3109],
        [0.7035, 0.2965],
        [0.6938, 0.3062],
        [0.6787, 0.3213],
        [0.6763, 0.3237],
        [0.6683, 0.3317],
        [0.6984, 0.3016],
        [0.6773, 0.3227],
        [0.6828, 0.3172],
        [0.6771, 0.3229],
        [0.6955, 0.3045],
        [0.6559, 0.3441],
        [0.6717, 0.3283],
        [0.6746, 0.3254],
        [0.6754, 0.3246],
        [0.7061, 0.2939],
        [0.6754, 0.3246],
        [0.6746, 0.3254],
        [0.6743, 0.3257],
        [0.6880, 0.3120],
        [0.6671, 0.3329],
        [0.6633, 0.3367],
        [0.6893, 0.3107],
        [0.6806, 0.3194],
        [0.6918, 0.3082],
        [0.6776, 0.3224],
        [0.6869, 0.3131],
        [0.6782, 0.3218],
        [0.6913, 0.3087],
        [0.6568, 0.3432],
        [0.6669, 0.3331],
        [0.6969, 0.3031],
        [0.6586, 0.3414],
        [0.6748, 0.3252],
        [0.6797, 0.3203],
        [0.6483, 0.3517],
        [0.6665, 0.3335],
        [0.6780, 0.3220],
        [0.6680, 0.3320],
        [0.6924, 0.3076],
        [0.6702, 0.3298],
        [0.6821, 0.3179],
        [0.6732, 0.3268],
        [0.7029, 0.2971],
        [0.6734, 0.3266],
        [0.6902, 0.3099],
        [0.6631, 0.3369],
        [0.6707, 0.3293],
        [0.6893, 0.3107],
        [0.6824, 0.3176],
        [0.6527, 0.3473],
        [0.6805, 0.3195],
        [0.6798, 0.3202],
        [0.6777, 0.3223],
        [0.6732, 0.3268],
        [0.6730, 0.3270],
        [0.6730, 0.3270],
        [0.6684, 0.3316],
        [0.6558, 0.3442],
        [0.6806, 0.3194],
        [0.6801, 0.3199],
        [0.6815, 0.3185],
        [0.6595, 0.3405],
        [0.7033, 0.2967],
        [0.7061, 0.2939],
        [0.7000, 0.3000],
        [0.6600, 0.3400],
        [0.6978, 0.3022],
        [0.6624, 0.3376],
        [0.6791, 0.3209],
        [0.6790, 0.3210],
        [0.6967, 0.3033],
        [0.6833, 0.3167],
        [0.6653, 0.3347],
        [0.6742, 0.3258],
        [0.6765, 0.3235],
        [0.6748, 0.3252],
        [0.6799, 0.3201],
        [0.7064, 0.2936],
        [0.6742, 0.3258],
        [0.6690, 0.3310],
        [0.6902, 0.3098],
        [0.6553, 0.3447],
        [0.6579, 0.3421],
        [0.6853, 0.3147],
        [0.6794, 0.3206],
        [0.6755, 0.3245],
        [0.6673, 0.3327],
        [0.6757, 0.3243],
        [0.6763, 0.3237],
        [0.6642, 0.3358],
        [0.6689, 0.3311],
        [0.6943, 0.3057],
        [0.6947, 0.3053],
        [0.6774, 0.3226],
        [0.6766, 0.3234],
        [0.6912, 0.3088],
        [0.6804, 0.3196],
        [0.7072, 0.2928],
        [0.6865, 0.3135],
        [0.6963, 0.3037],
        [0.6961, 0.3039],
        [0.6722, 0.3278],
        [0.6982, 0.3018],
        [0.6758, 0.3242],
        [0.6554, 0.3446],
        [0.6700, 0.3300],
        [0.6749, 0.3251],
        [0.6804, 0.3196],
        [0.6739, 0.3261],
        [0.6768, 0.3232],
        [0.6490, 0.3510],
        [0.6610, 0.3390],
        [0.6819, 0.3181],
        [0.6635, 0.3365],
        [0.6948, 0.3052],
        [0.6809, 0.3191],
        [0.6581, 0.3419],
        [0.6723, 0.3277],
        [0.6711, 0.3289],
        [0.6793, 0.3207],
        [0.6730, 0.3270],
        [0.6865, 0.3135],
        [0.6873, 0.3127],
        [0.6624, 0.3376],
        [0.6657, 0.3343],
        [0.6983, 0.3017],
        [0.7006, 0.2994],
        [0.6627, 0.3373],
        [0.6736, 0.3264],
        [0.6899, 0.3101],
        [0.6652, 0.3348],
        [0.6710, 0.3290],
        [0.6572, 0.3428],
        [0.6866, 0.3134],
        [0.6634, 0.3366],
        [0.6937, 0.3063],
        [0.6935, 0.3065],
        [0.6839, 0.3161],
        [0.6748, 0.3252],
        [0.6767, 0.3233],
        [0.6977, 0.3023],
        [0.7094, 0.2906],
        [0.7077, 0.2923],
        [0.6607, 0.3393],
        [0.6964, 0.3036],
        [0.6920, 0.3080],
        [0.6824, 0.3176],
        [0.7087, 0.2913],
        [0.6858, 0.3142],
        [0.6574, 0.3426],
        [0.6959, 0.3041],
        [0.6765, 0.3235],
        [0.6962, 0.3038],
        [0.6977, 0.3023],
        [0.6895, 0.3105],
        [0.6568, 0.3432],
        [0.6839, 0.3161],
        [0.6646, 0.3354],
        [0.6876, 0.3124],
        [0.6728, 0.3272],
        [0.6823, 0.3177],
        [0.6959, 0.3041],
        [0.6685, 0.3315],
        [0.6651, 0.3349],
        [0.6951, 0.3049],
        [0.6751, 0.3249],
        [0.6713, 0.3287],
        [0.7055, 0.2945],
        [0.6776, 0.3224],
        [0.6956, 0.3044],
        [0.6787, 0.3213],
        [0.6901, 0.3099],
        [0.6523, 0.3477],
        [0.6863, 0.3137],
        [0.6781, 0.3219],
        [0.6816, 0.3184],
        [0.6834, 0.3166],
        [0.6941, 0.3059],
        [0.6869, 0.3131],
        [0.6716, 0.3284],
        [0.6932, 0.3068],
        [0.7075, 0.2925],
        [0.6753, 0.3247],
        [0.6850, 0.3150],
        [0.6527, 0.3473],
        [0.6650, 0.3350],
        [0.6802, 0.3198],
        [0.6746, 0.3254],
        [0.6685, 0.3315],
        [0.6894, 0.3106],
        [0.6960, 0.3040],
        [0.7019, 0.2981],
        [0.6829, 0.3171],
        [0.6825, 0.3175],
        [0.6706, 0.3294],
        [0.6913, 0.3087],
        [0.6689, 0.3311],
        [0.7015, 0.2985],
        [0.6721, 0.3279],
        [0.6897, 0.3103],
        [0.6776, 0.3224],
        [0.6999, 0.3001],
        [0.6741, 0.3259],
        [0.6935, 0.3065],
        [0.6753, 0.3247],
        [0.6861, 0.3139],
        [0.6927, 0.3073],
        [0.6734, 0.3266],
        [0.6945, 0.3055],
        [0.6933, 0.3067],
        [0.6735, 0.3265],
        [0.6778, 0.3222],
        [0.6901, 0.3099],
        [0.6862, 0.3138],
        [0.6727, 0.3273],
        [0.6673, 0.3327],
        [0.7067, 0.2933],
        [0.6855, 0.3145]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0004 loss: 0.6645 acc_train: 0.6103 time: 0.1260s
tensor([[0.6901, 0.3099],
        [0.7093, 0.2907],
        [0.7428, 0.2572],
        [0.6987, 0.3013],
        [0.7143, 0.2857],
        [0.6735, 0.3265],
        [0.6769, 0.3231],
        [0.6846, 0.3154],
        [0.6973, 0.3027],
        [0.6672, 0.3328],
        [0.7282, 0.2718],
        [0.6755, 0.3245],
        [0.6998, 0.3002],
        [0.7002, 0.2998],
        [0.7144, 0.2856],
        [0.7000, 0.3000],
        [0.7096, 0.2904],
        [0.6756, 0.3244],
        [0.7128, 0.2872],
        [0.6741, 0.3259],
        [0.7015, 0.2985],
        [0.6915, 0.3085],
        [0.7176, 0.2824],
        [0.7379, 0.2621],
        [0.7127, 0.2873],
        [0.6807, 0.3193],
        [0.6872, 0.3128],
        [0.6991, 0.3009],
        [0.6829, 0.3171],
        [0.6866, 0.3134],
        [0.7008, 0.2992],
        [0.6795, 0.3205],
        [0.7093, 0.2907],
        [0.6921, 0.3079],
        [0.7009, 0.2991],
        [0.6593, 0.3407],
        [0.7002, 0.2998],
        [0.6974, 0.3026],
        [0.7102, 0.2898],
        [0.6754, 0.3246],
        [0.6973, 0.3027],
        [0.7085, 0.2915],
        [0.6893, 0.3107],
        [0.6901, 0.3099],
        [0.6796, 0.3204],
        [0.6785, 0.3215],
        [0.7187, 0.2813],
        [0.7271, 0.2729],
        [0.6721, 0.3279],
        [0.6928, 0.3072],
        [0.6938, 0.3062],
        [0.6941, 0.3059],
        [0.6913, 0.3087],
        [0.7145, 0.2855],
        [0.7210, 0.2790],
        [0.7189, 0.2811],
        [0.7016, 0.2984],
        [0.6955, 0.3045],
        [0.6808, 0.3192],
        [0.7060, 0.2940],
        [0.6901, 0.3099],
        [0.6998, 0.3002],
        [0.7038, 0.2962],
        [0.7236, 0.2764],
        [0.6733, 0.3267],
        [0.6896, 0.3104],
        [0.6941, 0.3059],
        [0.6952, 0.3048],
        [0.7285, 0.2715],
        [0.6965, 0.3035],
        [0.6892, 0.3108],
        [0.6857, 0.3143],
        [0.7007, 0.2993],
        [0.6882, 0.3118],
        [0.6840, 0.3160],
        [0.7033, 0.2967],
        [0.7064, 0.2936],
        [0.7023, 0.2977],
        [0.6961, 0.3039],
        [0.6997, 0.3003],
        [0.6926, 0.3074],
        [0.7009, 0.2991],
        [0.6811, 0.3189],
        [0.6857, 0.3143],
        [0.7164, 0.2836],
        [0.6755, 0.3245],
        [0.6996, 0.3004],
        [0.6994, 0.3006],
        [0.6658, 0.3342],
        [0.6914, 0.3086],
        [0.6971, 0.3029],
        [0.6862, 0.3138],
        [0.7125, 0.2875],
        [0.6798, 0.3202],
        [0.6968, 0.3032],
        [0.7012, 0.2988],
        [0.7265, 0.2735],
        [0.6882, 0.3118],
        [0.7126, 0.2874],
        [0.6890, 0.3110],
        [0.6928, 0.3072],
        [0.7074, 0.2926],
        [0.6977, 0.3023],
        [0.6669, 0.3331],
        [0.6991, 0.3009],
        [0.6911, 0.3089],
        [0.7058, 0.2942],
        [0.6991, 0.3009],
        [0.6746, 0.3254],
        [0.6893, 0.3107],
        [0.6800, 0.3200],
        [0.6856, 0.3144],
        [0.7054, 0.2946],
        [0.7037, 0.2963],
        [0.6965, 0.3035],
        [0.6726, 0.3274],
        [0.7195, 0.2805],
        [0.7294, 0.2706],
        [0.7173, 0.2827],
        [0.6820, 0.3180],
        [0.7096, 0.2904],
        [0.6722, 0.3278],
        [0.6951, 0.3049],
        [0.7016, 0.2984],
        [0.7175, 0.2825],
        [0.7052, 0.2948],
        [0.6758, 0.3242],
        [0.6948, 0.3052],
        [0.6975, 0.3025],
        [0.6910, 0.3090],
        [0.7029, 0.2971],
        [0.7155, 0.2845],
        [0.6907, 0.3093],
        [0.6852, 0.3148],
        [0.7050, 0.2950],
        [0.6719, 0.3281],
        [0.6836, 0.3164],
        [0.7071, 0.2929],
        [0.7040, 0.2960],
        [0.6839, 0.3161],
        [0.6800, 0.3200],
        [0.6965, 0.3035],
        [0.6838, 0.3162],
        [0.6822, 0.3178],
        [0.6781, 0.3219],
        [0.7124, 0.2876],
        [0.7165, 0.2835],
        [0.6982, 0.3018],
        [0.6985, 0.3015],
        [0.7193, 0.2807],
        [0.6970, 0.3030],
        [0.7323, 0.2677],
        [0.7169, 0.2831],
        [0.7183, 0.2817],
        [0.7228, 0.2772],
        [0.6827, 0.3173],
        [0.7258, 0.2742],
        [0.7034, 0.2966],
        [0.6775, 0.3225],
        [0.6874, 0.3126],
        [0.6962, 0.3038],
        [0.7074, 0.2926],
        [0.6979, 0.3021],
        [0.6982, 0.3018],
        [0.6743, 0.3257],
        [0.6848, 0.3152],
        [0.6964, 0.3036],
        [0.6793, 0.3207],
        [0.7129, 0.2871],
        [0.6983, 0.3017],
        [0.6739, 0.3261],
        [0.7006, 0.2994],
        [0.6872, 0.3128],
        [0.6924, 0.3076],
        [0.6937, 0.3063],
        [0.6988, 0.3012],
        [0.7161, 0.2839],
        [0.6820, 0.3180],
        [0.6752, 0.3248],
        [0.7231, 0.2769],
        [0.7255, 0.2745],
        [0.6884, 0.3116],
        [0.6881, 0.3119],
        [0.7035, 0.2965],
        [0.6860, 0.3140],
        [0.6931, 0.3069],
        [0.6700, 0.3300],
        [0.7050, 0.2950],
        [0.6744, 0.3256],
        [0.7142, 0.2858],
        [0.7187, 0.2813],
        [0.6994, 0.3006],
        [0.6858, 0.3142],
        [0.6886, 0.3114],
        [0.7218, 0.2782],
        [0.7313, 0.2687],
        [0.7299, 0.2701],
        [0.6740, 0.3260],
        [0.7136, 0.2864],
        [0.7070, 0.2930],
        [0.6967, 0.3033],
        [0.7293, 0.2707],
        [0.7085, 0.2915],
        [0.6759, 0.3241],
        [0.7162, 0.2838],
        [0.6995, 0.3005],
        [0.7230, 0.2770],
        [0.7176, 0.2824],
        [0.7075, 0.2925],
        [0.6735, 0.3265],
        [0.7009, 0.2991],
        [0.6750, 0.3250],
        [0.7102, 0.2898],
        [0.6902, 0.3098],
        [0.7000, 0.3000],
        [0.7250, 0.2750],
        [0.6789, 0.3211],
        [0.6910, 0.3090],
        [0.7135, 0.2865],
        [0.6905, 0.3095],
        [0.6926, 0.3074],
        [0.7286, 0.2714],
        [0.6870, 0.3130],
        [0.7139, 0.2861],
        [0.7026, 0.2974],
        [0.7172, 0.2828],
        [0.6723, 0.3277],
        [0.7100, 0.2900],
        [0.6975, 0.3025],
        [0.7006, 0.2994],
        [0.6973, 0.3027],
        [0.7187, 0.2813],
        [0.7143, 0.2857],
        [0.6884, 0.3116],
        [0.7180, 0.2820],
        [0.7324, 0.2676],
        [0.6966, 0.3034],
        [0.7046, 0.2954],
        [0.6749, 0.3251],
        [0.6873, 0.3127],
        [0.6955, 0.3045],
        [0.6950, 0.3050],
        [0.6844, 0.3156],
        [0.7020, 0.2980],
        [0.7141, 0.2859],
        [0.7270, 0.2730],
        [0.7131, 0.2869],
        [0.7080, 0.2920],
        [0.6914, 0.3086],
        [0.7084, 0.2916],
        [0.6827, 0.3173],
        [0.7366, 0.2634],
        [0.6855, 0.3145],
        [0.7208, 0.2792],
        [0.7011, 0.2989],
        [0.7263, 0.2737],
        [0.6950, 0.3050],
        [0.7221, 0.2779],
        [0.6957, 0.3043],
        [0.7152, 0.2848],
        [0.7160, 0.2840],
        [0.6971, 0.3029],
        [0.7168, 0.2832],
        [0.7158, 0.2842],
        [0.6925, 0.3075],
        [0.6968, 0.3032],
        [0.7067, 0.2933],
        [0.7045, 0.2955],
        [0.6864, 0.3136],
        [0.6905, 0.3095],
        [0.7354, 0.2646],
        [0.7102, 0.2898]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0005 loss: 0.6618 acc_train: 0.6103 time: 0.1190s
tensor([[0.6863, 0.3137],
        [0.7040, 0.2960],
        [0.7477, 0.2523],
        [0.6943, 0.3057],
        [0.7184, 0.2816],
        [0.6732, 0.3268],
        [0.6621, 0.3379],
        [0.6832, 0.3168],
        [0.6923, 0.3077],
        [0.6590, 0.3410],
        [0.7244, 0.2756],
        [0.6706, 0.3294],
        [0.6961, 0.3039],
        [0.6948, 0.3052],
        [0.7172, 0.2828],
        [0.6989, 0.3011],
        [0.7057, 0.2943],
        [0.6647, 0.3353],
        [0.7116, 0.2884],
        [0.6673, 0.3327],
        [0.7067, 0.2933],
        [0.6841, 0.3159],
        [0.7144, 0.2856],
        [0.7418, 0.2582],
        [0.7161, 0.2839],
        [0.6755, 0.3245],
        [0.6704, 0.3296],
        [0.7003, 0.2997],
        [0.6778, 0.3222],
        [0.6824, 0.3176],
        [0.7009, 0.2991],
        [0.6756, 0.3244],
        [0.7144, 0.2856],
        [0.6896, 0.3104],
        [0.7001, 0.2999],
        [0.6684, 0.3316],
        [0.6987, 0.3013],
        [0.6950, 0.3050],
        [0.7109, 0.2891],
        [0.6624, 0.3376],
        [0.6977, 0.3023],
        [0.7088, 0.2912],
        [0.6921, 0.3079],
        [0.6874, 0.3126],
        [0.6761, 0.3239],
        [0.6647, 0.3353],
        [0.7250, 0.2750],
        [0.7320, 0.2680],
        [0.6657, 0.3343],
        [0.6938, 0.3062],
        [0.6893, 0.3107],
        [0.6982, 0.3018],
        [0.6942, 0.3058],
        [0.7173, 0.2827],
        [0.7182, 0.2818],
        [0.7215, 0.2785],
        [0.7041, 0.2959],
        [0.6945, 0.3055],
        [0.6716, 0.3284],
        [0.6966, 0.3034],
        [0.6833, 0.3167],
        [0.6961, 0.3039],
        [0.7068, 0.2932],
        [0.7288, 0.2712],
        [0.6701, 0.3299],
        [0.6841, 0.3159],
        [0.6911, 0.3089],
        [0.6918, 0.3082],
        [0.7254, 0.2746],
        [0.6966, 0.3034],
        [0.6840, 0.3160],
        [0.6777, 0.3223],
        [0.6936, 0.3064],
        [0.6896, 0.3104],
        [0.6828, 0.3172],
        [0.6973, 0.3027],
        [0.7088, 0.2912],
        [0.6924, 0.3076],
        [0.6914, 0.3086],
        [0.6882, 0.3118],
        [0.6857, 0.3143],
        [0.6887, 0.3113],
        [0.6813, 0.3187],
        [0.6809, 0.3191],
        [0.7135, 0.2865],
        [0.6701, 0.3299],
        [0.7016, 0.2984],
        [0.6973, 0.3027],
        [0.6629, 0.3371],
        [0.6918, 0.3082],
        [0.6930, 0.3070],
        [0.6832, 0.3168],
        [0.7101, 0.2899],
        [0.6693, 0.3307],
        [0.6899, 0.3101],
        [0.7035, 0.2965],
        [0.7281, 0.2719],
        [0.6818, 0.3182],
        [0.7127, 0.2873],
        [0.6897, 0.3103],
        [0.6892, 0.3108],
        [0.7014, 0.2986],
        [0.6918, 0.3082],
        [0.6602, 0.3398],
        [0.6994, 0.3006],
        [0.6807, 0.3193],
        [0.7098, 0.2902],
        [0.7025, 0.2975],
        [0.6581, 0.3419],
        [0.6842, 0.3158],
        [0.6751, 0.3249],
        [0.6920, 0.3080],
        [0.7097, 0.2903],
        [0.7067, 0.2933],
        [0.6900, 0.3100],
        [0.6688, 0.3312],
        [0.7158, 0.2842],
        [0.7290, 0.2710],
        [0.7151, 0.2849],
        [0.6821, 0.3179],
        [0.7013, 0.2987],
        [0.6640, 0.3360],
        [0.6895, 0.3105],
        [0.6995, 0.3005],
        [0.7188, 0.2812],
        [0.7026, 0.2974],
        [0.6680, 0.3320],
        [0.6949, 0.3051],
        [0.6965, 0.3035],
        [0.6875, 0.3125],
        [0.7030, 0.2970],
        [0.7061, 0.2939],
        [0.6869, 0.3131],
        [0.6785, 0.3215],
        [0.6971, 0.3029],
        [0.6656, 0.3344],
        [0.6870, 0.3130],
        [0.7084, 0.2916],
        [0.7046, 0.2954],
        [0.6742, 0.3258],
        [0.6702, 0.3298],
        [0.6938, 0.3062],
        [0.6736, 0.3264],
        [0.6764, 0.3236],
        [0.6632, 0.3368],
        [0.7108, 0.2892],
        [0.7175, 0.2825],
        [0.6969, 0.3031],
        [0.6979, 0.3021],
        [0.7260, 0.2740],
        [0.6926, 0.3074],
        [0.7359, 0.2641],
        [0.7212, 0.2788],
        [0.7214, 0.2786],
        [0.7243, 0.2757],
        [0.6741, 0.3259],
        [0.7303, 0.2697],
        [0.7060, 0.2940],
        [0.6770, 0.3230],
        [0.6845, 0.3155],
        [0.6967, 0.3033],
        [0.7096, 0.2904],
        [0.6988, 0.3012],
        [0.6988, 0.3012],
        [0.6758, 0.3242],
        [0.6893, 0.3107],
        [0.6904, 0.3096],
        [0.6742, 0.3258],
        [0.7070, 0.2930],
        [0.6915, 0.3085],
        [0.6741, 0.3259],
        [0.7024, 0.2976],
        [0.6842, 0.3158],
        [0.6821, 0.3179],
        [0.6928, 0.3072],
        [0.6913, 0.3087],
        [0.7193, 0.2807],
        [0.6804, 0.3196],
        [0.6635, 0.3365],
        [0.7264, 0.2736],
        [0.7304, 0.2696],
        [0.6893, 0.3107],
        [0.6827, 0.3173],
        [0.6960, 0.3040],
        [0.6880, 0.3120],
        [0.6964, 0.3036],
        [0.6592, 0.3408],
        [0.7030, 0.2970],
        [0.6676, 0.3324],
        [0.7113, 0.2887],
        [0.7223, 0.2777],
        [0.6975, 0.3025],
        [0.6786, 0.3214],
        [0.6786, 0.3214],
        [0.7250, 0.2750],
        [0.7313, 0.2687],
        [0.7308, 0.2692],
        [0.6664, 0.3336],
        [0.7101, 0.2899],
        [0.6991, 0.3009],
        [0.6874, 0.3126],
        [0.7274, 0.2726],
        [0.7119, 0.2881],
        [0.6718, 0.3282],
        [0.7135, 0.2865],
        [0.6987, 0.3013],
        [0.7295, 0.2705],
        [0.7168, 0.2832],
        [0.7025, 0.2975],
        [0.6676, 0.3324],
        [0.7008, 0.2992],
        [0.6642, 0.3358],
        [0.7129, 0.2871],
        [0.6846, 0.3154],
        [0.6982, 0.3018],
        [0.7326, 0.2674],
        [0.6697, 0.3303],
        [0.6959, 0.3041],
        [0.7095, 0.2905],
        [0.6879, 0.3121],
        [0.6889, 0.3111],
        [0.7312, 0.2688],
        [0.6747, 0.3253],
        [0.7106, 0.2894],
        [0.7065, 0.2935],
        [0.7178, 0.2822],
        [0.6737, 0.3263],
        [0.7119, 0.2881],
        [0.6911, 0.3089],
        [0.7001, 0.2999],
        [0.6890, 0.3110],
        [0.7228, 0.2772],
        [0.7231, 0.2769],
        [0.6839, 0.3161],
        [0.7195, 0.2805],
        [0.7354, 0.2646],
        [0.6943, 0.3057],
        [0.7005, 0.2995],
        [0.6745, 0.3255],
        [0.6900, 0.3100],
        [0.6919, 0.3081],
        [0.6928, 0.3072],
        [0.6772, 0.3228],
        [0.6948, 0.3052],
        [0.7121, 0.2879],
        [0.7311, 0.2689],
        [0.7227, 0.2773],
        [0.7114, 0.2886],
        [0.6911, 0.3089],
        [0.7027, 0.2973],
        [0.6763, 0.3237],
        [0.7449, 0.2551],
        [0.6754, 0.3246],
        [0.7295, 0.2705],
        [0.7023, 0.2977],
        [0.7305, 0.2695],
        [0.6969, 0.3031],
        [0.7275, 0.2725],
        [0.6942, 0.3058],
        [0.7221, 0.2779],
        [0.7157, 0.2843],
        [0.6977, 0.3023],
        [0.7193, 0.2807],
        [0.7173, 0.2827],
        [0.6884, 0.3116],
        [0.6956, 0.3044],
        [0.7051, 0.2949],
        [0.7025, 0.2975],
        [0.6795, 0.3205],
        [0.6921, 0.3079],
        [0.7434, 0.2566],
        [0.7158, 0.2842]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0006 loss: 0.6599 acc_train: 0.6103 time: 0.1115s
tensor([[0.6705, 0.3295],
        [0.6905, 0.3095],
        [0.7409, 0.2591],
        [0.6809, 0.3191],
        [0.7121, 0.2879],
        [0.6599, 0.3401],
        [0.6379, 0.3621],
        [0.6701, 0.3299],
        [0.6772, 0.3228],
        [0.6396, 0.3604],
        [0.7097, 0.2903],
        [0.6558, 0.3442],
        [0.6812, 0.3188],
        [0.6800, 0.3200],
        [0.7073, 0.2927],
        [0.6883, 0.3117],
        [0.6934, 0.3066],
        [0.6457, 0.3543],
        [0.7008, 0.2992],
        [0.6492, 0.3508],
        [0.7010, 0.2990],
        [0.6682, 0.3318],
        [0.6998, 0.3002],
        [0.7350, 0.2650],
        [0.7079, 0.2921],
        [0.6624, 0.3376],
        [0.6459, 0.3541],
        [0.6918, 0.3082],
        [0.6644, 0.3356],
        [0.6681, 0.3319],
        [0.6905, 0.3095],
        [0.6614, 0.3386],
        [0.7075, 0.2925],
        [0.6776, 0.3224],
        [0.6897, 0.3103],
        [0.6673, 0.3327],
        [0.6866, 0.3134],
        [0.6830, 0.3170],
        [0.6995, 0.3005],
        [0.6407, 0.3593],
        [0.6896, 0.3104],
        [0.6980, 0.3020],
        [0.6844, 0.3156],
        [0.6742, 0.3258],
        [0.6649, 0.3351],
        [0.6445, 0.3555],
        [0.7206, 0.2794],
        [0.7278, 0.2722],
        [0.6494, 0.3506],
        [0.6852, 0.3148],
        [0.6760, 0.3240],
        [0.6911, 0.3089],
        [0.6879, 0.3121],
        [0.7100, 0.2900],
        [0.7058, 0.2942],
        [0.7145, 0.2855],
        [0.6962, 0.3038],
        [0.6837, 0.3163],
        [0.6531, 0.3469],
        [0.6805, 0.3195],
        [0.6673, 0.3327],
        [0.6836, 0.3164],
        [0.6993, 0.3007],
        [0.7211, 0.2789],
        [0.6560, 0.3440],
        [0.6677, 0.3323],
        [0.6803, 0.3197],
        [0.6774, 0.3226],
        [0.7099, 0.2901],
        [0.6853, 0.3147],
        [0.6682, 0.3318],
        [0.6605, 0.3395],
        [0.6789, 0.3211],
        [0.6806, 0.3194],
        [0.6709, 0.3291],
        [0.6824, 0.3176],
        [0.7015, 0.2985],
        [0.6741, 0.3259],
        [0.6789, 0.3211],
        [0.6669, 0.3331],
        [0.6674, 0.3326],
        [0.6684, 0.3316],
        [0.6708, 0.3292],
        [0.6659, 0.3341],
        [0.7004, 0.2996],
        [0.6541, 0.3459],
        [0.6936, 0.3064],
        [0.6829, 0.3171],
        [0.6497, 0.3503],
        [0.6817, 0.3183],
        [0.6766, 0.3234],
        [0.6694, 0.3306],
        [0.7003, 0.2997],
        [0.6487, 0.3513],
        [0.6745, 0.3255],
        [0.6955, 0.3045],
        [0.7179, 0.2821],
        [0.6675, 0.3325],
        [0.7010, 0.2990],
        [0.6785, 0.3215],
        [0.6732, 0.3268],
        [0.6849, 0.3151],
        [0.6764, 0.3236],
        [0.6431, 0.3569],
        [0.6906, 0.3094],
        [0.6618, 0.3382],
        [0.7029, 0.2971],
        [0.6932, 0.3068],
        [0.6350, 0.3650],
        [0.6705, 0.3295],
        [0.6647, 0.3353],
        [0.6873, 0.3127],
        [0.7032, 0.2968],
        [0.6985, 0.3015],
        [0.6750, 0.3250],
        [0.6582, 0.3418],
        [0.7029, 0.2971],
        [0.7182, 0.2818],
        [0.7020, 0.2980],
        [0.6720, 0.3280],
        [0.6856, 0.3144],
        [0.6470, 0.3530],
        [0.6739, 0.3261],
        [0.6872, 0.3128],
        [0.7097, 0.2903],
        [0.6888, 0.3112],
        [0.6497, 0.3503],
        [0.6835, 0.3165],
        [0.6845, 0.3155],
        [0.6718, 0.3282],
        [0.6930, 0.3070],
        [0.6883, 0.3117],
        [0.6740, 0.3260],
        [0.6616, 0.3384],
        [0.6775, 0.3225],
        [0.6507, 0.3493],
        [0.6780, 0.3220],
        [0.6997, 0.3003],
        [0.6941, 0.3059],
        [0.6565, 0.3435],
        [0.6511, 0.3489],
        [0.6798, 0.3202],
        [0.6556, 0.3444],
        [0.6595, 0.3405],
        [0.6392, 0.3608],
        [0.7007, 0.2993],
        [0.7094, 0.2906],
        [0.6841, 0.3159],
        [0.6858, 0.3142],
        [0.7222, 0.2778],
        [0.6794, 0.3206],
        [0.7285, 0.2715],
        [0.7138, 0.2862],
        [0.7133, 0.2867],
        [0.7145, 0.2855],
        [0.6562, 0.3438],
        [0.7224, 0.2776],
        [0.6965, 0.3035],
        [0.6636, 0.3364],
        [0.6727, 0.3273],
        [0.6875, 0.3125],
        [0.7001, 0.2999],
        [0.6875, 0.3125],
        [0.6890, 0.3110],
        [0.6684, 0.3316],
        [0.6827, 0.3173],
        [0.6743, 0.3257],
        [0.6601, 0.3399],
        [0.6901, 0.3099],
        [0.6742, 0.3258],
        [0.6681, 0.3319],
        [0.6930, 0.3070],
        [0.6718, 0.3282],
        [0.6625, 0.3375],
        [0.6798, 0.3202],
        [0.6744, 0.3256],
        [0.7121, 0.2879],
        [0.6704, 0.3296],
        [0.6433, 0.3567],
        [0.7164, 0.2836],
        [0.7239, 0.2761],
        [0.6760, 0.3240],
        [0.6697, 0.3303],
        [0.6772, 0.3228],
        [0.6793, 0.3207],
        [0.6888, 0.3112],
        [0.6371, 0.3629],
        [0.6916, 0.3084],
        [0.6521, 0.3479],
        [0.6975, 0.3025],
        [0.7151, 0.2849],
        [0.6861, 0.3139],
        [0.6622, 0.3378],
        [0.6585, 0.3415],
        [0.7183, 0.2817],
        [0.7202, 0.2798],
        [0.7210, 0.2790],
        [0.6479, 0.3521],
        [0.6971, 0.3029],
        [0.6843, 0.3157],
        [0.6661, 0.3339],
        [0.7164, 0.2836],
        [0.7043, 0.2957],
        [0.6593, 0.3407],
        [0.7006, 0.2994],
        [0.6866, 0.3134],
        [0.7251, 0.2749],
        [0.7067, 0.2933],
        [0.6866, 0.3134],
        [0.6518, 0.3482],
        [0.6916, 0.3084],
        [0.6452, 0.3548],
        [0.7051, 0.2949],
        [0.6702, 0.3298],
        [0.6867, 0.3133],
        [0.7290, 0.2710],
        [0.6511, 0.3489],
        [0.6890, 0.3110],
        [0.6951, 0.3049],
        [0.6763, 0.3237],
        [0.6733, 0.3267],
        [0.7245, 0.2755],
        [0.6554, 0.3446],
        [0.6953, 0.3047],
        [0.7001, 0.2999],
        [0.7073, 0.2927],
        [0.6656, 0.3344],
        [0.7026, 0.2974],
        [0.6730, 0.3270],
        [0.6886, 0.3114],
        [0.6723, 0.3277],
        [0.7177, 0.2823],
        [0.7207, 0.2793],
        [0.6690, 0.3310],
        [0.7104, 0.2896],
        [0.7279, 0.2721],
        [0.6820, 0.3180],
        [0.6864, 0.3136],
        [0.6626, 0.3374],
        [0.6834, 0.3166],
        [0.6798, 0.3202],
        [0.6802, 0.3198],
        [0.6605, 0.3395],
        [0.6801, 0.3199],
        [0.7009, 0.2991],
        [0.7249, 0.2751],
        [0.7195, 0.2805],
        [0.7030, 0.2970],
        [0.6818, 0.3182],
        [0.6874, 0.3126],
        [0.6602, 0.3398],
        [0.7406, 0.2594],
        [0.6551, 0.3449],
        [0.7270, 0.2730],
        [0.6932, 0.3068],
        [0.7221, 0.2779],
        [0.6879, 0.3121],
        [0.7204, 0.2796],
        [0.6821, 0.3179],
        [0.7167, 0.2833],
        [0.7030, 0.2970],
        [0.6852, 0.3148],
        [0.7109, 0.2891],
        [0.7097, 0.2903],
        [0.6736, 0.3264],
        [0.6836, 0.3164],
        [0.6946, 0.3054],
        [0.6908, 0.3092],
        [0.6658, 0.3342],
        [0.6841, 0.3159],
        [0.7404, 0.2596],
        [0.7107, 0.2893]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0007 loss: 0.6584 acc_train: 0.6103 time: 0.1101s
tensor([[0.6539, 0.3461],
        [0.6748, 0.3252],
        [0.7308, 0.2692],
        [0.6653, 0.3347],
        [0.7030, 0.2970],
        [0.6434, 0.3566],
        [0.6147, 0.3853],
        [0.6553, 0.3447],
        [0.6620, 0.3380],
        [0.6192, 0.3808],
        [0.6938, 0.3062],
        [0.6421, 0.3579],
        [0.6639, 0.3361],
        [0.6635, 0.3365],
        [0.6939, 0.3061],
        [0.6751, 0.3249],
        [0.6805, 0.3195],
        [0.6267, 0.3733],
        [0.6875, 0.3125],
        [0.6298, 0.3702],
        [0.6927, 0.3073],
        [0.6523, 0.3477],
        [0.6831, 0.3169],
        [0.7252, 0.2748],
        [0.6974, 0.3026],
        [0.6481, 0.3519],
        [0.6222, 0.3778],
        [0.6809, 0.3191],
        [0.6483, 0.3517],
        [0.6538, 0.3462],
        [0.6778, 0.3222],
        [0.6471, 0.3529],
        [0.6978, 0.3022],
        [0.6650, 0.3350],
        [0.6783, 0.3217],
        [0.6634, 0.3366],
        [0.6727, 0.3273],
        [0.6686, 0.3314],
        [0.6831, 0.3169],
        [0.6182, 0.3818],
        [0.6797, 0.3203],
        [0.6853, 0.3147],
        [0.6726, 0.3274],
        [0.6598, 0.3402],
        [0.6537, 0.3463],
        [0.6270, 0.3730],
        [0.7118, 0.2882],
        [0.7221, 0.2779],
        [0.6319, 0.3681],
        [0.6733, 0.3267],
        [0.6623, 0.3377],
        [0.6834, 0.3166],
        [0.6786, 0.3214],
        [0.7016, 0.2984],
        [0.6911, 0.3089],
        [0.7038, 0.2962],
        [0.6860, 0.3140],
        [0.6731, 0.3269],
        [0.6346, 0.3654],
        [0.6628, 0.3372],
        [0.6493, 0.3507],
        [0.6694, 0.3306],
        [0.6890, 0.3110],
        [0.7098, 0.2902],
        [0.6402, 0.3598],
        [0.6492, 0.3508],
        [0.6682, 0.3318],
        [0.6607, 0.3393],
        [0.6930, 0.3070],
        [0.6713, 0.3287],
        [0.6516, 0.3484],
        [0.6424, 0.3576],
        [0.6633, 0.3367],
        [0.6685, 0.3315],
        [0.6564, 0.3436],
        [0.6671, 0.3329],
        [0.6920, 0.3080],
        [0.6570, 0.3430],
        [0.6641, 0.3359],
        [0.6441, 0.3559],
        [0.6472, 0.3528],
        [0.6481, 0.3519],
        [0.6578, 0.3422],
        [0.6510, 0.3490],
        [0.6856, 0.3144],
        [0.6366, 0.3634],
        [0.6830, 0.3170],
        [0.6671, 0.3329],
        [0.6342, 0.3658],
        [0.6697, 0.3303],
        [0.6591, 0.3409],
        [0.6544, 0.3456],
        [0.6890, 0.3110],
        [0.6300, 0.3700],
        [0.6581, 0.3419],
        [0.6861, 0.3139],
        [0.7056, 0.2944],
        [0.6516, 0.3484],
        [0.6871, 0.3129],
        [0.6626, 0.3374],
        [0.6556, 0.3444],
        [0.6658, 0.3342],
        [0.6590, 0.3410],
        [0.6236, 0.3764],
        [0.6801, 0.3199],
        [0.6432, 0.3568],
        [0.6941, 0.3059],
        [0.6819, 0.3181],
        [0.6139, 0.3861],
        [0.6565, 0.3435],
        [0.6539, 0.3461],
        [0.6798, 0.3202],
        [0.6936, 0.3064],
        [0.6884, 0.3116],
        [0.6601, 0.3399],
        [0.6466, 0.3534],
        [0.6888, 0.3112],
        [0.7059, 0.2941],
        [0.6871, 0.3129],
        [0.6620, 0.3380],
        [0.6697, 0.3303],
        [0.6284, 0.3716],
        [0.6580, 0.3420],
        [0.6735, 0.3265],
        [0.6986, 0.3014],
        [0.6734, 0.3266],
        [0.6300, 0.3700],
        [0.6691, 0.3309],
        [0.6703, 0.3297],
        [0.6549, 0.3451],
        [0.6812, 0.3188],
        [0.6713, 0.3287],
        [0.6600, 0.3400],
        [0.6436, 0.3564],
        [0.6573, 0.3427],
        [0.6358, 0.3642],
        [0.6667, 0.3333],
        [0.6881, 0.3119],
        [0.6793, 0.3207],
        [0.6375, 0.3625],
        [0.6332, 0.3668],
        [0.6639, 0.3361],
        [0.6381, 0.3619],
        [0.6422, 0.3578],
        [0.6161, 0.3839],
        [0.6893, 0.3107],
        [0.6991, 0.3009],
        [0.6692, 0.3308],
        [0.6719, 0.3281],
        [0.7148, 0.2852],
        [0.6647, 0.3353],
        [0.7180, 0.2820],
        [0.7034, 0.2966],
        [0.7031, 0.2969],
        [0.7023, 0.2977],
        [0.6370, 0.3630],
        [0.7107, 0.2893],
        [0.6840, 0.3160],
        [0.6473, 0.3527],
        [0.6582, 0.3418],
        [0.6759, 0.3241],
        [0.6875, 0.3125],
        [0.6735, 0.3265],
        [0.6777, 0.3223],
        [0.6588, 0.3412],
        [0.6732, 0.3268],
        [0.6566, 0.3434],
        [0.6439, 0.3561],
        [0.6736, 0.3264],
        [0.6556, 0.3444],
        [0.6596, 0.3404],
        [0.6806, 0.3194],
        [0.6578, 0.3422],
        [0.6420, 0.3580],
        [0.6645, 0.3355],
        [0.6552, 0.3448],
        [0.7015, 0.2985],
        [0.6588, 0.3412],
        [0.6226, 0.3774],
        [0.7041, 0.2959],
        [0.7136, 0.2864],
        [0.6607, 0.3393],
        [0.6575, 0.3425],
        [0.6566, 0.3434],
        [0.6677, 0.3323],
        [0.6780, 0.3220],
        [0.6162, 0.3838],
        [0.6784, 0.3216],
        [0.6371, 0.3629],
        [0.6820, 0.3180],
        [0.7065, 0.2935],
        [0.6743, 0.3257],
        [0.6455, 0.3545],
        [0.6384, 0.3616],
        [0.7088, 0.2912],
        [0.7070, 0.2930],
        [0.7088, 0.2912],
        [0.6269, 0.3731],
        [0.6824, 0.3176],
        [0.6694, 0.3306],
        [0.6440, 0.3560],
        [0.7039, 0.2961],
        [0.6932, 0.3068],
        [0.6458, 0.3542],
        [0.6865, 0.3135],
        [0.6726, 0.3274],
        [0.7176, 0.2824],
        [0.6944, 0.3056],
        [0.6696, 0.3304],
        [0.6356, 0.3644],
        [0.6816, 0.3184],
        [0.6241, 0.3759],
        [0.6949, 0.3051],
        [0.6559, 0.3441],
        [0.6728, 0.3272],
        [0.7227, 0.2773],
        [0.6325, 0.3675],
        [0.6802, 0.3198],
        [0.6808, 0.3192],
        [0.6638, 0.3362],
        [0.6554, 0.3446],
        [0.7142, 0.2858],
        [0.6347, 0.3653],
        [0.6784, 0.3216],
        [0.6924, 0.3076],
        [0.6955, 0.3045],
        [0.6556, 0.3444],
        [0.6924, 0.3076],
        [0.6529, 0.3471],
        [0.6758, 0.3242],
        [0.6550, 0.3450],
        [0.7088, 0.2912],
        [0.7143, 0.2857],
        [0.6534, 0.3466],
        [0.6989, 0.3011],
        [0.7165, 0.2835],
        [0.6695, 0.3305],
        [0.6733, 0.3267],
        [0.6490, 0.3510],
        [0.6744, 0.3256],
        [0.6658, 0.3342],
        [0.6650, 0.3350],
        [0.6450, 0.3550],
        [0.6638, 0.3362],
        [0.6864, 0.3136],
        [0.7144, 0.2856],
        [0.7119, 0.2881],
        [0.6908, 0.3092],
        [0.6707, 0.3293],
        [0.6705, 0.3295],
        [0.6429, 0.3571],
        [0.7331, 0.2669],
        [0.6360, 0.3640],
        [0.7216, 0.2784],
        [0.6823, 0.3177],
        [0.7101, 0.2899],
        [0.6774, 0.3226],
        [0.7090, 0.2910],
        [0.6677, 0.3323],
        [0.7075, 0.2925],
        [0.6878, 0.3122],
        [0.6699, 0.3301],
        [0.7002, 0.2998],
        [0.6988, 0.3012],
        [0.6570, 0.3430],
        [0.6683, 0.3317],
        [0.6837, 0.3163],
        [0.6777, 0.3223],
        [0.6522, 0.3478],
        [0.6739, 0.3261],
        [0.7333, 0.2667],
        [0.7024, 0.2976]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0008 loss: 0.6574 acc_train: 0.6103 time: 0.1136s
tensor([[0.6421, 0.3579],
        [0.6640, 0.3360],
        [0.7207, 0.2793],
        [0.6535, 0.3465],
        [0.6968, 0.3032],
        [0.6311, 0.3689],
        [0.5976, 0.4024],
        [0.6446, 0.3554],
        [0.6515, 0.3485],
        [0.6050, 0.3950],
        [0.6814, 0.3186],
        [0.6316, 0.3684],
        [0.6501, 0.3499],
        [0.6517, 0.3483],
        [0.6819, 0.3181],
        [0.6635, 0.3365],
        [0.6703, 0.3297],
        [0.6123, 0.3877],
        [0.6769, 0.3231],
        [0.6145, 0.3855],
        [0.6854, 0.3146],
        [0.6405, 0.3595],
        [0.6694, 0.3306],
        [0.7166, 0.2834],
        [0.6895, 0.3105],
        [0.6369, 0.3631],
        [0.6052, 0.3948],
        [0.6728, 0.3272],
        [0.6355, 0.3645],
        [0.6438, 0.3562],
        [0.6683, 0.3317],
        [0.6365, 0.3635],
        [0.6893, 0.3107],
        [0.6556, 0.3444],
        [0.6693, 0.3307],
        [0.6602, 0.3398],
        [0.6606, 0.3394],
        [0.6574, 0.3426],
        [0.6695, 0.3305],
        [0.6016, 0.3984],
        [0.6711, 0.3289],
        [0.6747, 0.3253],
        [0.6645, 0.3355],
        [0.6484, 0.3516],
        [0.6472, 0.3528],
        [0.6159, 0.3841],
        [0.7042, 0.2958],
        [0.7183, 0.2817],
        [0.6193, 0.3807],
        [0.6637, 0.3363],
        [0.6518, 0.3482],
        [0.6784, 0.3216],
        [0.6711, 0.3289],
        [0.6958, 0.3042],
        [0.6788, 0.3212],
        [0.6939, 0.3061],
        [0.6786, 0.3214],
        [0.6659, 0.3341],
        [0.6216, 0.3784],
        [0.6492, 0.3508],
        [0.6360, 0.3640],
        [0.6580, 0.3420],
        [0.6804, 0.3196],
        [0.7014, 0.2986],
        [0.6288, 0.3712],
        [0.6350, 0.3650],
        [0.6583, 0.3417],
        [0.6481, 0.3519],
        [0.6796, 0.3204],
        [0.6607, 0.3393],
        [0.6388, 0.3612],
        [0.6287, 0.3713],
        [0.6528, 0.3472],
        [0.6579, 0.3421],
        [0.6439, 0.3561],
        [0.6563, 0.3437],
        [0.6848, 0.3152],
        [0.6451, 0.3549],
        [0.6518, 0.3482],
        [0.6269, 0.3731],
        [0.6317, 0.3683],
        [0.6331, 0.3669],
        [0.6477, 0.3523],
        [0.6404, 0.3596],
        [0.6737, 0.3263],
        [0.6240, 0.3760],
        [0.6739, 0.3261],
        [0.6558, 0.3442],
        [0.6222, 0.3778],
        [0.6612, 0.3388],
        [0.6455, 0.3545],
        [0.6431, 0.3569],
        [0.6795, 0.3205],
        [0.6160, 0.3840],
        [0.6462, 0.3538],
        [0.6790, 0.3210],
        [0.6954, 0.3046],
        [0.6393, 0.3607],
        [0.6759, 0.3241],
        [0.6506, 0.3494],
        [0.6421, 0.3579],
        [0.6506, 0.3494],
        [0.6452, 0.3548],
        [0.6087, 0.3913],
        [0.6731, 0.3269],
        [0.6294, 0.3706],
        [0.6867, 0.3133],
        [0.6734, 0.3266],
        [0.5988, 0.4012],
        [0.6458, 0.3542],
        [0.6464, 0.3536],
        [0.6748, 0.3252],
        [0.6867, 0.3133],
        [0.6806, 0.3194],
        [0.6482, 0.3518],
        [0.6380, 0.3620],
        [0.6788, 0.3212],
        [0.6966, 0.3034],
        [0.6755, 0.3245],
        [0.6548, 0.3452],
        [0.6581, 0.3419],
        [0.6145, 0.3855],
        [0.6460, 0.3540],
        [0.6626, 0.3374],
        [0.6891, 0.3109],
        [0.6613, 0.3387],
        [0.6157, 0.3843],
        [0.6573, 0.3427],
        [0.6590, 0.3410],
        [0.6413, 0.3587],
        [0.6724, 0.3276],
        [0.6598, 0.3402],
        [0.6486, 0.3514],
        [0.6311, 0.3689],
        [0.6416, 0.3584],
        [0.6257, 0.3743],
        [0.6585, 0.3415],
        [0.6791, 0.3209],
        [0.6690, 0.3310],
        [0.6232, 0.3768],
        [0.6210, 0.3790],
        [0.6517, 0.3483],
        [0.6270, 0.3730],
        [0.6288, 0.3712],
        [0.5992, 0.4008],
        [0.6811, 0.3189],
        [0.6918, 0.3082],
        [0.6564, 0.3436],
        [0.6612, 0.3388],
        [0.7081, 0.2919],
        [0.6533, 0.3467],
        [0.7097, 0.2903],
        [0.6953, 0.3047],
        [0.6953, 0.3047],
        [0.6926, 0.3074],
        [0.6231, 0.3769],
        [0.6989, 0.3011],
        [0.6734, 0.3266],
        [0.6348, 0.3652],
        [0.6479, 0.3521],
        [0.6672, 0.3328],
        [0.6776, 0.3224],
        [0.6614, 0.3386],
        [0.6677, 0.3323],
        [0.6518, 0.3482],
        [0.6658, 0.3342],
        [0.6433, 0.3567],
        [0.6299, 0.3701],
        [0.6613, 0.3387],
        [0.6420, 0.3580],
        [0.6539, 0.3461],
        [0.6704, 0.3296],
        [0.6477, 0.3523],
        [0.6276, 0.3724],
        [0.6524, 0.3476],
        [0.6410, 0.3590],
        [0.6930, 0.3070],
        [0.6507, 0.3493],
        [0.6070, 0.3930],
        [0.6944, 0.3056],
        [0.7039, 0.2961],
        [0.6484, 0.3516],
        [0.6484, 0.3516],
        [0.6395, 0.3605],
        [0.6571, 0.3429],
        [0.6686, 0.3314],
        [0.6002, 0.3998],
        [0.6677, 0.3323],
        [0.6259, 0.3741],
        [0.6698, 0.3302],
        [0.6999, 0.3001],
        [0.6651, 0.3349],
        [0.6325, 0.3675],
        [0.6236, 0.3764],
        [0.7016, 0.2984],
        [0.6968, 0.3032],
        [0.6999, 0.3001],
        [0.6097, 0.3903],
        [0.6728, 0.3272],
        [0.6585, 0.3415],
        [0.6285, 0.3715],
        [0.6941, 0.3059],
        [0.6844, 0.3156],
        [0.6360, 0.3640],
        [0.6761, 0.3239],
        [0.6614, 0.3386],
        [0.7118, 0.2882],
        [0.6861, 0.3139],
        [0.6571, 0.3429],
        [0.6241, 0.3759],
        [0.6739, 0.3261],
        [0.6087, 0.3913],
        [0.6864, 0.3136],
        [0.6457, 0.3543],
        [0.6618, 0.3382],
        [0.7176, 0.2824],
        [0.6178, 0.3822],
        [0.6737, 0.3263],
        [0.6697, 0.3303],
        [0.6556, 0.3444],
        [0.6408, 0.3592],
        [0.7051, 0.2949],
        [0.6189, 0.3811],
        [0.6662, 0.3338],
        [0.6872, 0.3128],
        [0.6864, 0.3136],
        [0.6488, 0.3512],
        [0.6843, 0.3157],
        [0.6372, 0.3628],
        [0.6670, 0.3330],
        [0.6426, 0.3574],
        [0.7009, 0.2991],
        [0.7093, 0.2907],
        [0.6425, 0.3575],
        [0.6894, 0.3106],
        [0.7074, 0.2926],
        [0.6604, 0.3396],
        [0.6636, 0.3364],
        [0.6387, 0.3613],
        [0.6667, 0.3333],
        [0.6556, 0.3444],
        [0.6541, 0.3459],
        [0.6344, 0.3656],
        [0.6507, 0.3493],
        [0.6746, 0.3254],
        [0.7045, 0.2955],
        [0.7039, 0.2961],
        [0.6807, 0.3193],
        [0.6622, 0.3378],
        [0.6577, 0.3423],
        [0.6297, 0.3703],
        [0.7265, 0.2735],
        [0.6221, 0.3779],
        [0.7173, 0.2827],
        [0.6750, 0.3250],
        [0.6996, 0.3004],
        [0.6686, 0.3314],
        [0.6992, 0.3008],
        [0.6570, 0.3430],
        [0.6992, 0.3008],
        [0.6764, 0.3236],
        [0.6578, 0.3422],
        [0.6923, 0.3077],
        [0.6915, 0.3085],
        [0.6438, 0.3562],
        [0.6546, 0.3454],
        [0.6762, 0.3238],
        [0.6679, 0.3321],
        [0.6434, 0.3566],
        [0.6663, 0.3337],
        [0.7261, 0.2739],
        [0.6957, 0.3043]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0009 loss: 0.6569 acc_train: 0.6103 time: 0.1163s
tensor([[0.6349, 0.3651],
        [0.6577, 0.3423],
        [0.7137, 0.2863],
        [0.6460, 0.3540],
        [0.6934, 0.3066],
        [0.6234, 0.3766],
        [0.5879, 0.4121],
        [0.6375, 0.3625],
        [0.6454, 0.3546],
        [0.5968, 0.4032],
        [0.6734, 0.3266],
        [0.6253, 0.3747],
        [0.6416, 0.3584],
        [0.6445, 0.3555],
        [0.6756, 0.3244],
        [0.6565, 0.3435],
        [0.6638, 0.3362],
        [0.6035, 0.3965],
        [0.6698, 0.3302],
        [0.6051, 0.3949],
        [0.6814, 0.3186],
        [0.6337, 0.3663],
        [0.6606, 0.3394],
        [0.7105, 0.2895],
        [0.6845, 0.3155],
        [0.6307, 0.3693],
        [0.5954, 0.4046],
        [0.6686, 0.3314],
        [0.6279, 0.3721],
        [0.6374, 0.3626],
        [0.6621, 0.3379],
        [0.6301, 0.3699],
        [0.6832, 0.3168],
        [0.6498, 0.3502],
        [0.6633, 0.3367],
        [0.6585, 0.3415],
        [0.6525, 0.3475],
        [0.6512, 0.3488],
        [0.6616, 0.3384],
        [0.5920, 0.4080],
        [0.6653, 0.3347],
        [0.6675, 0.3325],
        [0.6600, 0.3400],
        [0.6419, 0.3581],
        [0.6437, 0.3563],
        [0.6098, 0.3902],
        [0.6992, 0.3008],
        [0.7163, 0.2837],
        [0.6118, 0.3882],
        [0.6579, 0.3421],
        [0.6452, 0.3548],
        [0.6763, 0.3237],
        [0.6666, 0.3334],
        [0.6920, 0.3080],
        [0.6711, 0.3289],
        [0.6871, 0.3129],
        [0.6744, 0.3256],
        [0.6625, 0.3375],
        [0.6133, 0.3867],
        [0.6407, 0.3593],
        [0.6278, 0.3722],
        [0.6511, 0.3489],
        [0.6760, 0.3240],
        [0.6976, 0.3024],
        [0.6225, 0.3775],
        [0.6259, 0.3741],
        [0.6531, 0.3469],
        [0.6397, 0.3603],
        [0.6707, 0.3293],
        [0.6549, 0.3451],
        [0.6322, 0.3678],
        [0.6203, 0.3797],
        [0.6468, 0.3532],
        [0.6521, 0.3479],
        [0.6356, 0.3644],
        [0.6500, 0.3500],
        [0.6806, 0.3194],
        [0.6386, 0.3614],
        [0.6443, 0.3557],
        [0.6169, 0.3831],
        [0.6218, 0.3782],
        [0.6239, 0.3761],
        [0.6428, 0.3572],
        [0.6342, 0.3658],
        [0.6653, 0.3347],
        [0.6163, 0.3837],
        [0.6686, 0.3314],
        [0.6493, 0.3507],
        [0.6152, 0.3848],
        [0.6567, 0.3433],
        [0.6366, 0.3634],
        [0.6359, 0.3641],
        [0.6729, 0.3271],
        [0.6074, 0.3926],
        [0.6385, 0.3615],
        [0.6748, 0.3252],
        [0.6897, 0.3103],
        [0.6321, 0.3679],
        [0.6687, 0.3313],
        [0.6431, 0.3569],
        [0.6335, 0.3665],
        [0.6411, 0.3589],
        [0.6367, 0.3633],
        [0.5993, 0.4007],
        [0.6694, 0.3306],
        [0.6219, 0.3781],
        [0.6812, 0.3188],
        [0.6685, 0.3315],
        [0.5893, 0.4107],
        [0.6387, 0.3613],
        [0.6435, 0.3565],
        [0.6729, 0.3271],
        [0.6815, 0.3185],
        [0.6760, 0.3240],
        [0.6412, 0.3588],
        [0.6336, 0.3664],
        [0.6735, 0.3265],
        [0.6906, 0.3094],
        [0.6686, 0.3314],
        [0.6525, 0.3475],
        [0.6513, 0.3487],
        [0.6055, 0.3945],
        [0.6393, 0.3607],
        [0.6567, 0.3433],
        [0.6823, 0.3177],
        [0.6539, 0.3461],
        [0.6076, 0.3924],
        [0.6503, 0.3497],
        [0.6522, 0.3478],
        [0.6325, 0.3675],
        [0.6670, 0.3330],
        [0.6539, 0.3461],
        [0.6413, 0.3587],
        [0.6244, 0.3756],
        [0.6315, 0.3685],
        [0.6202, 0.3798],
        [0.6532, 0.3468],
        [0.6745, 0.3255],
        [0.6626, 0.3374],
        [0.6153, 0.3847],
        [0.6136, 0.3864],
        [0.6435, 0.3565],
        [0.6214, 0.3786],
        [0.6209, 0.3791],
        [0.5890, 0.4110],
        [0.6767, 0.3233],
        [0.6876, 0.3124],
        [0.6478, 0.3522],
        [0.6542, 0.3458],
        [0.7050, 0.2950],
        [0.6460, 0.3540],
        [0.7047, 0.2953],
        [0.6907, 0.3093],
        [0.6905, 0.3095],
        [0.6866, 0.3134],
        [0.6162, 0.3838],
        [0.6915, 0.3085],
        [0.6675, 0.3325],
        [0.6271, 0.3729],
        [0.6409, 0.3591],
        [0.6619, 0.3381],
        [0.6714, 0.3286],
        [0.6538, 0.3462],
        [0.6616, 0.3384],
        [0.6487, 0.3513],
        [0.6614, 0.3386],
        [0.6350, 0.3650],
        [0.6212, 0.3788],
        [0.6536, 0.3464],
        [0.6340, 0.3660],
        [0.6512, 0.3488],
        [0.6635, 0.3365],
        [0.6410, 0.3590],
        [0.6195, 0.3805],
        [0.6446, 0.3554],
        [0.6325, 0.3675],
        [0.6871, 0.3129],
        [0.6464, 0.3536],
        [0.5973, 0.4027],
        [0.6886, 0.3114],
        [0.6971, 0.3029],
        [0.6403, 0.3597],
        [0.6430, 0.3570],
        [0.6282, 0.3718],
        [0.6516, 0.3484],
        [0.6630, 0.3370],
        [0.5884, 0.4116],
        [0.6620, 0.3380],
        [0.6192, 0.3808],
        [0.6622, 0.3378],
        [0.6960, 0.3040],
        [0.6593, 0.3407],
        [0.6263, 0.3737],
        [0.6148, 0.3852],
        [0.6970, 0.3030],
        [0.6900, 0.3100],
        [0.6946, 0.3054],
        [0.5982, 0.4018],
        [0.6676, 0.3324],
        [0.6528, 0.3472],
        [0.6192, 0.3808],
        [0.6886, 0.3114],
        [0.6787, 0.3213],
        [0.6301, 0.3699],
        [0.6700, 0.3300],
        [0.6535, 0.3465],
        [0.7078, 0.2922],
        [0.6820, 0.3180],
        [0.6494, 0.3506],
        [0.6179, 0.3821],
        [0.6706, 0.3294],
        [0.5992, 0.4008],
        [0.6802, 0.3198],
        [0.6395, 0.3605],
        [0.6567, 0.3433],
        [0.7141, 0.2859],
        [0.6084, 0.3916],
        [0.6695, 0.3305],
        [0.6629, 0.3371],
        [0.6507, 0.3493],
        [0.6327, 0.3673],
        [0.6991, 0.3009],
        [0.6094, 0.3906],
        [0.6590, 0.3410],
        [0.6844, 0.3156],
        [0.6808, 0.3192],
        [0.6455, 0.3545],
        [0.6795, 0.3205],
        [0.6275, 0.3725],
        [0.6622, 0.3378],
        [0.6353, 0.3647],
        [0.6951, 0.3049],
        [0.7066, 0.2934],
        [0.6360, 0.3640],
        [0.6838, 0.3162],
        [0.7011, 0.2989],
        [0.6561, 0.3439],
        [0.6575, 0.3425],
        [0.6330, 0.3670],
        [0.6614, 0.3386],
        [0.6502, 0.3498],
        [0.6477, 0.3523],
        [0.6287, 0.3713],
        [0.6425, 0.3575],
        [0.6663, 0.3337],
        [0.6975, 0.3025],
        [0.6987, 0.3013],
        [0.6754, 0.3246],
        [0.6571, 0.3429],
        [0.6499, 0.3501],
        [0.6211, 0.3789],
        [0.7221, 0.2779],
        [0.6138, 0.3862],
        [0.7147, 0.2853],
        [0.6704, 0.3296],
        [0.6921, 0.3079],
        [0.6632, 0.3368],
        [0.6925, 0.3075],
        [0.6511, 0.3489],
        [0.6937, 0.3063],
        [0.6688, 0.3312],
        [0.6507, 0.3493],
        [0.6872, 0.3128],
        [0.6873, 0.3127],
        [0.6351, 0.3649],
        [0.6456, 0.3544],
        [0.6721, 0.3279],
        [0.6618, 0.3382],
        [0.6394, 0.3606],
        [0.6623, 0.3377],
        [0.7202, 0.2798],
        [0.6913, 0.3087]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0010 loss: 0.6566 acc_train: 0.6103 time: 0.1174s
tensor([[0.6348, 0.3652],
        [0.6578, 0.3422],
        [0.7115, 0.2885],
        [0.6447, 0.3553],
        [0.6941, 0.3059],
        [0.6233, 0.3767],
        [0.5866, 0.4134],
        [0.6367, 0.3633],
        [0.6457, 0.3543],
        [0.5960, 0.4040],
        [0.6717, 0.3283],
        [0.6253, 0.3747],
        [0.6397, 0.3603],
        [0.6442, 0.3558],
        [0.6755, 0.3245],
        [0.6563, 0.3437],
        [0.6633, 0.3367],
        [0.6014, 0.3986],
        [0.6680, 0.3320],
        [0.6028, 0.3972],
        [0.6818, 0.3182],
        [0.6339, 0.3661],
        [0.6586, 0.3414],
        [0.7100, 0.2900],
        [0.6843, 0.3157],
        [0.6317, 0.3683],
        [0.5942, 0.4058],
        [0.6696, 0.3304],
        [0.6274, 0.3726],
        [0.6366, 0.3634],
        [0.6614, 0.3386],
        [0.6299, 0.3701],
        [0.6824, 0.3176],
        [0.6497, 0.3503],
        [0.6631, 0.3369],
        [0.6609, 0.3391],
        [0.6512, 0.3488],
        [0.6528, 0.3472],
        [0.6612, 0.3388],
        [0.5908, 0.4092],
        [0.6652, 0.3348],
        [0.6662, 0.3338],
        [0.6609, 0.3391],
        [0.6417, 0.3583],
        [0.6447, 0.3553],
        [0.6108, 0.3892],
        [0.6984, 0.3016],
        [0.7178, 0.2822],
        [0.6112, 0.3888],
        [0.6580, 0.3420],
        [0.6442, 0.3558],
        [0.6786, 0.3214],
        [0.6674, 0.3326],
        [0.6923, 0.3077],
        [0.6694, 0.3306],
        [0.6859, 0.3141],
        [0.6741, 0.3259],
        [0.6644, 0.3356],
        [0.6117, 0.3883],
        [0.6391, 0.3609],
        [0.6266, 0.3734],
        [0.6504, 0.3496],
        [0.6762, 0.3238],
        [0.6992, 0.3008],
        [0.6228, 0.3772],
        [0.6242, 0.3758],
        [0.6540, 0.3460],
        [0.6383, 0.3617],
        [0.6694, 0.3306],
        [0.6550, 0.3450],
        [0.6328, 0.3672],
        [0.6186, 0.3814],
        [0.6471, 0.3529],
        [0.6522, 0.3478],
        [0.6337, 0.3663],
        [0.6499, 0.3501],
        [0.6815, 0.3185],
        [0.6388, 0.3612],
        [0.6431, 0.3569],
        [0.6145, 0.3855],
        [0.6205, 0.3795],
        [0.6223, 0.3777],
        [0.6438, 0.3562],
        [0.6344, 0.3656],
        [0.6635, 0.3365],
        [0.6155, 0.3845],
        [0.6691, 0.3309],
        [0.6489, 0.3511],
        [0.6146, 0.3854],
        [0.6576, 0.3424],
        [0.6346, 0.3654],
        [0.6349, 0.3651],
        [0.6719, 0.3281],
        [0.6065, 0.3935],
        [0.6376, 0.3624],
        [0.6752, 0.3248],
        [0.6900, 0.3100],
        [0.6319, 0.3681],
        [0.6675, 0.3325],
        [0.6426, 0.3574],
        [0.6320, 0.3680],
        [0.6389, 0.3611],
        [0.6353, 0.3647],
        [0.5983, 0.4017],
        [0.6704, 0.3296],
        [0.6222, 0.3778],
        [0.6807, 0.3193],
        [0.6689, 0.3311],
        [0.5878, 0.4122],
        [0.6378, 0.3622],
        [0.6463, 0.3537],
        [0.6757, 0.3243],
        [0.6807, 0.3193],
        [0.6768, 0.3232],
        [0.6413, 0.3587],
        [0.6351, 0.3649],
        [0.6743, 0.3257],
        [0.6897, 0.3103],
        [0.6680, 0.3320],
        [0.6558, 0.3442],
        [0.6512, 0.3488],
        [0.6039, 0.3961],
        [0.6398, 0.3602],
        [0.6566, 0.3434],
        [0.6806, 0.3194],
        [0.6535, 0.3465],
        [0.6071, 0.3929],
        [0.6495, 0.3505],
        [0.6518, 0.3482],
        [0.6309, 0.3691],
        [0.6672, 0.3328],
        [0.6539, 0.3461],
        [0.6414, 0.3586],
        [0.6244, 0.3756],
        [0.6289, 0.3711],
        [0.6212, 0.3788],
        [0.6530, 0.3470],
        [0.6763, 0.3237],
        [0.6619, 0.3381],
        [0.6157, 0.3843],
        [0.6125, 0.3875],
        [0.6416, 0.3584],
        [0.6227, 0.3773],
        [0.6195, 0.3805],
        [0.5871, 0.4129],
        [0.6774, 0.3226],
        [0.6877, 0.3123],
        [0.6461, 0.3539],
        [0.6530, 0.3470],
        [0.7052, 0.2948],
        [0.6454, 0.3546],
        [0.7042, 0.2958],
        [0.6907, 0.3093],
        [0.6902, 0.3098],
        [0.6858, 0.3142],
        [0.6172, 0.3828],
        [0.6896, 0.3104],
        [0.6675, 0.3325],
        [0.6262, 0.3738],
        [0.6399, 0.3601],
        [0.6613, 0.3387],
        [0.6708, 0.3292],
        [0.6531, 0.3469],
        [0.6620, 0.3380],
        [0.6513, 0.3487],
        [0.6624, 0.3376],
        [0.6335, 0.3665],
        [0.6207, 0.3793],
        [0.6524, 0.3476],
        [0.6338, 0.3662],
        [0.6528, 0.3472],
        [0.6622, 0.3378],
        [0.6405, 0.3595],
        [0.6190, 0.3810],
        [0.6431, 0.3569],
        [0.6315, 0.3685],
        [0.6857, 0.3143],
        [0.6473, 0.3527],
        [0.5949, 0.4051],
        [0.6878, 0.3122],
        [0.6955, 0.3045],
        [0.6386, 0.3614],
        [0.6428, 0.3572],
        [0.6249, 0.3751],
        [0.6528, 0.3472],
        [0.6631, 0.3369],
        [0.5847, 0.4153],
        [0.6624, 0.3376],
        [0.6187, 0.3813],
        [0.6618, 0.3382],
        [0.6965, 0.3035],
        [0.6590, 0.3410],
        [0.6288, 0.3712],
        [0.6137, 0.3863],
        [0.6971, 0.3029],
        [0.6887, 0.3113],
        [0.6946, 0.3054],
        [0.5946, 0.4054],
        [0.6679, 0.3321],
        [0.6529, 0.3471],
        [0.6178, 0.3822],
        [0.6882, 0.3118],
        [0.6782, 0.3218],
        [0.6304, 0.3696],
        [0.6701, 0.3299],
        [0.6511, 0.3489],
        [0.7075, 0.2925],
        [0.6824, 0.3176],
        [0.6482, 0.3518],
        [0.6191, 0.3809],
        [0.6732, 0.3268],
        [0.5975, 0.4025],
        [0.6787, 0.3213],
        [0.6393, 0.3607],
        [0.6584, 0.3416],
        [0.7137, 0.2863],
        [0.6073, 0.3927],
        [0.6702, 0.3298],
        [0.6619, 0.3381],
        [0.6513, 0.3487],
        [0.6318, 0.3682],
        [0.6981, 0.3019],
        [0.6078, 0.3922],
        [0.6582, 0.3418],
        [0.6853, 0.3147],
        [0.6800, 0.3200],
        [0.6469, 0.3531],
        [0.6794, 0.3206],
        [0.6247, 0.3753],
        [0.6632, 0.3368],
        [0.6346, 0.3654],
        [0.6938, 0.3062],
        [0.7077, 0.2923],
        [0.6357, 0.3643],
        [0.6831, 0.3169],
        [0.6993, 0.3007],
        [0.6572, 0.3428],
        [0.6569, 0.3431],
        [0.6332, 0.3668],
        [0.6609, 0.3391],
        [0.6507, 0.3493],
        [0.6476, 0.3524],
        [0.6295, 0.3705],
        [0.6403, 0.3597],
        [0.6637, 0.3363],
        [0.6955, 0.3045],
        [0.6986, 0.3014],
        [0.6765, 0.3235],
        [0.6575, 0.3425],
        [0.6490, 0.3510],
        [0.6192, 0.3808],
        [0.7217, 0.2783],
        [0.6128, 0.3872],
        [0.7156, 0.2844],
        [0.6711, 0.3289],
        [0.6903, 0.3097],
        [0.6630, 0.3370],
        [0.6914, 0.3086],
        [0.6510, 0.3490],
        [0.6937, 0.3063],
        [0.6671, 0.3329],
        [0.6501, 0.3499],
        [0.6870, 0.3130],
        [0.6874, 0.3126],
        [0.6331, 0.3669],
        [0.6442, 0.3558],
        [0.6728, 0.3272],
        [0.6608, 0.3392],
        [0.6418, 0.3582],
        [0.6634, 0.3366],
        [0.7187, 0.2813],
        [0.6914, 0.3086]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0011 loss: 0.6564 acc_train: 0.6103 time: 0.1167s
tensor([[0.6379, 0.3621],
        [0.6608, 0.3392],
        [0.7114, 0.2886],
        [0.6457, 0.3543],
        [0.6960, 0.3040],
        [0.6275, 0.3725],
        [0.5899, 0.4101],
        [0.6392, 0.3608],
        [0.6488, 0.3512],
        [0.5985, 0.4015],
        [0.6732, 0.3268],
        [0.6283, 0.3717],
        [0.6416, 0.3584],
        [0.6467, 0.3533],
        [0.6779, 0.3221],
        [0.6590, 0.3410],
        [0.6649, 0.3351],
        [0.6027, 0.3973],
        [0.6689, 0.3311],
        [0.6047, 0.3953],
        [0.6834, 0.3166],
        [0.6379, 0.3621],
        [0.6601, 0.3399],
        [0.7111, 0.2889],
        [0.6855, 0.3145],
        [0.6362, 0.3638],
        [0.5983, 0.4017],
        [0.6727, 0.3273],
        [0.6303, 0.3697],
        [0.6384, 0.3616],
        [0.6636, 0.3364],
        [0.6332, 0.3668],
        [0.6836, 0.3164],
        [0.6523, 0.3477],
        [0.6652, 0.3348],
        [0.6642, 0.3358],
        [0.6528, 0.3472],
        [0.6563, 0.3437],
        [0.6642, 0.3358],
        [0.5940, 0.4060],
        [0.6676, 0.3324],
        [0.6670, 0.3330],
        [0.6631, 0.3369],
        [0.6436, 0.3564],
        [0.6471, 0.3529],
        [0.6156, 0.3844],
        [0.6994, 0.3006],
        [0.7200, 0.2800],
        [0.6141, 0.3859],
        [0.6607, 0.3393],
        [0.6464, 0.3536],
        [0.6820, 0.3180],
        [0.6700, 0.3300],
        [0.6943, 0.3057],
        [0.6699, 0.3301],
        [0.6875, 0.3125],
        [0.6753, 0.3247],
        [0.6678, 0.3322],
        [0.6139, 0.3861],
        [0.6409, 0.3591],
        [0.6294, 0.3706],
        [0.6519, 0.3481],
        [0.6781, 0.3219],
        [0.7015, 0.2985],
        [0.6261, 0.3739],
        [0.6262, 0.3738],
        [0.6568, 0.3432],
        [0.6404, 0.3596],
        [0.6709, 0.3291],
        [0.6576, 0.3424],
        [0.6367, 0.3633],
        [0.6203, 0.3797],
        [0.6503, 0.3497],
        [0.6554, 0.3446],
        [0.6351, 0.3649],
        [0.6526, 0.3474],
        [0.6843, 0.3157],
        [0.6423, 0.3577],
        [0.6449, 0.3551],
        [0.6166, 0.3834],
        [0.6236, 0.3764],
        [0.6252, 0.3748],
        [0.6465, 0.3535],
        [0.6376, 0.3624],
        [0.6652, 0.3348],
        [0.6181, 0.3819],
        [0.6717, 0.3283],
        [0.6515, 0.3485],
        [0.6169, 0.3831],
        [0.6606, 0.3394],
        [0.6364, 0.3636],
        [0.6368, 0.3632],
        [0.6740, 0.3260],
        [0.6089, 0.3911],
        [0.6398, 0.3602],
        [0.6773, 0.3227],
        [0.6932, 0.3068],
        [0.6357, 0.3643],
        [0.6691, 0.3309],
        [0.6457, 0.3543],
        [0.6342, 0.3658],
        [0.6407, 0.3593],
        [0.6377, 0.3623],
        [0.6014, 0.3986],
        [0.6731, 0.3269],
        [0.6252, 0.3748],
        [0.6821, 0.3179],
        [0.6714, 0.3286],
        [0.5914, 0.4086],
        [0.6396, 0.3604],
        [0.6514, 0.3486],
        [0.6800, 0.3200],
        [0.6816, 0.3184],
        [0.6796, 0.3204],
        [0.6441, 0.3559],
        [0.6395, 0.3605],
        [0.6779, 0.3221],
        [0.6908, 0.3092],
        [0.6701, 0.3299],
        [0.6606, 0.3394],
        [0.6536, 0.3464],
        [0.6061, 0.3939],
        [0.6430, 0.3570],
        [0.6594, 0.3406],
        [0.6815, 0.3185],
        [0.6563, 0.3437],
        [0.6100, 0.3900],
        [0.6518, 0.3482],
        [0.6544, 0.3456],
        [0.6329, 0.3671],
        [0.6698, 0.3302],
        [0.6567, 0.3433],
        [0.6441, 0.3559],
        [0.6283, 0.3717],
        [0.6304, 0.3696],
        [0.6251, 0.3749],
        [0.6549, 0.3451],
        [0.6803, 0.3197],
        [0.6636, 0.3364],
        [0.6204, 0.3796],
        [0.6154, 0.3846],
        [0.6430, 0.3570],
        [0.6272, 0.3728],
        [0.6219, 0.3781],
        [0.5895, 0.4105],
        [0.6802, 0.3198],
        [0.6897, 0.3103],
        [0.6481, 0.3519],
        [0.6552, 0.3448],
        [0.7064, 0.2936],
        [0.6477, 0.3523],
        [0.7053, 0.2947],
        [0.6926, 0.3074],
        [0.6914, 0.3086],
        [0.6869, 0.3131],
        [0.6213, 0.3787],
        [0.6901, 0.3099],
        [0.6700, 0.3300],
        [0.6288, 0.3712],
        [0.6420, 0.3580],
        [0.6630, 0.3370],
        [0.6726, 0.3274],
        [0.6554, 0.3446],
        [0.6650, 0.3350],
        [0.6549, 0.3451],
        [0.6655, 0.3345],
        [0.6358, 0.3642],
        [0.6239, 0.3761],
        [0.6544, 0.3456],
        [0.6368, 0.3632],
        [0.6561, 0.3439],
        [0.6634, 0.3366],
        [0.6430, 0.3570],
        [0.6216, 0.3784],
        [0.6448, 0.3552],
        [0.6341, 0.3659],
        [0.6866, 0.3134],
        [0.6507, 0.3493],
        [0.5969, 0.4031],
        [0.6890, 0.3110],
        [0.6958, 0.3042],
        [0.6403, 0.3597],
        [0.6453, 0.3547],
        [0.6264, 0.3736],
        [0.6562, 0.3438],
        [0.6644, 0.3356],
        [0.5861, 0.4139],
        [0.6643, 0.3357],
        [0.6210, 0.3790],
        [0.6649, 0.3351],
        [0.6982, 0.3018],
        [0.6607, 0.3393],
        [0.6342, 0.3658],
        [0.6168, 0.3832],
        [0.6992, 0.3008],
        [0.6898, 0.3102],
        [0.6970, 0.3030],
        [0.5961, 0.4039],
        [0.6705, 0.3295],
        [0.6557, 0.3443],
        [0.6200, 0.3800],
        [0.6902, 0.3098],
        [0.6797, 0.3203],
        [0.6338, 0.3662],
        [0.6726, 0.3274],
        [0.6519, 0.3481],
        [0.7085, 0.2915],
        [0.6845, 0.3155],
        [0.6509, 0.3491],
        [0.6235, 0.3765],
        [0.6777, 0.3223],
        [0.6008, 0.3992],
        [0.6791, 0.3209],
        [0.6421, 0.3579],
        [0.6622, 0.3378],
        [0.7146, 0.2854],
        [0.6103, 0.3897],
        [0.6727, 0.3273],
        [0.6636, 0.3364],
        [0.6542, 0.3458],
        [0.6348, 0.3652],
        [0.6990, 0.3010],
        [0.6106, 0.3894],
        [0.6605, 0.3395],
        [0.6871, 0.3129],
        [0.6811, 0.3189],
        [0.6500, 0.3500],
        [0.6815, 0.3185],
        [0.6254, 0.3746],
        [0.6653, 0.3347],
        [0.6371, 0.3629],
        [0.6947, 0.3053],
        [0.7091, 0.2909],
        [0.6384, 0.3616],
        [0.6842, 0.3158],
        [0.6995, 0.3005],
        [0.6608, 0.3392],
        [0.6592, 0.3408],
        [0.6358, 0.3642],
        [0.6625, 0.3375],
        [0.6541, 0.3459],
        [0.6504, 0.3496],
        [0.6334, 0.3666],
        [0.6419, 0.3581],
        [0.6639, 0.3361],
        [0.6956, 0.3044],
        [0.6996, 0.3004],
        [0.6789, 0.3211],
        [0.6600, 0.3400],
        [0.6511, 0.3489],
        [0.6216, 0.3784],
        [0.7222, 0.2778],
        [0.6158, 0.3842],
        [0.7170, 0.2830],
        [0.6733, 0.3267],
        [0.6914, 0.3086],
        [0.6653, 0.3347],
        [0.6926, 0.3074],
        [0.6535, 0.3465],
        [0.6955, 0.3045],
        [0.6688, 0.3312],
        [0.6522, 0.3478],
        [0.6887, 0.3113],
        [0.6892, 0.3108],
        [0.6347, 0.3653],
        [0.6463, 0.3537],
        [0.6752, 0.3248],
        [0.6622, 0.3378],
        [0.6472, 0.3528],
        [0.6662, 0.3338],
        [0.7182, 0.2818],
        [0.6930, 0.3070]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0012 loss: 0.6564 acc_train: 0.6103 time: 0.1278s
tensor([[0.6424, 0.3576],
        [0.6649, 0.3351],
        [0.7120, 0.2880],
        [0.6480, 0.3520],
        [0.6976, 0.3024],
        [0.6339, 0.3661],
        [0.5958, 0.4042],
        [0.6430, 0.3570],
        [0.6529, 0.3471],
        [0.6030, 0.3970],
        [0.6758, 0.3242],
        [0.6327, 0.3673],
        [0.6456, 0.3544],
        [0.6503, 0.3497],
        [0.6812, 0.3188],
        [0.6631, 0.3369],
        [0.6678, 0.3322],
        [0.6068, 0.3932],
        [0.6708, 0.3292],
        [0.6087, 0.3913],
        [0.6851, 0.3149],
        [0.6428, 0.3572],
        [0.6631, 0.3369],
        [0.7125, 0.2875],
        [0.6867, 0.3133],
        [0.6414, 0.3586],
        [0.6051, 0.3949],
        [0.6763, 0.3237],
        [0.6346, 0.3654],
        [0.6415, 0.3585],
        [0.6663, 0.3337],
        [0.6377, 0.3623],
        [0.6851, 0.3149],
        [0.6560, 0.3440],
        [0.6679, 0.3321],
        [0.6672, 0.3328],
        [0.6557, 0.3443],
        [0.6601, 0.3399],
        [0.6686, 0.3314],
        [0.5994, 0.4006],
        [0.6712, 0.3288],
        [0.6686, 0.3314],
        [0.6661, 0.3339],
        [0.6469, 0.3531],
        [0.6498, 0.3502],
        [0.6218, 0.3782],
        [0.7009, 0.2991],
        [0.7218, 0.2782],
        [0.6184, 0.3816],
        [0.6645, 0.3355],
        [0.6499, 0.3501],
        [0.6849, 0.3151],
        [0.6731, 0.3269],
        [0.6967, 0.3033],
        [0.6716, 0.3284],
        [0.6904, 0.3096],
        [0.6773, 0.3227],
        [0.6712, 0.3288],
        [0.6181, 0.3819],
        [0.6445, 0.3555],
        [0.6339, 0.3661],
        [0.6542, 0.3458],
        [0.6804, 0.3196],
        [0.7042, 0.2958],
        [0.6307, 0.3693],
        [0.6299, 0.3701],
        [0.6602, 0.3398],
        [0.6440, 0.3560],
        [0.6735, 0.3265],
        [0.6612, 0.3388],
        [0.6421, 0.3579],
        [0.6237, 0.3763],
        [0.6544, 0.3456],
        [0.6594, 0.3406],
        [0.6382, 0.3618],
        [0.6563, 0.3437],
        [0.6868, 0.3132],
        [0.6474, 0.3526],
        [0.6480, 0.3520],
        [0.6209, 0.3791],
        [0.6283, 0.3717],
        [0.6304, 0.3696],
        [0.6503, 0.3497],
        [0.6420, 0.3580],
        [0.6683, 0.3317],
        [0.6224, 0.3776],
        [0.6748, 0.3252],
        [0.6550, 0.3450],
        [0.6207, 0.3793],
        [0.6640, 0.3360],
        [0.6401, 0.3599],
        [0.6400, 0.3600],
        [0.6770, 0.3230],
        [0.6123, 0.3877],
        [0.6432, 0.3568],
        [0.6800, 0.3200],
        [0.6963, 0.3037],
        [0.6411, 0.3589],
        [0.6717, 0.3283],
        [0.6497, 0.3503],
        [0.6379, 0.3621],
        [0.6445, 0.3555],
        [0.6414, 0.3586],
        [0.6068, 0.3932],
        [0.6761, 0.3239],
        [0.6298, 0.3702],
        [0.6842, 0.3158],
        [0.6745, 0.3255],
        [0.5965, 0.4035],
        [0.6427, 0.3573],
        [0.6568, 0.3432],
        [0.6842, 0.3158],
        [0.6828, 0.3172],
        [0.6827, 0.3173],
        [0.6482, 0.3518],
        [0.6445, 0.3555],
        [0.6820, 0.3180],
        [0.6923, 0.3077],
        [0.6733, 0.3267],
        [0.6656, 0.3344],
        [0.6573, 0.3427],
        [0.6100, 0.3900],
        [0.6470, 0.3530],
        [0.6631, 0.3369],
        [0.6835, 0.3165],
        [0.6601, 0.3399],
        [0.6146, 0.3854],
        [0.6555, 0.3445],
        [0.6580, 0.3420],
        [0.6368, 0.3632],
        [0.6731, 0.3269],
        [0.6607, 0.3393],
        [0.6477, 0.3523],
        [0.6337, 0.3663],
        [0.6344, 0.3656],
        [0.6302, 0.3698],
        [0.6577, 0.3423],
        [0.6841, 0.3159],
        [0.6661, 0.3339],
        [0.6268, 0.3732],
        [0.6203, 0.3797],
        [0.6458, 0.3542],
        [0.6330, 0.3670],
        [0.6261, 0.3739],
        [0.5942, 0.4058],
        [0.6833, 0.3167],
        [0.6919, 0.3081],
        [0.6519, 0.3481],
        [0.6585, 0.3415],
        [0.7075, 0.2925],
        [0.6515, 0.3485],
        [0.7066, 0.2934],
        [0.6950, 0.3050],
        [0.6931, 0.3069],
        [0.6886, 0.3114],
        [0.6274, 0.3726],
        [0.6915, 0.3085],
        [0.6732, 0.3268],
        [0.6327, 0.3673],
        [0.6451, 0.3549],
        [0.6656, 0.3344],
        [0.6753, 0.3247],
        [0.6582, 0.3418],
        [0.6680, 0.3320],
        [0.6583, 0.3417],
        [0.6688, 0.3312],
        [0.6401, 0.3599],
        [0.6282, 0.3718],
        [0.6579, 0.3421],
        [0.6412, 0.3588],
        [0.6593, 0.3407],
        [0.6654, 0.3346],
        [0.6463, 0.3537],
        [0.6257, 0.3743],
        [0.6476, 0.3524],
        [0.6385, 0.3615],
        [0.6884, 0.3116],
        [0.6547, 0.3453],
        [0.6012, 0.3988],
        [0.6908, 0.3092],
        [0.6964, 0.3036],
        [0.6431, 0.3569],
        [0.6491, 0.3509],
        [0.6304, 0.3696],
        [0.6606, 0.3394],
        [0.6665, 0.3335],
        [0.5905, 0.4095],
        [0.6669, 0.3331],
        [0.6253, 0.3747],
        [0.6691, 0.3309],
        [0.6999, 0.3001],
        [0.6634, 0.3366],
        [0.6406, 0.3594],
        [0.6219, 0.3781],
        [0.7015, 0.2985],
        [0.6915, 0.3085],
        [0.6999, 0.3001],
        [0.6007, 0.3993],
        [0.6734, 0.3266],
        [0.6595, 0.3405],
        [0.6242, 0.3758],
        [0.6931, 0.3069],
        [0.6815, 0.3185],
        [0.6385, 0.3615],
        [0.6759, 0.3241],
        [0.6544, 0.3456],
        [0.7097, 0.2903],
        [0.6865, 0.3135],
        [0.6547, 0.3453],
        [0.6289, 0.3711],
        [0.6819, 0.3181],
        [0.6065, 0.3935],
        [0.6800, 0.3200],
        [0.6460, 0.3540],
        [0.6662, 0.3338],
        [0.7154, 0.2846],
        [0.6153, 0.3847],
        [0.6753, 0.3247],
        [0.6663, 0.3337],
        [0.6576, 0.3424],
        [0.6399, 0.3601],
        [0.6998, 0.3002],
        [0.6157, 0.3843],
        [0.6641, 0.3359],
        [0.6892, 0.3108],
        [0.6825, 0.3175],
        [0.6538, 0.3462],
        [0.6837, 0.3163],
        [0.6278, 0.3722],
        [0.6673, 0.3327],
        [0.6410, 0.3590],
        [0.6962, 0.3038],
        [0.7101, 0.2899],
        [0.6424, 0.3576],
        [0.6861, 0.3139],
        [0.6999, 0.3001],
        [0.6647, 0.3353],
        [0.6627, 0.3373],
        [0.6393, 0.3607],
        [0.6648, 0.3352],
        [0.6583, 0.3417],
        [0.6542, 0.3458],
        [0.6384, 0.3616],
        [0.6457, 0.3543],
        [0.6653, 0.3347],
        [0.6966, 0.3034],
        [0.7008, 0.2992],
        [0.6816, 0.3184],
        [0.6632, 0.3368],
        [0.6544, 0.3456],
        [0.6263, 0.3737],
        [0.7222, 0.2778],
        [0.6209, 0.3791],
        [0.7182, 0.2818],
        [0.6759, 0.3241],
        [0.6938, 0.3062],
        [0.6681, 0.3319],
        [0.6936, 0.3064],
        [0.6569, 0.3431],
        [0.6974, 0.3026],
        [0.6715, 0.3285],
        [0.6552, 0.3448],
        [0.6906, 0.3094],
        [0.6915, 0.3085],
        [0.6376, 0.3624],
        [0.6496, 0.3504],
        [0.6779, 0.3221],
        [0.6647, 0.3353],
        [0.6531, 0.3469],
        [0.6695, 0.3305],
        [0.7179, 0.2821],
        [0.6947, 0.3053]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0013 loss: 0.6567 acc_train: 0.6103 time: 0.1105s
tensor([[0.6463, 0.3537],
        [0.6681, 0.3319],
        [0.7119, 0.2881],
        [0.6499, 0.3501],
        [0.6981, 0.3019],
        [0.6395, 0.3605],
        [0.6020, 0.3980],
        [0.6465, 0.3535],
        [0.6565, 0.3435],
        [0.6075, 0.3925],
        [0.6778, 0.3222],
        [0.6368, 0.3632],
        [0.6483, 0.3517],
        [0.6536, 0.3464],
        [0.6834, 0.3166],
        [0.6657, 0.3343],
        [0.6703, 0.3297],
        [0.6114, 0.3886],
        [0.6722, 0.3278],
        [0.6127, 0.3873],
        [0.6856, 0.3144],
        [0.6469, 0.3531],
        [0.6654, 0.3346],
        [0.7126, 0.2874],
        [0.6868, 0.3132],
        [0.6454, 0.3546],
        [0.6122, 0.3878],
        [0.6784, 0.3216],
        [0.6381, 0.3619],
        [0.6441, 0.3559],
        [0.6686, 0.3314],
        [0.6416, 0.3584],
        [0.6857, 0.3143],
        [0.6590, 0.3410],
        [0.6701, 0.3299],
        [0.6691, 0.3309],
        [0.6582, 0.3418],
        [0.6625, 0.3375],
        [0.6724, 0.3276],
        [0.6045, 0.3955],
        [0.6737, 0.3263],
        [0.6695, 0.3305],
        [0.6684, 0.3316],
        [0.6500, 0.3500],
        [0.6516, 0.3484],
        [0.6279, 0.3721],
        [0.7013, 0.2987],
        [0.7215, 0.2785],
        [0.6227, 0.3773],
        [0.6677, 0.3323],
        [0.6530, 0.3470],
        [0.6864, 0.3136],
        [0.6747, 0.3253],
        [0.6977, 0.3023],
        [0.6729, 0.3271],
        [0.6922, 0.3078],
        [0.6782, 0.3218],
        [0.6730, 0.3270],
        [0.6220, 0.3780],
        [0.6481, 0.3519],
        [0.6381, 0.3619],
        [0.6563, 0.3437],
        [0.6813, 0.3187],
        [0.7054, 0.2946],
        [0.6349, 0.3651],
        [0.6332, 0.3668],
        [0.6632, 0.3368],
        [0.6475, 0.3525],
        [0.6755, 0.3245],
        [0.6638, 0.3362],
        [0.6473, 0.3527],
        [0.6271, 0.3729],
        [0.6575, 0.3425],
        [0.6621, 0.3379],
        [0.6415, 0.3585],
        [0.6591, 0.3409],
        [0.6877, 0.3123],
        [0.6521, 0.3479],
        [0.6503, 0.3497],
        [0.6257, 0.3743],
        [0.6324, 0.3676],
        [0.6357, 0.3643],
        [0.6528, 0.3472],
        [0.6459, 0.3541],
        [0.6708, 0.3292],
        [0.6265, 0.3735],
        [0.6764, 0.3236],
        [0.6580, 0.3420],
        [0.6240, 0.3760],
        [0.6665, 0.3335],
        [0.6436, 0.3564],
        [0.6428, 0.3572],
        [0.6791, 0.3209],
        [0.6161, 0.3839],
        [0.6463, 0.3537],
        [0.6817, 0.3183],
        [0.6978, 0.3022],
        [0.6452, 0.3548],
        [0.6737, 0.3263],
        [0.6529, 0.3471],
        [0.6413, 0.3587],
        [0.6482, 0.3518],
        [0.6449, 0.3551],
        [0.6125, 0.3875],
        [0.6778, 0.3222],
        [0.6346, 0.3654],
        [0.6852, 0.3148],
        [0.6765, 0.3235],
        [0.6025, 0.3975],
        [0.6452, 0.3548],
        [0.6613, 0.3387],
        [0.6868, 0.3132],
        [0.6831, 0.3169],
        [0.6846, 0.3154],
        [0.6516, 0.3484],
        [0.6485, 0.3515],
        [0.6853, 0.3147],
        [0.6930, 0.3070],
        [0.6759, 0.3241],
        [0.6686, 0.3314],
        [0.6603, 0.3397],
        [0.6144, 0.3856],
        [0.6503, 0.3497],
        [0.6657, 0.3343],
        [0.6849, 0.3151],
        [0.6631, 0.3369],
        [0.6194, 0.3806],
        [0.6584, 0.3416],
        [0.6610, 0.3390],
        [0.6403, 0.3597],
        [0.6756, 0.3244],
        [0.6638, 0.3362],
        [0.6508, 0.3492],
        [0.6377, 0.3623],
        [0.6386, 0.3614],
        [0.6349, 0.3651],
        [0.6595, 0.3405],
        [0.6865, 0.3135],
        [0.6679, 0.3321],
        [0.6325, 0.3675],
        [0.6255, 0.3745],
        [0.6483, 0.3517],
        [0.6378, 0.3622],
        [0.6302, 0.3698],
        [0.5994, 0.4006],
        [0.6853, 0.3147],
        [0.6929, 0.3071],
        [0.6552, 0.3448],
        [0.6610, 0.3390],
        [0.7070, 0.2930],
        [0.6545, 0.3455],
        [0.7062, 0.2938],
        [0.6963, 0.3037],
        [0.6930, 0.3070],
        [0.6895, 0.3105],
        [0.6328, 0.3672],
        [0.6920, 0.3080],
        [0.6753, 0.3247],
        [0.6361, 0.3639],
        [0.6480, 0.3520],
        [0.6678, 0.3322],
        [0.6771, 0.3229],
        [0.6602, 0.3398],
        [0.6701, 0.3299],
        [0.6605, 0.3395],
        [0.6709, 0.3291],
        [0.6442, 0.3558],
        [0.6320, 0.3680],
        [0.6604, 0.3396],
        [0.6447, 0.3553],
        [0.6617, 0.3383],
        [0.6667, 0.3333],
        [0.6487, 0.3513],
        [0.6296, 0.3704],
        [0.6499, 0.3501],
        [0.6428, 0.3572],
        [0.6895, 0.3105],
        [0.6580, 0.3420],
        [0.6056, 0.3944],
        [0.6918, 0.3082],
        [0.6958, 0.3042],
        [0.6453, 0.3547],
        [0.6525, 0.3475],
        [0.6346, 0.3654],
        [0.6641, 0.3359],
        [0.6674, 0.3326],
        [0.5955, 0.4045],
        [0.6687, 0.3313],
        [0.6293, 0.3707],
        [0.6726, 0.3274],
        [0.7004, 0.2996],
        [0.6655, 0.3345],
        [0.6456, 0.3544],
        [0.6267, 0.3733],
        [0.7024, 0.2976],
        [0.6924, 0.3076],
        [0.7017, 0.2983],
        [0.6059, 0.3941],
        [0.6756, 0.3244],
        [0.6628, 0.3372],
        [0.6287, 0.3713],
        [0.6946, 0.3054],
        [0.6823, 0.3177],
        [0.6425, 0.3575],
        [0.6781, 0.3219],
        [0.6564, 0.3436],
        [0.7100, 0.2900],
        [0.6872, 0.3128],
        [0.6572, 0.3428],
        [0.6336, 0.3664],
        [0.6845, 0.3155],
        [0.6124, 0.3876],
        [0.6798, 0.3202],
        [0.6493, 0.3507],
        [0.6694, 0.3306],
        [0.7144, 0.2856],
        [0.6202, 0.3798],
        [0.6760, 0.3240],
        [0.6679, 0.3321],
        [0.6604, 0.3396],
        [0.6448, 0.3552],
        [0.6994, 0.3006],
        [0.6210, 0.3790],
        [0.6668, 0.3332],
        [0.6896, 0.3104],
        [0.6829, 0.3171],
        [0.6564, 0.3436],
        [0.6846, 0.3154],
        [0.6301, 0.3699],
        [0.6680, 0.3320],
        [0.6446, 0.3554],
        [0.6967, 0.3033],
        [0.7097, 0.2903],
        [0.6458, 0.3542],
        [0.6873, 0.3127],
        [0.6994, 0.3006],
        [0.6674, 0.3326],
        [0.6652, 0.3348],
        [0.6420, 0.3580],
        [0.6666, 0.3334],
        [0.6622, 0.3378],
        [0.6572, 0.3428],
        [0.6425, 0.3575],
        [0.6493, 0.3507],
        [0.6661, 0.3339],
        [0.6967, 0.3033],
        [0.7007, 0.2993],
        [0.6831, 0.3169],
        [0.6658, 0.3342],
        [0.6568, 0.3432],
        [0.6307, 0.3693],
        [0.7207, 0.2793],
        [0.6259, 0.3741],
        [0.7178, 0.2822],
        [0.6776, 0.3224],
        [0.6955, 0.3045],
        [0.6701, 0.3299],
        [0.6934, 0.3066],
        [0.6595, 0.3405],
        [0.6977, 0.3023],
        [0.6734, 0.3266],
        [0.6574, 0.3426],
        [0.6913, 0.3087],
        [0.6928, 0.3072],
        [0.6401, 0.3599],
        [0.6530, 0.3470],
        [0.6796, 0.3204],
        [0.6665, 0.3335],
        [0.6579, 0.3421],
        [0.6717, 0.3283],
        [0.7165, 0.2835],
        [0.6951, 0.3049]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0014 loss: 0.6572 acc_train: 0.6103 time: 0.1183s
tensor([[0.6487, 0.3513],
        [0.6699, 0.3301],
        [0.7101, 0.2899],
        [0.6506, 0.3494],
        [0.6972, 0.3028],
        [0.6428, 0.3572],
        [0.6076, 0.3924],
        [0.6491, 0.3509],
        [0.6586, 0.3414],
        [0.6113, 0.3887],
        [0.6784, 0.3216],
        [0.6400, 0.3600],
        [0.6493, 0.3507],
        [0.6559, 0.3441],
        [0.6839, 0.3161],
        [0.6672, 0.3328],
        [0.6715, 0.3285],
        [0.6155, 0.3845],
        [0.6730, 0.3270],
        [0.6157, 0.3843],
        [0.6847, 0.3153],
        [0.6492, 0.3508],
        [0.6667, 0.3333],
        [0.7111, 0.2889],
        [0.6856, 0.3144],
        [0.6487, 0.3513],
        [0.6185, 0.3815],
        [0.6788, 0.3212],
        [0.6404, 0.3596],
        [0.6457, 0.3543],
        [0.6697, 0.3303],
        [0.6444, 0.3556],
        [0.6852, 0.3148],
        [0.6608, 0.3392],
        [0.6711, 0.3289],
        [0.6692, 0.3308],
        [0.6598, 0.3402],
        [0.6633, 0.3367],
        [0.6742, 0.3258],
        [0.6088, 0.3912],
        [0.6747, 0.3253],
        [0.6694, 0.3306],
        [0.6697, 0.3303],
        [0.6517, 0.3483],
        [0.6522, 0.3478],
        [0.6330, 0.3670],
        [0.7003, 0.2997],
        [0.7194, 0.2806],
        [0.6267, 0.3733],
        [0.6694, 0.3306],
        [0.6548, 0.3452],
        [0.6863, 0.3137],
        [0.6747, 0.3253],
        [0.6967, 0.3033],
        [0.6734, 0.3266],
        [0.6925, 0.3075],
        [0.6782, 0.3218],
        [0.6734, 0.3266],
        [0.6258, 0.3742],
        [0.6503, 0.3497],
        [0.6407, 0.3593],
        [0.6577, 0.3423],
        [0.6809, 0.3191],
        [0.7049, 0.2951],
        [0.6379, 0.3621],
        [0.6351, 0.3649],
        [0.6649, 0.3351],
        [0.6498, 0.3502],
        [0.6764, 0.3236],
        [0.6649, 0.3351],
        [0.6512, 0.3488],
        [0.6301, 0.3699],
        [0.6593, 0.3407],
        [0.6632, 0.3368],
        [0.6444, 0.3556],
        [0.6605, 0.3395],
        [0.6872, 0.3128],
        [0.6554, 0.3446],
        [0.6521, 0.3479],
        [0.6298, 0.3702],
        [0.6357, 0.3643],
        [0.6397, 0.3603],
        [0.6531, 0.3469],
        [0.6486, 0.3514],
        [0.6721, 0.3279],
        [0.6297, 0.3703],
        [0.6760, 0.3240],
        [0.6599, 0.3401],
        [0.6266, 0.3734],
        [0.6672, 0.3328],
        [0.6464, 0.3536],
        [0.6443, 0.3557],
        [0.6797, 0.3203],
        [0.6199, 0.3801],
        [0.6486, 0.3514],
        [0.6822, 0.3178],
        [0.6978, 0.3022],
        [0.6481, 0.3519],
        [0.6748, 0.3252],
        [0.6544, 0.3456],
        [0.6432, 0.3568],
        [0.6512, 0.3488],
        [0.6476, 0.3524],
        [0.6174, 0.3826],
        [0.6782, 0.3218],
        [0.6381, 0.3619],
        [0.6848, 0.3152],
        [0.6773, 0.3227],
        [0.6084, 0.3916],
        [0.6467, 0.3533],
        [0.6642, 0.3358],
        [0.6871, 0.3129],
        [0.6815, 0.3185],
        [0.6849, 0.3151],
        [0.6540, 0.3460],
        [0.6505, 0.3495],
        [0.6868, 0.3132],
        [0.6926, 0.3074],
        [0.6767, 0.3233],
        [0.6700, 0.3300],
        [0.6622, 0.3378],
        [0.6185, 0.3815],
        [0.6524, 0.3476],
        [0.6671, 0.3329],
        [0.6845, 0.3155],
        [0.6648, 0.3352],
        [0.6235, 0.3765],
        [0.6599, 0.3401],
        [0.6627, 0.3373],
        [0.6432, 0.3568],
        [0.6768, 0.3232],
        [0.6651, 0.3349],
        [0.6529, 0.3471],
        [0.6406, 0.3594],
        [0.6421, 0.3579],
        [0.6386, 0.3614],
        [0.6603, 0.3397],
        [0.6875, 0.3125],
        [0.6684, 0.3316],
        [0.6365, 0.3635],
        [0.6299, 0.3701],
        [0.6499, 0.3501],
        [0.6411, 0.3589],
        [0.6332, 0.3668],
        [0.6046, 0.3954],
        [0.6857, 0.3143],
        [0.6924, 0.3076],
        [0.6572, 0.3428],
        [0.6624, 0.3376],
        [0.7050, 0.2950],
        [0.6563, 0.3437],
        [0.7043, 0.2957],
        [0.6956, 0.3044],
        [0.6911, 0.3089],
        [0.6890, 0.3110],
        [0.6373, 0.3627],
        [0.6917, 0.3083],
        [0.6761, 0.3239],
        [0.6384, 0.3616],
        [0.6501, 0.3499],
        [0.6690, 0.3310],
        [0.6776, 0.3224],
        [0.6609, 0.3391],
        [0.6708, 0.3292],
        [0.6610, 0.3390],
        [0.6714, 0.3286],
        [0.6470, 0.3530],
        [0.6350, 0.3650],
        [0.6618, 0.3382],
        [0.6474, 0.3526],
        [0.6631, 0.3369],
        [0.6668, 0.3332],
        [0.6498, 0.3502],
        [0.6327, 0.3673],
        [0.6519, 0.3481],
        [0.6459, 0.3541],
        [0.6894, 0.3106],
        [0.6601, 0.3399],
        [0.6101, 0.3899],
        [0.6913, 0.3087],
        [0.6939, 0.3061],
        [0.6463, 0.3537],
        [0.6546, 0.3454],
        [0.6384, 0.3616],
        [0.6660, 0.3340],
        [0.6671, 0.3329],
        [0.6003, 0.3997],
        [0.6696, 0.3304],
        [0.6324, 0.3676],
        [0.6748, 0.3252],
        [0.6996, 0.3004],
        [0.6666, 0.3334],
        [0.6488, 0.3512],
        [0.6302, 0.3698],
        [0.7017, 0.2983],
        [0.6918, 0.3082],
        [0.7019, 0.2981],
        [0.6110, 0.3890],
        [0.6764, 0.3236],
        [0.6646, 0.3354],
        [0.6321, 0.3679],
        [0.6942, 0.3058],
        [0.6818, 0.3182],
        [0.6451, 0.3549],
        [0.6787, 0.3213],
        [0.6571, 0.3429],
        [0.7090, 0.2910],
        [0.6864, 0.3136],
        [0.6583, 0.3417],
        [0.6367, 0.3633],
        [0.6854, 0.3146],
        [0.6175, 0.3825],
        [0.6787, 0.3213],
        [0.6516, 0.3484],
        [0.6716, 0.3284],
        [0.7114, 0.2886],
        [0.6243, 0.3757],
        [0.6749, 0.3251],
        [0.6683, 0.3317],
        [0.6623, 0.3377],
        [0.6486, 0.3514],
        [0.6977, 0.3023],
        [0.6253, 0.3747],
        [0.6681, 0.3319],
        [0.6885, 0.3115],
        [0.6823, 0.3177],
        [0.6579, 0.3421],
        [0.6840, 0.3160],
        [0.6319, 0.3681],
        [0.6672, 0.3328],
        [0.6476, 0.3524],
        [0.6957, 0.3043],
        [0.7074, 0.2926],
        [0.6480, 0.3520],
        [0.6872, 0.3128],
        [0.6983, 0.3017],
        [0.6690, 0.3310],
        [0.6662, 0.3338],
        [0.6440, 0.3560],
        [0.6673, 0.3327],
        [0.6648, 0.3352],
        [0.6589, 0.3411],
        [0.6452, 0.3548],
        [0.6520, 0.3480],
        [0.6664, 0.3336],
        [0.6960, 0.3040],
        [0.6992, 0.3008],
        [0.6833, 0.3167],
        [0.6673, 0.3327],
        [0.6585, 0.3415],
        [0.6339, 0.3661],
        [0.7173, 0.2827],
        [0.6302, 0.3698],
        [0.7155, 0.2845],
        [0.6784, 0.3216],
        [0.6958, 0.3042],
        [0.6708, 0.3292],
        [0.6919, 0.3081],
        [0.6613, 0.3387],
        [0.6962, 0.3038],
        [0.6737, 0.3263],
        [0.6590, 0.3410],
        [0.6904, 0.3096],
        [0.6927, 0.3073],
        [0.6423, 0.3577],
        [0.6563, 0.3437],
        [0.6802, 0.3198],
        [0.6670, 0.3330],
        [0.6606, 0.3394],
        [0.6723, 0.3277],
        [0.7137, 0.2863],
        [0.6941, 0.3059]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0015 loss: 0.6579 acc_train: 0.6103 time: 0.1116s
tensor([[0.6500, 0.3500],
        [0.6701, 0.3299],
        [0.7066, 0.2934],
        [0.6507, 0.3493],
        [0.6949, 0.3051],
        [0.6444, 0.3556],
        [0.6125, 0.3875],
        [0.6500, 0.3500],
        [0.6594, 0.3406],
        [0.6138, 0.3862],
        [0.6769, 0.3231],
        [0.6422, 0.3578],
        [0.6494, 0.3506],
        [0.6564, 0.3436],
        [0.6829, 0.3171],
        [0.6672, 0.3328],
        [0.6714, 0.3286],
        [0.6190, 0.3810],
        [0.6724, 0.3276],
        [0.6182, 0.3818],
        [0.6823, 0.3177],
        [0.6499, 0.3501],
        [0.6667, 0.3333],
        [0.7079, 0.2921],
        [0.6831, 0.3169],
        [0.6510, 0.3490],
        [0.6235, 0.3765],
        [0.6775, 0.3225],
        [0.6413, 0.3587],
        [0.6466, 0.3534],
        [0.6694, 0.3306],
        [0.6459, 0.3541],
        [0.6835, 0.3165],
        [0.6607, 0.3393],
        [0.6703, 0.3297],
        [0.6680, 0.3320],
        [0.6603, 0.3397],
        [0.6625, 0.3375],
        [0.6740, 0.3260],
        [0.6119, 0.3881],
        [0.6745, 0.3255],
        [0.6681, 0.3319],
        [0.6695, 0.3305],
        [0.6522, 0.3478],
        [0.6519, 0.3481],
        [0.6364, 0.3636],
        [0.6973, 0.3027],
        [0.7155, 0.2845],
        [0.6296, 0.3704],
        [0.6693, 0.3307],
        [0.6554, 0.3446],
        [0.6846, 0.3154],
        [0.6733, 0.3267],
        [0.6941, 0.3059],
        [0.6728, 0.3272],
        [0.6909, 0.3091],
        [0.6774, 0.3226],
        [0.6727, 0.3273],
        [0.6283, 0.3717],
        [0.6515, 0.3485],
        [0.6420, 0.3580],
        [0.6577, 0.3423],
        [0.6792, 0.3208],
        [0.7021, 0.2979],
        [0.6394, 0.3606],
        [0.6364, 0.3636],
        [0.6658, 0.3342],
        [0.6508, 0.3492],
        [0.6762, 0.3238],
        [0.6644, 0.3356],
        [0.6536, 0.3464],
        [0.6324, 0.3676],
        [0.6599, 0.3401],
        [0.6630, 0.3370],
        [0.6459, 0.3541],
        [0.6604, 0.3396],
        [0.6849, 0.3151],
        [0.6570, 0.3430],
        [0.6532, 0.3468],
        [0.6330, 0.3670],
        [0.6374, 0.3626],
        [0.6420, 0.3580],
        [0.6513, 0.3487],
        [0.6499, 0.3501],
        [0.6715, 0.3285],
        [0.6319, 0.3681],
        [0.6744, 0.3256],
        [0.6606, 0.3394],
        [0.6285, 0.3715],
        [0.6669, 0.3331],
        [0.6481, 0.3519],
        [0.6451, 0.3549],
        [0.6785, 0.3215],
        [0.6231, 0.3769],
        [0.6499, 0.3501],
        [0.6809, 0.3191],
        [0.6957, 0.3043],
        [0.6499, 0.3501],
        [0.6749, 0.3251],
        [0.6547, 0.3453],
        [0.6440, 0.3560],
        [0.6530, 0.3470],
        [0.6489, 0.3511],
        [0.6217, 0.3783],
        [0.6766, 0.3234],
        [0.6404, 0.3596],
        [0.6826, 0.3174],
        [0.6766, 0.3234],
        [0.6134, 0.3866],
        [0.6475, 0.3525],
        [0.6654, 0.3346],
        [0.6855, 0.3145],
        [0.6785, 0.3215],
        [0.6835, 0.3165],
        [0.6552, 0.3448],
        [0.6505, 0.3495],
        [0.6862, 0.3138],
        [0.6907, 0.3093],
        [0.6764, 0.3236],
        [0.6701, 0.3299],
        [0.6627, 0.3373],
        [0.6223, 0.3777],
        [0.6528, 0.3472],
        [0.6670, 0.3330],
        [0.6823, 0.3177],
        [0.6646, 0.3354],
        [0.6264, 0.3736],
        [0.6601, 0.3399],
        [0.6630, 0.3370],
        [0.6452, 0.3548],
        [0.6761, 0.3239],
        [0.6650, 0.3350],
        [0.6538, 0.3462],
        [0.6420, 0.3580],
        [0.6449, 0.3551],
        [0.6409, 0.3591],
        [0.6599, 0.3401],
        [0.6872, 0.3128],
        [0.6679, 0.3321],
        [0.6389, 0.3611],
        [0.6336, 0.3664],
        [0.6508, 0.3492],
        [0.6428, 0.3572],
        [0.6353, 0.3647],
        [0.6093, 0.3907],
        [0.6840, 0.3160],
        [0.6902, 0.3098],
        [0.6578, 0.3422],
        [0.6629, 0.3371],
        [0.7018, 0.2982],
        [0.6566, 0.3434],
        [0.7006, 0.2994],
        [0.6933, 0.3067],
        [0.6881, 0.3119],
        [0.6869, 0.3131],
        [0.6398, 0.3602],
        [0.6896, 0.3104],
        [0.6750, 0.3250],
        [0.6395, 0.3605],
        [0.6512, 0.3488],
        [0.6686, 0.3314],
        [0.6766, 0.3234],
        [0.6604, 0.3396],
        [0.6700, 0.3300],
        [0.6597, 0.3403],
        [0.6706, 0.3294],
        [0.6488, 0.3512],
        [0.6366, 0.3634],
        [0.6618, 0.3382],
        [0.6488, 0.3512],
        [0.6629, 0.3371],
        [0.6655, 0.3345],
        [0.6485, 0.3515],
        [0.6349, 0.3651],
        [0.6530, 0.3470],
        [0.6476, 0.3524],
        [0.6874, 0.3126],
        [0.6608, 0.3392],
        [0.6141, 0.3859],
        [0.6894, 0.3106],
        [0.6908, 0.3092],
        [0.6464, 0.3536],
        [0.6555, 0.3445],
        [0.6410, 0.3590],
        [0.6662, 0.3338],
        [0.6658, 0.3342],
        [0.6046, 0.3954],
        [0.6692, 0.3308],
        [0.6345, 0.3655],
        [0.6755, 0.3245],
        [0.6972, 0.3028],
        [0.6661, 0.3339],
        [0.6503, 0.3497],
        [0.6326, 0.3674],
        [0.6993, 0.3007],
        [0.6897, 0.3103],
        [0.6998, 0.3002],
        [0.6158, 0.3842],
        [0.6753, 0.3247],
        [0.6650, 0.3350],
        [0.6341, 0.3659],
        [0.6920, 0.3080],
        [0.6802, 0.3198],
        [0.6463, 0.3537],
        [0.6779, 0.3221],
        [0.6567, 0.3433],
        [0.7062, 0.2938],
        [0.6841, 0.3159],
        [0.6580, 0.3420],
        [0.6377, 0.3623],
        [0.6845, 0.3155],
        [0.6213, 0.3787],
        [0.6766, 0.3234],
        [0.6524, 0.3476],
        [0.6721, 0.3279],
        [0.7069, 0.2931],
        [0.6274, 0.3726],
        [0.6721, 0.3279],
        [0.6672, 0.3328],
        [0.6630, 0.3370],
        [0.6506, 0.3494],
        [0.6944, 0.3056],
        [0.6286, 0.3714],
        [0.6681, 0.3319],
        [0.6857, 0.3143],
        [0.6806, 0.3194],
        [0.6580, 0.3420],
        [0.6822, 0.3178],
        [0.6336, 0.3664],
        [0.6649, 0.3351],
        [0.6494, 0.3506],
        [0.6929, 0.3071],
        [0.7035, 0.2965],
        [0.6489, 0.3511],
        [0.6859, 0.3141],
        [0.6961, 0.3039],
        [0.6691, 0.3309],
        [0.6663, 0.3337],
        [0.6446, 0.3554],
        [0.6670, 0.3330],
        [0.6658, 0.3342],
        [0.6591, 0.3409],
        [0.6462, 0.3538],
        [0.6536, 0.3464],
        [0.6664, 0.3336],
        [0.6938, 0.3062],
        [0.6965, 0.3035],
        [0.6818, 0.3182],
        [0.6673, 0.3327],
        [0.6592, 0.3408],
        [0.6364, 0.3636],
        [0.7122, 0.2878],
        [0.6332, 0.3668],
        [0.7112, 0.2888],
        [0.6779, 0.3221],
        [0.6944, 0.3056],
        [0.6702, 0.3298],
        [0.6891, 0.3109],
        [0.6619, 0.3381],
        [0.6930, 0.3070],
        [0.6726, 0.3274],
        [0.6597, 0.3403],
        [0.6882, 0.3118],
        [0.6917, 0.3083],
        [0.6437, 0.3563],
        [0.6589, 0.3411],
        [0.6793, 0.3207],
        [0.6663, 0.3337],
        [0.6617, 0.3383],
        [0.6710, 0.3290],
        [0.7094, 0.2906],
        [0.6917, 0.3083]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0016 loss: 0.6588 acc_train: 0.6103 time: 0.1084s
tensor([[0.6497, 0.3503],
        [0.6682, 0.3318],
        [0.7014, 0.2986],
        [0.6496, 0.3504],
        [0.6902, 0.3098],
        [0.6434, 0.3566],
        [0.6155, 0.3845],
        [0.6489, 0.3511],
        [0.6582, 0.3418],
        [0.6147, 0.3853],
        [0.6731, 0.3269],
        [0.6426, 0.3574],
        [0.6475, 0.3525],
        [0.6550, 0.3450],
        [0.6795, 0.3205],
        [0.6649, 0.3351],
        [0.6690, 0.3310],
        [0.6209, 0.3791],
        [0.6699, 0.3301],
        [0.6195, 0.3805],
        [0.6782, 0.3218],
        [0.6483, 0.3517],
        [0.6645, 0.3355],
        [0.7025, 0.2975],
        [0.6784, 0.3216],
        [0.6508, 0.3492],
        [0.6264, 0.3736],
        [0.6740, 0.3260],
        [0.6404, 0.3596],
        [0.6460, 0.3540],
        [0.6669, 0.3331],
        [0.6455, 0.3545],
        [0.6797, 0.3203],
        [0.6583, 0.3417],
        [0.6675, 0.3325],
        [0.6644, 0.3356],
        [0.6588, 0.3412],
        [0.6598, 0.3402],
        [0.6713, 0.3287],
        [0.6134, 0.3866],
        [0.6721, 0.3279],
        [0.6648, 0.3352],
        [0.6672, 0.3328],
        [0.6510, 0.3490],
        [0.6500, 0.3500],
        [0.6376, 0.3624],
        [0.6922, 0.3078],
        [0.7092, 0.2908],
        [0.6309, 0.3691],
        [0.6671, 0.3329],
        [0.6540, 0.3460],
        [0.6805, 0.3195],
        [0.6697, 0.3303],
        [0.6892, 0.3108],
        [0.6700, 0.3300],
        [0.6868, 0.3132],
        [0.6747, 0.3253],
        [0.6699, 0.3301],
        [0.6290, 0.3710],
        [0.6507, 0.3493],
        [0.6412, 0.3588],
        [0.6557, 0.3443],
        [0.6755, 0.3245],
        [0.6970, 0.3030],
        [0.6386, 0.3614],
        [0.6361, 0.3639],
        [0.6648, 0.3352],
        [0.6502, 0.3498],
        [0.6742, 0.3258],
        [0.6616, 0.3384],
        [0.6537, 0.3463],
        [0.6333, 0.3667],
        [0.6589, 0.3411],
        [0.6607, 0.3393],
        [0.6454, 0.3546],
        [0.6584, 0.3416],
        [0.6801, 0.3199],
        [0.6564, 0.3436],
        [0.6527, 0.3473],
        [0.6347, 0.3653],
        [0.6368, 0.3632],
        [0.6421, 0.3579],
        [0.6478, 0.3522],
        [0.6490, 0.3510],
        [0.6689, 0.3311],
        [0.6326, 0.3674],
        [0.6707, 0.3293],
        [0.6586, 0.3414],
        [0.6288, 0.3711],
        [0.6644, 0.3356],
        [0.6473, 0.3527],
        [0.6441, 0.3559],
        [0.6749, 0.3251],
        [0.6246, 0.3754],
        [0.6493, 0.3507],
        [0.6773, 0.3227],
        [0.6913, 0.3087],
        [0.6494, 0.3506],
        [0.6729, 0.3271],
        [0.6529, 0.3471],
        [0.6431, 0.3569],
        [0.6529, 0.3471],
        [0.6479, 0.3521],
        [0.6238, 0.3762],
        [0.6732, 0.3268],
        [0.6404, 0.3596],
        [0.6781, 0.3219],
        [0.6739, 0.3261],
        [0.6167, 0.3833],
        [0.6468, 0.3532],
        [0.6639, 0.3361],
        [0.6816, 0.3184],
        [0.6737, 0.3263],
        [0.6796, 0.3204],
        [0.6540, 0.3460],
        [0.6482, 0.3518],
        [0.6830, 0.3170],
        [0.6869, 0.3131],
        [0.6740, 0.3260],
        [0.6679, 0.3321],
        [0.6610, 0.3390],
        [0.6244, 0.3756],
        [0.6516, 0.3484],
        [0.6649, 0.3351],
        [0.6782, 0.3218],
        [0.6623, 0.3377],
        [0.6277, 0.3723],
        [0.6584, 0.3416],
        [0.6613, 0.3387],
        [0.6453, 0.3547],
        [0.6730, 0.3270],
        [0.6626, 0.3374],
        [0.6526, 0.3474],
        [0.6410, 0.3590],
        [0.6459, 0.3541],
        [0.6411, 0.3589],
        [0.6577, 0.3423],
        [0.6847, 0.3153],
        [0.6659, 0.3341],
        [0.6392, 0.3608],
        [0.6353, 0.3647],
        [0.6497, 0.3503],
        [0.6424, 0.3576],
        [0.6358, 0.3642],
        [0.6122, 0.3878],
        [0.6803, 0.3197],
        [0.6857, 0.3143],
        [0.6563, 0.3437],
        [0.6616, 0.3384],
        [0.6966, 0.3034],
        [0.6551, 0.3449],
        [0.6951, 0.3049],
        [0.6888, 0.3112],
        [0.6832, 0.3168],
        [0.6829, 0.3171],
        [0.6399, 0.3601],
        [0.6853, 0.3147],
        [0.6719, 0.3281],
        [0.6387, 0.3613],
        [0.6507, 0.3493],
        [0.6660, 0.3340],
        [0.6732, 0.3268],
        [0.6577, 0.3423],
        [0.6669, 0.3331],
        [0.6566, 0.3434],
        [0.6677, 0.3323],
        [0.6489, 0.3511],
        [0.6359, 0.3641],
        [0.6598, 0.3402],
        [0.6482, 0.3518],
        [0.6603, 0.3397],
        [0.6623, 0.3377],
        [0.6451, 0.3549],
        [0.6353, 0.3647],
        [0.6523, 0.3477],
        [0.6475, 0.3525],
        [0.6834, 0.3166],
        [0.6591, 0.3409],
        [0.6166, 0.3834],
        [0.6855, 0.3145],
        [0.6860, 0.3140],
        [0.6449, 0.3551],
        [0.6547, 0.3453],
        [0.6413, 0.3587],
        [0.6643, 0.3357],
        [0.6625, 0.3375],
        [0.6076, 0.3924],
        [0.6666, 0.3334],
        [0.6349, 0.3651],
        [0.6732, 0.3268],
        [0.6928, 0.3072],
        [0.6632, 0.3368],
        [0.6493, 0.3507],
        [0.6332, 0.3668],
        [0.6943, 0.3057],
        [0.6858, 0.3142],
        [0.6954, 0.3046],
        [0.6190, 0.3810],
        [0.6721, 0.3279],
        [0.6635, 0.3365],
        [0.6341, 0.3659],
        [0.6876, 0.3124],
        [0.6767, 0.3233],
        [0.6452, 0.3548],
        [0.6751, 0.3249],
        [0.6547, 0.3453],
        [0.7011, 0.2989],
        [0.6798, 0.3202],
        [0.6557, 0.3443],
        [0.6363, 0.3637],
        [0.6814, 0.3186],
        [0.6230, 0.3770],
        [0.6727, 0.3273],
        [0.6514, 0.3486],
        [0.6707, 0.3293],
        [0.7004, 0.2996],
        [0.6282, 0.3718],
        [0.6677, 0.3323],
        [0.6642, 0.3358],
        [0.6617, 0.3383],
        [0.6499, 0.3501],
        [0.6892, 0.3108],
        [0.6299, 0.3701],
        [0.6662, 0.3338],
        [0.6811, 0.3189],
        [0.6766, 0.3234],
        [0.6557, 0.3443],
        [0.6781, 0.3219],
        [0.6340, 0.3660],
        [0.6611, 0.3389],
        [0.6493, 0.3507],
        [0.6883, 0.3117],
        [0.6973, 0.3027],
        [0.6477, 0.3523],
        [0.6823, 0.3177],
        [0.6923, 0.3077],
        [0.6671, 0.3329],
        [0.6644, 0.3356],
        [0.6438, 0.3562],
        [0.6649, 0.3351],
        [0.6646, 0.3354],
        [0.6571, 0.3429],
        [0.6452, 0.3548],
        [0.6531, 0.3469],
        [0.6648, 0.3352],
        [0.6895, 0.3105],
        [0.6920, 0.3080],
        [0.6786, 0.3214],
        [0.6653, 0.3347],
        [0.6581, 0.3419],
        [0.6371, 0.3629],
        [0.7054, 0.2946],
        [0.6343, 0.3657],
        [0.7045, 0.2955],
        [0.6751, 0.3249],
        [0.6907, 0.3093],
        [0.6671, 0.3329],
        [0.6844, 0.3156],
        [0.6603, 0.3397],
        [0.6882, 0.3118],
        [0.6695, 0.3305],
        [0.6585, 0.3415],
        [0.6837, 0.3163],
        [0.6886, 0.3114],
        [0.6434, 0.3566],
        [0.6597, 0.3403],
        [0.6763, 0.3237],
        [0.6636, 0.3364],
        [0.6602, 0.3398],
        [0.6677, 0.3323],
        [0.7029, 0.2971],
        [0.6869, 0.3131]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0017 loss: 0.6599 acc_train: 0.6103 time: 0.1162s
tensor([[0.6488, 0.3512],
        [0.6656, 0.3344],
        [0.6958, 0.3042],
        [0.6485, 0.3515],
        [0.6848, 0.3152],
        [0.6418, 0.3582],
        [0.6175, 0.3825],
        [0.6470, 0.3530],
        [0.6561, 0.3439],
        [0.6155, 0.3845],
        [0.6686, 0.3314],
        [0.6422, 0.3578],
        [0.6453, 0.3547],
        [0.6528, 0.3472],
        [0.6753, 0.3247],
        [0.6616, 0.3384],
        [0.6661, 0.3339],
        [0.6227, 0.3773],
        [0.6668, 0.3332],
        [0.6207, 0.3793],
        [0.6737, 0.3263],
        [0.6461, 0.3539],
        [0.6619, 0.3381],
        [0.6965, 0.3035],
        [0.6730, 0.3270],
        [0.6495, 0.3505],
        [0.6285, 0.3715],
        [0.6697, 0.3303],
        [0.6394, 0.3606],
        [0.6451, 0.3549],
        [0.6636, 0.3364],
        [0.6443, 0.3557],
        [0.6752, 0.3248],
        [0.6553, 0.3447],
        [0.6640, 0.3360],
        [0.6599, 0.3401],
        [0.6568, 0.3432],
        [0.6566, 0.3434],
        [0.6675, 0.3325],
        [0.6148, 0.3852],
        [0.6691, 0.3309],
        [0.6615, 0.3385],
        [0.6639, 0.3361],
        [0.6495, 0.3505],
        [0.6476, 0.3524],
        [0.6379, 0.3621],
        [0.6863, 0.3137],
        [0.7019, 0.2981],
        [0.6316, 0.3684],
        [0.6642, 0.3358],
        [0.6519, 0.3481],
        [0.6758, 0.3242],
        [0.6655, 0.3345],
        [0.6835, 0.3165],
        [0.6663, 0.3337],
        [0.6818, 0.3182],
        [0.6717, 0.3283],
        [0.6666, 0.3334],
        [0.6291, 0.3709],
        [0.6492, 0.3508],
        [0.6397, 0.3603],
        [0.6532, 0.3468],
        [0.6711, 0.3289],
        [0.6912, 0.3088],
        [0.6372, 0.3628],
        [0.6357, 0.3643],
        [0.6629, 0.3371],
        [0.6492, 0.3508],
        [0.6718, 0.3282],
        [0.6582, 0.3418],
        [0.6530, 0.3470],
        [0.6341, 0.3659],
        [0.6573, 0.3427],
        [0.6574, 0.3426],
        [0.6444, 0.3556],
        [0.6560, 0.3440],
        [0.6747, 0.3253],
        [0.6547, 0.3453],
        [0.6518, 0.3482],
        [0.6360, 0.3640],
        [0.6356, 0.3644],
        [0.6413, 0.3587],
        [0.6441, 0.3559],
        [0.6476, 0.3524],
        [0.6656, 0.3344],
        [0.6330, 0.3670],
        [0.6661, 0.3339],
        [0.6561, 0.3439],
        [0.6288, 0.3712],
        [0.6612, 0.3388],
        [0.6457, 0.3543],
        [0.6423, 0.3577],
        [0.6705, 0.3295],
        [0.6258, 0.3742],
        [0.6479, 0.3521],
        [0.6729, 0.3271],
        [0.6861, 0.3139],
        [0.6478, 0.3522],
        [0.6703, 0.3297],
        [0.6506, 0.3494],
        [0.6419, 0.3581],
        [0.6522, 0.3478],
        [0.6465, 0.3535],
        [0.6253, 0.3747],
        [0.6691, 0.3309],
        [0.6396, 0.3604],
        [0.6732, 0.3268],
        [0.6704, 0.3296],
        [0.6194, 0.3806],
        [0.6460, 0.3540],
        [0.6607, 0.3393],
        [0.6767, 0.3233],
        [0.6687, 0.3313],
        [0.6749, 0.3251],
        [0.6519, 0.3481],
        [0.6452, 0.3548],
        [0.6785, 0.3215],
        [0.6823, 0.3177],
        [0.6711, 0.3289],
        [0.6648, 0.3352],
        [0.6586, 0.3414],
        [0.6259, 0.3741],
        [0.6501, 0.3499],
        [0.6622, 0.3378],
        [0.6736, 0.3264],
        [0.6593, 0.3407],
        [0.6285, 0.3715],
        [0.6562, 0.3438],
        [0.6588, 0.3412],
        [0.6446, 0.3554],
        [0.6692, 0.3308],
        [0.6601, 0.3399],
        [0.6507, 0.3493],
        [0.6394, 0.3606],
        [0.6461, 0.3539],
        [0.6404, 0.3596],
        [0.6551, 0.3449],
        [0.6813, 0.3187],
        [0.6634, 0.3366],
        [0.6386, 0.3614],
        [0.6363, 0.3637],
        [0.6482, 0.3518],
        [0.6412, 0.3588],
        [0.6359, 0.3641],
        [0.6147, 0.3853],
        [0.6757, 0.3243],
        [0.6804, 0.3196],
        [0.6542, 0.3458],
        [0.6600, 0.3400],
        [0.6905, 0.3095],
        [0.6530, 0.3470],
        [0.6893, 0.3107],
        [0.6837, 0.3163],
        [0.6780, 0.3220],
        [0.6784, 0.3216],
        [0.6392, 0.3608],
        [0.6802, 0.3198],
        [0.6681, 0.3319],
        [0.6372, 0.3628],
        [0.6494, 0.3506],
        [0.6630, 0.3370],
        [0.6690, 0.3310],
        [0.6547, 0.3453],
        [0.6630, 0.3370],
        [0.6533, 0.3467],
        [0.6640, 0.3360],
        [0.6484, 0.3516],
        [0.6349, 0.3651],
        [0.6573, 0.3427],
        [0.6471, 0.3529],
        [0.6570, 0.3430],
        [0.6588, 0.3412],
        [0.6416, 0.3584],
        [0.6354, 0.3646],
        [0.6514, 0.3486],
        [0.6469, 0.3531],
        [0.6787, 0.3213],
        [0.6567, 0.3433],
        [0.6187, 0.3813],
        [0.6810, 0.3190],
        [0.6808, 0.3192],
        [0.6432, 0.3568],
        [0.6535, 0.3465],
        [0.6409, 0.3591],
        [0.6618, 0.3382],
        [0.6589, 0.3411],
        [0.6101, 0.3899],
        [0.6631, 0.3369],
        [0.6352, 0.3648],
        [0.6701, 0.3299],
        [0.6878, 0.3122],
        [0.6595, 0.3405],
        [0.6473, 0.3527],
        [0.6330, 0.3670],
        [0.6883, 0.3117],
        [0.6813, 0.3187],
        [0.6903, 0.3097],
        [0.6214, 0.3786],
        [0.6682, 0.3318],
        [0.6612, 0.3388],
        [0.6336, 0.3664],
        [0.6823, 0.3177],
        [0.6726, 0.3274],
        [0.6433, 0.3567],
        [0.6718, 0.3282],
        [0.6524, 0.3476],
        [0.6951, 0.3049],
        [0.6750, 0.3250],
        [0.6526, 0.3474],
        [0.6345, 0.3655],
        [0.6774, 0.3226],
        [0.6237, 0.3763],
        [0.6685, 0.3315],
        [0.6497, 0.3503],
        [0.6684, 0.3316],
        [0.6934, 0.3066],
        [0.6283, 0.3717],
        [0.6630, 0.3370],
        [0.6605, 0.3395],
        [0.6595, 0.3405],
        [0.6483, 0.3517],
        [0.6833, 0.3167],
        [0.6304, 0.3696],
        [0.6636, 0.3364],
        [0.6759, 0.3241],
        [0.6721, 0.3279],
        [0.6525, 0.3475],
        [0.6733, 0.3267],
        [0.6340, 0.3660],
        [0.6572, 0.3428],
        [0.6484, 0.3516],
        [0.6830, 0.3170],
        [0.6903, 0.3097],
        [0.6456, 0.3544],
        [0.6780, 0.3220],
        [0.6877, 0.3123],
        [0.6642, 0.3358],
        [0.6617, 0.3383],
        [0.6427, 0.3573],
        [0.6622, 0.3378],
        [0.6627, 0.3373],
        [0.6543, 0.3457],
        [0.6437, 0.3563],
        [0.6514, 0.3486],
        [0.6629, 0.3371],
        [0.6845, 0.3155],
        [0.6867, 0.3133],
        [0.6750, 0.3250],
        [0.6626, 0.3374],
        [0.6569, 0.3431],
        [0.6374, 0.3626],
        [0.6979, 0.3021],
        [0.6348, 0.3652],
        [0.6970, 0.3030],
        [0.6717, 0.3283],
        [0.6858, 0.3142],
        [0.6637, 0.3363],
        [0.6795, 0.3205],
        [0.6581, 0.3419],
        [0.6831, 0.3169],
        [0.6660, 0.3340],
        [0.6569, 0.3431],
        [0.6786, 0.3214],
        [0.6843, 0.3157],
        [0.6423, 0.3577],
        [0.6600, 0.3400],
        [0.6726, 0.3274],
        [0.6605, 0.3395],
        [0.6575, 0.3425],
        [0.6639, 0.3361],
        [0.6959, 0.3041],
        [0.6815, 0.3185]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0018 loss: 0.6611 acc_train: 0.6103 time: 0.1174s
tensor([[0.6492, 0.3508],
        [0.6639, 0.3361],
        [0.6916, 0.3084],
        [0.6491, 0.3509],
        [0.6807, 0.3193],
        [0.6410, 0.3590],
        [0.6204, 0.3796],
        [0.6465, 0.3535],
        [0.6556, 0.3444],
        [0.6179, 0.3821],
        [0.6659, 0.3341],
        [0.6429, 0.3571],
        [0.6444, 0.3556],
        [0.6520, 0.3480],
        [0.6721, 0.3279],
        [0.6595, 0.3405],
        [0.6643, 0.3357],
        [0.6259, 0.3741],
        [0.6650, 0.3350],
        [0.6233, 0.3767],
        [0.6708, 0.3292],
        [0.6451, 0.3549],
        [0.6607, 0.3393],
        [0.6921, 0.3079],
        [0.6690, 0.3310],
        [0.6492, 0.3508],
        [0.6312, 0.3688],
        [0.6669, 0.3331],
        [0.6397, 0.3603],
        [0.6456, 0.3544],
        [0.6615, 0.3385],
        [0.6440, 0.3560],
        [0.6723, 0.3277],
        [0.6538, 0.3462],
        [0.6617, 0.3383],
        [0.6569, 0.3431],
        [0.6560, 0.3440],
        [0.6547, 0.3453],
        [0.6648, 0.3352],
        [0.6175, 0.3825],
        [0.6674, 0.3326],
        [0.6599, 0.3401],
        [0.6618, 0.3382],
        [0.6496, 0.3504],
        [0.6466, 0.3534],
        [0.6392, 0.3608],
        [0.6817, 0.3183],
        [0.6957, 0.3043],
        [0.6332, 0.3668],
        [0.6621, 0.3379],
        [0.6514, 0.3486],
        [0.6726, 0.3274],
        [0.6628, 0.3372],
        [0.6795, 0.3205],
        [0.6640, 0.3360],
        [0.6778, 0.3222],
        [0.6703, 0.3297],
        [0.6643, 0.3357],
        [0.6308, 0.3692],
        [0.6486, 0.3514],
        [0.6394, 0.3606],
        [0.6521, 0.3479],
        [0.6680, 0.3320],
        [0.6864, 0.3136],
        [0.6371, 0.3629],
        [0.6370, 0.3630],
        [0.6620, 0.3380],
        [0.6493, 0.3507],
        [0.6703, 0.3297],
        [0.6561, 0.3439],
        [0.6536, 0.3464],
        [0.6362, 0.3638],
        [0.6570, 0.3430],
        [0.6553, 0.3447],
        [0.6446, 0.3554],
        [0.6551, 0.3449],
        [0.6707, 0.3293],
        [0.6538, 0.3462],
        [0.6521, 0.3479],
        [0.6385, 0.3615],
        [0.6359, 0.3641],
        [0.6414, 0.3586],
        [0.6423, 0.3577],
        [0.6475, 0.3525],
        [0.6635, 0.3365],
        [0.6346, 0.3654],
        [0.6627, 0.3373],
        [0.6549, 0.3451],
        [0.6302, 0.3698],
        [0.6593, 0.3407],
        [0.6454, 0.3546],
        [0.6416, 0.3584],
        [0.6675, 0.3325],
        [0.6285, 0.3715],
        [0.6474, 0.3526],
        [0.6698, 0.3302],
        [0.6823, 0.3177],
        [0.6471, 0.3529],
        [0.6685, 0.3315],
        [0.6494, 0.3506],
        [0.6422, 0.3578],
        [0.6527, 0.3473],
        [0.6464, 0.3536],
        [0.6279, 0.3721],
        [0.6664, 0.3336],
        [0.6402, 0.3598],
        [0.6699, 0.3301],
        [0.6679, 0.3321],
        [0.6231, 0.3769],
        [0.6469, 0.3531],
        [0.6588, 0.3412],
        [0.6731, 0.3269],
        [0.6653, 0.3347],
        [0.6715, 0.3285],
        [0.6507, 0.3493],
        [0.6433, 0.3567],
        [0.6747, 0.3253],
        [0.6790, 0.3210],
        [0.6697, 0.3303],
        [0.6626, 0.3374],
        [0.6572, 0.3428],
        [0.6284, 0.3716],
        [0.6501, 0.3499],
        [0.6606, 0.3394],
        [0.6704, 0.3296],
        [0.6577, 0.3423],
        [0.6305, 0.3695],
        [0.6556, 0.3444],
        [0.6573, 0.3427],
        [0.6453, 0.3547],
        [0.6664, 0.3336],
        [0.6590, 0.3410],
        [0.6500, 0.3500],
        [0.6390, 0.3610],
        [0.6470, 0.3530],
        [0.6410, 0.3590],
        [0.6539, 0.3461],
        [0.6788, 0.3212],
        [0.6620, 0.3380],
        [0.6390, 0.3610],
        [0.6384, 0.3616],
        [0.6481, 0.3519],
        [0.6413, 0.3587],
        [0.6373, 0.3627],
        [0.6186, 0.3814],
        [0.6724, 0.3276],
        [0.6764, 0.3236],
        [0.6532, 0.3468],
        [0.6593, 0.3407],
        [0.6856, 0.3144],
        [0.6520, 0.3480],
        [0.6851, 0.3149],
        [0.6798, 0.3202],
        [0.6744, 0.3256],
        [0.6753, 0.3247],
        [0.6393, 0.3607],
        [0.6769, 0.3231],
        [0.6655, 0.3345],
        [0.6371, 0.3629],
        [0.6493, 0.3507],
        [0.6617, 0.3383],
        [0.6664, 0.3336],
        [0.6535, 0.3465],
        [0.6606, 0.3394],
        [0.6515, 0.3485],
        [0.6617, 0.3383],
        [0.6492, 0.3508],
        [0.6354, 0.3646],
        [0.6563, 0.3437],
        [0.6474, 0.3526],
        [0.6550, 0.3450],
        [0.6567, 0.3433],
        [0.6400, 0.3600],
        [0.6370, 0.3630],
        [0.6515, 0.3485],
        [0.6474, 0.3526],
        [0.6751, 0.3249],
        [0.6558, 0.3442],
        [0.6222, 0.3778],
        [0.6777, 0.3223],
        [0.6774, 0.3226],
        [0.6433, 0.3567],
        [0.6535, 0.3465],
        [0.6417, 0.3583],
        [0.6605, 0.3395],
        [0.6570, 0.3430],
        [0.6140, 0.3860],
        [0.6608, 0.3392],
        [0.6369, 0.3631],
        [0.6677, 0.3323],
        [0.6842, 0.3158],
        [0.6572, 0.3428],
        [0.6468, 0.3532],
        [0.6337, 0.3663],
        [0.6834, 0.3166],
        [0.6780, 0.3220],
        [0.6863, 0.3137],
        [0.6248, 0.3752],
        [0.6657, 0.3343],
        [0.6600, 0.3400],
        [0.6343, 0.3657],
        [0.6784, 0.3216],
        [0.6701, 0.3299],
        [0.6427, 0.3573],
        [0.6697, 0.3302],
        [0.6517, 0.3483],
        [0.6900, 0.3100],
        [0.6717, 0.3283],
        [0.6510, 0.3490],
        [0.6342, 0.3658],
        [0.6743, 0.3257],
        [0.6258, 0.3742],
        [0.6658, 0.3342],
        [0.6493, 0.3507],
        [0.6674, 0.3326],
        [0.6876, 0.3124],
        [0.6295, 0.3705],
        [0.6601, 0.3399],
        [0.6582, 0.3418],
        [0.6586, 0.3414],
        [0.6477, 0.3523],
        [0.6786, 0.3214],
        [0.6319, 0.3681],
        [0.6623, 0.3377],
        [0.6719, 0.3281],
        [0.6690, 0.3310],
        [0.6506, 0.3494],
        [0.6699, 0.3301],
        [0.6353, 0.3647],
        [0.6553, 0.3447],
        [0.6489, 0.3511],
        [0.6791, 0.3209],
        [0.6845, 0.3155],
        [0.6451, 0.3549],
        [0.6751, 0.3249],
        [0.6838, 0.3162],
        [0.6625, 0.3375],
        [0.6601, 0.3399],
        [0.6430, 0.3570],
        [0.6606, 0.3394],
        [0.6617, 0.3383],
        [0.6531, 0.3469],
        [0.6436, 0.3564],
        [0.6506, 0.3494],
        [0.6625, 0.3375],
        [0.6809, 0.3191],
        [0.6827, 0.3173],
        [0.6728, 0.3272],
        [0.6611, 0.3389],
        [0.6570, 0.3430],
        [0.6389, 0.3611],
        [0.6918, 0.3082],
        [0.6364, 0.3636],
        [0.6910, 0.3090],
        [0.6693, 0.3307],
        [0.6820, 0.3180],
        [0.6617, 0.3383],
        [0.6765, 0.3235],
        [0.6573, 0.3427],
        [0.6797, 0.3203],
        [0.6638, 0.3362],
        [0.6567, 0.3433],
        [0.6748, 0.3252],
        [0.6809, 0.3191],
        [0.6423, 0.3577],
        [0.6611, 0.3389],
        [0.6703, 0.3297],
        [0.6586, 0.3414],
        [0.6558, 0.3442],
        [0.6613, 0.3387],
        [0.6904, 0.3096],
        [0.6774, 0.3226]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0019 loss: 0.6622 acc_train: 0.6103 time: 0.1275s
tensor([[0.6501, 0.3499],
        [0.6630, 0.3370],
        [0.6883, 0.3117],
        [0.6503, 0.3497],
        [0.6776, 0.3224],
        [0.6410, 0.3590],
        [0.6234, 0.3766],
        [0.6463, 0.3537],
        [0.6557, 0.3443],
        [0.6209, 0.3791],
        [0.6641, 0.3359],
        [0.6441, 0.3559],
        [0.6445, 0.3555],
        [0.6521, 0.3479],
        [0.6699, 0.3301],
        [0.6582, 0.3418],
        [0.6631, 0.3369],
        [0.6293, 0.3707],
        [0.6638, 0.3362],
        [0.6266, 0.3734],
        [0.6686, 0.3314],
        [0.6447, 0.3553],
        [0.6600, 0.3400],
        [0.6888, 0.3112],
        [0.6658, 0.3342],
        [0.6491, 0.3509],
        [0.6343, 0.3657],
        [0.6650, 0.3350],
        [0.6405, 0.3595],
        [0.6466, 0.3534],
        [0.6601, 0.3399],
        [0.6442, 0.3558],
        [0.6701, 0.3299],
        [0.6532, 0.3468],
        [0.6600, 0.3400],
        [0.6550, 0.3450],
        [0.6556, 0.3444],
        [0.6537, 0.3463],
        [0.6631, 0.3369],
        [0.6208, 0.3792],
        [0.6661, 0.3339],
        [0.6592, 0.3408],
        [0.6604, 0.3396],
        [0.6504, 0.3496],
        [0.6466, 0.3534],
        [0.6407, 0.3593],
        [0.6779, 0.3221],
        [0.6903, 0.3097],
        [0.6356, 0.3644],
        [0.6606, 0.3394],
        [0.6516, 0.3484],
        [0.6699, 0.3301],
        [0.6610, 0.3390],
        [0.6761, 0.3239],
        [0.6629, 0.3371],
        [0.6745, 0.3255],
        [0.6691, 0.3309],
        [0.6624, 0.3376],
        [0.6330, 0.3670],
        [0.6489, 0.3511],
        [0.6397, 0.3603],
        [0.6517, 0.3483],
        [0.6652, 0.3348],
        [0.6824, 0.3176],
        [0.6374, 0.3626],
        [0.6389, 0.3611],
        [0.6613, 0.3387],
        [0.6498, 0.3502],
        [0.6694, 0.3306],
        [0.6548, 0.3452],
        [0.6542, 0.3458],
        [0.6388, 0.3612],
        [0.6570, 0.3430],
        [0.6539, 0.3461],
        [0.6454, 0.3546],
        [0.6552, 0.3448],
        [0.6677, 0.3323],
        [0.6530, 0.3470],
        [0.6527, 0.3473],
        [0.6413, 0.3587],
        [0.6371, 0.3629],
        [0.6418, 0.3582],
        [0.6419, 0.3581],
        [0.6476, 0.3524],
        [0.6619, 0.3381],
        [0.6365, 0.3635],
        [0.6600, 0.3400],
        [0.6542, 0.3458],
        [0.6323, 0.3677],
        [0.6578, 0.3422],
        [0.6456, 0.3544],
        [0.6422, 0.3578],
        [0.6650, 0.3350],
        [0.6316, 0.3684],
        [0.6476, 0.3524],
        [0.6671, 0.3329],
        [0.6792, 0.3208],
        [0.6467, 0.3533],
        [0.6668, 0.3332],
        [0.6491, 0.3509],
        [0.6436, 0.3564],
        [0.6536, 0.3464],
        [0.6472, 0.3528],
        [0.6307, 0.3693],
        [0.6640, 0.3360],
        [0.6411, 0.3589],
        [0.6675, 0.3325],
        [0.6658, 0.3342],
        [0.6272, 0.3728],
        [0.6481, 0.3519],
        [0.6571, 0.3429],
        [0.6699, 0.3301],
        [0.6631, 0.3369],
        [0.6689, 0.3311],
        [0.6500, 0.3500],
        [0.6421, 0.3579],
        [0.6714, 0.3286],
        [0.6765, 0.3235],
        [0.6688, 0.3312],
        [0.6610, 0.3390],
        [0.6568, 0.3432],
        [0.6310, 0.3690],
        [0.6507, 0.3493],
        [0.6597, 0.3403],
        [0.6683, 0.3317],
        [0.6565, 0.3435],
        [0.6330, 0.3670],
        [0.6557, 0.3443],
        [0.6562, 0.3438],
        [0.6465, 0.3535],
        [0.6641, 0.3359],
        [0.6584, 0.3416],
        [0.6503, 0.3497],
        [0.6394, 0.3606],
        [0.6484, 0.3516],
        [0.6416, 0.3584],
        [0.6533, 0.3467],
        [0.6764, 0.3236],
        [0.6612, 0.3388],
        [0.6401, 0.3599],
        [0.6404, 0.3596],
        [0.6483, 0.3517],
        [0.6418, 0.3582],
        [0.6387, 0.3613],
        [0.6233, 0.3767],
        [0.6700, 0.3300],
        [0.6734, 0.3266],
        [0.6528, 0.3472],
        [0.6593, 0.3407],
        [0.6815, 0.3185],
        [0.6520, 0.3480],
        [0.6817, 0.3183],
        [0.6765, 0.3235],
        [0.6719, 0.3281],
        [0.6727, 0.3273],
        [0.6400, 0.3600],
        [0.6744, 0.3256],
        [0.6636, 0.3364],
        [0.6375, 0.3625],
        [0.6493, 0.3507],
        [0.6609, 0.3391],
        [0.6646, 0.3354],
        [0.6532, 0.3468],
        [0.6593, 0.3407],
        [0.6505, 0.3495],
        [0.6601, 0.3399],
        [0.6506, 0.3494],
        [0.6367, 0.3633],
        [0.6561, 0.3439],
        [0.6481, 0.3519],
        [0.6538, 0.3462],
        [0.6555, 0.3445],
        [0.6396, 0.3604],
        [0.6391, 0.3609],
        [0.6523, 0.3477],
        [0.6488, 0.3512],
        [0.6719, 0.3281],
        [0.6552, 0.3448],
        [0.6260, 0.3740],
        [0.6749, 0.3251],
        [0.6752, 0.3248],
        [0.6441, 0.3559],
        [0.6539, 0.3461],
        [0.6432, 0.3568],
        [0.6598, 0.3402],
        [0.6564, 0.3436],
        [0.6184, 0.3816],
        [0.6595, 0.3405],
        [0.6387, 0.3613],
        [0.6657, 0.3343],
        [0.6810, 0.3190],
        [0.6558, 0.3442],
        [0.6473, 0.3527],
        [0.6350, 0.3650],
        [0.6792, 0.3208],
        [0.6755, 0.3245],
        [0.6829, 0.3171],
        [0.6284, 0.3716],
        [0.6639, 0.3361],
        [0.6591, 0.3409],
        [0.6357, 0.3643],
        [0.6755, 0.3245],
        [0.6685, 0.3315],
        [0.6424, 0.3576],
        [0.6680, 0.3320],
        [0.6515, 0.3485],
        [0.6855, 0.3145],
        [0.6693, 0.3307],
        [0.6502, 0.3498],
        [0.6346, 0.3654],
        [0.6719, 0.3281],
        [0.6284, 0.3716],
        [0.6641, 0.3359],
        [0.6493, 0.3507],
        [0.6666, 0.3334],
        [0.6825, 0.3175],
        [0.6313, 0.3687],
        [0.6585, 0.3415],
        [0.6567, 0.3433],
        [0.6584, 0.3416],
        [0.6479, 0.3521],
        [0.6749, 0.3251],
        [0.6337, 0.3663],
        [0.6614, 0.3386],
        [0.6690, 0.3310],
        [0.6672, 0.3328],
        [0.6490, 0.3510],
        [0.6674, 0.3326],
        [0.6367, 0.3633],
        [0.6547, 0.3453],
        [0.6501, 0.3499],
        [0.6759, 0.3241],
        [0.6797, 0.3203],
        [0.6455, 0.3545],
        [0.6727, 0.3273],
        [0.6807, 0.3193],
        [0.6614, 0.3386],
        [0.6590, 0.3410],
        [0.6444, 0.3556],
        [0.6597, 0.3403],
        [0.6612, 0.3388],
        [0.6524, 0.3476],
        [0.6437, 0.3563],
        [0.6501, 0.3499],
        [0.6627, 0.3373],
        [0.6779, 0.3221],
        [0.6793, 0.3207],
        [0.6713, 0.3287],
        [0.6600, 0.3400],
        [0.6580, 0.3420],
        [0.6408, 0.3592],
        [0.6867, 0.3133],
        [0.6384, 0.3616],
        [0.6861, 0.3139],
        [0.6674, 0.3326],
        [0.6786, 0.3214],
        [0.6609, 0.3391],
        [0.6748, 0.3252],
        [0.6568, 0.3432],
        [0.6772, 0.3228],
        [0.6622, 0.3378],
        [0.6571, 0.3429],
        [0.6717, 0.3283],
        [0.6782, 0.3218],
        [0.6428, 0.3572],
        [0.6623, 0.3377],
        [0.6685, 0.3315],
        [0.6576, 0.3424],
        [0.6543, 0.3457],
        [0.6598, 0.3402],
        [0.6859, 0.3141],
        [0.6742, 0.3258]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0020 loss: 0.6632 acc_train: 0.6103 time: 0.1096s
tensor([[0.6522, 0.3478],
        [0.6634, 0.3366],
        [0.6861, 0.3139],
        [0.6526, 0.3474],
        [0.6755, 0.3245],
        [0.6422, 0.3578],
        [0.6276, 0.3724],
        [0.6474, 0.3526],
        [0.6568, 0.3432],
        [0.6251, 0.3749],
        [0.6636, 0.3364],
        [0.6458, 0.3542],
        [0.6457, 0.3543],
        [0.6533, 0.3467],
        [0.6686, 0.3314],
        [0.6578, 0.3422],
        [0.6635, 0.3365],
        [0.6338, 0.3662],
        [0.6637, 0.3363],
        [0.6311, 0.3689],
        [0.6678, 0.3322],
        [0.6457, 0.3543],
        [0.6605, 0.3395],
        [0.6866, 0.3134],
        [0.6644, 0.3356],
        [0.6500, 0.3500],
        [0.6381, 0.3619],
        [0.6644, 0.3356],
        [0.6428, 0.3572],
        [0.6484, 0.3516],
        [0.6602, 0.3398],
        [0.6456, 0.3544],
        [0.6691, 0.3309],
        [0.6537, 0.3463],
        [0.6595, 0.3405],
        [0.6542, 0.3458],
        [0.6561, 0.3439],
        [0.6533, 0.3467],
        [0.6624, 0.3376],
        [0.6254, 0.3746],
        [0.6657, 0.3343],
        [0.6600, 0.3400],
        [0.6600, 0.3400],
        [0.6520, 0.3480],
        [0.6479, 0.3521],
        [0.6431, 0.3569],
        [0.6758, 0.3242],
        [0.6863, 0.3137],
        [0.6391, 0.3609],
        [0.6601, 0.3399],
        [0.6527, 0.3473],
        [0.6685, 0.3315],
        [0.6602, 0.3398],
        [0.6740, 0.3260],
        [0.6632, 0.3368],
        [0.6726, 0.3274],
        [0.6688, 0.3312],
        [0.6619, 0.3381],
        [0.6364, 0.3636],
        [0.6507, 0.3493],
        [0.6414, 0.3586],
        [0.6520, 0.3480],
        [0.6639, 0.3361],
        [0.6795, 0.3205],
        [0.6391, 0.3609],
        [0.6420, 0.3580],
        [0.6610, 0.3390],
        [0.6516, 0.3484],
        [0.6693, 0.3307],
        [0.6549, 0.3451],
        [0.6555, 0.3445],
        [0.6423, 0.3577],
        [0.6582, 0.3418],
        [0.6538, 0.3462],
        [0.6469, 0.3531],
        [0.6562, 0.3438],
        [0.6663, 0.3337],
        [0.6531, 0.3469],
        [0.6539, 0.3461],
        [0.6451, 0.3549],
        [0.6390, 0.3610],
        [0.6435, 0.3565],
        [0.6432, 0.3568],
        [0.6487, 0.3513],
        [0.6615, 0.3385],
        [0.6394, 0.3606],
        [0.6591, 0.3409],
        [0.6547, 0.3453],
        [0.6356, 0.3644],
        [0.6576, 0.3424],
        [0.6470, 0.3530],
        [0.6444, 0.3556],
        [0.6641, 0.3359],
        [0.6357, 0.3643],
        [0.6490, 0.3510],
        [0.6655, 0.3345],
        [0.6774, 0.3226],
        [0.6475, 0.3525],
        [0.6663, 0.3337],
        [0.6502, 0.3498],
        [0.6463, 0.3537],
        [0.6555, 0.3445],
        [0.6491, 0.3509],
        [0.6347, 0.3653],
        [0.6629, 0.3371],
        [0.6428, 0.3572],
        [0.6667, 0.3333],
        [0.6649, 0.3351],
        [0.6314, 0.3686],
        [0.6506, 0.3494],
        [0.6566, 0.3434],
        [0.6680, 0.3320],
        [0.6626, 0.3374],
        [0.6673, 0.3327],
        [0.6505, 0.3495],
        [0.6419, 0.3581],
        [0.6693, 0.3307],
        [0.6751, 0.3249],
        [0.6689, 0.3311],
        [0.6605, 0.3395],
        [0.6576, 0.3424],
        [0.6346, 0.3654],
        [0.6522, 0.3478],
        [0.6594, 0.3406],
        [0.6676, 0.3324],
        [0.6565, 0.3435],
        [0.6364, 0.3636],
        [0.6566, 0.3434],
        [0.6563, 0.3437],
        [0.6487, 0.3513],
        [0.6631, 0.3369],
        [0.6587, 0.3413],
        [0.6518, 0.3482],
        [0.6413, 0.3587],
        [0.6509, 0.3491],
        [0.6433, 0.3567],
        [0.6542, 0.3458],
        [0.6747, 0.3253],
        [0.6612, 0.3388],
        [0.6424, 0.3576],
        [0.6432, 0.3568],
        [0.6498, 0.3502],
        [0.6433, 0.3567],
        [0.6412, 0.3588],
        [0.6287, 0.3713],
        [0.6689, 0.3311],
        [0.6721, 0.3279],
        [0.6537, 0.3463],
        [0.6603, 0.3397],
        [0.6786, 0.3214],
        [0.6534, 0.3466],
        [0.6793, 0.3207],
        [0.6744, 0.3256],
        [0.6711, 0.3289],
        [0.6717, 0.3283],
        [0.6410, 0.3590],
        [0.6733, 0.3267],
        [0.6631, 0.3369],
        [0.6394, 0.3606],
        [0.6507, 0.3493],
        [0.6615, 0.3385],
        [0.6639, 0.3361],
        [0.6544, 0.3456],
        [0.6590, 0.3410],
        [0.6506, 0.3494],
        [0.6593, 0.3407],
        [0.6530, 0.3470],
        [0.6395, 0.3605],
        [0.6571, 0.3429],
        [0.6497, 0.3503],
        [0.6533, 0.3467],
        [0.6557, 0.3443],
        [0.6405, 0.3595],
        [0.6422, 0.3578],
        [0.6542, 0.3458],
        [0.6513, 0.3487],
        [0.6703, 0.3297],
        [0.6554, 0.3446],
        [0.6305, 0.3695],
        [0.6734, 0.3266],
        [0.6745, 0.3255],
        [0.6464, 0.3536],
        [0.6552, 0.3448],
        [0.6459, 0.3541],
        [0.6597, 0.3403],
        [0.6571, 0.3429],
        [0.6241, 0.3759],
        [0.6593, 0.3407],
        [0.6414, 0.3586],
        [0.6650, 0.3350],
        [0.6787, 0.3213],
        [0.6559, 0.3441],
        [0.6486, 0.3514],
        [0.6374, 0.3626],
        [0.6765, 0.3235],
        [0.6741, 0.3259],
        [0.6807, 0.3193],
        [0.6327, 0.3673],
        [0.6636, 0.3364],
        [0.6596, 0.3404],
        [0.6384, 0.3616],
        [0.6735, 0.3265],
        [0.6678, 0.3322],
        [0.6434, 0.3566],
        [0.6672, 0.3328],
        [0.6529, 0.3471],
        [0.6820, 0.3180],
        [0.6685, 0.3315],
        [0.6507, 0.3493],
        [0.6368, 0.3632],
        [0.6705, 0.3295],
        [0.6322, 0.3678],
        [0.6639, 0.3361],
        [0.6504, 0.3496],
        [0.6666, 0.3334],
        [0.6790, 0.3210],
        [0.6345, 0.3655],
        [0.6585, 0.3415],
        [0.6562, 0.3438],
        [0.6595, 0.3405],
        [0.6488, 0.3512],
        [0.6731, 0.3269],
        [0.6367, 0.3633],
        [0.6613, 0.3387],
        [0.6677, 0.3323],
        [0.6671, 0.3329],
        [0.6489, 0.3511],
        [0.6663, 0.3337],
        [0.6396, 0.3604],
        [0.6553, 0.3447],
        [0.6521, 0.3479],
        [0.6742, 0.3258],
        [0.6765, 0.3235],
        [0.6472, 0.3528],
        [0.6717, 0.3283],
        [0.6792, 0.3208],
        [0.6608, 0.3392],
        [0.6591, 0.3409],
        [0.6469, 0.3531],
        [0.6600, 0.3400],
        [0.6617, 0.3383],
        [0.6530, 0.3470],
        [0.6447, 0.3553],
        [0.6507, 0.3493],
        [0.6640, 0.3360],
        [0.6760, 0.3240],
        [0.6772, 0.3228],
        [0.6706, 0.3294],
        [0.6599, 0.3401],
        [0.6599, 0.3401],
        [0.6439, 0.3561],
        [0.6832, 0.3168],
        [0.6414, 0.3586],
        [0.6823, 0.3177],
        [0.6668, 0.3332],
        [0.6763, 0.3237],
        [0.6614, 0.3386],
        [0.6743, 0.3257],
        [0.6576, 0.3424],
        [0.6759, 0.3241],
        [0.6621, 0.3379],
        [0.6584, 0.3416],
        [0.6698, 0.3302],
        [0.6768, 0.3232],
        [0.6447, 0.3553],
        [0.6636, 0.3364],
        [0.6681, 0.3319],
        [0.6579, 0.3421],
        [0.6540, 0.3460],
        [0.6595, 0.3405],
        [0.6831, 0.3169],
        [0.6726, 0.3274]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0021 loss: 0.6641 acc_train: 0.6103 time: 0.1116s
tensor([[0.6548, 0.3452],
        [0.6646, 0.3354],
        [0.6848, 0.3152],
        [0.6555, 0.3445],
        [0.6745, 0.3255],
        [0.6447, 0.3553],
        [0.6327, 0.3673],
        [0.6495, 0.3505],
        [0.6585, 0.3415],
        [0.6301, 0.3699],
        [0.6643, 0.3357],
        [0.6482, 0.3518],
        [0.6478, 0.3522],
        [0.6554, 0.3446],
        [0.6683, 0.3317],
        [0.6582, 0.3418],
        [0.6648, 0.3352],
        [0.6386, 0.3614],
        [0.6644, 0.3356],
        [0.6364, 0.3636],
        [0.6678, 0.3322],
        [0.6480, 0.3520],
        [0.6617, 0.3383],
        [0.6851, 0.3149],
        [0.6645, 0.3355],
        [0.6515, 0.3485],
        [0.6425, 0.3575],
        [0.6648, 0.3352],
        [0.6459, 0.3541],
        [0.6508, 0.3492],
        [0.6613, 0.3387],
        [0.6478, 0.3522],
        [0.6691, 0.3309],
        [0.6551, 0.3449],
        [0.6600, 0.3400],
        [0.6541, 0.3459],
        [0.6576, 0.3424],
        [0.6539, 0.3461],
        [0.6627, 0.3373],
        [0.6308, 0.3692],
        [0.6661, 0.3339],
        [0.6617, 0.3383],
        [0.6601, 0.3399],
        [0.6543, 0.3457],
        [0.6502, 0.3498],
        [0.6460, 0.3540],
        [0.6748, 0.3252],
        [0.6834, 0.3166],
        [0.6432, 0.3568],
        [0.6606, 0.3394],
        [0.6546, 0.3454],
        [0.6682, 0.3318],
        [0.6603, 0.3397],
        [0.6730, 0.3270],
        [0.6644, 0.3356],
        [0.6718, 0.3282],
        [0.6692, 0.3308],
        [0.6624, 0.3376],
        [0.6407, 0.3593],
        [0.6533, 0.3467],
        [0.6443, 0.3557],
        [0.6534, 0.3466],
        [0.6637, 0.3363],
        [0.6773, 0.3227],
        [0.6420, 0.3580],
        [0.6459, 0.3541],
        [0.6611, 0.3389],
        [0.6541, 0.3459],
        [0.6698, 0.3302],
        [0.6562, 0.3438],
        [0.6571, 0.3429],
        [0.6463, 0.3537],
        [0.6601, 0.3399],
        [0.6549, 0.3451],
        [0.6493, 0.3507],
        [0.6577, 0.3423],
        [0.6661, 0.3339],
        [0.6541, 0.3459],
        [0.6557, 0.3443],
        [0.6490, 0.3510],
        [0.6420, 0.3580],
        [0.6459, 0.3541],
        [0.6459, 0.3541],
        [0.6508, 0.3492],
        [0.6621, 0.3379],
        [0.6429, 0.3571],
        [0.6595, 0.3405],
        [0.6561, 0.3439],
        [0.6396, 0.3604],
        [0.6582, 0.3418],
        [0.6495, 0.3505],
        [0.6475, 0.3525],
        [0.6642, 0.3358],
        [0.6404, 0.3596],
        [0.6513, 0.3487],
        [0.6651, 0.3349],
        [0.6765, 0.3235],
        [0.6492, 0.3508],
        [0.6668, 0.3332],
        [0.6524, 0.3476],
        [0.6497, 0.3503],
        [0.6581, 0.3419],
        [0.6517, 0.3483],
        [0.6391, 0.3609],
        [0.6631, 0.3369],
        [0.6454, 0.3546],
        [0.6671, 0.3329],
        [0.6650, 0.3350],
        [0.6360, 0.3640],
        [0.6537, 0.3463],
        [0.6568, 0.3432],
        [0.6672, 0.3328],
        [0.6634, 0.3366],
        [0.6666, 0.3334],
        [0.6517, 0.3483],
        [0.6429, 0.3571],
        [0.6684, 0.3316],
        [0.6748, 0.3252],
        [0.6694, 0.3306],
        [0.6611, 0.3389],
        [0.6592, 0.3408],
        [0.6387, 0.3613],
        [0.6543, 0.3457],
        [0.6597, 0.3403],
        [0.6679, 0.3321],
        [0.6574, 0.3426],
        [0.6405, 0.3595],
        [0.6580, 0.3420],
        [0.6573, 0.3427],
        [0.6515, 0.3485],
        [0.6633, 0.3367],
        [0.6600, 0.3400],
        [0.6540, 0.3460],
        [0.6442, 0.3558],
        [0.6538, 0.3462],
        [0.6457, 0.3543],
        [0.6561, 0.3439],
        [0.6736, 0.3264],
        [0.6621, 0.3379],
        [0.6453, 0.3547],
        [0.6464, 0.3536],
        [0.6520, 0.3480],
        [0.6457, 0.3543],
        [0.6445, 0.3555],
        [0.6344, 0.3656],
        [0.6688, 0.3312],
        [0.6718, 0.3282],
        [0.6554, 0.3446],
        [0.6620, 0.3380],
        [0.6769, 0.3231],
        [0.6557, 0.3443],
        [0.6777, 0.3223],
        [0.6735, 0.3265],
        [0.6713, 0.3287],
        [0.6714, 0.3286],
        [0.6429, 0.3571],
        [0.6732, 0.3268],
        [0.6635, 0.3365],
        [0.6425, 0.3575],
        [0.6528, 0.3472],
        [0.6628, 0.3372],
        [0.6641, 0.3359],
        [0.6566, 0.3434],
        [0.6597, 0.3403],
        [0.6516, 0.3484],
        [0.6595, 0.3405],
        [0.6559, 0.3441],
        [0.6431, 0.3569],
        [0.6588, 0.3412],
        [0.6519, 0.3481],
        [0.6535, 0.3465],
        [0.6573, 0.3427],
        [0.6428, 0.3572],
        [0.6460, 0.3540],
        [0.6566, 0.3434],
        [0.6544, 0.3456],
        [0.6698, 0.3302],
        [0.6564, 0.3436],
        [0.6356, 0.3644],
        [0.6728, 0.3272],
        [0.6747, 0.3253],
        [0.6495, 0.3505],
        [0.6568, 0.3432],
        [0.6492, 0.3508],
        [0.6602, 0.3398],
        [0.6586, 0.3414],
        [0.6303, 0.3697],
        [0.6600, 0.3400],
        [0.6444, 0.3556],
        [0.6652, 0.3348],
        [0.6772, 0.3228],
        [0.6571, 0.3429],
        [0.6506, 0.3494],
        [0.6407, 0.3593],
        [0.6749, 0.3251],
        [0.6737, 0.3263],
        [0.6796, 0.3204],
        [0.6374, 0.3626],
        [0.6644, 0.3356],
        [0.6608, 0.3392],
        [0.6422, 0.3578],
        [0.6727, 0.3273],
        [0.6681, 0.3319],
        [0.6457, 0.3543],
        [0.6673, 0.3327],
        [0.6553, 0.3447],
        [0.6798, 0.3202],
        [0.6686, 0.3314],
        [0.6521, 0.3479],
        [0.6402, 0.3598],
        [0.6697, 0.3303],
        [0.6367, 0.3633],
        [0.6650, 0.3350],
        [0.6524, 0.3476],
        [0.6671, 0.3329],
        [0.6769, 0.3231],
        [0.6384, 0.3616],
        [0.6597, 0.3403],
        [0.6568, 0.3432],
        [0.6612, 0.3388],
        [0.6506, 0.3494],
        [0.6727, 0.3273],
        [0.6406, 0.3594],
        [0.6621, 0.3379],
        [0.6677, 0.3323],
        [0.6680, 0.3320],
        [0.6497, 0.3503],
        [0.6662, 0.3338],
        [0.6434, 0.3566],
        [0.6569, 0.3431],
        [0.6546, 0.3454],
        [0.6736, 0.3264],
        [0.6748, 0.3252],
        [0.6498, 0.3502],
        [0.6716, 0.3284],
        [0.6786, 0.3214],
        [0.6609, 0.3391],
        [0.6599, 0.3401],
        [0.6500, 0.3500],
        [0.6613, 0.3387],
        [0.6629, 0.3371],
        [0.6545, 0.3455],
        [0.6470, 0.3530],
        [0.6523, 0.3477],
        [0.6660, 0.3340],
        [0.6750, 0.3250],
        [0.6763, 0.3237],
        [0.6704, 0.3296],
        [0.6606, 0.3394],
        [0.6623, 0.3377],
        [0.6477, 0.3523],
        [0.6813, 0.3187],
        [0.6450, 0.3550],
        [0.6800, 0.3200],
        [0.6669, 0.3331],
        [0.6749, 0.3251],
        [0.6630, 0.3370],
        [0.6747, 0.3253],
        [0.6594, 0.3406],
        [0.6757, 0.3243],
        [0.6630, 0.3370],
        [0.6604, 0.3396],
        [0.6691, 0.3309],
        [0.6761, 0.3239],
        [0.6475, 0.3525],
        [0.6650, 0.3350],
        [0.6687, 0.3313],
        [0.6594, 0.3406],
        [0.6546, 0.3454],
        [0.6603, 0.3397],
        [0.6815, 0.3185],
        [0.6721, 0.3279]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0022 loss: 0.6648 acc_train: 0.6103 time: 0.1278s
tensor([[0.6566, 0.3434],
        [0.6654, 0.3346],
        [0.6832, 0.3168],
        [0.6577, 0.3423],
        [0.6731, 0.3269],
        [0.6468, 0.3532],
        [0.6370, 0.3630],
        [0.6511, 0.3489],
        [0.6595, 0.3405],
        [0.6346, 0.3654],
        [0.6646, 0.3354],
        [0.6502, 0.3498],
        [0.6496, 0.3504],
        [0.6567, 0.3433],
        [0.6677, 0.3323],
        [0.6584, 0.3416],
        [0.6657, 0.3343],
        [0.6425, 0.3575],
        [0.6647, 0.3353],
        [0.6409, 0.3591],
        [0.6676, 0.3324],
        [0.6499, 0.3501],
        [0.6624, 0.3376],
        [0.6833, 0.3167],
        [0.6645, 0.3355],
        [0.6526, 0.3474],
        [0.6459, 0.3541],
        [0.6648, 0.3351],
        [0.6485, 0.3515],
        [0.6524, 0.3476],
        [0.6621, 0.3379],
        [0.6497, 0.3503],
        [0.6687, 0.3313],
        [0.6563, 0.3437],
        [0.6603, 0.3397],
        [0.6538, 0.3462],
        [0.6585, 0.3415],
        [0.6545, 0.3455],
        [0.6628, 0.3372],
        [0.6354, 0.3646],
        [0.6659, 0.3341],
        [0.6628, 0.3372],
        [0.6597, 0.3403],
        [0.6559, 0.3441],
        [0.6520, 0.3480],
        [0.6483, 0.3517],
        [0.6737, 0.3263],
        [0.6805, 0.3195],
        [0.6465, 0.3535],
        [0.6609, 0.3391],
        [0.6563, 0.3437],
        [0.6678, 0.3322],
        [0.6599, 0.3401],
        [0.6719, 0.3281],
        [0.6653, 0.3347],
        [0.6707, 0.3293],
        [0.6688, 0.3312],
        [0.6624, 0.3376],
        [0.6445, 0.3555],
        [0.6553, 0.3447],
        [0.6468, 0.3532],
        [0.6546, 0.3454],
        [0.6635, 0.3365],
        [0.6751, 0.3249],
        [0.6446, 0.3554],
        [0.6490, 0.3510],
        [0.6608, 0.3392],
        [0.6560, 0.3440],
        [0.6696, 0.3304],
        [0.6573, 0.3427],
        [0.6580, 0.3420],
        [0.6493, 0.3507],
        [0.6613, 0.3387],
        [0.6559, 0.3441],
        [0.6513, 0.3487],
        [0.6588, 0.3412],
        [0.6656, 0.3344],
        [0.6548, 0.3452],
        [0.6572, 0.3428],
        [0.6517, 0.3483],
        [0.6447, 0.3553],
        [0.6480, 0.3520],
        [0.6486, 0.3514],
        [0.6524, 0.3476],
        [0.6625, 0.3375],
        [0.6457, 0.3543],
        [0.6599, 0.3401],
        [0.6569, 0.3431],
        [0.6431, 0.3569],
        [0.6587, 0.3413],
        [0.6517, 0.3483],
        [0.6500, 0.3500],
        [0.6641, 0.3359],
        [0.6444, 0.3556],
        [0.6530, 0.3470],
        [0.6646, 0.3354],
        [0.6753, 0.3247],
        [0.6505, 0.3495],
        [0.6667, 0.3333],
        [0.6543, 0.3457],
        [0.6525, 0.3475],
        [0.6596, 0.3404],
        [0.6537, 0.3463],
        [0.6427, 0.3573],
        [0.6631, 0.3369],
        [0.6477, 0.3523],
        [0.6672, 0.3328],
        [0.6649, 0.3351],
        [0.6398, 0.3602],
        [0.6559, 0.3441],
        [0.6567, 0.3433],
        [0.6664, 0.3336],
        [0.6640, 0.3360],
        [0.6659, 0.3341],
        [0.6528, 0.3472],
        [0.6439, 0.3561],
        [0.6674, 0.3326],
        [0.6742, 0.3258],
        [0.6694, 0.3306],
        [0.6616, 0.3384],
        [0.6606, 0.3394],
        [0.6419, 0.3581],
        [0.6560, 0.3440],
        [0.6597, 0.3403],
        [0.6676, 0.3324],
        [0.6581, 0.3419],
        [0.6440, 0.3560],
        [0.6588, 0.3412],
        [0.6580, 0.3420],
        [0.6537, 0.3463],
        [0.6633, 0.3367],
        [0.6608, 0.3392],
        [0.6558, 0.3442],
        [0.6467, 0.3533],
        [0.6560, 0.3440],
        [0.6476, 0.3524],
        [0.6574, 0.3426],
        [0.6718, 0.3282],
        [0.6625, 0.3375],
        [0.6475, 0.3525],
        [0.6489, 0.3511],
        [0.6538, 0.3462],
        [0.6478, 0.3522],
        [0.6473, 0.3527],
        [0.6392, 0.3608],
        [0.6683, 0.3317],
        [0.6714, 0.3286],
        [0.6566, 0.3434],
        [0.6629, 0.3371],
        [0.6752, 0.3248],
        [0.6574, 0.3426],
        [0.6761, 0.3239],
        [0.6723, 0.3277],
        [0.6714, 0.3286],
        [0.6710, 0.3290],
        [0.6447, 0.3553],
        [0.6727, 0.3273],
        [0.6635, 0.3365],
        [0.6452, 0.3548],
        [0.6543, 0.3457],
        [0.6636, 0.3364],
        [0.6641, 0.3359],
        [0.6582, 0.3418],
        [0.6602, 0.3398],
        [0.6522, 0.3478],
        [0.6596, 0.3404],
        [0.6581, 0.3419],
        [0.6462, 0.3538],
        [0.6601, 0.3399],
        [0.6535, 0.3465],
        [0.6531, 0.3469],
        [0.6586, 0.3414],
        [0.6451, 0.3549],
        [0.6491, 0.3509],
        [0.6583, 0.3417],
        [0.6568, 0.3432],
        [0.6692, 0.3308],
        [0.6571, 0.3429],
        [0.6397, 0.3603],
        [0.6719, 0.3281],
        [0.6745, 0.3255],
        [0.6520, 0.3480],
        [0.6578, 0.3422],
        [0.6520, 0.3480],
        [0.6604, 0.3396],
        [0.6596, 0.3404],
        [0.6356, 0.3644],
        [0.6605, 0.3395],
        [0.6466, 0.3534],
        [0.6650, 0.3350],
        [0.6755, 0.3245],
        [0.6583, 0.3417],
        [0.6522, 0.3478],
        [0.6434, 0.3566],
        [0.6734, 0.3266],
        [0.6731, 0.3269],
        [0.6782, 0.3218],
        [0.6413, 0.3587],
        [0.6647, 0.3353],
        [0.6616, 0.3384],
        [0.6455, 0.3545],
        [0.6718, 0.3282],
        [0.6679, 0.3321],
        [0.6477, 0.3523],
        [0.6670, 0.3330],
        [0.6572, 0.3428],
        [0.6776, 0.3224],
        [0.6683, 0.3317],
        [0.6534, 0.3466],
        [0.6431, 0.3569],
        [0.6688, 0.3312],
        [0.6405, 0.3595],
        [0.6658, 0.3342],
        [0.6539, 0.3461],
        [0.6669, 0.3331],
        [0.6749, 0.3251],
        [0.6417, 0.3583],
        [0.6607, 0.3393],
        [0.6574, 0.3426],
        [0.6623, 0.3377],
        [0.6520, 0.3480],
        [0.6722, 0.3278],
        [0.6439, 0.3561],
        [0.6625, 0.3375],
        [0.6677, 0.3323],
        [0.6685, 0.3315],
        [0.6502, 0.3498],
        [0.6660, 0.3340],
        [0.6468, 0.3532],
        [0.6581, 0.3419],
        [0.6565, 0.3435],
        [0.6727, 0.3273],
        [0.6731, 0.3269],
        [0.6518, 0.3482],
        [0.6713, 0.3287],
        [0.6778, 0.3222],
        [0.6609, 0.3391],
        [0.6603, 0.3397],
        [0.6524, 0.3476],
        [0.6621, 0.3379],
        [0.6634, 0.3366],
        [0.6558, 0.3442],
        [0.6490, 0.3510],
        [0.6537, 0.3463],
        [0.6670, 0.3330],
        [0.6739, 0.3261],
        [0.6751, 0.3249],
        [0.6699, 0.3301],
        [0.6608, 0.3392],
        [0.6638, 0.3362],
        [0.6505, 0.3495],
        [0.6796, 0.3204],
        [0.6480, 0.3520],
        [0.6779, 0.3221],
        [0.6665, 0.3335],
        [0.6734, 0.3266],
        [0.6641, 0.3359],
        [0.6745, 0.3255],
        [0.6606, 0.3394],
        [0.6752, 0.3248],
        [0.6636, 0.3364],
        [0.6615, 0.3385],
        [0.6682, 0.3318],
        [0.6749, 0.3251],
        [0.6499, 0.3501],
        [0.6655, 0.3345],
        [0.6686, 0.3314],
        [0.6605, 0.3395],
        [0.6550, 0.3450],
        [0.6607, 0.3393],
        [0.6801, 0.3199],
        [0.6713, 0.3287]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0023 loss: 0.6656 acc_train: 0.6103 time: 0.1089s
tensor([[0.6576, 0.3424],
        [0.6656, 0.3344],
        [0.6809, 0.3191],
        [0.6589, 0.3411],
        [0.6715, 0.3285],
        [0.6483, 0.3517],
        [0.6404, 0.3596],
        [0.6524, 0.3476],
        [0.6599, 0.3401],
        [0.6382, 0.3618],
        [0.6647, 0.3353],
        [0.6516, 0.3484],
        [0.6510, 0.3490],
        [0.6573, 0.3427],
        [0.6669, 0.3331],
        [0.6585, 0.3415],
        [0.6658, 0.3342],
        [0.6454, 0.3546],
        [0.6646, 0.3354],
        [0.6443, 0.3557],
        [0.6669, 0.3331],
        [0.6513, 0.3487],
        [0.6626, 0.3374],
        [0.6811, 0.3189],
        [0.6644, 0.3356],
        [0.6533, 0.3467],
        [0.6481, 0.3519],
        [0.6646, 0.3354],
        [0.6505, 0.3495],
        [0.6534, 0.3466],
        [0.6625, 0.3375],
        [0.6512, 0.3488],
        [0.6680, 0.3320],
        [0.6569, 0.3431],
        [0.6605, 0.3395],
        [0.6531, 0.3469],
        [0.6591, 0.3409],
        [0.6550, 0.3450],
        [0.6625, 0.3375],
        [0.6390, 0.3610],
        [0.6653, 0.3347],
        [0.6631, 0.3369],
        [0.6588, 0.3412],
        [0.6567, 0.3433],
        [0.6533, 0.3467],
        [0.6497, 0.3503],
        [0.6724, 0.3276],
        [0.6777, 0.3223],
        [0.6488, 0.3512],
        [0.6610, 0.3390],
        [0.6574, 0.3426],
        [0.6671, 0.3329],
        [0.6595, 0.3405],
        [0.6706, 0.3294],
        [0.6657, 0.3343],
        [0.6695, 0.3305],
        [0.6678, 0.3322],
        [0.6621, 0.3379],
        [0.6474, 0.3526],
        [0.6567, 0.3433],
        [0.6488, 0.3512],
        [0.6557, 0.3443],
        [0.6631, 0.3369],
        [0.6728, 0.3272],
        [0.6468, 0.3532],
        [0.6511, 0.3489],
        [0.6604, 0.3396],
        [0.6572, 0.3428],
        [0.6689, 0.3311],
        [0.6580, 0.3420],
        [0.6581, 0.3419],
        [0.6515, 0.3485],
        [0.6619, 0.3381],
        [0.6564, 0.3436],
        [0.6529, 0.3471],
        [0.6593, 0.3407],
        [0.6648, 0.3352],
        [0.6552, 0.3448],
        [0.6583, 0.3417],
        [0.6536, 0.3464],
        [0.6469, 0.3531],
        [0.6496, 0.3504],
        [0.6508, 0.3492],
        [0.6535, 0.3465],
        [0.6626, 0.3374],
        [0.6477, 0.3523],
        [0.6602, 0.3398],
        [0.6572, 0.3428],
        [0.6457, 0.3543],
        [0.6588, 0.3412],
        [0.6534, 0.3466],
        [0.6520, 0.3480],
        [0.6639, 0.3361],
        [0.6473, 0.3527],
        [0.6541, 0.3459],
        [0.6641, 0.3359],
        [0.6737, 0.3263],
        [0.6516, 0.3484],
        [0.6664, 0.3336],
        [0.6556, 0.3444],
        [0.6542, 0.3458],
        [0.6603, 0.3397],
        [0.6551, 0.3449],
        [0.6455, 0.3545],
        [0.6628, 0.3372],
        [0.6495, 0.3505],
        [0.6670, 0.3330],
        [0.6646, 0.3354],
        [0.6427, 0.3573],
        [0.6571, 0.3429],
        [0.6562, 0.3438],
        [0.6655, 0.3345],
        [0.6640, 0.3360],
        [0.6650, 0.3350],
        [0.6535, 0.3465],
        [0.6448, 0.3552],
        [0.6663, 0.3337],
        [0.6732, 0.3268],
        [0.6686, 0.3314],
        [0.6617, 0.3383],
        [0.6614, 0.3386],
        [0.6442, 0.3558],
        [0.6569, 0.3431],
        [0.6595, 0.3405],
        [0.6667, 0.3333],
        [0.6585, 0.3415],
        [0.6465, 0.3535],
        [0.6588, 0.3412],
        [0.6584, 0.3416],
        [0.6552, 0.3448],
        [0.6630, 0.3370],
        [0.6611, 0.3389],
        [0.6568, 0.3432],
        [0.6485, 0.3515],
        [0.6570, 0.3430],
        [0.6489, 0.3511],
        [0.6582, 0.3418],
        [0.6698, 0.3302],
        [0.6623, 0.3377],
        [0.6488, 0.3512],
        [0.6506, 0.3494],
        [0.6550, 0.3450],
        [0.6493, 0.3507],
        [0.6492, 0.3508],
        [0.6428, 0.3572],
        [0.6673, 0.3327],
        [0.6707, 0.3293],
        [0.6575, 0.3425],
        [0.6629, 0.3371],
        [0.6733, 0.3267],
        [0.6583, 0.3417],
        [0.6744, 0.3256],
        [0.6709, 0.3291],
        [0.6710, 0.3290],
        [0.6702, 0.3298],
        [0.6463, 0.3537],
        [0.6718, 0.3282],
        [0.6631, 0.3369],
        [0.6473, 0.3527],
        [0.6552, 0.3448],
        [0.6640, 0.3360],
        [0.6638, 0.3362],
        [0.6592, 0.3408],
        [0.6603, 0.3397],
        [0.6523, 0.3477],
        [0.6595, 0.3405],
        [0.6592, 0.3408],
        [0.6485, 0.3515],
        [0.6607, 0.3393],
        [0.6544, 0.3456],
        [0.6523, 0.3477],
        [0.6593, 0.3407],
        [0.6472, 0.3528],
        [0.6513, 0.3487],
        [0.6591, 0.3409],
        [0.6581, 0.3419],
        [0.6683, 0.3317],
        [0.6572, 0.3428],
        [0.6428, 0.3572],
        [0.6706, 0.3294],
        [0.6737, 0.3263],
        [0.6538, 0.3462],
        [0.6582, 0.3418],
        [0.6541, 0.3459],
        [0.6600, 0.3400],
        [0.6602, 0.3398],
        [0.6395, 0.3605],
        [0.6606, 0.3394],
        [0.6480, 0.3520],
        [0.6643, 0.3357],
        [0.6735, 0.3265],
        [0.6592, 0.3408],
        [0.6531, 0.3469],
        [0.6456, 0.3544],
        [0.6719, 0.3281],
        [0.6722, 0.3278],
        [0.6762, 0.3238],
        [0.6442, 0.3558],
        [0.6644, 0.3356],
        [0.6618, 0.3382],
        [0.6481, 0.3519],
        [0.6707, 0.3293],
        [0.6672, 0.3328],
        [0.6494, 0.3506],
        [0.6663, 0.3337],
        [0.6585, 0.3415],
        [0.6753, 0.3247],
        [0.6677, 0.3323],
        [0.6544, 0.3456],
        [0.6456, 0.3544],
        [0.6676, 0.3324],
        [0.6435, 0.3565],
        [0.6660, 0.3340],
        [0.6548, 0.3452],
        [0.6659, 0.3341],
        [0.6730, 0.3270],
        [0.6443, 0.3557],
        [0.6613, 0.3387],
        [0.6579, 0.3421],
        [0.6625, 0.3375],
        [0.6530, 0.3470],
        [0.6715, 0.3285],
        [0.6465, 0.3535],
        [0.6625, 0.3375],
        [0.6672, 0.3328],
        [0.6684, 0.3316],
        [0.6501, 0.3499],
        [0.6657, 0.3343],
        [0.6495, 0.3505],
        [0.6590, 0.3410],
        [0.6576, 0.3424],
        [0.6715, 0.3285],
        [0.6712, 0.3288],
        [0.6532, 0.3468],
        [0.6704, 0.3296],
        [0.6766, 0.3234],
        [0.6606, 0.3394],
        [0.6600, 0.3400],
        [0.6537, 0.3463],
        [0.6624, 0.3376],
        [0.6633, 0.3367],
        [0.6565, 0.3435],
        [0.6505, 0.3495],
        [0.6548, 0.3452],
        [0.6672, 0.3328],
        [0.6724, 0.3276],
        [0.6736, 0.3264],
        [0.6688, 0.3312],
        [0.6606, 0.3394],
        [0.6645, 0.3355],
        [0.6522, 0.3478],
        [0.6777, 0.3223],
        [0.6502, 0.3498],
        [0.6760, 0.3240],
        [0.6657, 0.3343],
        [0.6718, 0.3282],
        [0.6646, 0.3354],
        [0.6736, 0.3264],
        [0.6612, 0.3388],
        [0.6743, 0.3257],
        [0.6638, 0.3362],
        [0.6615, 0.3385],
        [0.6670, 0.3330],
        [0.6735, 0.3265],
        [0.6517, 0.3483],
        [0.6652, 0.3348],
        [0.6680, 0.3320],
        [0.6611, 0.3389],
        [0.6553, 0.3447],
        [0.6607, 0.3393],
        [0.6785, 0.3215],
        [0.6702, 0.3298]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0024 loss: 0.6662 acc_train: 0.6103 time: 0.1213s
tensor([[0.6584, 0.3416],
        [0.6655, 0.3345],
        [0.6791, 0.3209],
        [0.6599, 0.3401],
        [0.6703, 0.3297],
        [0.6501, 0.3499],
        [0.6437, 0.3563],
        [0.6538, 0.3462],
        [0.6602, 0.3398],
        [0.6415, 0.3585],
        [0.6652, 0.3348],
        [0.6530, 0.3470],
        [0.6525, 0.3475],
        [0.6581, 0.3419],
        [0.6664, 0.3336],
        [0.6588, 0.3412],
        [0.6661, 0.3339],
        [0.6480, 0.3520],
        [0.6648, 0.3352],
        [0.6472, 0.3528],
        [0.6665, 0.3335],
        [0.6528, 0.3472],
        [0.6628, 0.3372],
        [0.6794, 0.3206],
        [0.6646, 0.3354],
        [0.6541, 0.3459],
        [0.6499, 0.3501],
        [0.6646, 0.3354],
        [0.6525, 0.3475],
        [0.6544, 0.3456],
        [0.6630, 0.3370],
        [0.6528, 0.3472],
        [0.6676, 0.3324],
        [0.6578, 0.3422],
        [0.6612, 0.3388],
        [0.6528, 0.3472],
        [0.6598, 0.3402],
        [0.6560, 0.3440],
        [0.6626, 0.3374],
        [0.6424, 0.3576],
        [0.6651, 0.3349],
        [0.6636, 0.3364],
        [0.6583, 0.3417],
        [0.6576, 0.3424],
        [0.6548, 0.3452],
        [0.6511, 0.3489],
        [0.6715, 0.3285],
        [0.6758, 0.3242],
        [0.6509, 0.3491],
        [0.6613, 0.3387],
        [0.6585, 0.3415],
        [0.6667, 0.3333],
        [0.6595, 0.3405],
        [0.6698, 0.3302],
        [0.6662, 0.3338],
        [0.6688, 0.3312],
        [0.6671, 0.3329],
        [0.6621, 0.3379],
        [0.6501, 0.3499],
        [0.6581, 0.3419],
        [0.6509, 0.3491],
        [0.6572, 0.3428],
        [0.6631, 0.3369],
        [0.6712, 0.3288],
        [0.6491, 0.3509],
        [0.6530, 0.3470],
        [0.6604, 0.3396],
        [0.6585, 0.3415],
        [0.6682, 0.3318],
        [0.6588, 0.3412],
        [0.6584, 0.3416],
        [0.6534, 0.3466],
        [0.6623, 0.3377],
        [0.6573, 0.3427],
        [0.6545, 0.3455],
        [0.6600, 0.3400],
        [0.6645, 0.3355],
        [0.6560, 0.3440],
        [0.6595, 0.3405],
        [0.6553, 0.3447],
        [0.6493, 0.3507],
        [0.6515, 0.3485],
        [0.6530, 0.3470],
        [0.6548, 0.3452],
        [0.6630, 0.3370],
        [0.6497, 0.3503],
        [0.6608, 0.3392],
        [0.6578, 0.3422],
        [0.6482, 0.3518],
        [0.6593, 0.3407],
        [0.6552, 0.3448],
        [0.6541, 0.3459],
        [0.6640, 0.3360],
        [0.6499, 0.3501],
        [0.6555, 0.3445],
        [0.6639, 0.3361],
        [0.6723, 0.3277],
        [0.6528, 0.3472],
        [0.6664, 0.3336],
        [0.6568, 0.3432],
        [0.6557, 0.3443],
        [0.6612, 0.3388],
        [0.6565, 0.3435],
        [0.6480, 0.3520],
        [0.6629, 0.3371],
        [0.6515, 0.3485],
        [0.6670, 0.3330],
        [0.6644, 0.3356],
        [0.6453, 0.3547],
        [0.6581, 0.3419],
        [0.6558, 0.3442],
        [0.6651, 0.3349],
        [0.6644, 0.3356],
        [0.6646, 0.3354],
        [0.6546, 0.3454],
        [0.6460, 0.3540],
        [0.6658, 0.3342],
        [0.6723, 0.3277],
        [0.6679, 0.3321],
        [0.6620, 0.3380],
        [0.6623, 0.3377],
        [0.6464, 0.3536],
        [0.6577, 0.3423],
        [0.6595, 0.3405],
        [0.6663, 0.3337],
        [0.6593, 0.3407],
        [0.6490, 0.3510],
        [0.6591, 0.3409],
        [0.6590, 0.3410],
        [0.6567, 0.3433],
        [0.6628, 0.3372],
        [0.6615, 0.3385],
        [0.6578, 0.3422],
        [0.6503, 0.3497],
        [0.6579, 0.3421],
        [0.6502, 0.3498],
        [0.6591, 0.3409],
        [0.6682, 0.3318],
        [0.6622, 0.3378],
        [0.6501, 0.3499],
        [0.6522, 0.3478],
        [0.6564, 0.3436],
        [0.6511, 0.3489],
        [0.6512, 0.3488],
        [0.6460, 0.3540],
        [0.6665, 0.3335],
        [0.6702, 0.3298],
        [0.6587, 0.3413],
        [0.6630, 0.3370],
        [0.6718, 0.3282],
        [0.6592, 0.3408],
        [0.6731, 0.3269],
        [0.6698, 0.3302],
        [0.6707, 0.3293],
        [0.6698, 0.3302],
        [0.6483, 0.3517],
        [0.6714, 0.3286],
        [0.6629, 0.3371],
        [0.6495, 0.3505],
        [0.6561, 0.3439],
        [0.6643, 0.3357],
        [0.6639, 0.3361],
        [0.6601, 0.3399],
        [0.6606, 0.3394],
        [0.6525, 0.3475],
        [0.6598, 0.3402],
        [0.6601, 0.3399],
        [0.6509, 0.3491],
        [0.6613, 0.3387],
        [0.6553, 0.3447],
        [0.6519, 0.3481],
        [0.6603, 0.3397],
        [0.6496, 0.3504],
        [0.6532, 0.3468],
        [0.6599, 0.3401],
        [0.6591, 0.3409],
        [0.6680, 0.3320],
        [0.6577, 0.3423],
        [0.6456, 0.3544],
        [0.6696, 0.3304],
        [0.6730, 0.3270],
        [0.6555, 0.3445],
        [0.6587, 0.3413],
        [0.6560, 0.3440],
        [0.6600, 0.3400],
        [0.6610, 0.3390],
        [0.6430, 0.3570],
        [0.6611, 0.3389],
        [0.6494, 0.3506],
        [0.6640, 0.3360],
        [0.6722, 0.3278],
        [0.6605, 0.3395],
        [0.6541, 0.3459],
        [0.6481, 0.3519],
        [0.6710, 0.3290],
        [0.6717, 0.3283],
        [0.6747, 0.3253],
        [0.6469, 0.3531],
        [0.6644, 0.3356],
        [0.6621, 0.3379],
        [0.6506, 0.3494],
        [0.6699, 0.3301],
        [0.6668, 0.3332],
        [0.6514, 0.3486],
        [0.6660, 0.3340],
        [0.6598, 0.3402],
        [0.6737, 0.3263],
        [0.6674, 0.3326],
        [0.6557, 0.3443],
        [0.6483, 0.3517],
        [0.6669, 0.3331],
        [0.6463, 0.3537],
        [0.6663, 0.3337],
        [0.6560, 0.3440],
        [0.6652, 0.3348],
        [0.6718, 0.3282],
        [0.6469, 0.3531],
        [0.6621, 0.3379],
        [0.6589, 0.3411],
        [0.6625, 0.3375],
        [0.6542, 0.3458],
        [0.6711, 0.3289],
        [0.6489, 0.3511],
        [0.6628, 0.3372],
        [0.6670, 0.3330],
        [0.6685, 0.3315],
        [0.6502, 0.3498],
        [0.6657, 0.3343],
        [0.6522, 0.3478],
        [0.6599, 0.3401],
        [0.6586, 0.3414],
        [0.6708, 0.3292],
        [0.6701, 0.3299],
        [0.6545, 0.3455],
        [0.6698, 0.3302],
        [0.6757, 0.3243],
        [0.6605, 0.3395],
        [0.6602, 0.3398],
        [0.6550, 0.3450],
        [0.6629, 0.3371],
        [0.6632, 0.3368],
        [0.6574, 0.3426],
        [0.6522, 0.3478],
        [0.6562, 0.3438],
        [0.6673, 0.3327],
        [0.6715, 0.3285],
        [0.6725, 0.3275],
        [0.6680, 0.3320],
        [0.6606, 0.3394],
        [0.6651, 0.3349],
        [0.6537, 0.3463],
        [0.6764, 0.3236],
        [0.6524, 0.3476],
        [0.6747, 0.3253],
        [0.6654, 0.3346],
        [0.6706, 0.3294],
        [0.6651, 0.3349],
        [0.6727, 0.3273],
        [0.6615, 0.3385],
        [0.6733, 0.3267],
        [0.6641, 0.3359],
        [0.6617, 0.3383],
        [0.6662, 0.3338],
        [0.6724, 0.3276],
        [0.6535, 0.3465],
        [0.6647, 0.3353],
        [0.6676, 0.3324],
        [0.6620, 0.3380],
        [0.6560, 0.3440],
        [0.6611, 0.3389],
        [0.6773, 0.3227],
        [0.6696, 0.3304]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0025 loss: 0.6668 acc_train: 0.6103 time: 0.1187s
tensor([[0.6594, 0.3406],
        [0.6657, 0.3343],
        [0.6779, 0.3221],
        [0.6609, 0.3391],
        [0.6698, 0.3302],
        [0.6522, 0.3478],
        [0.6470, 0.3530],
        [0.6556, 0.3444],
        [0.6609, 0.3391],
        [0.6449, 0.3551],
        [0.6661, 0.3339],
        [0.6547, 0.3453],
        [0.6546, 0.3454],
        [0.6591, 0.3409],
        [0.6664, 0.3336],
        [0.6596, 0.3404],
        [0.6666, 0.3334],
        [0.6503, 0.3497],
        [0.6653, 0.3347],
        [0.6499, 0.3501],
        [0.6665, 0.3335],
        [0.6546, 0.3454],
        [0.6635, 0.3365],
        [0.6782, 0.3218],
        [0.6653, 0.3347],
        [0.6551, 0.3449],
        [0.6518, 0.3482],
        [0.6649, 0.3351],
        [0.6546, 0.3454],
        [0.6557, 0.3443],
        [0.6638, 0.3362],
        [0.6545, 0.3455],
        [0.6677, 0.3323],
        [0.6592, 0.3408],
        [0.6623, 0.3377],
        [0.6528, 0.3472],
        [0.6610, 0.3390],
        [0.6573, 0.3427],
        [0.6632, 0.3368],
        [0.6456, 0.3544],
        [0.6653, 0.3347],
        [0.6645, 0.3355],
        [0.6582, 0.3418],
        [0.6586, 0.3414],
        [0.6565, 0.3435],
        [0.6528, 0.3472],
        [0.6712, 0.3288],
        [0.6747, 0.3253],
        [0.6529, 0.3471],
        [0.6621, 0.3379],
        [0.6600, 0.3400],
        [0.6668, 0.3332],
        [0.6602, 0.3398],
        [0.6695, 0.3305],
        [0.6667, 0.3333],
        [0.6687, 0.3313],
        [0.6668, 0.3332],
        [0.6626, 0.3374],
        [0.6526, 0.3474],
        [0.6594, 0.3406],
        [0.6532, 0.3468],
        [0.6592, 0.3408],
        [0.6634, 0.3366],
        [0.6704, 0.3296],
        [0.6515, 0.3485],
        [0.6549, 0.3451],
        [0.6609, 0.3391],
        [0.6601, 0.3399],
        [0.6679, 0.3321],
        [0.6601, 0.3399],
        [0.6589, 0.3411],
        [0.6553, 0.3447],
        [0.6628, 0.3372],
        [0.6586, 0.3414],
        [0.6563, 0.3437],
        [0.6610, 0.3390],
        [0.6647, 0.3353],
        [0.6574, 0.3426],
        [0.6612, 0.3388],
        [0.6572, 0.3428],
        [0.6520, 0.3480],
        [0.6537, 0.3463],
        [0.6553, 0.3447],
        [0.6564, 0.3436],
        [0.6638, 0.3362],
        [0.6519, 0.3481],
        [0.6618, 0.3382],
        [0.6588, 0.3412],
        [0.6508, 0.3492],
        [0.6602, 0.3398],
        [0.6572, 0.3428],
        [0.6564, 0.3436],
        [0.6646, 0.3354],
        [0.6524, 0.3476],
        [0.6572, 0.3428],
        [0.6645, 0.3355],
        [0.6716, 0.3284],
        [0.6545, 0.3455],
        [0.6668, 0.3332],
        [0.6581, 0.3419],
        [0.6571, 0.3429],
        [0.6623, 0.3377],
        [0.6583, 0.3417],
        [0.6503, 0.3497],
        [0.6634, 0.3366],
        [0.6536, 0.3464],
        [0.6674, 0.3326],
        [0.6647, 0.3353],
        [0.6480, 0.3520],
        [0.6592, 0.3408],
        [0.6556, 0.3444],
        [0.6651, 0.3349],
        [0.6652, 0.3348],
        [0.6648, 0.3352],
        [0.6561, 0.3439],
        [0.6474, 0.3526],
        [0.6660, 0.3340],
        [0.6717, 0.3283],
        [0.6676, 0.3324],
        [0.6626, 0.3374],
        [0.6633, 0.3367],
        [0.6487, 0.3513],
        [0.6588, 0.3412],
        [0.6602, 0.3398],
        [0.6663, 0.3337],
        [0.6605, 0.3395],
        [0.6515, 0.3485],
        [0.6598, 0.3402],
        [0.6601, 0.3399],
        [0.6583, 0.3417],
        [0.6632, 0.3368],
        [0.6621, 0.3379],
        [0.6590, 0.3410],
        [0.6523, 0.3477],
        [0.6590, 0.3410],
        [0.6519, 0.3481],
        [0.6602, 0.3398],
        [0.6674, 0.3326],
        [0.6624, 0.3376],
        [0.6516, 0.3484],
        [0.6540, 0.3460],
        [0.6581, 0.3419],
        [0.6530, 0.3470],
        [0.6533, 0.3467],
        [0.6491, 0.3509],
        [0.6664, 0.3336],
        [0.6702, 0.3298],
        [0.6601, 0.3399],
        [0.6634, 0.3366],
        [0.6711, 0.3289],
        [0.6602, 0.3398],
        [0.6726, 0.3274],
        [0.6692, 0.3308],
        [0.6706, 0.3294],
        [0.6699, 0.3301],
        [0.6507, 0.3493],
        [0.6714, 0.3286],
        [0.6632, 0.3368],
        [0.6519, 0.3481],
        [0.6574, 0.3426],
        [0.6649, 0.3351],
        [0.6645, 0.3355],
        [0.6610, 0.3390],
        [0.6615, 0.3385],
        [0.6526, 0.3474],
        [0.6606, 0.3394],
        [0.6609, 0.3391],
        [0.6534, 0.3466],
        [0.6620, 0.3380],
        [0.6566, 0.3434],
        [0.6520, 0.3480],
        [0.6615, 0.3385],
        [0.6526, 0.3474],
        [0.6551, 0.3449],
        [0.6608, 0.3392],
        [0.6600, 0.3400],
        [0.6681, 0.3319],
        [0.6587, 0.3413],
        [0.6484, 0.3516],
        [0.6692, 0.3308],
        [0.6727, 0.3273],
        [0.6571, 0.3429],
        [0.6596, 0.3404],
        [0.6579, 0.3421],
        [0.6605, 0.3395],
        [0.6622, 0.3378],
        [0.6462, 0.3538],
        [0.6621, 0.3379],
        [0.6511, 0.3489],
        [0.6642, 0.3358],
        [0.6714, 0.3286],
        [0.6622, 0.3378],
        [0.6556, 0.3444],
        [0.6509, 0.3491],
        [0.6708, 0.3292],
        [0.6715, 0.3285],
        [0.6736, 0.3264],
        [0.6496, 0.3504],
        [0.6647, 0.3353],
        [0.6627, 0.3373],
        [0.6532, 0.3468],
        [0.6697, 0.3303],
        [0.6668, 0.3332],
        [0.6536, 0.3464],
        [0.6661, 0.3339],
        [0.6612, 0.3388],
        [0.6729, 0.3271],
        [0.6676, 0.3324],
        [0.6576, 0.3424],
        [0.6512, 0.3488],
        [0.6669, 0.3331],
        [0.6490, 0.3510],
        [0.6668, 0.3332],
        [0.6575, 0.3425],
        [0.6651, 0.3349],
        [0.6713, 0.3287],
        [0.6494, 0.3506],
        [0.6634, 0.3366],
        [0.6604, 0.3396],
        [0.6627, 0.3373],
        [0.6558, 0.3442],
        [0.6711, 0.3289],
        [0.6513, 0.3487],
        [0.6634, 0.3366],
        [0.6671, 0.3329],
        [0.6690, 0.3310],
        [0.6506, 0.3494],
        [0.6663, 0.3337],
        [0.6549, 0.3451],
        [0.6611, 0.3389],
        [0.6598, 0.3402],
        [0.6705, 0.3295],
        [0.6697, 0.3303],
        [0.6560, 0.3440],
        [0.6696, 0.3304],
        [0.6751, 0.3249],
        [0.6610, 0.3390],
        [0.6609, 0.3391],
        [0.6563, 0.3437],
        [0.6636, 0.3364],
        [0.6633, 0.3367],
        [0.6587, 0.3413],
        [0.6542, 0.3458],
        [0.6581, 0.3419],
        [0.6672, 0.3328],
        [0.6714, 0.3286],
        [0.6718, 0.3282],
        [0.6677, 0.3323],
        [0.6611, 0.3389],
        [0.6658, 0.3342],
        [0.6554, 0.3446],
        [0.6756, 0.3244],
        [0.6546, 0.3454],
        [0.6741, 0.3259],
        [0.6656, 0.3344],
        [0.6701, 0.3299],
        [0.6657, 0.3343],
        [0.6721, 0.3279],
        [0.6620, 0.3380],
        [0.6726, 0.3274],
        [0.6648, 0.3352],
        [0.6621, 0.3379],
        [0.6661, 0.3339],
        [0.6717, 0.3283],
        [0.6554, 0.3446],
        [0.6643, 0.3357],
        [0.6676, 0.3324],
        [0.6631, 0.3369],
        [0.6572, 0.3428],
        [0.6618, 0.3382],
        [0.6767, 0.3233],
        [0.6695, 0.3305]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0026 loss: 0.6673 acc_train: 0.6103 time: 0.1275s
tensor([[0.6606, 0.3394],
        [0.6660, 0.3340],
        [0.6773, 0.3227],
        [0.6619, 0.3381],
        [0.6697, 0.3303],
        [0.6543, 0.3457],
        [0.6501, 0.3499],
        [0.6575, 0.3425],
        [0.6619, 0.3381],
        [0.6480, 0.3520],
        [0.6672, 0.3328],
        [0.6564, 0.3436],
        [0.6570, 0.3430],
        [0.6603, 0.3397],
        [0.6668, 0.3332],
        [0.6608, 0.3392],
        [0.6673, 0.3327],
        [0.6524, 0.3476],
        [0.6661, 0.3339],
        [0.6524, 0.3476],
        [0.6669, 0.3331],
        [0.6566, 0.3434],
        [0.6644, 0.3356],
        [0.6776, 0.3224],
        [0.6663, 0.3337],
        [0.6564, 0.3436],
        [0.6536, 0.3464],
        [0.6653, 0.3347],
        [0.6564, 0.3436],
        [0.6573, 0.3427],
        [0.6646, 0.3354],
        [0.6564, 0.3436],
        [0.6682, 0.3318],
        [0.6608, 0.3392],
        [0.6637, 0.3363],
        [0.6532, 0.3468],
        [0.6624, 0.3376],
        [0.6588, 0.3412],
        [0.6642, 0.3358],
        [0.6486, 0.3514],
        [0.6659, 0.3341],
        [0.6655, 0.3345],
        [0.6584, 0.3416],
        [0.6597, 0.3403],
        [0.6583, 0.3417],
        [0.6548, 0.3452],
        [0.6713, 0.3287],
        [0.6744, 0.3256],
        [0.6548, 0.3452],
        [0.6631, 0.3369],
        [0.6617, 0.3383],
        [0.6674, 0.3326],
        [0.6613, 0.3387],
        [0.6696, 0.3304],
        [0.6672, 0.3328],
        [0.6689, 0.3311],
        [0.6669, 0.3331],
        [0.6634, 0.3366],
        [0.6551, 0.3449],
        [0.6608, 0.3392],
        [0.6554, 0.3446],
        [0.6614, 0.3386],
        [0.6641, 0.3359],
        [0.6703, 0.3297],
        [0.6540, 0.3460],
        [0.6569, 0.3431],
        [0.6620, 0.3380],
        [0.6618, 0.3382],
        [0.6680, 0.3320],
        [0.6615, 0.3385],
        [0.6597, 0.3403],
        [0.6572, 0.3428],
        [0.6634, 0.3366],
        [0.6601, 0.3399],
        [0.6584, 0.3416],
        [0.6623, 0.3377],
        [0.6653, 0.3347],
        [0.6593, 0.3407],
        [0.6629, 0.3371],
        [0.6589, 0.3411],
        [0.6547, 0.3453],
        [0.6561, 0.3439],
        [0.6576, 0.3424],
        [0.6581, 0.3419],
        [0.6649, 0.3351],
        [0.6540, 0.3460],
        [0.6632, 0.3368],
        [0.6600, 0.3400],
        [0.6531, 0.3469],
        [0.6614, 0.3386],
        [0.6591, 0.3409],
        [0.6586, 0.3414],
        [0.6653, 0.3347],
        [0.6546, 0.3454],
        [0.6590, 0.3410],
        [0.6658, 0.3342],
        [0.6713, 0.3287],
        [0.6563, 0.3437],
        [0.6674, 0.3326],
        [0.6594, 0.3406],
        [0.6586, 0.3414],
        [0.6635, 0.3365],
        [0.6601, 0.3399],
        [0.6525, 0.3475],
        [0.6641, 0.3359],
        [0.6559, 0.3441],
        [0.6679, 0.3321],
        [0.6655, 0.3345],
        [0.6507, 0.3493],
        [0.6603, 0.3397],
        [0.6556, 0.3444],
        [0.6655, 0.3345],
        [0.6662, 0.3337],
        [0.6653, 0.3347],
        [0.6578, 0.3422],
        [0.6491, 0.3509],
        [0.6667, 0.3333],
        [0.6714, 0.3286],
        [0.6677, 0.3323],
        [0.6634, 0.3366],
        [0.6646, 0.3354],
        [0.6511, 0.3489],
        [0.6600, 0.3400],
        [0.6613, 0.3387],
        [0.6667, 0.3333],
        [0.6619, 0.3381],
        [0.6539, 0.3461],
        [0.6608, 0.3392],
        [0.6615, 0.3385],
        [0.6599, 0.3401],
        [0.6642, 0.3358],
        [0.6629, 0.3371],
        [0.6603, 0.3397],
        [0.6543, 0.3457],
        [0.6601, 0.3399],
        [0.6539, 0.3461],
        [0.6614, 0.3386],
        [0.6672, 0.3328],
        [0.6628, 0.3372],
        [0.6534, 0.3466],
        [0.6557, 0.3443],
        [0.6599, 0.3401],
        [0.6551, 0.3449],
        [0.6554, 0.3446],
        [0.6519, 0.3481],
        [0.6667, 0.3333],
        [0.6703, 0.3297],
        [0.6617, 0.3383],
        [0.6638, 0.3362],
        [0.6710, 0.3290],
        [0.6614, 0.3386],
        [0.6726, 0.3274],
        [0.6691, 0.3309],
        [0.6707, 0.3293],
        [0.6704, 0.3296],
        [0.6533, 0.3467],
        [0.6717, 0.3283],
        [0.6638, 0.3362],
        [0.6543, 0.3457],
        [0.6588, 0.3412],
        [0.6657, 0.3343],
        [0.6655, 0.3345],
        [0.6620, 0.3380],
        [0.6626, 0.3374],
        [0.6530, 0.3470],
        [0.6616, 0.3384],
        [0.6616, 0.3384],
        [0.6559, 0.3441],
        [0.6629, 0.3371],
        [0.6582, 0.3418],
        [0.6525, 0.3475],
        [0.6628, 0.3372],
        [0.6557, 0.3443],
        [0.6568, 0.3432],
        [0.6618, 0.3382],
        [0.6609, 0.3391],
        [0.6686, 0.3314],
        [0.6602, 0.3398],
        [0.6512, 0.3488],
        [0.6693, 0.3307],
        [0.6727, 0.3273],
        [0.6586, 0.3414],
        [0.6607, 0.3393],
        [0.6597, 0.3403],
        [0.6614, 0.3386],
        [0.6633, 0.3367],
        [0.6490, 0.3510],
        [0.6635, 0.3365],
        [0.6529, 0.3471],
        [0.6647, 0.3353],
        [0.6712, 0.3288],
        [0.6640, 0.3360],
        [0.6572, 0.3428],
        [0.6536, 0.3464],
        [0.6710, 0.3290],
        [0.6717, 0.3283],
        [0.6730, 0.3270],
        [0.6522, 0.3478],
        [0.6653, 0.3347],
        [0.6636, 0.3364],
        [0.6556, 0.3444],
        [0.6700, 0.3300],
        [0.6672, 0.3328],
        [0.6560, 0.3440],
        [0.6667, 0.3333],
        [0.6625, 0.3375],
        [0.6727, 0.3273],
        [0.6681, 0.3319],
        [0.6597, 0.3403],
        [0.6541, 0.3459],
        [0.6672, 0.3328],
        [0.6516, 0.3484],
        [0.6676, 0.3324],
        [0.6590, 0.3410],
        [0.6653, 0.3347],
        [0.6714, 0.3286],
        [0.6520, 0.3480],
        [0.6649, 0.3351],
        [0.6622, 0.3378],
        [0.6631, 0.3369],
        [0.6576, 0.3424],
        [0.6713, 0.3287],
        [0.6538, 0.3462],
        [0.6642, 0.3358],
        [0.6674, 0.3326],
        [0.6696, 0.3304],
        [0.6514, 0.3486],
        [0.6670, 0.3330],
        [0.6574, 0.3426],
        [0.6624, 0.3376],
        [0.6612, 0.3388],
        [0.6706, 0.3294],
        [0.6700, 0.3300],
        [0.6576, 0.3424],
        [0.6697, 0.3303],
        [0.6747, 0.3253],
        [0.6619, 0.3381],
        [0.6621, 0.3379],
        [0.6576, 0.3424],
        [0.6644, 0.3356],
        [0.6636, 0.3364],
        [0.6602, 0.3398],
        [0.6563, 0.3437],
        [0.6602, 0.3398],
        [0.6673, 0.3327],
        [0.6718, 0.3282],
        [0.6716, 0.3284],
        [0.6678, 0.3322],
        [0.6621, 0.3379],
        [0.6666, 0.3334],
        [0.6571, 0.3429],
        [0.6754, 0.3246],
        [0.6566, 0.3434],
        [0.6741, 0.3259],
        [0.6662, 0.3338],
        [0.6700, 0.3300],
        [0.6663, 0.3337],
        [0.6717, 0.3283],
        [0.6627, 0.3373],
        [0.6721, 0.3279],
        [0.6657, 0.3343],
        [0.6628, 0.3372],
        [0.6666, 0.3334],
        [0.6714, 0.3286],
        [0.6573, 0.3427],
        [0.6641, 0.3359],
        [0.6679, 0.3321],
        [0.6644, 0.3356],
        [0.6588, 0.3412],
        [0.6629, 0.3371],
        [0.6764, 0.3236],
        [0.6699, 0.3301]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0027 loss: 0.6676 acc_train: 0.6103 time: 0.1376s
tensor([[0.6617, 0.3383],
        [0.6664, 0.3336],
        [0.6770, 0.3230],
        [0.6627, 0.3373],
        [0.6700, 0.3300],
        [0.6562, 0.3438],
        [0.6528, 0.3472],
        [0.6590, 0.3410],
        [0.6630, 0.3370],
        [0.6509, 0.3491],
        [0.6685, 0.3315],
        [0.6581, 0.3419],
        [0.6593, 0.3407],
        [0.6615, 0.3385],
        [0.6674, 0.3326],
        [0.6621, 0.3379],
        [0.6680, 0.3320],
        [0.6542, 0.3458],
        [0.6670, 0.3330],
        [0.6546, 0.3454],
        [0.6674, 0.3326],
        [0.6587, 0.3413],
        [0.6654, 0.3346],
        [0.6773, 0.3227],
        [0.6674, 0.3326],
        [0.6579, 0.3421],
        [0.6554, 0.3446],
        [0.6657, 0.3343],
        [0.6581, 0.3419],
        [0.6589, 0.3411],
        [0.6654, 0.3346],
        [0.6583, 0.3417],
        [0.6687, 0.3313],
        [0.6625, 0.3375],
        [0.6652, 0.3348],
        [0.6538, 0.3462],
        [0.6636, 0.3364],
        [0.6603, 0.3397],
        [0.6651, 0.3349],
        [0.6514, 0.3486],
        [0.6667, 0.3333],
        [0.6666, 0.3334],
        [0.6586, 0.3414],
        [0.6608, 0.3392],
        [0.6601, 0.3399],
        [0.6566, 0.3434],
        [0.6715, 0.3285],
        [0.6745, 0.3255],
        [0.6566, 0.3434],
        [0.6641, 0.3360],
        [0.6633, 0.3367],
        [0.6680, 0.3320],
        [0.6626, 0.3374],
        [0.6698, 0.3302],
        [0.6676, 0.3324],
        [0.6693, 0.3307],
        [0.6671, 0.3329],
        [0.6642, 0.3358],
        [0.6572, 0.3428],
        [0.6622, 0.3378],
        [0.6575, 0.3425],
        [0.6635, 0.3365],
        [0.6649, 0.3351],
        [0.6705, 0.3295],
        [0.6562, 0.3438],
        [0.6587, 0.3413],
        [0.6633, 0.3367],
        [0.6634, 0.3366],
        [0.6682, 0.3318],
        [0.6628, 0.3372],
        [0.6605, 0.3395],
        [0.6587, 0.3413],
        [0.6639, 0.3361],
        [0.6616, 0.3384],
        [0.6603, 0.3397],
        [0.6635, 0.3365],
        [0.6661, 0.3339],
        [0.6612, 0.3388],
        [0.6646, 0.3354],
        [0.6603, 0.3397],
        [0.6573, 0.3427],
        [0.6583, 0.3417],
        [0.6596, 0.3404],
        [0.6598, 0.3402],
        [0.6660, 0.3340],
        [0.6559, 0.3441],
        [0.6644, 0.3356],
        [0.6612, 0.3388],
        [0.6552, 0.3448],
        [0.6626, 0.3374],
        [0.6609, 0.3391],
        [0.6604, 0.3396],
        [0.6660, 0.3340],
        [0.6564, 0.3436],
        [0.6605, 0.3395],
        [0.6672, 0.3328],
        [0.6713, 0.3287],
        [0.6582, 0.3418],
        [0.6681, 0.3319],
        [0.6605, 0.3395],
        [0.6599, 0.3401],
        [0.6645, 0.3355],
        [0.6618, 0.3382],
        [0.6544, 0.3456],
        [0.6650, 0.3350],
        [0.6580, 0.3420],
        [0.6685, 0.3315],
        [0.6663, 0.3337],
        [0.6531, 0.3469],
        [0.6613, 0.3387],
        [0.6556, 0.3444],
        [0.6662, 0.3338],
        [0.6672, 0.3328],
        [0.6659, 0.3341],
        [0.6594, 0.3406],
        [0.6506, 0.3494],
        [0.6677, 0.3323],
        [0.6713, 0.3287],
        [0.6680, 0.3320],
        [0.6642, 0.3358],
        [0.6657, 0.3343],
        [0.6534, 0.3466],
        [0.6611, 0.3389],
        [0.6625, 0.3375],
        [0.6672, 0.3328],
        [0.6632, 0.3368],
        [0.6560, 0.3440],
        [0.6620, 0.3380],
        [0.6628, 0.3372],
        [0.6611, 0.3389],
        [0.6654, 0.3346],
        [0.6638, 0.3362],
        [0.6615, 0.3385],
        [0.6563, 0.3437],
        [0.6610, 0.3390],
        [0.6558, 0.3442],
        [0.6625, 0.3375],
        [0.6675, 0.3325],
        [0.6634, 0.3366],
        [0.6552, 0.3448],
        [0.6574, 0.3426],
        [0.6614, 0.3386],
        [0.6570, 0.3430],
        [0.6575, 0.3425],
        [0.6544, 0.3456],
        [0.6672, 0.3328],
        [0.6706, 0.3294],
        [0.6632, 0.3368],
        [0.6643, 0.3357],
        [0.6711, 0.3289],
        [0.6626, 0.3374],
        [0.6729, 0.3271],
        [0.6692, 0.3308],
        [0.6709, 0.3291],
        [0.6710, 0.3290],
        [0.6557, 0.3443],
        [0.6721, 0.3279],
        [0.6645, 0.3355],
        [0.6565, 0.3435],
        [0.6602, 0.3398],
        [0.6665, 0.3335],
        [0.6665, 0.3335],
        [0.6629, 0.3371],
        [0.6639, 0.3361],
        [0.6534, 0.3466],
        [0.6627, 0.3373],
        [0.6623, 0.3377],
        [0.6582, 0.3418],
        [0.6637, 0.3363],
        [0.6597, 0.3403],
        [0.6532, 0.3468],
        [0.6641, 0.3359],
        [0.6585, 0.3415],
        [0.6584, 0.3416],
        [0.6626, 0.3374],
        [0.6617, 0.3383],
        [0.6692, 0.3308],
        [0.6617, 0.3383],
        [0.6536, 0.3464],
        [0.6697, 0.3303],
        [0.6726, 0.3274],
        [0.6598, 0.3402],
        [0.6619, 0.3381],
        [0.6611, 0.3389],
        [0.6626, 0.3374],
        [0.6644, 0.3356],
        [0.6514, 0.3486],
        [0.6649, 0.3351],
        [0.6547, 0.3453],
        [0.6655, 0.3345],
        [0.6713, 0.3287],
        [0.6656, 0.3344],
        [0.6587, 0.3413],
        [0.6561, 0.3439],
        [0.6715, 0.3285],
        [0.6721, 0.3279],
        [0.6726, 0.3274],
        [0.6545, 0.3455],
        [0.6661, 0.3339],
        [0.6644, 0.3356],
        [0.6577, 0.3423],
        [0.6703, 0.3297],
        [0.6678, 0.3322],
        [0.6580, 0.3420],
        [0.6675, 0.3325],
        [0.6636, 0.3364],
        [0.6728, 0.3272],
        [0.6688, 0.3312],
        [0.6618, 0.3382],
        [0.6568, 0.3432],
        [0.6678, 0.3322],
        [0.6538, 0.3462],
        [0.6683, 0.3317],
        [0.6605, 0.3395],
        [0.6656, 0.3344],
        [0.6717, 0.3283],
        [0.6543, 0.3457],
        [0.6663, 0.3337],
        [0.6641, 0.3359],
        [0.6635, 0.3365],
        [0.6593, 0.3407],
        [0.6715, 0.3285],
        [0.6560, 0.3440],
        [0.6652, 0.3348],
        [0.6678, 0.3322],
        [0.6702, 0.3298],
        [0.6522, 0.3478],
        [0.6678, 0.3322],
        [0.6597, 0.3403],
        [0.6635, 0.3365],
        [0.6625, 0.3375],
        [0.6707, 0.3293],
        [0.6705, 0.3295],
        [0.6591, 0.3409],
        [0.6698, 0.3302],
        [0.6744, 0.3256],
        [0.6629, 0.3371],
        [0.6633, 0.3367],
        [0.6590, 0.3410],
        [0.6650, 0.3350],
        [0.6641, 0.3359],
        [0.6616, 0.3384],
        [0.6584, 0.3416],
        [0.6620, 0.3380],
        [0.6674, 0.3326],
        [0.6723, 0.3277],
        [0.6715, 0.3285],
        [0.6680, 0.3320],
        [0.6631, 0.3369],
        [0.6671, 0.3329],
        [0.6586, 0.3414],
        [0.6753, 0.3247],
        [0.6583, 0.3417],
        [0.6744, 0.3256],
        [0.6669, 0.3331],
        [0.6702, 0.3298],
        [0.6669, 0.3331],
        [0.6716, 0.3284],
        [0.6633, 0.3367],
        [0.6718, 0.3282],
        [0.6668, 0.3332],
        [0.6634, 0.3366],
        [0.6674, 0.3326],
        [0.6712, 0.3288],
        [0.6591, 0.3409],
        [0.6640, 0.3360],
        [0.6684, 0.3316],
        [0.6656, 0.3344],
        [0.6604, 0.3396],
        [0.6641, 0.3359],
        [0.6762, 0.3238],
        [0.6703, 0.3297]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0028 loss: 0.6679 acc_train: 0.6103 time: 0.1231s
tensor([[0.6626, 0.3374],
        [0.6667, 0.3333],
        [0.6767, 0.3233],
        [0.6633, 0.3367],
        [0.6703, 0.3297],
        [0.6578, 0.3422],
        [0.6550, 0.3450],
        [0.6603, 0.3397],
        [0.6641, 0.3359],
        [0.6534, 0.3466],
        [0.6697, 0.3303],
        [0.6595, 0.3405],
        [0.6615, 0.3385],
        [0.6626, 0.3374],
        [0.6679, 0.3321],
        [0.6634, 0.3366],
        [0.6685, 0.3315],
        [0.6557, 0.3443],
        [0.6678, 0.3322],
        [0.6565, 0.3435],
        [0.6679, 0.3321],
        [0.6607, 0.3393],
        [0.6664, 0.3336],
        [0.6771, 0.3229],
        [0.6684, 0.3316],
        [0.6594, 0.3406],
        [0.6570, 0.3430],
        [0.6661, 0.3339],
        [0.6593, 0.3407],
        [0.6604, 0.3396],
        [0.6660, 0.3340],
        [0.6599, 0.3401],
        [0.6692, 0.3308],
        [0.6641, 0.3359],
        [0.6665, 0.3335],
        [0.6544, 0.3456],
        [0.6647, 0.3353],
        [0.6618, 0.3382],
        [0.6660, 0.3340],
        [0.6537, 0.3463],
        [0.6675, 0.3325],
        [0.6677, 0.3323],
        [0.6588, 0.3412],
        [0.6617, 0.3383],
        [0.6616, 0.3384],
        [0.6582, 0.3418],
        [0.6717, 0.3283],
        [0.6748, 0.3252],
        [0.6581, 0.3419],
        [0.6650, 0.3350],
        [0.6647, 0.3353],
        [0.6685, 0.3315],
        [0.6640, 0.3360],
        [0.6701, 0.3299],
        [0.6679, 0.3321],
        [0.6697, 0.3303],
        [0.6675, 0.3325],
        [0.6652, 0.3348],
        [0.6588, 0.3412],
        [0.6633, 0.3367],
        [0.6592, 0.3408],
        [0.6651, 0.3349],
        [0.6657, 0.3343],
        [0.6711, 0.3289],
        [0.6582, 0.3418],
        [0.6602, 0.3398],
        [0.6645, 0.3355],
        [0.6647, 0.3353],
        [0.6686, 0.3314],
        [0.6640, 0.3360],
        [0.6614, 0.3386],
        [0.6599, 0.3401],
        [0.6644, 0.3356],
        [0.6630, 0.3370],
        [0.6619, 0.3381],
        [0.6645, 0.3355],
        [0.6669, 0.3331],
        [0.6630, 0.3370],
        [0.6659, 0.3341],
        [0.6613, 0.3387],
        [0.6595, 0.3405],
        [0.6602, 0.3398],
        [0.6613, 0.3387],
        [0.6612, 0.3388],
        [0.6668, 0.3332],
        [0.6576, 0.3424],
        [0.6656, 0.3344],
        [0.6623, 0.3377],
        [0.6569, 0.3431],
        [0.6637, 0.3363],
        [0.6622, 0.3378],
        [0.6619, 0.3381],
        [0.6666, 0.3334],
        [0.6579, 0.3421],
        [0.6616, 0.3384],
        [0.6685, 0.3315],
        [0.6715, 0.3285],
        [0.6600, 0.3400],
        [0.6687, 0.3313],
        [0.6616, 0.3384],
        [0.6611, 0.3389],
        [0.6653, 0.3347],
        [0.6631, 0.3369],
        [0.6561, 0.3439],
        [0.6659, 0.3341],
        [0.6597, 0.3403],
        [0.6690, 0.3310],
        [0.6672, 0.3328],
        [0.6552, 0.3448],
        [0.6622, 0.3378],
        [0.6556, 0.3444],
        [0.6669, 0.3331],
        [0.6680, 0.3320],
        [0.6667, 0.3333],
        [0.6607, 0.3393],
        [0.6520, 0.3480],
        [0.6687, 0.3313],
        [0.6712, 0.3288],
        [0.6684, 0.3316],
        [0.6649, 0.3351],
        [0.6667, 0.3333],
        [0.6554, 0.3446],
        [0.6621, 0.3379],
        [0.6637, 0.3363],
        [0.6679, 0.3321],
        [0.6644, 0.3356],
        [0.6578, 0.3422],
        [0.6631, 0.3369],
        [0.6640, 0.3360],
        [0.6622, 0.3378],
        [0.6665, 0.3335],
        [0.6646, 0.3354],
        [0.6627, 0.3373],
        [0.6580, 0.3420],
        [0.6618, 0.3382],
        [0.6575, 0.3425],
        [0.6634, 0.3366],
        [0.6680, 0.3320],
        [0.6639, 0.3361],
        [0.6570, 0.3430],
        [0.6589, 0.3411],
        [0.6627, 0.3373],
        [0.6586, 0.3414],
        [0.6593, 0.3407],
        [0.6563, 0.3437],
        [0.6677, 0.3323],
        [0.6708, 0.3292],
        [0.6644, 0.3356],
        [0.6648, 0.3352],
        [0.6714, 0.3286],
        [0.6637, 0.3363],
        [0.6733, 0.3267],
        [0.6694, 0.3306],
        [0.6710, 0.3290],
        [0.6716, 0.3284],
        [0.6580, 0.3420],
        [0.6724, 0.3276],
        [0.6651, 0.3349],
        [0.6584, 0.3416],
        [0.6614, 0.3386],
        [0.6670, 0.3330],
        [0.6674, 0.3326],
        [0.6637, 0.3363],
        [0.6651, 0.3349],
        [0.6540, 0.3460],
        [0.6638, 0.3362],
        [0.6629, 0.3371],
        [0.6600, 0.3400],
        [0.6645, 0.3355],
        [0.6610, 0.3390],
        [0.6541, 0.3459],
        [0.6652, 0.3348],
        [0.6608, 0.3392],
        [0.6597, 0.3403],
        [0.6633, 0.3367],
        [0.6623, 0.3377],
        [0.6698, 0.3302],
        [0.6630, 0.3370],
        [0.6557, 0.3443],
        [0.6702, 0.3298],
        [0.6727, 0.3273],
        [0.6609, 0.3391],
        [0.6630, 0.3370],
        [0.6622, 0.3378],
        [0.6639, 0.3361],
        [0.6652, 0.3348],
        [0.6534, 0.3466],
        [0.6660, 0.3340],
        [0.6564, 0.3436],
        [0.6663, 0.3337],
        [0.6716, 0.3284],
        [0.6669, 0.3331],
        [0.6600, 0.3400],
        [0.6582, 0.3418],
        [0.6720, 0.3280],
        [0.6723, 0.3277],
        [0.6724, 0.3276],
        [0.6562, 0.3438],
        [0.6669, 0.3331],
        [0.6652, 0.3348],
        [0.6595, 0.3405],
        [0.6707, 0.3293],
        [0.6683, 0.3317],
        [0.6597, 0.3403],
        [0.6682, 0.3318],
        [0.6644, 0.3356],
        [0.6730, 0.3270],
        [0.6696, 0.3304],
        [0.6637, 0.3363],
        [0.6591, 0.3409],
        [0.6685, 0.3315],
        [0.6556, 0.3444],
        [0.6690, 0.3310],
        [0.6618, 0.3382],
        [0.6659, 0.3341],
        [0.6722, 0.3278],
        [0.6563, 0.3437],
        [0.6676, 0.3324],
        [0.6657, 0.3343],
        [0.6639, 0.3361],
        [0.6608, 0.3392],
        [0.6717, 0.3283],
        [0.6579, 0.3421],
        [0.6661, 0.3339],
        [0.6682, 0.3318],
        [0.6707, 0.3293],
        [0.6531, 0.3469],
        [0.6685, 0.3315],
        [0.6615, 0.3385],
        [0.6644, 0.3356],
        [0.6634, 0.3366],
        [0.6709, 0.3291],
        [0.6710, 0.3290],
        [0.6606, 0.3394],
        [0.6700, 0.3300],
        [0.6742, 0.3258],
        [0.6640, 0.3360],
        [0.6645, 0.3355],
        [0.6602, 0.3398],
        [0.6656, 0.3344],
        [0.6646, 0.3354],
        [0.6629, 0.3371],
        [0.6603, 0.3397],
        [0.6635, 0.3365],
        [0.6675, 0.3325],
        [0.6727, 0.3273],
        [0.6715, 0.3285],
        [0.6683, 0.3317],
        [0.6642, 0.3358],
        [0.6674, 0.3326],
        [0.6600, 0.3400],
        [0.6754, 0.3246],
        [0.6596, 0.3404],
        [0.6747, 0.3253],
        [0.6676, 0.3324],
        [0.6704, 0.3296],
        [0.6673, 0.3327],
        [0.6715, 0.3285],
        [0.6638, 0.3362],
        [0.6717, 0.3283],
        [0.6676, 0.3324],
        [0.6640, 0.3360],
        [0.6683, 0.3317],
        [0.6711, 0.3289],
        [0.6606, 0.3394],
        [0.6641, 0.3359],
        [0.6688, 0.3312],
        [0.6666, 0.3334],
        [0.6621, 0.3379],
        [0.6652, 0.3348],
        [0.6761, 0.3239],
        [0.6709, 0.3291]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0029 loss: 0.6681 acc_train: 0.6103 time: 0.1169s
tensor([[0.6633, 0.3367],
        [0.6669, 0.3331],
        [0.6763, 0.3237],
        [0.6638, 0.3362],
        [0.6707, 0.3293],
        [0.6590, 0.3410],
        [0.6567, 0.3433],
        [0.6614, 0.3386],
        [0.6651, 0.3349],
        [0.6555, 0.3445],
        [0.6706, 0.3294],
        [0.6608, 0.3392],
        [0.6632, 0.3368],
        [0.6635, 0.3365],
        [0.6684, 0.3316],
        [0.6646, 0.3354],
        [0.6689, 0.3311],
        [0.6568, 0.3432],
        [0.6683, 0.3317],
        [0.6581, 0.3419],
        [0.6684, 0.3316],
        [0.6624, 0.3376],
        [0.6673, 0.3327],
        [0.6769, 0.3231],
        [0.6692, 0.3308],
        [0.6608, 0.3392],
        [0.6584, 0.3416],
        [0.6665, 0.3335],
        [0.6603, 0.3397],
        [0.6616, 0.3384],
        [0.6665, 0.3335],
        [0.6613, 0.3387],
        [0.6696, 0.3304],
        [0.6654, 0.3346],
        [0.6675, 0.3325],
        [0.6551, 0.3449],
        [0.6655, 0.3345],
        [0.6631, 0.3369],
        [0.6667, 0.3333],
        [0.6556, 0.3444],
        [0.6681, 0.3319],
        [0.6685, 0.3315],
        [0.6590, 0.3410],
        [0.6625, 0.3375],
        [0.6629, 0.3371],
        [0.6594, 0.3406],
        [0.6719, 0.3281],
        [0.6751, 0.3249],
        [0.6593, 0.3407],
        [0.6657, 0.3343],
        [0.6656, 0.3344],
        [0.6690, 0.3310],
        [0.6652, 0.3348],
        [0.6704, 0.3296],
        [0.6681, 0.3319],
        [0.6700, 0.3300],
        [0.6677, 0.3323],
        [0.6660, 0.3340],
        [0.6601, 0.3399],
        [0.6642, 0.3358],
        [0.6607, 0.3393],
        [0.6662, 0.3338],
        [0.6664, 0.3336],
        [0.6717, 0.3283],
        [0.6598, 0.3402],
        [0.6615, 0.3385],
        [0.6656, 0.3344],
        [0.6656, 0.3344],
        [0.6690, 0.3310],
        [0.6649, 0.3351],
        [0.6622, 0.3378],
        [0.6608, 0.3392],
        [0.6647, 0.3353],
        [0.6641, 0.3359],
        [0.6632, 0.3368],
        [0.6653, 0.3347],
        [0.6676, 0.3324],
        [0.6645, 0.3355],
        [0.6669, 0.3331],
        [0.6620, 0.3380],
        [0.6612, 0.3388],
        [0.6617, 0.3383],
        [0.6626, 0.3374],
        [0.6623, 0.3377],
        [0.6674, 0.3326],
        [0.6590, 0.3410],
        [0.6665, 0.3335],
        [0.6633, 0.3367],
        [0.6582, 0.3418],
        [0.6648, 0.3352],
        [0.6632, 0.3368],
        [0.6629, 0.3371],
        [0.6670, 0.3330],
        [0.6591, 0.3409],
        [0.6624, 0.3376],
        [0.6696, 0.3304],
        [0.6718, 0.3282],
        [0.6616, 0.3384],
        [0.6691, 0.3309],
        [0.6625, 0.3375],
        [0.6621, 0.3379],
        [0.6657, 0.3343],
        [0.6642, 0.3358],
        [0.6575, 0.3425],
        [0.6666, 0.3334],
        [0.6610, 0.3390],
        [0.6693, 0.3307],
        [0.6679, 0.3321],
        [0.6569, 0.3431],
        [0.6629, 0.3371],
        [0.6554, 0.3446],
        [0.6675, 0.3325],
        [0.6686, 0.3314],
        [0.6674, 0.3326],
        [0.6617, 0.3383],
        [0.6533, 0.3467],
        [0.6694, 0.3306],
        [0.6712, 0.3288],
        [0.6687, 0.3313],
        [0.6654, 0.3346],
        [0.6674, 0.3326],
        [0.6570, 0.3430],
        [0.6630, 0.3370],
        [0.6647, 0.3353],
        [0.6685, 0.3315],
        [0.6653, 0.3347],
        [0.6591, 0.3409],
        [0.6641, 0.3359],
        [0.6648, 0.3352],
        [0.6629, 0.3371],
        [0.6676, 0.3324],
        [0.6653, 0.3347],
        [0.6636, 0.3364],
        [0.6594, 0.3406],
        [0.6624, 0.3376],
        [0.6590, 0.3410],
        [0.6641, 0.3359],
        [0.6686, 0.3314],
        [0.6644, 0.3356],
        [0.6586, 0.3414],
        [0.6601, 0.3399],
        [0.6635, 0.3365],
        [0.6600, 0.3400],
        [0.6608, 0.3392],
        [0.6577, 0.3423],
        [0.6681, 0.3319],
        [0.6709, 0.3291],
        [0.6654, 0.3346],
        [0.6652, 0.3348],
        [0.6716, 0.3284],
        [0.6646, 0.3354],
        [0.6736, 0.3264],
        [0.6698, 0.3302],
        [0.6711, 0.3289],
        [0.6720, 0.3280],
        [0.6599, 0.3401],
        [0.6726, 0.3274],
        [0.6656, 0.3344],
        [0.6599, 0.3401],
        [0.6624, 0.3376],
        [0.6674, 0.3326],
        [0.6681, 0.3319],
        [0.6643, 0.3357],
        [0.6661, 0.3339],
        [0.6545, 0.3455],
        [0.6647, 0.3353],
        [0.6634, 0.3366],
        [0.6614, 0.3386],
        [0.6652, 0.3348],
        [0.6622, 0.3378],
        [0.6550, 0.3450],
        [0.6661, 0.3339],
        [0.6624, 0.3376],
        [0.6607, 0.3393],
        [0.6638, 0.3362],
        [0.6629, 0.3371],
        [0.6702, 0.3298],
        [0.6642, 0.3358],
        [0.6573, 0.3427],
        [0.6706, 0.3294],
        [0.6727, 0.3273],
        [0.6617, 0.3383],
        [0.6638, 0.3362],
        [0.6629, 0.3371],
        [0.6651, 0.3349],
        [0.6658, 0.3342],
        [0.6550, 0.3450],
        [0.6668, 0.3332],
        [0.6578, 0.3422],
        [0.6671, 0.3329],
        [0.6720, 0.3280],
        [0.6678, 0.3322],
        [0.6610, 0.3390],
        [0.6598, 0.3402],
        [0.6724, 0.3276],
        [0.6725, 0.3275],
        [0.6723, 0.3277],
        [0.6575, 0.3425],
        [0.6677, 0.3323],
        [0.6657, 0.3343],
        [0.6609, 0.3391],
        [0.6709, 0.3291],
        [0.6688, 0.3312],
        [0.6610, 0.3390],
        [0.6688, 0.3312],
        [0.6650, 0.3350],
        [0.6732, 0.3268],
        [0.6702, 0.3298],
        [0.6651, 0.3349],
        [0.6608, 0.3392],
        [0.6691, 0.3309],
        [0.6571, 0.3429],
        [0.6695, 0.3305],
        [0.6628, 0.3372],
        [0.6660, 0.3340],
        [0.6727, 0.3273],
        [0.6578, 0.3422],
        [0.6685, 0.3315],
        [0.6671, 0.3329],
        [0.6643, 0.3357],
        [0.6620, 0.3380],
        [0.6717, 0.3283],
        [0.6594, 0.3406],
        [0.6669, 0.3331],
        [0.6685, 0.3315],
        [0.6710, 0.3290],
        [0.6539, 0.3461],
        [0.6689, 0.3311],
        [0.6629, 0.3371],
        [0.6651, 0.3349],
        [0.6641, 0.3359],
        [0.6711, 0.3289],
        [0.6716, 0.3284],
        [0.6618, 0.3382],
        [0.6702, 0.3298],
        [0.6739, 0.3261],
        [0.6650, 0.3350],
        [0.6656, 0.3344],
        [0.6612, 0.3388],
        [0.6659, 0.3341],
        [0.6651, 0.3349],
        [0.6640, 0.3360],
        [0.6618, 0.3382],
        [0.6646, 0.3354],
        [0.6675, 0.3325],
        [0.6730, 0.3270],
        [0.6714, 0.3286],
        [0.6684, 0.3316],
        [0.6651, 0.3349],
        [0.6674, 0.3326],
        [0.6611, 0.3389],
        [0.6754, 0.3246],
        [0.6604, 0.3396],
        [0.6750, 0.3250],
        [0.6681, 0.3319],
        [0.6707, 0.3293],
        [0.6675, 0.3325],
        [0.6715, 0.3285],
        [0.6641, 0.3359],
        [0.6716, 0.3284],
        [0.6684, 0.3316],
        [0.6646, 0.3354],
        [0.6691, 0.3309],
        [0.6709, 0.3291],
        [0.6619, 0.3381],
        [0.6642, 0.3358],
        [0.6691, 0.3309],
        [0.6672, 0.3328],
        [0.6635, 0.3365],
        [0.6661, 0.3339],
        [0.6759, 0.3241],
        [0.6713, 0.3287]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0030 loss: 0.6683 acc_train: 0.6103 time: 0.1203s
tensor([[0.6638, 0.3362],
        [0.6669, 0.3331],
        [0.6758, 0.3242],
        [0.6641, 0.3359],
        [0.6709, 0.3291],
        [0.6599, 0.3401],
        [0.6578, 0.3422],
        [0.6620, 0.3380],
        [0.6658, 0.3342],
        [0.6570, 0.3430],
        [0.6712, 0.3288],
        [0.6618, 0.3382],
        [0.6645, 0.3355],
        [0.6641, 0.3359],
        [0.6686, 0.3314],
        [0.6653, 0.3347],
        [0.6690, 0.3310],
        [0.6576, 0.3424],
        [0.6684, 0.3316],
        [0.6591, 0.3409],
        [0.6686, 0.3314],
        [0.6636, 0.3364],
        [0.6679, 0.3321],
        [0.6765, 0.3235],
        [0.6698, 0.3302],
        [0.6620, 0.3380],
        [0.6595, 0.3405],
        [0.6667, 0.3333],
        [0.6609, 0.3391],
        [0.6625, 0.3375],
        [0.6666, 0.3334],
        [0.6623, 0.3377],
        [0.6698, 0.3302],
        [0.6663, 0.3337],
        [0.6680, 0.3320],
        [0.6555, 0.3445],
        [0.6659, 0.3341],
        [0.6639, 0.3361],
        [0.6671, 0.3329],
        [0.6570, 0.3430],
        [0.6685, 0.3315],
        [0.6689, 0.3311],
        [0.6590, 0.3410],
        [0.6631, 0.3369],
        [0.6637, 0.3363],
        [0.6603, 0.3397],
        [0.6720, 0.3280],
        [0.6752, 0.3248],
        [0.6601, 0.3399],
        [0.6663, 0.3337],
        [0.6661, 0.3339],
        [0.6692, 0.3308],
        [0.6661, 0.3339],
        [0.6705, 0.3295],
        [0.6681, 0.3319],
        [0.6700, 0.3300],
        [0.6679, 0.3321],
        [0.6665, 0.3335],
        [0.6610, 0.3390],
        [0.6648, 0.3352],
        [0.6617, 0.3383],
        [0.6668, 0.3332],
        [0.6668, 0.3332],
        [0.6720, 0.3280],
        [0.6609, 0.3391],
        [0.6623, 0.3377],
        [0.6662, 0.3338],
        [0.6660, 0.3340],
        [0.6692, 0.3308],
        [0.6655, 0.3345],
        [0.6629, 0.3371],
        [0.6614, 0.3386],
        [0.6649, 0.3351],
        [0.6649, 0.3351],
        [0.6640, 0.3360],
        [0.6656, 0.3344],
        [0.6680, 0.3320],
        [0.6655, 0.3345],
        [0.6673, 0.3327],
        [0.6623, 0.3377],
        [0.6623, 0.3377],
        [0.6627, 0.3373],
        [0.6634, 0.3366],
        [0.6631, 0.3369],
        [0.6676, 0.3324],
        [0.6599, 0.3401],
        [0.6671, 0.3329],
        [0.6640, 0.3360],
        [0.6590, 0.3410],
        [0.6655, 0.3345],
        [0.6637, 0.3363],
        [0.6635, 0.3365],
        [0.6673, 0.3327],
        [0.6599, 0.3401],
        [0.6629, 0.3371],
        [0.6703, 0.3297],
        [0.6719, 0.3281],
        [0.6628, 0.3372],
        [0.6693, 0.3307],
        [0.6631, 0.3369],
        [0.6628, 0.3372],
        [0.6658, 0.3342],
        [0.6648, 0.3352],
        [0.6585, 0.3415],
        [0.6671, 0.3329],
        [0.6618, 0.3382],
        [0.6694, 0.3306],
        [0.6683, 0.3317],
        [0.6582, 0.3418],
        [0.6633, 0.3367],
        [0.6552, 0.3448],
        [0.6678, 0.3322],
        [0.6689, 0.3311],
        [0.6679, 0.3321],
        [0.6623, 0.3377],
        [0.6543, 0.3457],
        [0.6699, 0.3301],
        [0.6710, 0.3290],
        [0.6690, 0.3310],
        [0.6656, 0.3344],
        [0.6677, 0.3323],
        [0.6582, 0.3418],
        [0.6637, 0.3363],
        [0.6654, 0.3346],
        [0.6689, 0.3311],
        [0.6659, 0.3341],
        [0.6600, 0.3400],
        [0.6649, 0.3351],
        [0.6653, 0.3347],
        [0.6634, 0.3366],
        [0.6683, 0.3317],
        [0.6657, 0.3343],
        [0.6642, 0.3358],
        [0.6605, 0.3395],
        [0.6629, 0.3371],
        [0.6601, 0.3399],
        [0.6644, 0.3356],
        [0.6691, 0.3309],
        [0.6647, 0.3353],
        [0.6599, 0.3401],
        [0.6610, 0.3390],
        [0.6639, 0.3361],
        [0.6611, 0.3389],
        [0.6618, 0.3382],
        [0.6586, 0.3414],
        [0.6683, 0.3317],
        [0.6707, 0.3293],
        [0.6661, 0.3339],
        [0.6655, 0.3345],
        [0.6716, 0.3284],
        [0.6652, 0.3348],
        [0.6736, 0.3264],
        [0.6700, 0.3300],
        [0.6711, 0.3289],
        [0.6722, 0.3278],
        [0.6613, 0.3387],
        [0.6726, 0.3274],
        [0.6660, 0.3340],
        [0.6609, 0.3391],
        [0.6630, 0.3370],
        [0.6675, 0.3325],
        [0.6684, 0.3316],
        [0.6646, 0.3354],
        [0.6668, 0.3332],
        [0.6549, 0.3451],
        [0.6654, 0.3346],
        [0.6637, 0.3363],
        [0.6622, 0.3378],
        [0.6656, 0.3344],
        [0.6629, 0.3371],
        [0.6558, 0.3442],
        [0.6665, 0.3335],
        [0.6633, 0.3367],
        [0.6615, 0.3385],
        [0.6642, 0.3358],
        [0.6633, 0.3367],
        [0.6704, 0.3296],
        [0.6651, 0.3349],
        [0.6584, 0.3416],
        [0.6708, 0.3292],
        [0.6725, 0.3275],
        [0.6622, 0.3378],
        [0.6644, 0.3356],
        [0.6633, 0.3367],
        [0.6660, 0.3340],
        [0.6660, 0.3340],
        [0.6561, 0.3439],
        [0.6673, 0.3327],
        [0.6589, 0.3411],
        [0.6676, 0.3324],
        [0.6722, 0.3278],
        [0.6683, 0.3317],
        [0.6616, 0.3384],
        [0.6608, 0.3392],
        [0.6725, 0.3275],
        [0.6724, 0.3276],
        [0.6721, 0.3279],
        [0.6583, 0.3417],
        [0.6682, 0.3318],
        [0.6660, 0.3340],
        [0.6618, 0.3382],
        [0.6710, 0.3290],
        [0.6690, 0.3310],
        [0.6619, 0.3381],
        [0.6690, 0.3310],
        [0.6653, 0.3347],
        [0.6733, 0.3267],
        [0.6705, 0.3295],
        [0.6661, 0.3339],
        [0.6620, 0.3380],
        [0.6694, 0.3306],
        [0.6582, 0.3418],
        [0.6697, 0.3303],
        [0.6634, 0.3366],
        [0.6659, 0.3341],
        [0.6729, 0.3271],
        [0.6589, 0.3411],
        [0.6689, 0.3311],
        [0.6680, 0.3320],
        [0.6646, 0.3354],
        [0.6628, 0.3372],
        [0.6716, 0.3284],
        [0.6604, 0.3396],
        [0.6673, 0.3327],
        [0.6688, 0.3312],
        [0.6710, 0.3290],
        [0.6544, 0.3456],
        [0.6691, 0.3309],
        [0.6637, 0.3363],
        [0.6655, 0.3345],
        [0.6644, 0.3356],
        [0.6711, 0.3289],
        [0.6718, 0.3282],
        [0.6627, 0.3373],
        [0.6701, 0.3299],
        [0.6734, 0.3266],
        [0.6657, 0.3343],
        [0.6664, 0.3336],
        [0.6620, 0.3380],
        [0.6660, 0.3340],
        [0.6653, 0.3347],
        [0.6646, 0.3354],
        [0.6628, 0.3372],
        [0.6652, 0.3348],
        [0.6674, 0.3326],
        [0.6729, 0.3271],
        [0.6712, 0.3288],
        [0.6683, 0.3317],
        [0.6657, 0.3343],
        [0.6672, 0.3328],
        [0.6620, 0.3380],
        [0.6752, 0.3248],
        [0.6609, 0.3391],
        [0.6750, 0.3250],
        [0.6684, 0.3316],
        [0.6708, 0.3292],
        [0.6674, 0.3326],
        [0.6713, 0.3287],
        [0.6643, 0.3357],
        [0.6715, 0.3285],
        [0.6688, 0.3312],
        [0.6648, 0.3352],
        [0.6696, 0.3304],
        [0.6706, 0.3294],
        [0.6628, 0.3372],
        [0.6643, 0.3357],
        [0.6692, 0.3308],
        [0.6676, 0.3324],
        [0.6645, 0.3355],
        [0.6668, 0.3332],
        [0.6756, 0.3244],
        [0.6714, 0.3286]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0031 loss: 0.6684 acc_train: 0.6103 time: 0.1217s
tensor([[0.6640, 0.3360],
        [0.6669, 0.3331],
        [0.6752, 0.3248],
        [0.6642, 0.3358],
        [0.6709, 0.3291],
        [0.6605, 0.3395],
        [0.6586, 0.3414],
        [0.6623, 0.3377],
        [0.6663, 0.3337],
        [0.6580, 0.3420],
        [0.6715, 0.3285],
        [0.6623, 0.3377],
        [0.6652, 0.3348],
        [0.6644, 0.3356],
        [0.6685, 0.3315],
        [0.6657, 0.3343],
        [0.6688, 0.3312],
        [0.6581, 0.3419],
        [0.6683, 0.3317],
        [0.6597, 0.3403],
        [0.6685, 0.3315],
        [0.6643, 0.3357],
        [0.6683, 0.3317],
        [0.6759, 0.3241],
        [0.6700, 0.3300],
        [0.6628, 0.3372],
        [0.6603, 0.3397],
        [0.6668, 0.3332],
        [0.6613, 0.3387],
        [0.6631, 0.3369],
        [0.6664, 0.3336],
        [0.6629, 0.3371],
        [0.6698, 0.3302],
        [0.6667, 0.3333],
        [0.6680, 0.3320],
        [0.6558, 0.3442],
        [0.6659, 0.3341],
        [0.6644, 0.3356],
        [0.6671, 0.3329],
        [0.6580, 0.3420],
        [0.6685, 0.3315],
        [0.6690, 0.3310],
        [0.6589, 0.3411],
        [0.6634, 0.3366],
        [0.6641, 0.3359],
        [0.6607, 0.3393],
        [0.6719, 0.3281],
        [0.6750, 0.3250],
        [0.6607, 0.3393],
        [0.6664, 0.3336],
        [0.6662, 0.3338],
        [0.6691, 0.3309],
        [0.6666, 0.3334],
        [0.6704, 0.3296],
        [0.6679, 0.3321],
        [0.6698, 0.3302],
        [0.6678, 0.3322],
        [0.6668, 0.3332],
        [0.6615, 0.3385],
        [0.6651, 0.3349],
        [0.6625, 0.3375],
        [0.6669, 0.3331],
        [0.6670, 0.3330],
        [0.6722, 0.3278],
        [0.6617, 0.3383],
        [0.6629, 0.3371],
        [0.6666, 0.3334],
        [0.6661, 0.3339],
        [0.6693, 0.3307],
        [0.6658, 0.3342],
        [0.6634, 0.3366],
        [0.6617, 0.3383],
        [0.6648, 0.3352],
        [0.6654, 0.3346],
        [0.6644, 0.3356],
        [0.6658, 0.3342],
        [0.6682, 0.3318],
        [0.6661, 0.3339],
        [0.6672, 0.3328],
        [0.6623, 0.3377],
        [0.6631, 0.3369],
        [0.6633, 0.3367],
        [0.6639, 0.3361],
        [0.6634, 0.3366],
        [0.6676, 0.3324],
        [0.6604, 0.3396],
        [0.6674, 0.3326],
        [0.6644, 0.3356],
        [0.6596, 0.3404],
        [0.6659, 0.3341],
        [0.6640, 0.3360],
        [0.6638, 0.3362],
        [0.6672, 0.3328],
        [0.6604, 0.3396],
        [0.6629, 0.3371],
        [0.6704, 0.3296],
        [0.6719, 0.3281],
        [0.6636, 0.3364],
        [0.6692, 0.3308],
        [0.6634, 0.3366],
        [0.6633, 0.3367],
        [0.6657, 0.3343],
        [0.6650, 0.3350],
        [0.6591, 0.3409],
        [0.6675, 0.3325],
        [0.6622, 0.3378],
        [0.6693, 0.3307],
        [0.6684, 0.3316],
        [0.6590, 0.3410],
        [0.6636, 0.3364],
        [0.6550, 0.3450],
        [0.6679, 0.3321],
        [0.6690, 0.3310],
        [0.6681, 0.3319],
        [0.6625, 0.3375],
        [0.6550, 0.3450],
        [0.6700, 0.3300],
        [0.6706, 0.3294],
        [0.6690, 0.3310],
        [0.6655, 0.3345],
        [0.6675, 0.3325],
        [0.6591, 0.3409],
        [0.6641, 0.3359],
        [0.6657, 0.3343],
        [0.6691, 0.3309],
        [0.6662, 0.3338],
        [0.6606, 0.3394],
        [0.6654, 0.3346],
        [0.6655, 0.3345],
        [0.6636, 0.3364],
        [0.6686, 0.3314],
        [0.6660, 0.3340],
        [0.6644, 0.3356],
        [0.6612, 0.3388],
        [0.6631, 0.3369],
        [0.6608, 0.3392],
        [0.6645, 0.3355],
        [0.6695, 0.3305],
        [0.6649, 0.3351],
        [0.6608, 0.3392],
        [0.6616, 0.3384],
        [0.6639, 0.3361],
        [0.6618, 0.3382],
        [0.6624, 0.3376],
        [0.6591, 0.3409],
        [0.6684, 0.3316],
        [0.6702, 0.3298],
        [0.6663, 0.3337],
        [0.6656, 0.3344],
        [0.6715, 0.3285],
        [0.6654, 0.3346],
        [0.6733, 0.3267],
        [0.6701, 0.3299],
        [0.6708, 0.3292],
        [0.6721, 0.3279],
        [0.6623, 0.3377],
        [0.6725, 0.3275],
        [0.6662, 0.3338],
        [0.6616, 0.3384],
        [0.6633, 0.3367],
        [0.6673, 0.3327],
        [0.6684, 0.3316],
        [0.6646, 0.3354],
        [0.6671, 0.3329],
        [0.6552, 0.3448],
        [0.6659, 0.3341],
        [0.6639, 0.3361],
        [0.6626, 0.3374],
        [0.6659, 0.3341],
        [0.6633, 0.3367],
        [0.6563, 0.3437],
        [0.6666, 0.3334],
        [0.6637, 0.3363],
        [0.6619, 0.3381],
        [0.6645, 0.3355],
        [0.6635, 0.3365],
        [0.6703, 0.3297],
        [0.6656, 0.3344],
        [0.6591, 0.3409],
        [0.6707, 0.3293],
        [0.6722, 0.3278],
        [0.6624, 0.3376],
        [0.6647, 0.3353],
        [0.6634, 0.3366],
        [0.6667, 0.3333],
        [0.6660, 0.3340],
        [0.6568, 0.3432],
        [0.6674, 0.3326],
        [0.6596, 0.3404],
        [0.6679, 0.3321],
        [0.6723, 0.3277],
        [0.6683, 0.3317],
        [0.6619, 0.3381],
        [0.6614, 0.3386],
        [0.6723, 0.3277],
        [0.6721, 0.3279],
        [0.6719, 0.3281],
        [0.6588, 0.3412],
        [0.6685, 0.3315],
        [0.6662, 0.3338],
        [0.6623, 0.3377],
        [0.6709, 0.3291],
        [0.6690, 0.3310],
        [0.6624, 0.3376],
        [0.6689, 0.3311],
        [0.6653, 0.3347],
        [0.6731, 0.3269],
        [0.6706, 0.3294],
        [0.6667, 0.3333],
        [0.6628, 0.3372],
        [0.6694, 0.3306],
        [0.6590, 0.3410],
        [0.6696, 0.3304],
        [0.6636, 0.3364],
        [0.6657, 0.3343],
        [0.6730, 0.3270],
        [0.6596, 0.3404],
        [0.6688, 0.3312],
        [0.6683, 0.3317],
        [0.6648, 0.3352],
        [0.6633, 0.3367],
        [0.6713, 0.3287],
        [0.6610, 0.3390],
        [0.6676, 0.3324],
        [0.6689, 0.3311],
        [0.6707, 0.3293],
        [0.6548, 0.3452],
        [0.6690, 0.3310],
        [0.6640, 0.3360],
        [0.6657, 0.3343],
        [0.6645, 0.3355],
        [0.6709, 0.3291],
        [0.6719, 0.3281],
        [0.6632, 0.3368],
        [0.6699, 0.3301],
        [0.6728, 0.3272],
        [0.6661, 0.3339],
        [0.6668, 0.3332],
        [0.6624, 0.3376],
        [0.6659, 0.3341],
        [0.6653, 0.3347],
        [0.6648, 0.3352],
        [0.6634, 0.3366],
        [0.6655, 0.3345],
        [0.6672, 0.3328],
        [0.6726, 0.3274],
        [0.6709, 0.3291],
        [0.6680, 0.3320],
        [0.6659, 0.3341],
        [0.6669, 0.3331],
        [0.6625, 0.3375],
        [0.6748, 0.3252],
        [0.6610, 0.3390],
        [0.6747, 0.3253],
        [0.6683, 0.3317],
        [0.6707, 0.3293],
        [0.6672, 0.3328],
        [0.6710, 0.3290],
        [0.6644, 0.3356],
        [0.6712, 0.3288],
        [0.6690, 0.3310],
        [0.6649, 0.3351],
        [0.6700, 0.3300],
        [0.6701, 0.3298],
        [0.6632, 0.3368],
        [0.6644, 0.3356],
        [0.6689, 0.3311],
        [0.6677, 0.3323],
        [0.6651, 0.3349],
        [0.6672, 0.3328],
        [0.6750, 0.3250],
        [0.6712, 0.3288]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0032 loss: 0.6686 acc_train: 0.6103 time: 0.1300s
tensor([[0.6640, 0.3360],
        [0.6668, 0.3332],
        [0.6743, 0.3257],
        [0.6642, 0.3358],
        [0.6707, 0.3293],
        [0.6608, 0.3392],
        [0.6591, 0.3409],
        [0.6625, 0.3375],
        [0.6664, 0.3336],
        [0.6586, 0.3414],
        [0.6714, 0.3286],
        [0.6626, 0.3374],
        [0.6655, 0.3345],
        [0.6645, 0.3355],
        [0.6683, 0.3317],
        [0.6658, 0.3342],
        [0.6684, 0.3316],
        [0.6585, 0.3415],
        [0.6679, 0.3321],
        [0.6601, 0.3399],
        [0.6683, 0.3317],
        [0.6646, 0.3354],
        [0.6683, 0.3317],
        [0.6750, 0.3250],
        [0.6700, 0.3300],
        [0.6632, 0.3368],
        [0.6608, 0.3392],
        [0.6667, 0.3333],
        [0.6614, 0.3386],
        [0.6634, 0.3366],
        [0.6661, 0.3339],
        [0.6632, 0.3368],
        [0.6696, 0.3304],
        [0.6667, 0.3333],
        [0.6678, 0.3322],
        [0.6559, 0.3441],
        [0.6657, 0.3343],
        [0.6645, 0.3355],
        [0.6669, 0.3331],
        [0.6586, 0.3414],
        [0.6683, 0.3317],
        [0.6688, 0.3312],
        [0.6587, 0.3413],
        [0.6636, 0.3364],
        [0.6641, 0.3359],
        [0.6609, 0.3391],
        [0.6717, 0.3283],
        [0.6745, 0.3255],
        [0.6611, 0.3389],
        [0.6663, 0.3337],
        [0.6659, 0.3341],
        [0.6688, 0.3312],
        [0.6668, 0.3332],
        [0.6702, 0.3298],
        [0.6676, 0.3324],
        [0.6694, 0.3306],
        [0.6676, 0.3324],
        [0.6670, 0.3330],
        [0.6617, 0.3383],
        [0.6652, 0.3348],
        [0.6630, 0.3370],
        [0.6666, 0.3334],
        [0.6669, 0.3331],
        [0.6720, 0.3280],
        [0.6622, 0.3378],
        [0.6632, 0.3368],
        [0.6666, 0.3334],
        [0.6659, 0.3341],
        [0.6690, 0.3310],
        [0.6659, 0.3341],
        [0.6636, 0.3364],
        [0.6618, 0.3382],
        [0.6646, 0.3354],
        [0.6656, 0.3344],
        [0.6645, 0.3355],
        [0.6657, 0.3343],
        [0.6682, 0.3318],
        [0.6661, 0.3339],
        [0.6668, 0.3332],
        [0.6622, 0.3378],
        [0.6634, 0.3366],
        [0.6634, 0.3366],
        [0.6641, 0.3359],
        [0.6635, 0.3365],
        [0.6674, 0.3326],
        [0.6606, 0.3394],
        [0.6674, 0.3326],
        [0.6645, 0.3355],
        [0.6599, 0.3401],
        [0.6661, 0.3339],
        [0.6639, 0.3361],
        [0.6637, 0.3363],
        [0.6670, 0.3330],
        [0.6607, 0.3393],
        [0.6629, 0.3371],
        [0.6702, 0.3298],
        [0.6716, 0.3284],
        [0.6640, 0.3360],
        [0.6690, 0.3310],
        [0.6635, 0.3365],
        [0.6635, 0.3365],
        [0.6655, 0.3345],
        [0.6650, 0.3350],
        [0.6595, 0.3405],
        [0.6677, 0.3323],
        [0.6622, 0.3378],
        [0.6690, 0.3310],
        [0.6683, 0.3317],
        [0.6595, 0.3405],
        [0.6636, 0.3364],
        [0.6548, 0.3452],
        [0.6678, 0.3322],
        [0.6688, 0.3312],
        [0.6681, 0.3319],
        [0.6626, 0.3374],
        [0.6554, 0.3446],
        [0.6698, 0.3302],
        [0.6702, 0.3298],
        [0.6690, 0.3310],
        [0.6652, 0.3348],
        [0.6672, 0.3328],
        [0.6595, 0.3405],
        [0.6643, 0.3357],
        [0.6658, 0.3342],
        [0.6692, 0.3308],
        [0.6662, 0.3338],
        [0.6609, 0.3391],
        [0.6657, 0.3343],
        [0.6654, 0.3346],
        [0.6636, 0.3364],
        [0.6687, 0.3313],
        [0.6661, 0.3339],
        [0.6644, 0.3356],
        [0.6616, 0.3384],
        [0.6633, 0.3367],
        [0.6612, 0.3388],
        [0.6644, 0.3356],
        [0.6696, 0.3304],
        [0.6650, 0.3350],
        [0.6614, 0.3386],
        [0.6620, 0.3380],
        [0.6638, 0.3362],
        [0.6623, 0.3377],
        [0.6627, 0.3373],
        [0.6593, 0.3407],
        [0.6683, 0.3317],
        [0.6696, 0.3304],
        [0.6663, 0.3337],
        [0.6656, 0.3344],
        [0.6712, 0.3288],
        [0.6655, 0.3345],
        [0.6727, 0.3273],
        [0.6699, 0.3301],
        [0.6704, 0.3296],
        [0.6717, 0.3283],
        [0.6628, 0.3372],
        [0.6720, 0.3280],
        [0.6662, 0.3338],
        [0.6619, 0.3381],
        [0.6633, 0.3367],
        [0.6669, 0.3331],
        [0.6682, 0.3318],
        [0.6645, 0.3355],
        [0.6672, 0.3328],
        [0.6554, 0.3446],
        [0.6660, 0.3340],
        [0.6640, 0.3360],
        [0.6626, 0.3374],
        [0.6659, 0.3341],
        [0.6634, 0.3366],
        [0.6568, 0.3432],
        [0.6664, 0.3336],
        [0.6637, 0.3363],
        [0.6622, 0.3378],
        [0.6647, 0.3353],
        [0.6637, 0.3363],
        [0.6700, 0.3300],
        [0.6657, 0.3343],
        [0.6596, 0.3404],
        [0.6704, 0.3296],
        [0.6718, 0.3282],
        [0.6625, 0.3375],
        [0.6647, 0.3353],
        [0.6633, 0.3367],
        [0.6671, 0.3329],
        [0.6659, 0.3341],
        [0.6573, 0.3427],
        [0.6672, 0.3328],
        [0.6600, 0.3400],
        [0.6680, 0.3320],
        [0.6721, 0.3279],
        [0.6680, 0.3320],
        [0.6620, 0.3380],
        [0.6616, 0.3384],
        [0.6718, 0.3282],
        [0.6716, 0.3284],
        [0.6715, 0.3285],
        [0.6591, 0.3409],
        [0.6685, 0.3315],
        [0.6662, 0.3338],
        [0.6624, 0.3376],
        [0.6706, 0.3294],
        [0.6688, 0.3312],
        [0.6626, 0.3374],
        [0.6685, 0.3315],
        [0.6652, 0.3348],
        [0.6727, 0.3273],
        [0.6704, 0.3296],
        [0.6668, 0.3332],
        [0.6632, 0.3368],
        [0.6692, 0.3308],
        [0.6595, 0.3405],
        [0.6693, 0.3307],
        [0.6636, 0.3364],
        [0.6654, 0.3346],
        [0.6728, 0.3272],
        [0.6599, 0.3401],
        [0.6685, 0.3315],
        [0.6683, 0.3317],
        [0.6649, 0.3351],
        [0.6634, 0.3366],
        [0.6708, 0.3292],
        [0.6612, 0.3388],
        [0.6676, 0.3324],
        [0.6687, 0.3313],
        [0.6703, 0.3297],
        [0.6549, 0.3451],
        [0.6687, 0.3313],
        [0.6640, 0.3360],
        [0.6656, 0.3344],
        [0.6643, 0.3357],
        [0.6707, 0.3293],
        [0.6718, 0.3282],
        [0.6634, 0.3366],
        [0.6696, 0.3304],
        [0.6721, 0.3279],
        [0.6662, 0.3338],
        [0.6670, 0.3330],
        [0.6627, 0.3373],
        [0.6657, 0.3343],
        [0.6653, 0.3347],
        [0.6648, 0.3352],
        [0.6636, 0.3364],
        [0.6654, 0.3346],
        [0.6670, 0.3330],
        [0.6721, 0.3279],
        [0.6704, 0.3296],
        [0.6676, 0.3324],
        [0.6660, 0.3340],
        [0.6664, 0.3336],
        [0.6629, 0.3371],
        [0.6741, 0.3259],
        [0.6610, 0.3390],
        [0.6741, 0.3259],
        [0.6680, 0.3320],
        [0.6704, 0.3296],
        [0.6668, 0.3332],
        [0.6705, 0.3295],
        [0.6643, 0.3357],
        [0.6707, 0.3293],
        [0.6689, 0.3311],
        [0.6649, 0.3351],
        [0.6700, 0.3300],
        [0.6696, 0.3304],
        [0.6634, 0.3366],
        [0.6644, 0.3356],
        [0.6684, 0.3316],
        [0.6675, 0.3325],
        [0.6654, 0.3346],
        [0.6675, 0.3325],
        [0.6743, 0.3257],
        [0.6708, 0.3292]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0033 loss: 0.6687 acc_train: 0.6103 time: 0.1105s
tensor([[0.6638, 0.3362],
        [0.6666, 0.3334],
        [0.6734, 0.3266],
        [0.6641, 0.3359],
        [0.6704, 0.3296],
        [0.6610, 0.3390],
        [0.6594, 0.3406],
        [0.6625, 0.3375],
        [0.6662, 0.3338],
        [0.6590, 0.3410],
        [0.6709, 0.3291],
        [0.6628, 0.3372],
        [0.6655, 0.3345],
        [0.6644, 0.3356],
        [0.6679, 0.3321],
        [0.6657, 0.3343],
        [0.6679, 0.3321],
        [0.6588, 0.3412],
        [0.6674, 0.3326],
        [0.6603, 0.3397],
        [0.6680, 0.3320],
        [0.6646, 0.3354],
        [0.6682, 0.3318],
        [0.6741, 0.3259],
        [0.6698, 0.3302],
        [0.6634, 0.3366],
        [0.6610, 0.3390],
        [0.6665, 0.3335],
        [0.6614, 0.3386],
        [0.6634, 0.3366],
        [0.6656, 0.3344],
        [0.6632, 0.3368],
        [0.6692, 0.3308],
        [0.6663, 0.3337],
        [0.6672, 0.3328],
        [0.6559, 0.3441],
        [0.6654, 0.3346],
        [0.6644, 0.3356],
        [0.6666, 0.3334],
        [0.6591, 0.3409],
        [0.6679, 0.3321],
        [0.6683, 0.3317],
        [0.6585, 0.3415],
        [0.6637, 0.3363],
        [0.6638, 0.3362],
        [0.6609, 0.3391],
        [0.6713, 0.3287],
        [0.6739, 0.3261],
        [0.6613, 0.3387],
        [0.6660, 0.3340],
        [0.6654, 0.3346],
        [0.6684, 0.3316],
        [0.6668, 0.3332],
        [0.6699, 0.3301],
        [0.6673, 0.3327],
        [0.6689, 0.3311],
        [0.6673, 0.3327],
        [0.6669, 0.3331],
        [0.6617, 0.3383],
        [0.6653, 0.3347],
        [0.6633, 0.3367],
        [0.6662, 0.3338],
        [0.6668, 0.3332],
        [0.6715, 0.3285],
        [0.6624, 0.3376],
        [0.6633, 0.3367],
        [0.6664, 0.3336],
        [0.6656, 0.3344],
        [0.6686, 0.3314],
        [0.6658, 0.3342],
        [0.6637, 0.3363],
        [0.6618, 0.3382],
        [0.6643, 0.3357],
        [0.6656, 0.3344],
        [0.6643, 0.3357],
        [0.6655, 0.3345],
        [0.6680, 0.3320],
        [0.6659, 0.3341],
        [0.6663, 0.3337],
        [0.6621, 0.3379],
        [0.6635, 0.3365],
        [0.6633, 0.3367],
        [0.6640, 0.3360],
        [0.6634, 0.3366],
        [0.6671, 0.3329],
        [0.6607, 0.3393],
        [0.6673, 0.3327],
        [0.6645, 0.3355],
        [0.6601, 0.3399],
        [0.6662, 0.3338],
        [0.6636, 0.3364],
        [0.6636, 0.3364],
        [0.6667, 0.3333],
        [0.6609, 0.3391],
        [0.6627, 0.3373],
        [0.6697, 0.3303],
        [0.6711, 0.3289],
        [0.6641, 0.3359],
        [0.6686, 0.3314],
        [0.6635, 0.3365],
        [0.6635, 0.3365],
        [0.6652, 0.3348],
        [0.6648, 0.3352],
        [0.6596, 0.3404],
        [0.6677, 0.3323],
        [0.6621, 0.3379],
        [0.6686, 0.3314],
        [0.6680, 0.3320],
        [0.6597, 0.3403],
        [0.6635, 0.3365],
        [0.6548, 0.3452],
        [0.6674, 0.3326],
        [0.6684, 0.3316],
        [0.6679, 0.3321],
        [0.6625, 0.3375],
        [0.6557, 0.3443],
        [0.6694, 0.3306],
        [0.6696, 0.3304],
        [0.6688, 0.3312],
        [0.6648, 0.3352],
        [0.6667, 0.3333],
        [0.6598, 0.3402],
        [0.6644, 0.3356],
        [0.6656, 0.3344],
        [0.6690, 0.3310],
        [0.6660, 0.3340],
        [0.6610, 0.3390],
        [0.6657, 0.3343],
        [0.6652, 0.3348],
        [0.6635, 0.3365],
        [0.6684, 0.3316],
        [0.6661, 0.3339],
        [0.6643, 0.3357],
        [0.6618, 0.3382],
        [0.6633, 0.3367],
        [0.6615, 0.3385],
        [0.6642, 0.3358],
        [0.6695, 0.3305],
        [0.6650, 0.3350],
        [0.6616, 0.3384],
        [0.6622, 0.3378],
        [0.6636, 0.3364],
        [0.6625, 0.3375],
        [0.6628, 0.3372],
        [0.6593, 0.3407],
        [0.6680, 0.3320],
        [0.6689, 0.3311],
        [0.6659, 0.3341],
        [0.6656, 0.3344],
        [0.6707, 0.3293],
        [0.6653, 0.3347],
        [0.6719, 0.3281],
        [0.6695, 0.3305],
        [0.6699, 0.3301],
        [0.6711, 0.3289],
        [0.6630, 0.3370],
        [0.6714, 0.3286],
        [0.6661, 0.3339],
        [0.6620, 0.3380],
        [0.6632, 0.3368],
        [0.6665, 0.3335],
        [0.6678, 0.3322],
        [0.6642, 0.3358],
        [0.6670, 0.3330],
        [0.6555, 0.3445],
        [0.6660, 0.3340],
        [0.6641, 0.3359],
        [0.6624, 0.3376],
        [0.6657, 0.3343],
        [0.6632, 0.3368],
        [0.6570, 0.3430],
        [0.6661, 0.3339],
        [0.6635, 0.3365],
        [0.6623, 0.3377],
        [0.6647, 0.3353],
        [0.6639, 0.3361],
        [0.6695, 0.3305],
        [0.6657, 0.3343],
        [0.6598, 0.3402],
        [0.6699, 0.3301],
        [0.6712, 0.3288],
        [0.6625, 0.3375],
        [0.6647, 0.3353],
        [0.6631, 0.3369],
        [0.6671, 0.3329],
        [0.6656, 0.3344],
        [0.6576, 0.3424],
        [0.6669, 0.3331],
        [0.6603, 0.3397],
        [0.6678, 0.3322],
        [0.6718, 0.3282],
        [0.6675, 0.3325],
        [0.6619, 0.3381],
        [0.6615, 0.3385],
        [0.6712, 0.3288],
        [0.6709, 0.3291],
        [0.6711, 0.3289],
        [0.6592, 0.3408],
        [0.6684, 0.3316],
        [0.6661, 0.3339],
        [0.6623, 0.3377],
        [0.6701, 0.3299],
        [0.6685, 0.3315],
        [0.6627, 0.3373],
        [0.6679, 0.3321],
        [0.6649, 0.3351],
        [0.6722, 0.3278],
        [0.6699, 0.3301],
        [0.6667, 0.3333],
        [0.6633, 0.3367],
        [0.6688, 0.3312],
        [0.6599, 0.3401],
        [0.6690, 0.3310],
        [0.6635, 0.3365],
        [0.6652, 0.3348],
        [0.6725, 0.3275],
        [0.6600, 0.3400],
        [0.6679, 0.3321],
        [0.6679, 0.3321],
        [0.6650, 0.3350],
        [0.6634, 0.3366],
        [0.6703, 0.3297],
        [0.6612, 0.3388],
        [0.6674, 0.3326],
        [0.6685, 0.3315],
        [0.6698, 0.3302],
        [0.6548, 0.3452],
        [0.6683, 0.3317],
        [0.6638, 0.3362],
        [0.6654, 0.3346],
        [0.6640, 0.3360],
        [0.6703, 0.3297],
        [0.6715, 0.3285],
        [0.6634, 0.3366],
        [0.6692, 0.3308],
        [0.6714, 0.3286],
        [0.6661, 0.3339],
        [0.6669, 0.3331],
        [0.6628, 0.3372],
        [0.6655, 0.3345],
        [0.6651, 0.3349],
        [0.6645, 0.3355],
        [0.6636, 0.3364],
        [0.6653, 0.3347],
        [0.6667, 0.3333],
        [0.6714, 0.3286],
        [0.6699, 0.3301],
        [0.6671, 0.3329],
        [0.6659, 0.3341],
        [0.6660, 0.3340],
        [0.6630, 0.3370],
        [0.6733, 0.3267],
        [0.6609, 0.3391],
        [0.6732, 0.3268],
        [0.6676, 0.3324],
        [0.6700, 0.3300],
        [0.6664, 0.3336],
        [0.6700, 0.3300],
        [0.6642, 0.3358],
        [0.6702, 0.3298],
        [0.6686, 0.3314],
        [0.6648, 0.3352],
        [0.6698, 0.3302],
        [0.6691, 0.3309],
        [0.6633, 0.3367],
        [0.6644, 0.3356],
        [0.6677, 0.3323],
        [0.6671, 0.3329],
        [0.6655, 0.3345],
        [0.6675, 0.3325],
        [0.6734, 0.3266],
        [0.6702, 0.3298]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0034 loss: 0.6688 acc_train: 0.6103 time: 0.1116s
tensor([[0.6636, 0.3364],
        [0.6664, 0.3336],
        [0.6724, 0.3276],
        [0.6640, 0.3360],
        [0.6699, 0.3301],
        [0.6611, 0.3389],
        [0.6594, 0.3406],
        [0.6625, 0.3375],
        [0.6658, 0.3342],
        [0.6593, 0.3407],
        [0.6702, 0.3298],
        [0.6627, 0.3373],
        [0.6652, 0.3348],
        [0.6642, 0.3358],
        [0.6673, 0.3327],
        [0.6654, 0.3346],
        [0.6673, 0.3327],
        [0.6591, 0.3409],
        [0.6669, 0.3331],
        [0.6604, 0.3396],
        [0.6675, 0.3325],
        [0.6643, 0.3357],
        [0.6678, 0.3322],
        [0.6731, 0.3269],
        [0.6693, 0.3307],
        [0.6634, 0.3366],
        [0.6611, 0.3389],
        [0.6661, 0.3339],
        [0.6614, 0.3386],
        [0.6632, 0.3368],
        [0.6652, 0.3348],
        [0.6631, 0.3369],
        [0.6686, 0.3314],
        [0.6657, 0.3343],
        [0.6665, 0.3335],
        [0.6559, 0.3441],
        [0.6649, 0.3351],
        [0.6641, 0.3359],
        [0.6660, 0.3340],
        [0.6594, 0.3406],
        [0.6674, 0.3326],
        [0.6677, 0.3323],
        [0.6582, 0.3418],
        [0.6637, 0.3363],
        [0.6635, 0.3365],
        [0.6607, 0.3393],
        [0.6707, 0.3293],
        [0.6730, 0.3270],
        [0.6614, 0.3386],
        [0.6655, 0.3345],
        [0.6648, 0.3352],
        [0.6678, 0.3322],
        [0.6665, 0.3335],
        [0.6695, 0.3305],
        [0.6669, 0.3331],
        [0.6682, 0.3318],
        [0.6669, 0.3331],
        [0.6666, 0.3334],
        [0.6616, 0.3384],
        [0.6652, 0.3348],
        [0.6633, 0.3367],
        [0.6657, 0.3343],
        [0.6665, 0.3335],
        [0.6709, 0.3291],
        [0.6624, 0.3376],
        [0.6632, 0.3368],
        [0.6659, 0.3341],
        [0.6652, 0.3348],
        [0.6680, 0.3320],
        [0.6655, 0.3345],
        [0.6636, 0.3364],
        [0.6617, 0.3383],
        [0.6640, 0.3360],
        [0.6654, 0.3346],
        [0.6641, 0.3359],
        [0.6651, 0.3349],
        [0.6677, 0.3323],
        [0.6654, 0.3346],
        [0.6656, 0.3344],
        [0.6619, 0.3381],
        [0.6633, 0.3367],
        [0.6630, 0.3370],
        [0.6638, 0.3362],
        [0.6632, 0.3368],
        [0.6667, 0.3333],
        [0.6608, 0.3392],
        [0.6669, 0.3331],
        [0.6643, 0.3357],
        [0.6602, 0.3398],
        [0.6661, 0.3339],
        [0.6633, 0.3367],
        [0.6633, 0.3367],
        [0.6664, 0.3336],
        [0.6609, 0.3391],
        [0.6625, 0.3375],
        [0.6690, 0.3310],
        [0.6704, 0.3296],
        [0.6640, 0.3360],
        [0.6681, 0.3319],
        [0.6633, 0.3367],
        [0.6634, 0.3366],
        [0.6648, 0.3352],
        [0.6645, 0.3355],
        [0.6596, 0.3404],
        [0.6675, 0.3325],
        [0.6619, 0.3381],
        [0.6681, 0.3319],
        [0.6677, 0.3323],
        [0.6597, 0.3403],
        [0.6634, 0.3366],
        [0.6549, 0.3451],
        [0.6670, 0.3330],
        [0.6680, 0.3320],
        [0.6676, 0.3324],
        [0.6624, 0.3376],
        [0.6557, 0.3443],
        [0.6688, 0.3312],
        [0.6690, 0.3310],
        [0.6685, 0.3315],
        [0.6643, 0.3357],
        [0.6662, 0.3338],
        [0.6600, 0.3400],
        [0.6643, 0.3357],
        [0.6653, 0.3347],
        [0.6687, 0.3313],
        [0.6656, 0.3344],
        [0.6609, 0.3391],
        [0.6655, 0.3345],
        [0.6649, 0.3351],
        [0.6633, 0.3367],
        [0.6680, 0.3320],
        [0.6659, 0.3341],
        [0.6640, 0.3360],
        [0.6617, 0.3383],
        [0.6632, 0.3368],
        [0.6616, 0.3384],
        [0.6640, 0.3360],
        [0.6692, 0.3308],
        [0.6649, 0.3351],
        [0.6616, 0.3384],
        [0.6622, 0.3378],
        [0.6634, 0.3366],
        [0.6626, 0.3374],
        [0.6627, 0.3373],
        [0.6592, 0.3408],
        [0.6677, 0.3323],
        [0.6682, 0.3318],
        [0.6654, 0.3346],
        [0.6655, 0.3345],
        [0.6701, 0.3299],
        [0.6650, 0.3350],
        [0.6711, 0.3289],
        [0.6690, 0.3310],
        [0.6692, 0.3308],
        [0.6704, 0.3296],
        [0.6629, 0.3371],
        [0.6706, 0.3294],
        [0.6659, 0.3341],
        [0.6619, 0.3381],
        [0.6629, 0.3371],
        [0.6659, 0.3341],
        [0.6672, 0.3328],
        [0.6638, 0.3362],
        [0.6666, 0.3334],
        [0.6555, 0.3445],
        [0.6658, 0.3342],
        [0.6641, 0.3359],
        [0.6621, 0.3379],
        [0.6654, 0.3346],
        [0.6629, 0.3371],
        [0.6570, 0.3430],
        [0.6656, 0.3344],
        [0.6631, 0.3369],
        [0.6623, 0.3377],
        [0.6647, 0.3353],
        [0.6640, 0.3360],
        [0.6689, 0.3311],
        [0.6654, 0.3346],
        [0.6599, 0.3401],
        [0.6694, 0.3306],
        [0.6705, 0.3295],
        [0.6623, 0.3377],
        [0.6645, 0.3355],
        [0.6629, 0.3371],
        [0.6669, 0.3331],
        [0.6653, 0.3347],
        [0.6577, 0.3423],
        [0.6664, 0.3336],
        [0.6603, 0.3397],
        [0.6674, 0.3326],
        [0.6713, 0.3287],
        [0.6668, 0.3332],
        [0.6617, 0.3383],
        [0.6613, 0.3387],
        [0.6704, 0.3296],
        [0.6701, 0.3299],
        [0.6705, 0.3295],
        [0.6593, 0.3407],
        [0.6681, 0.3319],
        [0.6658, 0.3342],
        [0.6621, 0.3379],
        [0.6695, 0.3305],
        [0.6680, 0.3320],
        [0.6626, 0.3374],
        [0.6673, 0.3327],
        [0.6646, 0.3354],
        [0.6715, 0.3285],
        [0.6693, 0.3307],
        [0.6663, 0.3337],
        [0.6632, 0.3368],
        [0.6682, 0.3318],
        [0.6601, 0.3399],
        [0.6685, 0.3315],
        [0.6633, 0.3367],
        [0.6649, 0.3351],
        [0.6720, 0.3280],
        [0.6600, 0.3400],
        [0.6672, 0.3328],
        [0.6673, 0.3327],
        [0.6650, 0.3350],
        [0.6631, 0.3369],
        [0.6697, 0.3303],
        [0.6611, 0.3389],
        [0.6670, 0.3330],
        [0.6680, 0.3320],
        [0.6691, 0.3309],
        [0.6546, 0.3454],
        [0.6678, 0.3322],
        [0.6633, 0.3367],
        [0.6651, 0.3349],
        [0.6637, 0.3363],
        [0.6698, 0.3302],
        [0.6711, 0.3289],
        [0.6632, 0.3368],
        [0.6687, 0.3313],
        [0.6707, 0.3293],
        [0.6658, 0.3342],
        [0.6666, 0.3334],
        [0.6628, 0.3372],
        [0.6652, 0.3348],
        [0.6648, 0.3352],
        [0.6640, 0.3360],
        [0.6634, 0.3366],
        [0.6650, 0.3350],
        [0.6664, 0.3336],
        [0.6705, 0.3295],
        [0.6693, 0.3307],
        [0.6666, 0.3334],
        [0.6657, 0.3343],
        [0.6655, 0.3345],
        [0.6630, 0.3370],
        [0.6723, 0.3277],
        [0.6607, 0.3393],
        [0.6722, 0.3278],
        [0.6672, 0.3328],
        [0.6694, 0.3306],
        [0.6659, 0.3341],
        [0.6694, 0.3306],
        [0.6640, 0.3360],
        [0.6695, 0.3305],
        [0.6681, 0.3319],
        [0.6646, 0.3354],
        [0.6693, 0.3307],
        [0.6685, 0.3315],
        [0.6632, 0.3368],
        [0.6643, 0.3357],
        [0.6670, 0.3330],
        [0.6667, 0.3333],
        [0.6652, 0.3348],
        [0.6672, 0.3328],
        [0.6725, 0.3275],
        [0.6695, 0.3305]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0035 loss: 0.6689 acc_train: 0.6103 time: 0.1122s
tensor([[0.6633, 0.3367],
        [0.6661, 0.3339],
        [0.6714, 0.3286],
        [0.6639, 0.3361],
        [0.6693, 0.3307],
        [0.6611, 0.3389],
        [0.6594, 0.3406],
        [0.6624, 0.3376],
        [0.6652, 0.3348],
        [0.6593, 0.3407],
        [0.6693, 0.3307],
        [0.6626, 0.3374],
        [0.6646, 0.3354],
        [0.6639, 0.3361],
        [0.6666, 0.3334],
        [0.6649, 0.3351],
        [0.6667, 0.3333],
        [0.6592, 0.3408],
        [0.6663, 0.3337],
        [0.6603, 0.3397],
        [0.6671, 0.3329],
        [0.6640, 0.3360],
        [0.6673, 0.3327],
        [0.6720, 0.3280],
        [0.6688, 0.3312],
        [0.6633, 0.3367],
        [0.6611, 0.3389],
        [0.6658, 0.3342],
        [0.6614, 0.3386],
        [0.6629, 0.3371],
        [0.6648, 0.3352],
        [0.6628, 0.3372],
        [0.6680, 0.3320],
        [0.6650, 0.3350],
        [0.6657, 0.3343],
        [0.6558, 0.3442],
        [0.6644, 0.3356],
        [0.6638, 0.3362],
        [0.6654, 0.3346],
        [0.6596, 0.3404],
        [0.6669, 0.3331],
        [0.6671, 0.3329],
        [0.6579, 0.3421],
        [0.6636, 0.3364],
        [0.6630, 0.3370],
        [0.6606, 0.3394],
        [0.6700, 0.3300],
        [0.6721, 0.3279],
        [0.6614, 0.3386],
        [0.6649, 0.3351],
        [0.6642, 0.3358],
        [0.6672, 0.3328],
        [0.6661, 0.3339],
        [0.6689, 0.3311],
        [0.6665, 0.3335],
        [0.6676, 0.3324],
        [0.6664, 0.3336],
        [0.6663, 0.3337],
        [0.6615, 0.3385],
        [0.6650, 0.3350],
        [0.6632, 0.3368],
        [0.6650, 0.3350],
        [0.6661, 0.3339],
        [0.6701, 0.3299],
        [0.6622, 0.3378],
        [0.6631, 0.3369],
        [0.6653, 0.3347],
        [0.6647, 0.3353],
        [0.6673, 0.3327],
        [0.6651, 0.3349],
        [0.6634, 0.3366],
        [0.6616, 0.3384],
        [0.6637, 0.3363],
        [0.6650, 0.3350],
        [0.6637, 0.3363],
        [0.6647, 0.3353],
        [0.6672, 0.3328],
        [0.6648, 0.3352],
        [0.6649, 0.3351],
        [0.6617, 0.3383],
        [0.6630, 0.3370],
        [0.6625, 0.3375],
        [0.6635, 0.3365],
        [0.6629, 0.3371],
        [0.6662, 0.3338],
        [0.6608, 0.3392],
        [0.6664, 0.3336],
        [0.6640, 0.3360],
        [0.6602, 0.3398],
        [0.6659, 0.3341],
        [0.6628, 0.3372],
        [0.6629, 0.3371],
        [0.6660, 0.3340],
        [0.6610, 0.3390],
        [0.6622, 0.3378],
        [0.6682, 0.3318],
        [0.6696, 0.3304],
        [0.6638, 0.3362],
        [0.6675, 0.3325],
        [0.6630, 0.3370],
        [0.6631, 0.3369],
        [0.6644, 0.3356],
        [0.6641, 0.3359],
        [0.6595, 0.3405],
        [0.6671, 0.3329],
        [0.6617, 0.3383],
        [0.6675, 0.3325],
        [0.6672, 0.3328],
        [0.6597, 0.3403],
        [0.6632, 0.3368],
        [0.6551, 0.3449],
        [0.6664, 0.3336],
        [0.6674, 0.3326],
        [0.6672, 0.3328],
        [0.6623, 0.3377],
        [0.6555, 0.3445],
        [0.6681, 0.3319],
        [0.6683, 0.3317],
        [0.6682, 0.3318],
        [0.6637, 0.3363],
        [0.6657, 0.3343],
        [0.6601, 0.3399],
        [0.6641, 0.3359],
        [0.6649, 0.3351],
        [0.6682, 0.3318],
        [0.6651, 0.3349],
        [0.6608, 0.3392],
        [0.6651, 0.3349],
        [0.6645, 0.3355],
        [0.6630, 0.3370],
        [0.6674, 0.3326],
        [0.6656, 0.3344],
        [0.6637, 0.3363],
        [0.6616, 0.3384],
        [0.6630, 0.3370],
        [0.6616, 0.3384],
        [0.6637, 0.3363],
        [0.6687, 0.3313],
        [0.6647, 0.3353],
        [0.6614, 0.3386],
        [0.6622, 0.3378],
        [0.6631, 0.3369],
        [0.6625, 0.3375],
        [0.6625, 0.3375],
        [0.6591, 0.3409],
        [0.6672, 0.3328],
        [0.6675, 0.3325],
        [0.6648, 0.3352],
        [0.6652, 0.3348],
        [0.6695, 0.3305],
        [0.6645, 0.3355],
        [0.6701, 0.3299],
        [0.6684, 0.3316],
        [0.6684, 0.3316],
        [0.6695, 0.3305],
        [0.6627, 0.3373],
        [0.6697, 0.3303],
        [0.6656, 0.3344],
        [0.6617, 0.3383],
        [0.6627, 0.3373],
        [0.6654, 0.3346],
        [0.6666, 0.3334],
        [0.6634, 0.3366],
        [0.6661, 0.3339],
        [0.6554, 0.3446],
        [0.6655, 0.3345],
        [0.6640, 0.3360],
        [0.6617, 0.3383],
        [0.6651, 0.3349],
        [0.6626, 0.3374],
        [0.6569, 0.3431],
        [0.6650, 0.3350],
        [0.6626, 0.3374],
        [0.6622, 0.3378],
        [0.6646, 0.3354],
        [0.6639, 0.3361],
        [0.6682, 0.3318],
        [0.6649, 0.3351],
        [0.6600, 0.3400],
        [0.6687, 0.3313],
        [0.6697, 0.3303],
        [0.6622, 0.3378],
        [0.6643, 0.3357],
        [0.6627, 0.3373],
        [0.6664, 0.3336],
        [0.6650, 0.3350],
        [0.6579, 0.3421],
        [0.6658, 0.3342],
        [0.6603, 0.3397],
        [0.6668, 0.3332],
        [0.6707, 0.3293],
        [0.6661, 0.3339],
        [0.6614, 0.3386],
        [0.6611, 0.3389],
        [0.6696, 0.3304],
        [0.6692, 0.3308],
        [0.6698, 0.3302],
        [0.6592, 0.3408],
        [0.6677, 0.3323],
        [0.6655, 0.3345],
        [0.6618, 0.3382],
        [0.6687, 0.3313],
        [0.6675, 0.3325],
        [0.6625, 0.3375],
        [0.6666, 0.3334],
        [0.6643, 0.3357],
        [0.6707, 0.3293],
        [0.6687, 0.3313],
        [0.6657, 0.3343],
        [0.6629, 0.3371],
        [0.6675, 0.3325],
        [0.6602, 0.3398],
        [0.6680, 0.3320],
        [0.6630, 0.3370],
        [0.6646, 0.3354],
        [0.6713, 0.3287],
        [0.6599, 0.3401],
        [0.6664, 0.3336],
        [0.6666, 0.3334],
        [0.6649, 0.3351],
        [0.6627, 0.3373],
        [0.6691, 0.3309],
        [0.6609, 0.3391],
        [0.6665, 0.3335],
        [0.6674, 0.3326],
        [0.6684, 0.3316],
        [0.6544, 0.3456],
        [0.6672, 0.3328],
        [0.6629, 0.3371],
        [0.6647, 0.3353],
        [0.6633, 0.3367],
        [0.6692, 0.3308],
        [0.6705, 0.3295],
        [0.6630, 0.3370],
        [0.6682, 0.3318],
        [0.6701, 0.3299],
        [0.6654, 0.3346],
        [0.6662, 0.3338],
        [0.6626, 0.3374],
        [0.6648, 0.3352],
        [0.6645, 0.3355],
        [0.6634, 0.3366],
        [0.6631, 0.3369],
        [0.6647, 0.3353],
        [0.6662, 0.3338],
        [0.6697, 0.3303],
        [0.6686, 0.3314],
        [0.6660, 0.3340],
        [0.6655, 0.3345],
        [0.6650, 0.3350],
        [0.6628, 0.3372],
        [0.6713, 0.3287],
        [0.6605, 0.3395],
        [0.6711, 0.3289],
        [0.6668, 0.3332],
        [0.6686, 0.3314],
        [0.6654, 0.3346],
        [0.6687, 0.3313],
        [0.6638, 0.3362],
        [0.6688, 0.3312],
        [0.6674, 0.3326],
        [0.6644, 0.3356],
        [0.6687, 0.3313],
        [0.6679, 0.3321],
        [0.6629, 0.3371],
        [0.6643, 0.3357],
        [0.6663, 0.3337],
        [0.6662, 0.3338],
        [0.6648, 0.3352],
        [0.6668, 0.3332],
        [0.6715, 0.3285],
        [0.6687, 0.3313]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0036 loss: 0.6691 acc_train: 0.6103 time: 0.1081s
tensor([[0.6630, 0.3370],
        [0.6657, 0.3343],
        [0.6704, 0.3296],
        [0.6638, 0.3362],
        [0.6687, 0.3313],
        [0.6611, 0.3389],
        [0.6592, 0.3408],
        [0.6623, 0.3377],
        [0.6646, 0.3354],
        [0.6594, 0.3406],
        [0.6684, 0.3316],
        [0.6623, 0.3377],
        [0.6641, 0.3359],
        [0.6636, 0.3364],
        [0.6660, 0.3340],
        [0.6643, 0.3357],
        [0.6661, 0.3339],
        [0.6594, 0.3406],
        [0.6658, 0.3342],
        [0.6602, 0.3398],
        [0.6666, 0.3334],
        [0.6635, 0.3365],
        [0.6667, 0.3333],
        [0.6710, 0.3290],
        [0.6682, 0.3318],
        [0.6631, 0.3369],
        [0.6610, 0.3390],
        [0.6654, 0.3346],
        [0.6614, 0.3386],
        [0.6626, 0.3374],
        [0.6645, 0.3355],
        [0.6625, 0.3375],
        [0.6674, 0.3326],
        [0.6644, 0.3356],
        [0.6649, 0.3351],
        [0.6557, 0.3443],
        [0.6640, 0.3360],
        [0.6634, 0.3366],
        [0.6648, 0.3352],
        [0.6597, 0.3403],
        [0.6663, 0.3337],
        [0.6665, 0.3335],
        [0.6577, 0.3423],
        [0.6634, 0.3366],
        [0.6627, 0.3373],
        [0.6605, 0.3395],
        [0.6693, 0.3307],
        [0.6712, 0.3288],
        [0.6614, 0.3386],
        [0.6644, 0.3356],
        [0.6637, 0.3363],
        [0.6665, 0.3335],
        [0.6657, 0.3343],
        [0.6683, 0.3317],
        [0.6660, 0.3340],
        [0.6669, 0.3331],
        [0.6659, 0.3341],
        [0.6658, 0.3342],
        [0.6613, 0.3387],
        [0.6648, 0.3352],
        [0.6630, 0.3370],
        [0.6644, 0.3356],
        [0.6658, 0.3342],
        [0.6693, 0.3307],
        [0.6619, 0.3381],
        [0.6628, 0.3372],
        [0.6647, 0.3353],
        [0.6643, 0.3357],
        [0.6666, 0.3334],
        [0.6646, 0.3354],
        [0.6631, 0.3369],
        [0.6614, 0.3386],
        [0.6634, 0.3366],
        [0.6646, 0.3354],
        [0.6632, 0.3368],
        [0.6644, 0.3356],
        [0.6666, 0.3334],
        [0.6641, 0.3359],
        [0.6643, 0.3357],
        [0.6615, 0.3385],
        [0.6626, 0.3374],
        [0.6621, 0.3379],
        [0.6632, 0.3368],
        [0.6626, 0.3374],
        [0.6657, 0.3343],
        [0.6608, 0.3392],
        [0.6659, 0.3341],
        [0.6637, 0.3363],
        [0.6602, 0.3398],
        [0.6655, 0.3345],
        [0.6625, 0.3375],
        [0.6626, 0.3374],
        [0.6656, 0.3344],
        [0.6610, 0.3390],
        [0.6618, 0.3382],
        [0.6674, 0.3326],
        [0.6688, 0.3312],
        [0.6635, 0.3365],
        [0.6669, 0.3331],
        [0.6627, 0.3373],
        [0.6628, 0.3372],
        [0.6641, 0.3359],
        [0.6637, 0.3363],
        [0.6593, 0.3407],
        [0.6667, 0.3333],
        [0.6615, 0.3385],
        [0.6669, 0.3331],
        [0.6667, 0.3333],
        [0.6596, 0.3404],
        [0.6630, 0.3370],
        [0.6553, 0.3447],
        [0.6658, 0.3342],
        [0.6669, 0.3331],
        [0.6667, 0.3333],
        [0.6621, 0.3379],
        [0.6554, 0.3446],
        [0.6674, 0.3326],
        [0.6677, 0.3323],
        [0.6678, 0.3322],
        [0.6632, 0.3368],
        [0.6652, 0.3348],
        [0.6602, 0.3398],
        [0.6638, 0.3362],
        [0.6645, 0.3355],
        [0.6677, 0.3323],
        [0.6646, 0.3354],
        [0.6607, 0.3393],
        [0.6646, 0.3354],
        [0.6641, 0.3359],
        [0.6628, 0.3372],
        [0.6667, 0.3333],
        [0.6653, 0.3347],
        [0.6633, 0.3367],
        [0.6614, 0.3386],
        [0.6627, 0.3373],
        [0.6616, 0.3384],
        [0.6634, 0.3366],
        [0.6680, 0.3320],
        [0.6645, 0.3355],
        [0.6613, 0.3387],
        [0.6621, 0.3379],
        [0.6629, 0.3371],
        [0.6625, 0.3375],
        [0.6622, 0.3378],
        [0.6590, 0.3410],
        [0.6667, 0.3333],
        [0.6669, 0.3331],
        [0.6642, 0.3358],
        [0.6650, 0.3350],
        [0.6689, 0.3311],
        [0.6641, 0.3359],
        [0.6693, 0.3307],
        [0.6678, 0.3322],
        [0.6676, 0.3324],
        [0.6686, 0.3314],
        [0.6624, 0.3376],
        [0.6688, 0.3312],
        [0.6653, 0.3347],
        [0.6613, 0.3387],
        [0.6624, 0.3376],
        [0.6649, 0.3351],
        [0.6660, 0.3340],
        [0.6630, 0.3370],
        [0.6657, 0.3343],
        [0.6553, 0.3447],
        [0.6652, 0.3348],
        [0.6638, 0.3362],
        [0.6614, 0.3386],
        [0.6647, 0.3353],
        [0.6623, 0.3377],
        [0.6567, 0.3433],
        [0.6645, 0.3355],
        [0.6622, 0.3378],
        [0.6621, 0.3379],
        [0.6644, 0.3356],
        [0.6637, 0.3363],
        [0.6675, 0.3325],
        [0.6645, 0.3355],
        [0.6600, 0.3400],
        [0.6682, 0.3318],
        [0.6689, 0.3311],
        [0.6620, 0.3380],
        [0.6640, 0.3360],
        [0.6625, 0.3375],
        [0.6659, 0.3341],
        [0.6647, 0.3353],
        [0.6580, 0.3420],
        [0.6653, 0.3347],
        [0.6602, 0.3398],
        [0.6662, 0.3338],
        [0.6700, 0.3300],
        [0.6654, 0.3346],
        [0.6611, 0.3389],
        [0.6609, 0.3391],
        [0.6688, 0.3312],
        [0.6683, 0.3317],
        [0.6692, 0.3308],
        [0.6592, 0.3408],
        [0.6673, 0.3327],
        [0.6650, 0.3350],
        [0.6615, 0.3385],
        [0.6680, 0.3320],
        [0.6670, 0.3330],
        [0.6623, 0.3377],
        [0.6661, 0.3339],
        [0.6639, 0.3361],
        [0.6699, 0.3301],
        [0.6680, 0.3320],
        [0.6650, 0.3350],
        [0.6626, 0.3374],
        [0.6669, 0.3331],
        [0.6603, 0.3397],
        [0.6675, 0.3325],
        [0.6627, 0.3373],
        [0.6643, 0.3357],
        [0.6706, 0.3294],
        [0.6598, 0.3402],
        [0.6658, 0.3342],
        [0.6658, 0.3342],
        [0.6649, 0.3351],
        [0.6624, 0.3376],
        [0.6685, 0.3315],
        [0.6607, 0.3393],
        [0.6660, 0.3340],
        [0.6668, 0.3332],
        [0.6678, 0.3322],
        [0.6542, 0.3458],
        [0.6666, 0.3334],
        [0.6625, 0.3375],
        [0.6643, 0.3357],
        [0.6630, 0.3370],
        [0.6686, 0.3314],
        [0.6699, 0.3301],
        [0.6627, 0.3373],
        [0.6677, 0.3323],
        [0.6694, 0.3306],
        [0.6649, 0.3351],
        [0.6658, 0.3342],
        [0.6625, 0.3375],
        [0.6644, 0.3356],
        [0.6642, 0.3358],
        [0.6629, 0.3371],
        [0.6628, 0.3372],
        [0.6643, 0.3357],
        [0.6659, 0.3341],
        [0.6688, 0.3312],
        [0.6679, 0.3321],
        [0.6654, 0.3346],
        [0.6653, 0.3347],
        [0.6645, 0.3355],
        [0.6627, 0.3373],
        [0.6703, 0.3297],
        [0.6603, 0.3397],
        [0.6700, 0.3300],
        [0.6663, 0.3337],
        [0.6679, 0.3321],
        [0.6650, 0.3350],
        [0.6680, 0.3320],
        [0.6636, 0.3364],
        [0.6680, 0.3320],
        [0.6667, 0.3333],
        [0.6641, 0.3359],
        [0.6681, 0.3319],
        [0.6673, 0.3327],
        [0.6626, 0.3374],
        [0.6642, 0.3358],
        [0.6657, 0.3343],
        [0.6658, 0.3342],
        [0.6644, 0.3356],
        [0.6663, 0.3337],
        [0.6706, 0.3294],
        [0.6679, 0.3321]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0037 loss: 0.6692 acc_train: 0.6103 time: 0.1195s
tensor([[0.6627, 0.3373],
        [0.6653, 0.3347],
        [0.6696, 0.3304],
        [0.6637, 0.3363],
        [0.6681, 0.3319],
        [0.6609, 0.3391],
        [0.6590, 0.3410],
        [0.6621, 0.3379],
        [0.6640, 0.3360],
        [0.6593, 0.3407],
        [0.6676, 0.3324],
        [0.6620, 0.3380],
        [0.6635, 0.3365],
        [0.6633, 0.3367],
        [0.6653, 0.3347],
        [0.6638, 0.3362],
        [0.6656, 0.3344],
        [0.6595, 0.3405],
        [0.6654, 0.3346],
        [0.6601, 0.3399],
        [0.6661, 0.3339],
        [0.6631, 0.3369],
        [0.6662, 0.3338],
        [0.6701, 0.3299],
        [0.6677, 0.3323],
        [0.6630, 0.3370],
        [0.6610, 0.3390],
        [0.6650, 0.3350],
        [0.6614, 0.3386],
        [0.6623, 0.3377],
        [0.6642, 0.3358],
        [0.6622, 0.3378],
        [0.6667, 0.3333],
        [0.6638, 0.3362],
        [0.6642, 0.3358],
        [0.6556, 0.3444],
        [0.6636, 0.3364],
        [0.6631, 0.3369],
        [0.6643, 0.3357],
        [0.6597, 0.3403],
        [0.6658, 0.3342],
        [0.6660, 0.3340],
        [0.6574, 0.3426],
        [0.6632, 0.3368],
        [0.6624, 0.3376],
        [0.6605, 0.3395],
        [0.6687, 0.3313],
        [0.6703, 0.3297],
        [0.6613, 0.3387],
        [0.6639, 0.3361],
        [0.6634, 0.3366],
        [0.6659, 0.3341],
        [0.6652, 0.3348],
        [0.6677, 0.3323],
        [0.6656, 0.3344],
        [0.6663, 0.3337],
        [0.6655, 0.3345],
        [0.6653, 0.3347],
        [0.6611, 0.3389],
        [0.6645, 0.3355],
        [0.6627, 0.3373],
        [0.6638, 0.3362],
        [0.6654, 0.3346],
        [0.6684, 0.3316],
        [0.6615, 0.3385],
        [0.6626, 0.3374],
        [0.6640, 0.3360],
        [0.6640, 0.3360],
        [0.6659, 0.3341],
        [0.6641, 0.3359],
        [0.6627, 0.3373],
        [0.6612, 0.3388],
        [0.6632, 0.3368],
        [0.6641, 0.3359],
        [0.6628, 0.3372],
        [0.6640, 0.3360],
        [0.6661, 0.3339],
        [0.6635, 0.3365],
        [0.6637, 0.3363],
        [0.6614, 0.3386],
        [0.6622, 0.3378],
        [0.6618, 0.3382],
        [0.6629, 0.3371],
        [0.6622, 0.3378],
        [0.6652, 0.3348],
        [0.6608, 0.3392],
        [0.6653, 0.3347],
        [0.6635, 0.3365],
        [0.6602, 0.3398],
        [0.6650, 0.3350],
        [0.6622, 0.3378],
        [0.6623, 0.3377],
        [0.6652, 0.3348],
        [0.6610, 0.3390],
        [0.6614, 0.3386],
        [0.6667, 0.3333],
        [0.6680, 0.3320],
        [0.6633, 0.3367],
        [0.6664, 0.3336],
        [0.6624, 0.3376],
        [0.6625, 0.3375],
        [0.6637, 0.3363],
        [0.6633, 0.3367],
        [0.6592, 0.3408],
        [0.6662, 0.3338],
        [0.6613, 0.3387],
        [0.6663, 0.3337],
        [0.6662, 0.3338],
        [0.6596, 0.3404],
        [0.6628, 0.3372],
        [0.6555, 0.3445],
        [0.6652, 0.3348],
        [0.6664, 0.3336],
        [0.6663, 0.3337],
        [0.6619, 0.3381],
        [0.6552, 0.3448],
        [0.6667, 0.3333],
        [0.6671, 0.3329],
        [0.6674, 0.3326],
        [0.6627, 0.3373],
        [0.6647, 0.3353],
        [0.6603, 0.3397],
        [0.6634, 0.3366],
        [0.6640, 0.3360],
        [0.6672, 0.3328],
        [0.6641, 0.3359],
        [0.6605, 0.3395],
        [0.6641, 0.3359],
        [0.6638, 0.3362],
        [0.6625, 0.3375],
        [0.6660, 0.3340],
        [0.6649, 0.3351],
        [0.6629, 0.3371],
        [0.6612, 0.3388],
        [0.6624, 0.3376],
        [0.6615, 0.3385],
        [0.6630, 0.3370],
        [0.6673, 0.3327],
        [0.6643, 0.3357],
        [0.6611, 0.3389],
        [0.6620, 0.3380],
        [0.6626, 0.3374],
        [0.6624, 0.3376],
        [0.6620, 0.3380],
        [0.6590, 0.3410],
        [0.6662, 0.3338],
        [0.6664, 0.3336],
        [0.6636, 0.3364],
        [0.6646, 0.3354],
        [0.6684, 0.3316],
        [0.6638, 0.3362],
        [0.6685, 0.3315],
        [0.6672, 0.3328],
        [0.6669, 0.3331],
        [0.6678, 0.3322],
        [0.6622, 0.3378],
        [0.6680, 0.3320],
        [0.6649, 0.3351],
        [0.6610, 0.3390],
        [0.6622, 0.3378],
        [0.6645, 0.3355],
        [0.6654, 0.3346],
        [0.6627, 0.3373],
        [0.6652, 0.3348],
        [0.6552, 0.3448],
        [0.6648, 0.3352],
        [0.6635, 0.3365],
        [0.6612, 0.3388],
        [0.6644, 0.3356],
        [0.6621, 0.3379],
        [0.6565, 0.3435],
        [0.6640, 0.3360],
        [0.6619, 0.3381],
        [0.6618, 0.3382],
        [0.6642, 0.3358],
        [0.6634, 0.3366],
        [0.6667, 0.3333],
        [0.6641, 0.3359],
        [0.6600, 0.3400],
        [0.6677, 0.3323],
        [0.6681, 0.3319],
        [0.6618, 0.3382],
        [0.6638, 0.3362],
        [0.6623, 0.3377],
        [0.6653, 0.3347],
        [0.6643, 0.3357],
        [0.6582, 0.3418],
        [0.6648, 0.3352],
        [0.6601, 0.3399],
        [0.6656, 0.3344],
        [0.6694, 0.3306],
        [0.6647, 0.3353],
        [0.6608, 0.3392],
        [0.6608, 0.3392],
        [0.6681, 0.3319],
        [0.6674, 0.3326],
        [0.6684, 0.3316],
        [0.6592, 0.3408],
        [0.6668, 0.3332],
        [0.6646, 0.3354],
        [0.6613, 0.3387],
        [0.6673, 0.3327],
        [0.6665, 0.3335],
        [0.6621, 0.3379],
        [0.6657, 0.3343],
        [0.6636, 0.3364],
        [0.6692, 0.3308],
        [0.6674, 0.3326],
        [0.6645, 0.3355],
        [0.6622, 0.3378],
        [0.6663, 0.3337],
        [0.6603, 0.3397],
        [0.6670, 0.3330],
        [0.6624, 0.3376],
        [0.6640, 0.3360],
        [0.6699, 0.3301],
        [0.6597, 0.3403],
        [0.6652, 0.3348],
        [0.6650, 0.3350],
        [0.6648, 0.3352],
        [0.6620, 0.3380],
        [0.6679, 0.3321],
        [0.6605, 0.3395],
        [0.6655, 0.3345],
        [0.6662, 0.3338],
        [0.6672, 0.3328],
        [0.6540, 0.3460],
        [0.6660, 0.3340],
        [0.6621, 0.3379],
        [0.6639, 0.3361],
        [0.6627, 0.3373],
        [0.6680, 0.3320],
        [0.6692, 0.3308],
        [0.6625, 0.3375],
        [0.6672, 0.3328],
        [0.6688, 0.3312],
        [0.6645, 0.3355],
        [0.6653, 0.3347],
        [0.6624, 0.3376],
        [0.6640, 0.3360],
        [0.6640, 0.3360],
        [0.6625, 0.3375],
        [0.6625, 0.3375],
        [0.6640, 0.3360],
        [0.6656, 0.3344],
        [0.6680, 0.3320],
        [0.6672, 0.3328],
        [0.6648, 0.3352],
        [0.6650, 0.3350],
        [0.6640, 0.3360],
        [0.6625, 0.3375],
        [0.6693, 0.3307],
        [0.6601, 0.3399],
        [0.6691, 0.3309],
        [0.6659, 0.3341],
        [0.6671, 0.3329],
        [0.6646, 0.3354],
        [0.6674, 0.3326],
        [0.6633, 0.3367],
        [0.6673, 0.3327],
        [0.6660, 0.3340],
        [0.6639, 0.3361],
        [0.6675, 0.3325],
        [0.6668, 0.3332],
        [0.6623, 0.3377],
        [0.6640, 0.3360],
        [0.6652, 0.3348],
        [0.6654, 0.3346],
        [0.6639, 0.3361],
        [0.6658, 0.3342],
        [0.6697, 0.3303],
        [0.6672, 0.3328]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0038 loss: 0.6693 acc_train: 0.6103 time: 0.1206s
tensor([[0.6624, 0.3376],
        [0.6648, 0.3352],
        [0.6688, 0.3312],
        [0.6635, 0.3365],
        [0.6675, 0.3325],
        [0.6607, 0.3393],
        [0.6588, 0.3412],
        [0.6619, 0.3381],
        [0.6634, 0.3366],
        [0.6593, 0.3407],
        [0.6668, 0.3332],
        [0.6617, 0.3383],
        [0.6630, 0.3370],
        [0.6630, 0.3370],
        [0.6647, 0.3353],
        [0.6633, 0.3367],
        [0.6650, 0.3350],
        [0.6595, 0.3405],
        [0.6650, 0.3350],
        [0.6600, 0.3400],
        [0.6657, 0.3343],
        [0.6627, 0.3373],
        [0.6656, 0.3344],
        [0.6693, 0.3307],
        [0.6671, 0.3329],
        [0.6628, 0.3372],
        [0.6608, 0.3392],
        [0.6646, 0.3354],
        [0.6613, 0.3387],
        [0.6620, 0.3380],
        [0.6639, 0.3361],
        [0.6619, 0.3381],
        [0.6661, 0.3339],
        [0.6633, 0.3367],
        [0.6636, 0.3364],
        [0.6555, 0.3445],
        [0.6632, 0.3368],
        [0.6628, 0.3372],
        [0.6638, 0.3362],
        [0.6597, 0.3403],
        [0.6653, 0.3347],
        [0.6655, 0.3345],
        [0.6571, 0.3429],
        [0.6629, 0.3371],
        [0.6622, 0.3378],
        [0.6606, 0.3394],
        [0.6680, 0.3320],
        [0.6695, 0.3305],
        [0.6612, 0.3388],
        [0.6635, 0.3365],
        [0.6630, 0.3370],
        [0.6653, 0.3347],
        [0.6647, 0.3353],
        [0.6671, 0.3329],
        [0.6651, 0.3349],
        [0.6656, 0.3344],
        [0.6650, 0.3350],
        [0.6649, 0.3351],
        [0.6608, 0.3392],
        [0.6642, 0.3358],
        [0.6624, 0.3376],
        [0.6632, 0.3368],
        [0.6651, 0.3349],
        [0.6677, 0.3323],
        [0.6611, 0.3389],
        [0.6623, 0.3377],
        [0.6635, 0.3365],
        [0.6637, 0.3363],
        [0.6653, 0.3347],
        [0.6636, 0.3364],
        [0.6623, 0.3377],
        [0.6610, 0.3390],
        [0.6630, 0.3370],
        [0.6636, 0.3364],
        [0.6624, 0.3376],
        [0.6636, 0.3364],
        [0.6657, 0.3343],
        [0.6630, 0.3370],
        [0.6633, 0.3367],
        [0.6613, 0.3387],
        [0.6619, 0.3381],
        [0.6615, 0.3385],
        [0.6626, 0.3374],
        [0.6619, 0.3381],
        [0.6647, 0.3353],
        [0.6608, 0.3392],
        [0.6647, 0.3353],
        [0.6632, 0.3368],
        [0.6601, 0.3399],
        [0.6645, 0.3355],
        [0.6619, 0.3381],
        [0.6620, 0.3380],
        [0.6647, 0.3353],
        [0.6610, 0.3390],
        [0.6610, 0.3390],
        [0.6661, 0.3339],
        [0.6672, 0.3328],
        [0.6630, 0.3370],
        [0.6658, 0.3342],
        [0.6620, 0.3380],
        [0.6622, 0.3378],
        [0.6634, 0.3366],
        [0.6629, 0.3371],
        [0.6591, 0.3409],
        [0.6656, 0.3344],
        [0.6612, 0.3388],
        [0.6657, 0.3343],
        [0.6658, 0.3342],
        [0.6595, 0.3405],
        [0.6625, 0.3375],
        [0.6556, 0.3444],
        [0.6647, 0.3353],
        [0.6660, 0.3340],
        [0.6657, 0.3343],
        [0.6616, 0.3384],
        [0.6550, 0.3450],
        [0.6660, 0.3340],
        [0.6665, 0.3335],
        [0.6671, 0.3329],
        [0.6624, 0.3376],
        [0.6644, 0.3356],
        [0.6604, 0.3396],
        [0.6631, 0.3369],
        [0.6636, 0.3364],
        [0.6667, 0.3333],
        [0.6637, 0.3363],
        [0.6604, 0.3396],
        [0.6636, 0.3364],
        [0.6634, 0.3366],
        [0.6623, 0.3377],
        [0.6654, 0.3346],
        [0.6645, 0.3355],
        [0.6625, 0.3375],
        [0.6611, 0.3389],
        [0.6621, 0.3379],
        [0.6614, 0.3386],
        [0.6627, 0.3373],
        [0.6666, 0.3334],
        [0.6640, 0.3360],
        [0.6610, 0.3390],
        [0.6618, 0.3382],
        [0.6623, 0.3377],
        [0.6623, 0.3377],
        [0.6616, 0.3384],
        [0.6589, 0.3411],
        [0.6657, 0.3343],
        [0.6659, 0.3341],
        [0.6632, 0.3368],
        [0.6642, 0.3358],
        [0.6679, 0.3321],
        [0.6635, 0.3365],
        [0.6678, 0.3322],
        [0.6667, 0.3333],
        [0.6662, 0.3338],
        [0.6671, 0.3329],
        [0.6620, 0.3380],
        [0.6672, 0.3328],
        [0.6645, 0.3355],
        [0.6607, 0.3393],
        [0.6620, 0.3380],
        [0.6640, 0.3360],
        [0.6649, 0.3351],
        [0.6623, 0.3377],
        [0.6647, 0.3353],
        [0.6552, 0.3448],
        [0.6643, 0.3357],
        [0.6631, 0.3369],
        [0.6610, 0.3390],
        [0.6640, 0.3360],
        [0.6619, 0.3381],
        [0.6563, 0.3437],
        [0.6636, 0.3364],
        [0.6616, 0.3384],
        [0.6615, 0.3385],
        [0.6638, 0.3362],
        [0.6630, 0.3370],
        [0.6660, 0.3340],
        [0.6636, 0.3364],
        [0.6600, 0.3400],
        [0.6672, 0.3328],
        [0.6673, 0.3327],
        [0.6616, 0.3384],
        [0.6636, 0.3364],
        [0.6621, 0.3379],
        [0.6646, 0.3354],
        [0.6639, 0.3361],
        [0.6583, 0.3417],
        [0.6644, 0.3356],
        [0.6600, 0.3400],
        [0.6650, 0.3350],
        [0.6688, 0.3312],
        [0.6641, 0.3359],
        [0.6605, 0.3395],
        [0.6606, 0.3394],
        [0.6674, 0.3326],
        [0.6667, 0.3333],
        [0.6677, 0.3323],
        [0.6591, 0.3409],
        [0.6663, 0.3337],
        [0.6641, 0.3359],
        [0.6611, 0.3389],
        [0.6666, 0.3334],
        [0.6661, 0.3339],
        [0.6618, 0.3382],
        [0.6654, 0.3346],
        [0.6632, 0.3368],
        [0.6685, 0.3315],
        [0.6668, 0.3332],
        [0.6639, 0.3361],
        [0.6619, 0.3381],
        [0.6657, 0.3343],
        [0.6603, 0.3397],
        [0.6665, 0.3335],
        [0.6621, 0.3379],
        [0.6636, 0.3364],
        [0.6692, 0.3308],
        [0.6596, 0.3404],
        [0.6647, 0.3353],
        [0.6642, 0.3358],
        [0.6646, 0.3354],
        [0.6616, 0.3384],
        [0.6673, 0.3327],
        [0.6604, 0.3396],
        [0.6651, 0.3349],
        [0.6656, 0.3344],
        [0.6666, 0.3334],
        [0.6540, 0.3460],
        [0.6654, 0.3346],
        [0.6618, 0.3382],
        [0.6635, 0.3365],
        [0.6623, 0.3377],
        [0.6673, 0.3327],
        [0.6685, 0.3315],
        [0.6623, 0.3377],
        [0.6666, 0.3334],
        [0.6682, 0.3318],
        [0.6640, 0.3360],
        [0.6650, 0.3350],
        [0.6622, 0.3378],
        [0.6636, 0.3364],
        [0.6637, 0.3363],
        [0.6621, 0.3379],
        [0.6621, 0.3379],
        [0.6636, 0.3364],
        [0.6653, 0.3347],
        [0.6673, 0.3327],
        [0.6666, 0.3335],
        [0.6643, 0.3357],
        [0.6647, 0.3353],
        [0.6636, 0.3364],
        [0.6624, 0.3376],
        [0.6683, 0.3317],
        [0.6599, 0.3401],
        [0.6682, 0.3318],
        [0.6655, 0.3345],
        [0.6664, 0.3336],
        [0.6642, 0.3358],
        [0.6668, 0.3332],
        [0.6631, 0.3369],
        [0.6666, 0.3334],
        [0.6653, 0.3347],
        [0.6637, 0.3363],
        [0.6669, 0.3331],
        [0.6663, 0.3337],
        [0.6620, 0.3380],
        [0.6639, 0.3361],
        [0.6647, 0.3353],
        [0.6650, 0.3350],
        [0.6635, 0.3365],
        [0.6652, 0.3348],
        [0.6689, 0.3311],
        [0.6665, 0.3335]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0039 loss: 0.6694 acc_train: 0.6103 time: 0.1174s
tensor([[0.6622, 0.3378],
        [0.6644, 0.3356],
        [0.6681, 0.3319],
        [0.6633, 0.3367],
        [0.6669, 0.3331],
        [0.6605, 0.3395],
        [0.6586, 0.3414],
        [0.6616, 0.3384],
        [0.6629, 0.3371],
        [0.6592, 0.3408],
        [0.6660, 0.3340],
        [0.6613, 0.3387],
        [0.6626, 0.3374],
        [0.6627, 0.3373],
        [0.6642, 0.3358],
        [0.6628, 0.3372],
        [0.6646, 0.3354],
        [0.6594, 0.3406],
        [0.6646, 0.3354],
        [0.6598, 0.3402],
        [0.6652, 0.3348],
        [0.6623, 0.3377],
        [0.6650, 0.3350],
        [0.6686, 0.3314],
        [0.6667, 0.3333],
        [0.6626, 0.3374],
        [0.6607, 0.3393],
        [0.6641, 0.3359],
        [0.6613, 0.3387],
        [0.6617, 0.3383],
        [0.6636, 0.3364],
        [0.6617, 0.3383],
        [0.6655, 0.3345],
        [0.6629, 0.3371],
        [0.6631, 0.3369],
        [0.6555, 0.3445],
        [0.6629, 0.3371],
        [0.6625, 0.3375],
        [0.6633, 0.3367],
        [0.6597, 0.3403],
        [0.6649, 0.3351],
        [0.6651, 0.3349],
        [0.6568, 0.3432],
        [0.6625, 0.3375],
        [0.6620, 0.3380],
        [0.6606, 0.3394],
        [0.6674, 0.3326],
        [0.6687, 0.3313],
        [0.6611, 0.3389],
        [0.6631, 0.3369],
        [0.6628, 0.3372],
        [0.6648, 0.3352],
        [0.6642, 0.3358],
        [0.6665, 0.3335],
        [0.6647, 0.3353],
        [0.6651, 0.3349],
        [0.6646, 0.3354],
        [0.6645, 0.3355],
        [0.6606, 0.3394],
        [0.6639, 0.3361],
        [0.6620, 0.3380],
        [0.6627, 0.3373],
        [0.6648, 0.3352],
        [0.6669, 0.3331],
        [0.6608, 0.3392],
        [0.6620, 0.3380],
        [0.6630, 0.3370],
        [0.6635, 0.3365],
        [0.6649, 0.3351],
        [0.6631, 0.3369],
        [0.6620, 0.3380],
        [0.6608, 0.3392],
        [0.6628, 0.3372],
        [0.6632, 0.3368],
        [0.6620, 0.3380],
        [0.6633, 0.3367],
        [0.6653, 0.3347],
        [0.6626, 0.3374],
        [0.6630, 0.3370],
        [0.6612, 0.3388],
        [0.6616, 0.3384],
        [0.6613, 0.3387],
        [0.6623, 0.3377],
        [0.6617, 0.3383],
        [0.6643, 0.3357],
        [0.6606, 0.3394],
        [0.6642, 0.3358],
        [0.6629, 0.3371],
        [0.6601, 0.3399],
        [0.6639, 0.3361],
        [0.6617, 0.3383],
        [0.6618, 0.3382],
        [0.6642, 0.3358],
        [0.6609, 0.3391],
        [0.6607, 0.3393],
        [0.6656, 0.3344],
        [0.6665, 0.3335],
        [0.6628, 0.3372],
        [0.6652, 0.3348],
        [0.6617, 0.3383],
        [0.6619, 0.3381],
        [0.6631, 0.3369],
        [0.6626, 0.3374],
        [0.6591, 0.3409],
        [0.6651, 0.3349],
        [0.6610, 0.3390],
        [0.6652, 0.3348],
        [0.6653, 0.3347],
        [0.6595, 0.3405],
        [0.6623, 0.3377],
        [0.6557, 0.3443],
        [0.6642, 0.3358],
        [0.6655, 0.3345],
        [0.6652, 0.3348],
        [0.6614, 0.3386],
        [0.6549, 0.3451],
        [0.6654, 0.3346],
        [0.6660, 0.3340],
        [0.6666, 0.3334],
        [0.6622, 0.3378],
        [0.6640, 0.3360],
        [0.6604, 0.3396],
        [0.6627, 0.3373],
        [0.6632, 0.3368],
        [0.6662, 0.3338],
        [0.6633, 0.3367],
        [0.6604, 0.3396],
        [0.6631, 0.3369],
        [0.6630, 0.3370],
        [0.6621, 0.3379],
        [0.6648, 0.3352],
        [0.6641, 0.3359],
        [0.6622, 0.3378],
        [0.6609, 0.3391],
        [0.6618, 0.3382],
        [0.6612, 0.3388],
        [0.6624, 0.3376],
        [0.6659, 0.3341],
        [0.6637, 0.3363],
        [0.6610, 0.3390],
        [0.6616, 0.3384],
        [0.6621, 0.3379],
        [0.6622, 0.3378],
        [0.6613, 0.3387],
        [0.6589, 0.3411],
        [0.6652, 0.3348],
        [0.6655, 0.3345],
        [0.6628, 0.3372],
        [0.6637, 0.3363],
        [0.6674, 0.3326],
        [0.6632, 0.3368],
        [0.6672, 0.3328],
        [0.6662, 0.3338],
        [0.6656, 0.3344],
        [0.6664, 0.3336],
        [0.6618, 0.3382],
        [0.6666, 0.3334],
        [0.6641, 0.3359],
        [0.6605, 0.3395],
        [0.6619, 0.3381],
        [0.6636, 0.3364],
        [0.6645, 0.3355],
        [0.6621, 0.3379],
        [0.6643, 0.3357],
        [0.6551, 0.3449],
        [0.6639, 0.3361],
        [0.6627, 0.3373],
        [0.6608, 0.3392],
        [0.6636, 0.3364],
        [0.6617, 0.3383],
        [0.6561, 0.3439],
        [0.6632, 0.3368],
        [0.6614, 0.3386],
        [0.6613, 0.3387],
        [0.6635, 0.3365],
        [0.6626, 0.3374],
        [0.6654, 0.3346],
        [0.6632, 0.3368],
        [0.6599, 0.3401],
        [0.6668, 0.3332],
        [0.6666, 0.3334],
        [0.6614, 0.3386],
        [0.6633, 0.3367],
        [0.6618, 0.3382],
        [0.6641, 0.3359],
        [0.6636, 0.3364],
        [0.6584, 0.3416],
        [0.6640, 0.3360],
        [0.6599, 0.3401],
        [0.6645, 0.3355],
        [0.6681, 0.3319],
        [0.6636, 0.3364],
        [0.6603, 0.3397],
        [0.6605, 0.3395],
        [0.6669, 0.3331],
        [0.6660, 0.3340],
        [0.6670, 0.3330],
        [0.6590, 0.3410],
        [0.6658, 0.3342],
        [0.6637, 0.3363],
        [0.6609, 0.3391],
        [0.6659, 0.3341],
        [0.6656, 0.3344],
        [0.6616, 0.3384],
        [0.6651, 0.3349],
        [0.6629, 0.3371],
        [0.6679, 0.3321],
        [0.6663, 0.3337],
        [0.6635, 0.3365],
        [0.6616, 0.3384],
        [0.6652, 0.3348],
        [0.6603, 0.3397],
        [0.6661, 0.3339],
        [0.6619, 0.3381],
        [0.6632, 0.3368],
        [0.6685, 0.3315],
        [0.6594, 0.3406],
        [0.6643, 0.3357],
        [0.6637, 0.3363],
        [0.6645, 0.3355],
        [0.6613, 0.3387],
        [0.6667, 0.3333],
        [0.6603, 0.3397],
        [0.6648, 0.3352],
        [0.6650, 0.3350],
        [0.6660, 0.3340],
        [0.6540, 0.3460],
        [0.6649, 0.3351],
        [0.6615, 0.3385],
        [0.6632, 0.3368],
        [0.6620, 0.3380],
        [0.6667, 0.3333],
        [0.6679, 0.3321],
        [0.6621, 0.3379],
        [0.6661, 0.3339],
        [0.6676, 0.3324],
        [0.6636, 0.3364],
        [0.6646, 0.3354],
        [0.6620, 0.3380],
        [0.6633, 0.3367],
        [0.6635, 0.3365],
        [0.6618, 0.3382],
        [0.6618, 0.3382],
        [0.6633, 0.3367],
        [0.6649, 0.3351],
        [0.6667, 0.3333],
        [0.6660, 0.3340],
        [0.6638, 0.3362],
        [0.6643, 0.3357],
        [0.6633, 0.3367],
        [0.6622, 0.3378],
        [0.6676, 0.3324],
        [0.6598, 0.3402],
        [0.6674, 0.3326],
        [0.6650, 0.3350],
        [0.6657, 0.3343],
        [0.6638, 0.3362],
        [0.6662, 0.3338],
        [0.6628, 0.3372],
        [0.6660, 0.3340],
        [0.6647, 0.3353],
        [0.6635, 0.3365],
        [0.6664, 0.3336],
        [0.6658, 0.3342],
        [0.6618, 0.3382],
        [0.6637, 0.3363],
        [0.6643, 0.3357],
        [0.6646, 0.3354],
        [0.6630, 0.3370],
        [0.6647, 0.3353],
        [0.6681, 0.3319],
        [0.6660, 0.3340]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0040 loss: 0.6695 acc_train: 0.6103 time: 0.1105s
tensor([[0.6620, 0.3380],
        [0.6639, 0.3361],
        [0.6675, 0.3325],
        [0.6629, 0.3371],
        [0.6664, 0.3336],
        [0.6602, 0.3398],
        [0.6584, 0.3416],
        [0.6612, 0.3388],
        [0.6625, 0.3375],
        [0.6590, 0.3410],
        [0.6654, 0.3346],
        [0.6610, 0.3390],
        [0.6623, 0.3377],
        [0.6623, 0.3377],
        [0.6638, 0.3362],
        [0.6624, 0.3376],
        [0.6641, 0.3359],
        [0.6593, 0.3407],
        [0.6642, 0.3358],
        [0.6597, 0.3403],
        [0.6648, 0.3352],
        [0.6620, 0.3380],
        [0.6645, 0.3355],
        [0.6679, 0.3321],
        [0.6662, 0.3338],
        [0.6623, 0.3377],
        [0.6605, 0.3395],
        [0.6637, 0.3363],
        [0.6612, 0.3388],
        [0.6616, 0.3384],
        [0.6634, 0.3366],
        [0.6616, 0.3384],
        [0.6649, 0.3351],
        [0.6625, 0.3375],
        [0.6628, 0.3372],
        [0.6555, 0.3445],
        [0.6626, 0.3374],
        [0.6623, 0.3377],
        [0.6630, 0.3370],
        [0.6596, 0.3404],
        [0.6645, 0.3355],
        [0.6647, 0.3353],
        [0.6565, 0.3435],
        [0.6622, 0.3378],
        [0.6618, 0.3382],
        [0.6607, 0.3393],
        [0.6668, 0.3332],
        [0.6680, 0.3320],
        [0.6610, 0.3390],
        [0.6628, 0.3372],
        [0.6627, 0.3373],
        [0.6643, 0.3357],
        [0.6638, 0.3362],
        [0.6660, 0.3340],
        [0.6642, 0.3358],
        [0.6646, 0.3354],
        [0.6641, 0.3359],
        [0.6641, 0.3359],
        [0.6604, 0.3396],
        [0.6635, 0.3365],
        [0.6617, 0.3383],
        [0.6623, 0.3377],
        [0.6645, 0.3355],
        [0.6663, 0.3337],
        [0.6605, 0.3395],
        [0.6618, 0.3382],
        [0.6626, 0.3374],
        [0.6633, 0.3367],
        [0.6645, 0.3355],
        [0.6627, 0.3373],
        [0.6617, 0.3383],
        [0.6606, 0.3394],
        [0.6627, 0.3373],
        [0.6628, 0.3372],
        [0.6616, 0.3384],
        [0.6629, 0.3371],
        [0.6649, 0.3351],
        [0.6624, 0.3376],
        [0.6628, 0.3372],
        [0.6611, 0.3389],
        [0.6614, 0.3386],
        [0.6612, 0.3388],
        [0.6621, 0.3379],
        [0.6614, 0.3386],
        [0.6639, 0.3361],
        [0.6604, 0.3396],
        [0.6637, 0.3363],
        [0.6626, 0.3374],
        [0.6600, 0.3400],
        [0.6634, 0.3366],
        [0.6616, 0.3384],
        [0.6616, 0.3384],
        [0.6638, 0.3362],
        [0.6608, 0.3392],
        [0.6604, 0.3396],
        [0.6651, 0.3349],
        [0.6659, 0.3341],
        [0.6625, 0.3375],
        [0.6647, 0.3353],
        [0.6615, 0.3385],
        [0.6616, 0.3384],
        [0.6629, 0.3371],
        [0.6623, 0.3377],
        [0.6590, 0.3410],
        [0.6645, 0.3355],
        [0.6609, 0.3391],
        [0.6647, 0.3353],
        [0.6649, 0.3351],
        [0.6595, 0.3405],
        [0.6620, 0.3380],
        [0.6558, 0.3442],
        [0.6638, 0.3362],
        [0.6651, 0.3349],
        [0.6647, 0.3353],
        [0.6611, 0.3389],
        [0.6548, 0.3452],
        [0.6650, 0.3350],
        [0.6656, 0.3344],
        [0.6662, 0.3338],
        [0.6620, 0.3380],
        [0.6637, 0.3363],
        [0.6603, 0.3397],
        [0.6623, 0.3377],
        [0.6628, 0.3372],
        [0.6657, 0.3343],
        [0.6630, 0.3370],
        [0.6603, 0.3397],
        [0.6627, 0.3373],
        [0.6627, 0.3373],
        [0.6619, 0.3381],
        [0.6644, 0.3356],
        [0.6637, 0.3363],
        [0.6619, 0.3381],
        [0.6608, 0.3392],
        [0.6615, 0.3385],
        [0.6609, 0.3391],
        [0.6621, 0.3379],
        [0.6653, 0.3347],
        [0.6633, 0.3367],
        [0.6609, 0.3391],
        [0.6613, 0.3387],
        [0.6619, 0.3381],
        [0.6620, 0.3380],
        [0.6610, 0.3390],
        [0.6589, 0.3411],
        [0.6648, 0.3352],
        [0.6651, 0.3349],
        [0.6625, 0.3375],
        [0.6632, 0.3368],
        [0.6669, 0.3331],
        [0.6630, 0.3370],
        [0.6667, 0.3333],
        [0.6657, 0.3343],
        [0.6650, 0.3350],
        [0.6659, 0.3341],
        [0.6616, 0.3384],
        [0.6661, 0.3339],
        [0.6636, 0.3364],
        [0.6603, 0.3397],
        [0.6617, 0.3383],
        [0.6632, 0.3368],
        [0.6641, 0.3359],
        [0.6618, 0.3382],
        [0.6639, 0.3361],
        [0.6551, 0.3449],
        [0.6636, 0.3364],
        [0.6623, 0.3377],
        [0.6606, 0.3394],
        [0.6633, 0.3367],
        [0.6615, 0.3385],
        [0.6560, 0.3440],
        [0.6630, 0.3370],
        [0.6612, 0.3388],
        [0.6610, 0.3390],
        [0.6631, 0.3369],
        [0.6622, 0.3378],
        [0.6649, 0.3351],
        [0.6629, 0.3371],
        [0.6599, 0.3401],
        [0.6664, 0.3336],
        [0.6660, 0.3340],
        [0.6611, 0.3389],
        [0.6631, 0.3369],
        [0.6616, 0.3384],
        [0.6635, 0.3365],
        [0.6631, 0.3369],
        [0.6584, 0.3416],
        [0.6637, 0.3363],
        [0.6597, 0.3403],
        [0.6640, 0.3360],
        [0.6675, 0.3325],
        [0.6632, 0.3368],
        [0.6601, 0.3399],
        [0.6604, 0.3396],
        [0.6664, 0.3336],
        [0.6655, 0.3345],
        [0.6664, 0.3336],
        [0.6590, 0.3410],
        [0.6652, 0.3348],
        [0.6633, 0.3367],
        [0.6609, 0.3391],
        [0.6654, 0.3346],
        [0.6652, 0.3348],
        [0.6613, 0.3387],
        [0.6649, 0.3351],
        [0.6626, 0.3374],
        [0.6674, 0.3326],
        [0.6657, 0.3343],
        [0.6632, 0.3368],
        [0.6613, 0.3387],
        [0.6647, 0.3353],
        [0.6602, 0.3398],
        [0.6656, 0.3344],
        [0.6617, 0.3383],
        [0.6628, 0.3372],
        [0.6678, 0.3322],
        [0.6593, 0.3407],
        [0.6640, 0.3360],
        [0.6632, 0.3368],
        [0.6642, 0.3358],
        [0.6611, 0.3389],
        [0.6662, 0.3338],
        [0.6603, 0.3397],
        [0.6644, 0.3356],
        [0.6645, 0.3355],
        [0.6655, 0.3345],
        [0.6541, 0.3459],
        [0.6644, 0.3356],
        [0.6614, 0.3386],
        [0.6628, 0.3372],
        [0.6617, 0.3383],
        [0.6660, 0.3340],
        [0.6672, 0.3328],
        [0.6619, 0.3381],
        [0.6655, 0.3345],
        [0.6670, 0.3330],
        [0.6632, 0.3368],
        [0.6643, 0.3357],
        [0.6617, 0.3383],
        [0.6629, 0.3371],
        [0.6632, 0.3368],
        [0.6617, 0.3383],
        [0.6615, 0.3385],
        [0.6629, 0.3371],
        [0.6645, 0.3355],
        [0.6661, 0.3339],
        [0.6655, 0.3345],
        [0.6634, 0.3366],
        [0.6638, 0.3362],
        [0.6630, 0.3370],
        [0.6620, 0.3380],
        [0.6669, 0.3331],
        [0.6597, 0.3403],
        [0.6669, 0.3331],
        [0.6645, 0.3355],
        [0.6651, 0.3349],
        [0.6634, 0.3366],
        [0.6656, 0.3344],
        [0.6626, 0.3374],
        [0.6655, 0.3345],
        [0.6643, 0.3357],
        [0.6633, 0.3367],
        [0.6659, 0.3341],
        [0.6654, 0.3346],
        [0.6615, 0.3385],
        [0.6634, 0.3366],
        [0.6640, 0.3360],
        [0.6643, 0.3357],
        [0.6627, 0.3373],
        [0.6642, 0.3358],
        [0.6675, 0.3325],
        [0.6655, 0.3345]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0041 loss: 0.6696 acc_train: 0.6103 time: 0.1148s
tensor([[0.6618, 0.3382],
        [0.6634, 0.3366],
        [0.6669, 0.3331],
        [0.6625, 0.3375],
        [0.6658, 0.3342],
        [0.6600, 0.3400],
        [0.6582, 0.3418],
        [0.6609, 0.3391],
        [0.6621, 0.3379],
        [0.6588, 0.3412],
        [0.6649, 0.3351],
        [0.6607, 0.3393],
        [0.6620, 0.3380],
        [0.6620, 0.3380],
        [0.6635, 0.3365],
        [0.6621, 0.3379],
        [0.6636, 0.3364],
        [0.6592, 0.3408],
        [0.6639, 0.3361],
        [0.6595, 0.3405],
        [0.6643, 0.3357],
        [0.6617, 0.3383],
        [0.6640, 0.3360],
        [0.6673, 0.3327],
        [0.6658, 0.3342],
        [0.6621, 0.3379],
        [0.6603, 0.3397],
        [0.6633, 0.3367],
        [0.6610, 0.3390],
        [0.6614, 0.3386],
        [0.6631, 0.3369],
        [0.6615, 0.3385],
        [0.6644, 0.3356],
        [0.6622, 0.3378],
        [0.6625, 0.3375],
        [0.6555, 0.3445],
        [0.6623, 0.3377],
        [0.6621, 0.3379],
        [0.6627, 0.3373],
        [0.6594, 0.3406],
        [0.6641, 0.3359],
        [0.6643, 0.3357],
        [0.6562, 0.3438],
        [0.6618, 0.3382],
        [0.6616, 0.3384],
        [0.6608, 0.3392],
        [0.6663, 0.3337],
        [0.6674, 0.3326],
        [0.6608, 0.3392],
        [0.6625, 0.3375],
        [0.6625, 0.3375],
        [0.6639, 0.3361],
        [0.6634, 0.3366],
        [0.6655, 0.3345],
        [0.6637, 0.3363],
        [0.6641, 0.3359],
        [0.6636, 0.3364],
        [0.6637, 0.3363],
        [0.6602, 0.3398],
        [0.6631, 0.3369],
        [0.6613, 0.3387],
        [0.6620, 0.3380],
        [0.6642, 0.3358],
        [0.6657, 0.3343],
        [0.6603, 0.3397],
        [0.6616, 0.3384],
        [0.6623, 0.3377],
        [0.6630, 0.3370],
        [0.6641, 0.3359],
        [0.6624, 0.3376],
        [0.6615, 0.3385],
        [0.6604, 0.3396],
        [0.6625, 0.3375],
        [0.6624, 0.3376],
        [0.6613, 0.3387],
        [0.6625, 0.3375],
        [0.6646, 0.3354],
        [0.6621, 0.3379],
        [0.6626, 0.3374],
        [0.6610, 0.3390],
        [0.6612, 0.3388],
        [0.6611, 0.3389],
        [0.6618, 0.3382],
        [0.6612, 0.3388],
        [0.6636, 0.3364],
        [0.6601, 0.3399],
        [0.6632, 0.3368],
        [0.6623, 0.3377],
        [0.6599, 0.3401],
        [0.6628, 0.3372],
        [0.6614, 0.3386],
        [0.6614, 0.3386],
        [0.6634, 0.3366],
        [0.6606, 0.3394],
        [0.6602, 0.3398],
        [0.6647, 0.3353],
        [0.6654, 0.3346],
        [0.6622, 0.3378],
        [0.6643, 0.3357],
        [0.6612, 0.3388],
        [0.6612, 0.3388],
        [0.6626, 0.3374],
        [0.6620, 0.3380],
        [0.6589, 0.3411],
        [0.6640, 0.3360],
        [0.6607, 0.3393],
        [0.6643, 0.3357],
        [0.6644, 0.3356],
        [0.6594, 0.3406],
        [0.6616, 0.3384],
        [0.6558, 0.3442],
        [0.6635, 0.3365],
        [0.6646, 0.3354],
        [0.6642, 0.3358],
        [0.6608, 0.3392],
        [0.6548, 0.3452],
        [0.6646, 0.3354],
        [0.6652, 0.3348],
        [0.6657, 0.3343],
        [0.6618, 0.3382],
        [0.6634, 0.3366],
        [0.6602, 0.3398],
        [0.6620, 0.3380],
        [0.6625, 0.3375],
        [0.6651, 0.3349],
        [0.6627, 0.3373],
        [0.6603, 0.3397],
        [0.6622, 0.3378],
        [0.6624, 0.3376],
        [0.6617, 0.3383],
        [0.6640, 0.3360],
        [0.6633, 0.3367],
        [0.6616, 0.3384],
        [0.6607, 0.3393],
        [0.6612, 0.3388],
        [0.6606, 0.3394],
        [0.6618, 0.3382],
        [0.6647, 0.3353],
        [0.6630, 0.3370],
        [0.6608, 0.3392],
        [0.6610, 0.3390],
        [0.6617, 0.3383],
        [0.6618, 0.3382],
        [0.6607, 0.3393],
        [0.6588, 0.3412],
        [0.6644, 0.3356],
        [0.6648, 0.3352],
        [0.6623, 0.3377],
        [0.6627, 0.3373],
        [0.6665, 0.3335],
        [0.6628, 0.3372],
        [0.6663, 0.3337],
        [0.6653, 0.3347],
        [0.6645, 0.3355],
        [0.6654, 0.3346],
        [0.6614, 0.3386],
        [0.6657, 0.3343],
        [0.6632, 0.3368],
        [0.6601, 0.3399],
        [0.6615, 0.3385],
        [0.6629, 0.3371],
        [0.6638, 0.3362],
        [0.6616, 0.3384],
        [0.6635, 0.3365],
        [0.6551, 0.3449],
        [0.6632, 0.3368],
        [0.6619, 0.3381],
        [0.6604, 0.3396],
        [0.6630, 0.3370],
        [0.6614, 0.3386],
        [0.6558, 0.3442],
        [0.6628, 0.3372],
        [0.6610, 0.3390],
        [0.6608, 0.3392],
        [0.6626, 0.3374],
        [0.6618, 0.3382],
        [0.6644, 0.3356],
        [0.6625, 0.3375],
        [0.6598, 0.3402],
        [0.6660, 0.3340],
        [0.6655, 0.3345],
        [0.6608, 0.3392],
        [0.6627, 0.3373],
        [0.6613, 0.3387],
        [0.6630, 0.3370],
        [0.6627, 0.3373],
        [0.6583, 0.3417],
        [0.6633, 0.3367],
        [0.6595, 0.3405],
        [0.6636, 0.3364],
        [0.6669, 0.3331],
        [0.6628, 0.3372],
        [0.6600, 0.3400],
        [0.6603, 0.3397],
        [0.6660, 0.3340],
        [0.6650, 0.3350],
        [0.6658, 0.3342],
        [0.6589, 0.3411],
        [0.6647, 0.3353],
        [0.6629, 0.3371],
        [0.6608, 0.3392],
        [0.6648, 0.3352],
        [0.6647, 0.3353],
        [0.6611, 0.3389],
        [0.6646, 0.3354],
        [0.6623, 0.3377],
        [0.6669, 0.3331],
        [0.6652, 0.3348],
        [0.6629, 0.3371],
        [0.6611, 0.3389],
        [0.6643, 0.3357],
        [0.6600, 0.3400],
        [0.6651, 0.3349],
        [0.6616, 0.3384],
        [0.6625, 0.3375],
        [0.6671, 0.3329],
        [0.6592, 0.3408],
        [0.6637, 0.3363],
        [0.6629, 0.3371],
        [0.6639, 0.3361],
        [0.6609, 0.3391],
        [0.6656, 0.3344],
        [0.6601, 0.3399],
        [0.6641, 0.3359],
        [0.6640, 0.3360],
        [0.6650, 0.3350],
        [0.6542, 0.3458],
        [0.6640, 0.3360],
        [0.6613, 0.3387],
        [0.6624, 0.3376],
        [0.6615, 0.3385],
        [0.6654, 0.3346],
        [0.6666, 0.3334],
        [0.6617, 0.3383],
        [0.6650, 0.3350],
        [0.6665, 0.3335],
        [0.6628, 0.3372],
        [0.6640, 0.3360],
        [0.6615, 0.3385],
        [0.6626, 0.3374],
        [0.6629, 0.3371],
        [0.6615, 0.3385],
        [0.6613, 0.3387],
        [0.6626, 0.3374],
        [0.6641, 0.3359],
        [0.6656, 0.3344],
        [0.6651, 0.3349],
        [0.6630, 0.3370],
        [0.6633, 0.3367],
        [0.6627, 0.3373],
        [0.6618, 0.3382],
        [0.6664, 0.3336],
        [0.6596, 0.3404],
        [0.6664, 0.3336],
        [0.6639, 0.3361],
        [0.6647, 0.3353],
        [0.6630, 0.3370],
        [0.6651, 0.3349],
        [0.6623, 0.3377],
        [0.6650, 0.3350],
        [0.6639, 0.3361],
        [0.6630, 0.3370],
        [0.6655, 0.3345],
        [0.6650, 0.3350],
        [0.6612, 0.3388],
        [0.6631, 0.3369],
        [0.6638, 0.3362],
        [0.6639, 0.3361],
        [0.6623, 0.3377],
        [0.6638, 0.3362],
        [0.6669, 0.3331],
        [0.6650, 0.3350]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0042 loss: 0.6696 acc_train: 0.6103 time: 0.1137s
tensor([[0.6616, 0.3384],
        [0.6630, 0.3370],
        [0.6664, 0.3336],
        [0.6621, 0.3379],
        [0.6653, 0.3347],
        [0.6598, 0.3402],
        [0.6581, 0.3419],
        [0.6606, 0.3394],
        [0.6618, 0.3382],
        [0.6586, 0.3414],
        [0.6645, 0.3355],
        [0.6605, 0.3395],
        [0.6618, 0.3382],
        [0.6618, 0.3382],
        [0.6632, 0.3368],
        [0.6618, 0.3382],
        [0.6632, 0.3368],
        [0.6590, 0.3410],
        [0.6635, 0.3365],
        [0.6593, 0.3407],
        [0.6639, 0.3361],
        [0.6614, 0.3386],
        [0.6635, 0.3365],
        [0.6667, 0.3333],
        [0.6655, 0.3345],
        [0.6617, 0.3383],
        [0.6601, 0.3399],
        [0.6629, 0.3371],
        [0.6608, 0.3392],
        [0.6611, 0.3389],
        [0.6629, 0.3371],
        [0.6613, 0.3387],
        [0.6640, 0.3360],
        [0.6619, 0.3381],
        [0.6623, 0.3377],
        [0.6555, 0.3445],
        [0.6620, 0.3380],
        [0.6618, 0.3382],
        [0.6624, 0.3376],
        [0.6592, 0.3408],
        [0.6639, 0.3361],
        [0.6639, 0.3361],
        [0.6560, 0.3440],
        [0.6614, 0.3386],
        [0.6614, 0.3386],
        [0.6608, 0.3392],
        [0.6658, 0.3342],
        [0.6669, 0.3331],
        [0.6605, 0.3395],
        [0.6622, 0.3378],
        [0.6623, 0.3377],
        [0.6636, 0.3364],
        [0.6631, 0.3369],
        [0.6650, 0.3350],
        [0.6633, 0.3367],
        [0.6637, 0.3363],
        [0.6632, 0.3368],
        [0.6633, 0.3367],
        [0.6599, 0.3401],
        [0.6628, 0.3372],
        [0.6610, 0.3390],
        [0.6618, 0.3382],
        [0.6638, 0.3362],
        [0.6652, 0.3348],
        [0.6601, 0.3399],
        [0.6614, 0.3386],
        [0.6621, 0.3379],
        [0.6628, 0.3372],
        [0.6638, 0.3362],
        [0.6621, 0.3379],
        [0.6613, 0.3387],
        [0.6602, 0.3398],
        [0.6622, 0.3378],
        [0.6621, 0.3379],
        [0.6609, 0.3391],
        [0.6621, 0.3379],
        [0.6642, 0.3358],
        [0.6620, 0.3380],
        [0.6625, 0.3375],
        [0.6609, 0.3391],
        [0.6611, 0.3389],
        [0.6610, 0.3390],
        [0.6616, 0.3384],
        [0.6611, 0.3389],
        [0.6633, 0.3367],
        [0.6598, 0.3402],
        [0.6628, 0.3372],
        [0.6619, 0.3381],
        [0.6597, 0.3403],
        [0.6623, 0.3377],
        [0.6613, 0.3387],
        [0.6611, 0.3389],
        [0.6631, 0.3369],
        [0.6603, 0.3397],
        [0.6601, 0.3399],
        [0.6643, 0.3357],
        [0.6649, 0.3351],
        [0.6618, 0.3382],
        [0.6639, 0.3361],
        [0.6609, 0.3391],
        [0.6609, 0.3391],
        [0.6624, 0.3376],
        [0.6618, 0.3382],
        [0.6588, 0.3412],
        [0.6635, 0.3365],
        [0.6605, 0.3395],
        [0.6639, 0.3361],
        [0.6640, 0.3360],
        [0.6593, 0.3407],
        [0.6613, 0.3387],
        [0.6559, 0.3441],
        [0.6632, 0.3368],
        [0.6641, 0.3359],
        [0.6637, 0.3363],
        [0.6605, 0.3395],
        [0.6549, 0.3451],
        [0.6642, 0.3358],
        [0.6648, 0.3352],
        [0.6653, 0.3347],
        [0.6616, 0.3384],
        [0.6632, 0.3368],
        [0.6600, 0.3400],
        [0.6617, 0.3383],
        [0.6621, 0.3379],
        [0.6646, 0.3354],
        [0.6625, 0.3375],
        [0.6602, 0.3398],
        [0.6619, 0.3381],
        [0.6622, 0.3378],
        [0.6616, 0.3384],
        [0.6636, 0.3364],
        [0.6628, 0.3372],
        [0.6613, 0.3387],
        [0.6606, 0.3394],
        [0.6610, 0.3390],
        [0.6604, 0.3396],
        [0.6616, 0.3384],
        [0.6642, 0.3358],
        [0.6627, 0.3373],
        [0.6607, 0.3393],
        [0.6607, 0.3393],
        [0.6614, 0.3386],
        [0.6615, 0.3385],
        [0.6604, 0.3396],
        [0.6587, 0.3413],
        [0.6640, 0.3360],
        [0.6644, 0.3356],
        [0.6620, 0.3380],
        [0.6623, 0.3377],
        [0.6660, 0.3340],
        [0.6625, 0.3375],
        [0.6659, 0.3341],
        [0.6648, 0.3352],
        [0.6641, 0.3359],
        [0.6651, 0.3349],
        [0.6613, 0.3387],
        [0.6653, 0.3347],
        [0.6627, 0.3373],
        [0.6600, 0.3400],
        [0.6613, 0.3387],
        [0.6625, 0.3375],
        [0.6634, 0.3366],
        [0.6614, 0.3386],
        [0.6631, 0.3369],
        [0.6551, 0.3449],
        [0.6629, 0.3371],
        [0.6615, 0.3385],
        [0.6602, 0.3398],
        [0.6626, 0.3374],
        [0.6612, 0.3388],
        [0.6557, 0.3443],
        [0.6626, 0.3374],
        [0.6609, 0.3391],
        [0.6605, 0.3395],
        [0.6621, 0.3379],
        [0.6614, 0.3386],
        [0.6640, 0.3360],
        [0.6622, 0.3378],
        [0.6596, 0.3404],
        [0.6656, 0.3344],
        [0.6650, 0.3350],
        [0.6606, 0.3394],
        [0.6624, 0.3376],
        [0.6611, 0.3389],
        [0.6625, 0.3375],
        [0.6623, 0.3377],
        [0.6582, 0.3418],
        [0.6630, 0.3370],
        [0.6593, 0.3407],
        [0.6633, 0.3367],
        [0.6662, 0.3338],
        [0.6625, 0.3375],
        [0.6599, 0.3401],
        [0.6602, 0.3398],
        [0.6657, 0.3343],
        [0.6647, 0.3353],
        [0.6652, 0.3348],
        [0.6588, 0.3412],
        [0.6642, 0.3358],
        [0.6625, 0.3375],
        [0.6607, 0.3393],
        [0.6643, 0.3357],
        [0.6643, 0.3357],
        [0.6609, 0.3391],
        [0.6643, 0.3357],
        [0.6620, 0.3380],
        [0.6664, 0.3336],
        [0.6647, 0.3353],
        [0.6626, 0.3374],
        [0.6609, 0.3391],
        [0.6639, 0.3361],
        [0.6598, 0.3402],
        [0.6646, 0.3354],
        [0.6614, 0.3386],
        [0.6621, 0.3379],
        [0.6664, 0.3336],
        [0.6591, 0.3409],
        [0.6634, 0.3366],
        [0.6628, 0.3372],
        [0.6634, 0.3366],
        [0.6607, 0.3393],
        [0.6651, 0.3349],
        [0.6600, 0.3400],
        [0.6638, 0.3362],
        [0.6635, 0.3365],
        [0.6646, 0.3354],
        [0.6543, 0.3457],
        [0.6636, 0.3364],
        [0.6612, 0.3388],
        [0.6621, 0.3379],
        [0.6612, 0.3388],
        [0.6648, 0.3352],
        [0.6660, 0.3340],
        [0.6615, 0.3385],
        [0.6644, 0.3356],
        [0.6660, 0.3340],
        [0.6625, 0.3375],
        [0.6637, 0.3363],
        [0.6612, 0.3388],
        [0.6623, 0.3377],
        [0.6626, 0.3374],
        [0.6613, 0.3387],
        [0.6610, 0.3390],
        [0.6622, 0.3378],
        [0.6636, 0.3364],
        [0.6652, 0.3348],
        [0.6647, 0.3353],
        [0.6627, 0.3373],
        [0.6628, 0.3372],
        [0.6625, 0.3375],
        [0.6615, 0.3385],
        [0.6661, 0.3339],
        [0.6596, 0.3404],
        [0.6660, 0.3340],
        [0.6634, 0.3366],
        [0.6643, 0.3357],
        [0.6626, 0.3374],
        [0.6646, 0.3354],
        [0.6621, 0.3379],
        [0.6646, 0.3354],
        [0.6635, 0.3365],
        [0.6627, 0.3373],
        [0.6651, 0.3349],
        [0.6646, 0.3354],
        [0.6610, 0.3390],
        [0.6628, 0.3372],
        [0.6635, 0.3365],
        [0.6635, 0.3365],
        [0.6620, 0.3380],
        [0.6634, 0.3366],
        [0.6664, 0.3336],
        [0.6646, 0.3354]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0043 loss: 0.6697 acc_train: 0.6103 time: 0.1123s
tensor([[0.6613, 0.3387],
        [0.6626, 0.3374],
        [0.6659, 0.3341],
        [0.6617, 0.3383],
        [0.6648, 0.3352],
        [0.6596, 0.3404],
        [0.6580, 0.3420],
        [0.6602, 0.3398],
        [0.6615, 0.3385],
        [0.6585, 0.3415],
        [0.6641, 0.3359],
        [0.6603, 0.3397],
        [0.6617, 0.3383],
        [0.6616, 0.3384],
        [0.6629, 0.3371],
        [0.6616, 0.3384],
        [0.6628, 0.3372],
        [0.6588, 0.3412],
        [0.6632, 0.3368],
        [0.6592, 0.3408],
        [0.6635, 0.3365],
        [0.6612, 0.3388],
        [0.6631, 0.3369],
        [0.6662, 0.3338],
        [0.6651, 0.3349],
        [0.6614, 0.3386],
        [0.6598, 0.3402],
        [0.6626, 0.3374],
        [0.6606, 0.3394],
        [0.6609, 0.3391],
        [0.6626, 0.3374],
        [0.6612, 0.3388],
        [0.6636, 0.3364],
        [0.6617, 0.3383],
        [0.6621, 0.3379],
        [0.6556, 0.3444],
        [0.6618, 0.3382],
        [0.6616, 0.3384],
        [0.6622, 0.3378],
        [0.6590, 0.3410],
        [0.6636, 0.3364],
        [0.6635, 0.3365],
        [0.6560, 0.3440],
        [0.6611, 0.3389],
        [0.6612, 0.3388],
        [0.6607, 0.3393],
        [0.6653, 0.3347],
        [0.6664, 0.3336],
        [0.6603, 0.3397],
        [0.6619, 0.3381],
        [0.6621, 0.3379],
        [0.6634, 0.3366],
        [0.6629, 0.3371],
        [0.6645, 0.3355],
        [0.6629, 0.3371],
        [0.6634, 0.3366],
        [0.6627, 0.3373],
        [0.6630, 0.3370],
        [0.6597, 0.3403],
        [0.6624, 0.3376],
        [0.6608, 0.3392],
        [0.6617, 0.3383],
        [0.6635, 0.3365],
        [0.6647, 0.3353],
        [0.6600, 0.3400],
        [0.6613, 0.3387],
        [0.6619, 0.3381],
        [0.6626, 0.3374],
        [0.6635, 0.3365],
        [0.6619, 0.3381],
        [0.6611, 0.3389],
        [0.6600, 0.3400],
        [0.6620, 0.3380],
        [0.6618, 0.3382],
        [0.6607, 0.3393],
        [0.6618, 0.3382],
        [0.6639, 0.3361],
        [0.6619, 0.3381],
        [0.6623, 0.3377],
        [0.6607, 0.3393],
        [0.6610, 0.3390],
        [0.6609, 0.3391],
        [0.6614, 0.3386],
        [0.6609, 0.3391],
        [0.6630, 0.3370],
        [0.6595, 0.3405],
        [0.6625, 0.3375],
        [0.6616, 0.3384],
        [0.6596, 0.3404],
        [0.6618, 0.3382],
        [0.6612, 0.3388],
        [0.6609, 0.3391],
        [0.6627, 0.3373],
        [0.6600, 0.3400],
        [0.6600, 0.3400],
        [0.6640, 0.3360],
        [0.6645, 0.3355],
        [0.6615, 0.3385],
        [0.6635, 0.3365],
        [0.6607, 0.3393],
        [0.6606, 0.3394],
        [0.6622, 0.3378],
        [0.6616, 0.3384],
        [0.6587, 0.3413],
        [0.6630, 0.3370],
        [0.6604, 0.3396],
        [0.6636, 0.3364],
        [0.6636, 0.3364],
        [0.6592, 0.3408],
        [0.6609, 0.3391],
        [0.6559, 0.3441],
        [0.6629, 0.3371],
        [0.6637, 0.3363],
        [0.6633, 0.3367],
        [0.6603, 0.3397],
        [0.6551, 0.3449],
        [0.6640, 0.3360],
        [0.6645, 0.3355],
        [0.6648, 0.3352],
        [0.6615, 0.3385],
        [0.6630, 0.3370],
        [0.6598, 0.3402],
        [0.6614, 0.3386],
        [0.6618, 0.3382],
        [0.6642, 0.3358],
        [0.6622, 0.3378],
        [0.6601, 0.3399],
        [0.6615, 0.3385],
        [0.6620, 0.3380],
        [0.6614, 0.3386],
        [0.6634, 0.3366],
        [0.6624, 0.3376],
        [0.6611, 0.3389],
        [0.6605, 0.3395],
        [0.6607, 0.3393],
        [0.6601, 0.3399],
        [0.6614, 0.3386],
        [0.6637, 0.3363],
        [0.6625, 0.3375],
        [0.6605, 0.3395],
        [0.6604, 0.3396],
        [0.6612, 0.3388],
        [0.6612, 0.3388],
        [0.6601, 0.3399],
        [0.6586, 0.3413],
        [0.6638, 0.3362],
        [0.6641, 0.3359],
        [0.6618, 0.3382],
        [0.6619, 0.3381],
        [0.6656, 0.3344],
        [0.6623, 0.3377],
        [0.6656, 0.3344],
        [0.6645, 0.3355],
        [0.6637, 0.3363],
        [0.6647, 0.3353],
        [0.6611, 0.3389],
        [0.6650, 0.3350],
        [0.6622, 0.3378],
        [0.6599, 0.3401],
        [0.6611, 0.3389],
        [0.6622, 0.3378],
        [0.6631, 0.3369],
        [0.6612, 0.3388],
        [0.6627, 0.3373],
        [0.6552, 0.3448],
        [0.6625, 0.3375],
        [0.6612, 0.3388],
        [0.6600, 0.3400],
        [0.6624, 0.3376],
        [0.6611, 0.3389],
        [0.6557, 0.3443],
        [0.6625, 0.3375],
        [0.6608, 0.3392],
        [0.6603, 0.3397],
        [0.6617, 0.3383],
        [0.6610, 0.3390],
        [0.6637, 0.3363],
        [0.6620, 0.3380],
        [0.6594, 0.3406],
        [0.6652, 0.3348],
        [0.6646, 0.3354],
        [0.6603, 0.3397],
        [0.6621, 0.3379],
        [0.6609, 0.3391],
        [0.6621, 0.3379],
        [0.6619, 0.3381],
        [0.6580, 0.3420],
        [0.6627, 0.3373],
        [0.6590, 0.3410],
        [0.6630, 0.3370],
        [0.6655, 0.3345],
        [0.6623, 0.3377],
        [0.6598, 0.3402],
        [0.6601, 0.3399],
        [0.6654, 0.3346],
        [0.6644, 0.3356],
        [0.6647, 0.3353],
        [0.6587, 0.3413],
        [0.6637, 0.3363],
        [0.6622, 0.3378],
        [0.6606, 0.3394],
        [0.6639, 0.3361],
        [0.6639, 0.3361],
        [0.6606, 0.3394],
        [0.6640, 0.3360],
        [0.6618, 0.3382],
        [0.6660, 0.3340],
        [0.6643, 0.3357],
        [0.6624, 0.3376],
        [0.6608, 0.3392],
        [0.6636, 0.3364],
        [0.6596, 0.3404],
        [0.6642, 0.3358],
        [0.6613, 0.3387],
        [0.6619, 0.3381],
        [0.6658, 0.3342],
        [0.6590, 0.3410],
        [0.6631, 0.3369],
        [0.6627, 0.3373],
        [0.6630, 0.3370],
        [0.6606, 0.3394],
        [0.6646, 0.3354],
        [0.6599, 0.3401],
        [0.6634, 0.3366],
        [0.6631, 0.3369],
        [0.6642, 0.3358],
        [0.6544, 0.3456],
        [0.6633, 0.3367],
        [0.6611, 0.3389],
        [0.6618, 0.3382],
        [0.6610, 0.3390],
        [0.6643, 0.3357],
        [0.6655, 0.3345],
        [0.6612, 0.3388],
        [0.6640, 0.3360],
        [0.6655, 0.3345],
        [0.6622, 0.3378],
        [0.6633, 0.3367],
        [0.6609, 0.3391],
        [0.6620, 0.3380],
        [0.6622, 0.3378],
        [0.6612, 0.3388],
        [0.6608, 0.3392],
        [0.6620, 0.3380],
        [0.6631, 0.3369],
        [0.6648, 0.3352],
        [0.6644, 0.3356],
        [0.6625, 0.3375],
        [0.6623, 0.3377],
        [0.6623, 0.3377],
        [0.6612, 0.3388],
        [0.6658, 0.3342],
        [0.6596, 0.3404],
        [0.6657, 0.3343],
        [0.6630, 0.3370],
        [0.6639, 0.3361],
        [0.6622, 0.3378],
        [0.6641, 0.3359],
        [0.6618, 0.3382],
        [0.6642, 0.3358],
        [0.6633, 0.3367],
        [0.6625, 0.3375],
        [0.6647, 0.3353],
        [0.6643, 0.3357],
        [0.6608, 0.3392],
        [0.6624, 0.3376],
        [0.6633, 0.3367],
        [0.6631, 0.3369],
        [0.6617, 0.3383],
        [0.6631, 0.3369],
        [0.6660, 0.3340],
        [0.6643, 0.3357]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0044 loss: 0.6698 acc_train: 0.6103 time: 0.1222s
tensor([[0.6611, 0.3389],
        [0.6622, 0.3378],
        [0.6656, 0.3344],
        [0.6613, 0.3387],
        [0.6644, 0.3356],
        [0.6595, 0.3405],
        [0.6580, 0.3420],
        [0.6600, 0.3400],
        [0.6613, 0.3387],
        [0.6583, 0.3417],
        [0.6639, 0.3361],
        [0.6602, 0.3398],
        [0.6615, 0.3385],
        [0.6615, 0.3385],
        [0.6628, 0.3372],
        [0.6615, 0.3385],
        [0.6625, 0.3375],
        [0.6586, 0.3414],
        [0.6630, 0.3370],
        [0.6590, 0.3410],
        [0.6632, 0.3368],
        [0.6611, 0.3389],
        [0.6627, 0.3373],
        [0.6658, 0.3342],
        [0.6648, 0.3352],
        [0.6611, 0.3389],
        [0.6597, 0.3403],
        [0.6622, 0.3378],
        [0.6604, 0.3396],
        [0.6608, 0.3392],
        [0.6625, 0.3375],
        [0.6610, 0.3390],
        [0.6633, 0.3367],
        [0.6615, 0.3385],
        [0.6621, 0.3379],
        [0.6557, 0.3443],
        [0.6616, 0.3384],
        [0.6614, 0.3386],
        [0.6620, 0.3380],
        [0.6588, 0.3412],
        [0.6635, 0.3365],
        [0.6632, 0.3368],
        [0.6561, 0.3439],
        [0.6608, 0.3392],
        [0.6610, 0.3390],
        [0.6606, 0.3394],
        [0.6649, 0.3351],
        [0.6660, 0.3340],
        [0.6601, 0.3399],
        [0.6617, 0.3383],
        [0.6620, 0.3380],
        [0.6632, 0.3368],
        [0.6627, 0.3373],
        [0.6641, 0.3359],
        [0.6626, 0.3374],
        [0.6631, 0.3369],
        [0.6624, 0.3376],
        [0.6627, 0.3373],
        [0.6596, 0.3404],
        [0.6622, 0.3378],
        [0.6606, 0.3394],
        [0.6617, 0.3383],
        [0.6631, 0.3369],
        [0.6643, 0.3357],
        [0.6599, 0.3401],
        [0.6612, 0.3388],
        [0.6619, 0.3381],
        [0.6624, 0.3376],
        [0.6633, 0.3367],
        [0.6617, 0.3383],
        [0.6610, 0.3390],
        [0.6598, 0.3402],
        [0.6617, 0.3383],
        [0.6617, 0.3383],
        [0.6605, 0.3395],
        [0.6615, 0.3385],
        [0.6637, 0.3363],
        [0.6618, 0.3382],
        [0.6622, 0.3378],
        [0.6606, 0.3394],
        [0.6609, 0.3391],
        [0.6608, 0.3392],
        [0.6613, 0.3387],
        [0.6609, 0.3391],
        [0.6629, 0.3371],
        [0.6593, 0.3407],
        [0.6622, 0.3378],
        [0.6613, 0.3387],
        [0.6594, 0.3406],
        [0.6615, 0.3385],
        [0.6611, 0.3389],
        [0.6608, 0.3392],
        [0.6625, 0.3375],
        [0.6598, 0.3402],
        [0.6601, 0.3399],
        [0.6637, 0.3363],
        [0.6641, 0.3359],
        [0.6612, 0.3388],
        [0.6632, 0.3368],
        [0.6604, 0.3396],
        [0.6603, 0.3397],
        [0.6620, 0.3380],
        [0.6614, 0.3386],
        [0.6586, 0.3414],
        [0.6626, 0.3374],
        [0.6604, 0.3396],
        [0.6634, 0.3366],
        [0.6633, 0.3367],
        [0.6590, 0.3410],
        [0.6606, 0.3394],
        [0.6560, 0.3440],
        [0.6627, 0.3373],
        [0.6633, 0.3367],
        [0.6629, 0.3371],
        [0.6602, 0.3398],
        [0.6553, 0.3447],
        [0.6637, 0.3363],
        [0.6642, 0.3358],
        [0.6644, 0.3356],
        [0.6614, 0.3386],
        [0.6628, 0.3372],
        [0.6595, 0.3405],
        [0.6612, 0.3388],
        [0.6615, 0.3385],
        [0.6638, 0.3362],
        [0.6620, 0.3380],
        [0.6600, 0.3400],
        [0.6612, 0.3388],
        [0.6619, 0.3381],
        [0.6613, 0.3387],
        [0.6632, 0.3368],
        [0.6621, 0.3379],
        [0.6609, 0.3391],
        [0.6605, 0.3395],
        [0.6605, 0.3395],
        [0.6599, 0.3401],
        [0.6613, 0.3387],
        [0.6634, 0.3366],
        [0.6622, 0.3378],
        [0.6604, 0.3396],
        [0.6602, 0.3398],
        [0.6610, 0.3390],
        [0.6609, 0.3391],
        [0.6599, 0.3401],
        [0.6586, 0.3414],
        [0.6636, 0.3364],
        [0.6639, 0.3361],
        [0.6617, 0.3383],
        [0.6616, 0.3384],
        [0.6652, 0.3348],
        [0.6621, 0.3379],
        [0.6652, 0.3348],
        [0.6641, 0.3359],
        [0.6633, 0.3367],
        [0.6644, 0.3356],
        [0.6609, 0.3391],
        [0.6647, 0.3353],
        [0.6618, 0.3382],
        [0.6598, 0.3402],
        [0.6609, 0.3391],
        [0.6619, 0.3381],
        [0.6628, 0.3372],
        [0.6611, 0.3389],
        [0.6624, 0.3376],
        [0.6552, 0.3448],
        [0.6622, 0.3378],
        [0.6609, 0.3391],
        [0.6599, 0.3401],
        [0.6621, 0.3379],
        [0.6610, 0.3390],
        [0.6556, 0.3444],
        [0.6624, 0.3376],
        [0.6608, 0.3392],
        [0.6602, 0.3398],
        [0.6613, 0.3387],
        [0.6608, 0.3392],
        [0.6634, 0.3366],
        [0.6618, 0.3382],
        [0.6593, 0.3407],
        [0.6648, 0.3352],
        [0.6643, 0.3357],
        [0.6601, 0.3399],
        [0.6618, 0.3382],
        [0.6607, 0.3393],
        [0.6618, 0.3382],
        [0.6616, 0.3384],
        [0.6579, 0.3421],
        [0.6625, 0.3375],
        [0.6588, 0.3412],
        [0.6628, 0.3372],
        [0.6650, 0.3350],
        [0.6622, 0.3378],
        [0.6598, 0.3402],
        [0.6600, 0.3400],
        [0.6651, 0.3349],
        [0.6642, 0.3358],
        [0.6643, 0.3357],
        [0.6586, 0.3414],
        [0.6632, 0.3368],
        [0.6619, 0.3381],
        [0.6605, 0.3395],
        [0.6636, 0.3364],
        [0.6635, 0.3365],
        [0.6605, 0.3395],
        [0.6637, 0.3363],
        [0.6616, 0.3384],
        [0.6657, 0.3343],
        [0.6639, 0.3361],
        [0.6622, 0.3378],
        [0.6607, 0.3393],
        [0.6633, 0.3367],
        [0.6595, 0.3405],
        [0.6638, 0.3362],
        [0.6612, 0.3388],
        [0.6617, 0.3383],
        [0.6654, 0.3346],
        [0.6590, 0.3410],
        [0.6629, 0.3371],
        [0.6626, 0.3374],
        [0.6626, 0.3374],
        [0.6605, 0.3395],
        [0.6642, 0.3358],
        [0.6598, 0.3402],
        [0.6631, 0.3369],
        [0.6628, 0.3372],
        [0.6638, 0.3362],
        [0.6546, 0.3454],
        [0.6631, 0.3369],
        [0.6610, 0.3390],
        [0.6615, 0.3385],
        [0.6609, 0.3391],
        [0.6639, 0.3361],
        [0.6651, 0.3349],
        [0.6610, 0.3390],
        [0.6635, 0.3365],
        [0.6652, 0.3348],
        [0.6619, 0.3381],
        [0.6630, 0.3370],
        [0.6606, 0.3394],
        [0.6617, 0.3383],
        [0.6619, 0.3381],
        [0.6611, 0.3389],
        [0.6607, 0.3393],
        [0.6618, 0.3382],
        [0.6627, 0.3373],
        [0.6644, 0.3356],
        [0.6641, 0.3359],
        [0.6623, 0.3377],
        [0.6620, 0.3380],
        [0.6620, 0.3380],
        [0.6609, 0.3391],
        [0.6656, 0.3344],
        [0.6596, 0.3404],
        [0.6655, 0.3345],
        [0.6626, 0.3374],
        [0.6636, 0.3364],
        [0.6619, 0.3381],
        [0.6638, 0.3362],
        [0.6616, 0.3384],
        [0.6639, 0.3361],
        [0.6630, 0.3370],
        [0.6622, 0.3378],
        [0.6645, 0.3355],
        [0.6640, 0.3360],
        [0.6606, 0.3394],
        [0.6621, 0.3379],
        [0.6631, 0.3369],
        [0.6627, 0.3373],
        [0.6615, 0.3385],
        [0.6628, 0.3372],
        [0.6656, 0.3344],
        [0.6640, 0.3360]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0045 loss: 0.6698 acc_train: 0.6103 time: 0.1228s
tensor([[0.6610, 0.3390],
        [0.6619, 0.3381],
        [0.6653, 0.3347],
        [0.6611, 0.3389],
        [0.6641, 0.3359],
        [0.6595, 0.3405],
        [0.6581, 0.3419],
        [0.6598, 0.3402],
        [0.6612, 0.3388],
        [0.6582, 0.3418],
        [0.6637, 0.3363],
        [0.6601, 0.3399],
        [0.6614, 0.3386],
        [0.6614, 0.3386],
        [0.6626, 0.3374],
        [0.6615, 0.3385],
        [0.6623, 0.3377],
        [0.6585, 0.3415],
        [0.6628, 0.3372],
        [0.6589, 0.3411],
        [0.6629, 0.3371],
        [0.6611, 0.3389],
        [0.6624, 0.3376],
        [0.6655, 0.3345],
        [0.6646, 0.3354],
        [0.6608, 0.3392],
        [0.6595, 0.3405],
        [0.6620, 0.3380],
        [0.6603, 0.3397],
        [0.6606, 0.3394],
        [0.6624, 0.3376],
        [0.6608, 0.3392],
        [0.6631, 0.3369],
        [0.6614, 0.3386],
        [0.6620, 0.3380],
        [0.6559, 0.3441],
        [0.6615, 0.3385],
        [0.6612, 0.3388],
        [0.6618, 0.3382],
        [0.6586, 0.3414],
        [0.6634, 0.3366],
        [0.6629, 0.3371],
        [0.6564, 0.3436],
        [0.6606, 0.3394],
        [0.6608, 0.3392],
        [0.6605, 0.3395],
        [0.6646, 0.3354],
        [0.6658, 0.3342],
        [0.6600, 0.3400],
        [0.6614, 0.3386],
        [0.6618, 0.3382],
        [0.6631, 0.3369],
        [0.6625, 0.3375],
        [0.6637, 0.3363],
        [0.6624, 0.3376],
        [0.6629, 0.3371],
        [0.6621, 0.3379],
        [0.6625, 0.3375],
        [0.6595, 0.3405],
        [0.6620, 0.3380],
        [0.6605, 0.3395],
        [0.6617, 0.3383],
        [0.6628, 0.3372],
        [0.6640, 0.3360],
        [0.6599, 0.3401],
        [0.6611, 0.3389],
        [0.6618, 0.3382],
        [0.6622, 0.3378],
        [0.6631, 0.3369],
        [0.6616, 0.3384],
        [0.6609, 0.3391],
        [0.6596, 0.3404],
        [0.6614, 0.3386],
        [0.6616, 0.3384],
        [0.6604, 0.3396],
        [0.6613, 0.3387],
        [0.6634, 0.3366],
        [0.6617, 0.3383],
        [0.6621, 0.3379],
        [0.6605, 0.3395],
        [0.6608, 0.3392],
        [0.6608, 0.3392],
        [0.6612, 0.3388],
        [0.6608, 0.3392],
        [0.6628, 0.3372],
        [0.6592, 0.3408],
        [0.6619, 0.3381],
        [0.6611, 0.3389],
        [0.6593, 0.3407],
        [0.6613, 0.3387],
        [0.6611, 0.3389],
        [0.6607, 0.3393],
        [0.6623, 0.3377],
        [0.6596, 0.3404],
        [0.6602, 0.3398],
        [0.6634, 0.3366],
        [0.6639, 0.3361],
        [0.6609, 0.3391],
        [0.6629, 0.3371],
        [0.6603, 0.3397],
        [0.6602, 0.3398],
        [0.6619, 0.3381],
        [0.6613, 0.3387],
        [0.6585, 0.3415],
        [0.6624, 0.3376],
        [0.6603, 0.3397],
        [0.6632, 0.3368],
        [0.6630, 0.3370],
        [0.6589, 0.3411],
        [0.6603, 0.3397],
        [0.6561, 0.3439],
        [0.6625, 0.3375],
        [0.6630, 0.3370],
        [0.6626, 0.3374],
        [0.6602, 0.3398],
        [0.6555, 0.3445],
        [0.6635, 0.3365],
        [0.6640, 0.3360],
        [0.6640, 0.3360],
        [0.6613, 0.3387],
        [0.6627, 0.3373],
        [0.6593, 0.3407],
        [0.6610, 0.3390],
        [0.6613, 0.3387],
        [0.6636, 0.3364],
        [0.6618, 0.3382],
        [0.6599, 0.3401],
        [0.6610, 0.3390],
        [0.6618, 0.3382],
        [0.6612, 0.3388],
        [0.6631, 0.3369],
        [0.6619, 0.3381],
        [0.6609, 0.3391],
        [0.6604, 0.3396],
        [0.6604, 0.3396],
        [0.6598, 0.3402],
        [0.6612, 0.3388],
        [0.6632, 0.3368],
        [0.6620, 0.3380],
        [0.6602, 0.3398],
        [0.6601, 0.3399],
        [0.6608, 0.3392],
        [0.6606, 0.3394],
        [0.6598, 0.3402],
        [0.6586, 0.3414],
        [0.6635, 0.3365],
        [0.6637, 0.3363],
        [0.6616, 0.3384],
        [0.6615, 0.3385],
        [0.6648, 0.3352],
        [0.6620, 0.3380],
        [0.6649, 0.3351],
        [0.6638, 0.3362],
        [0.6631, 0.3369],
        [0.6642, 0.3358],
        [0.6608, 0.3392],
        [0.6645, 0.3355],
        [0.6615, 0.3385],
        [0.6598, 0.3402],
        [0.6607, 0.3393],
        [0.6617, 0.3383],
        [0.6625, 0.3375],
        [0.6611, 0.3389],
        [0.6622, 0.3378],
        [0.6554, 0.3446],
        [0.6620, 0.3380],
        [0.6607, 0.3393],
        [0.6598, 0.3402],
        [0.6620, 0.3380],
        [0.6609, 0.3391],
        [0.6557, 0.3443],
        [0.6623, 0.3377],
        [0.6608, 0.3392],
        [0.6601, 0.3399],
        [0.6610, 0.3390],
        [0.6606, 0.3394],
        [0.6632, 0.3368],
        [0.6617, 0.3383],
        [0.6592, 0.3408],
        [0.6644, 0.3356],
        [0.6641, 0.3359],
        [0.6599, 0.3401],
        [0.6616, 0.3384],
        [0.6607, 0.3393],
        [0.6615, 0.3385],
        [0.6614, 0.3386],
        [0.6578, 0.3422],
        [0.6623, 0.3377],
        [0.6587, 0.3413],
        [0.6626, 0.3374],
        [0.6645, 0.3355],
        [0.6622, 0.3378],
        [0.6598, 0.3402],
        [0.6599, 0.3401],
        [0.6649, 0.3351],
        [0.6640, 0.3360],
        [0.6640, 0.3360],
        [0.6586, 0.3414],
        [0.6629, 0.3371],
        [0.6617, 0.3383],
        [0.6604, 0.3396],
        [0.6634, 0.3366],
        [0.6633, 0.3367],
        [0.6604, 0.3396],
        [0.6635, 0.3365],
        [0.6615, 0.3385],
        [0.6653, 0.3347],
        [0.6636, 0.3364],
        [0.6621, 0.3379],
        [0.6607, 0.3393],
        [0.6631, 0.3369],
        [0.6593, 0.3407],
        [0.6635, 0.3365],
        [0.6611, 0.3389],
        [0.6615, 0.3385],
        [0.6650, 0.3350],
        [0.6590, 0.3410],
        [0.6626, 0.3374],
        [0.6627, 0.3373],
        [0.6622, 0.3378],
        [0.6604, 0.3396],
        [0.6638, 0.3362],
        [0.6597, 0.3403],
        [0.6629, 0.3371],
        [0.6625, 0.3375],
        [0.6636, 0.3364],
        [0.6547, 0.3453],
        [0.6629, 0.3371],
        [0.6610, 0.3390],
        [0.6612, 0.3388],
        [0.6608, 0.3392],
        [0.6636, 0.3364],
        [0.6648, 0.3352],
        [0.6608, 0.3392],
        [0.6632, 0.3368],
        [0.6649, 0.3351],
        [0.6617, 0.3383],
        [0.6628, 0.3372],
        [0.6604, 0.3396],
        [0.6615, 0.3385],
        [0.6616, 0.3384],
        [0.6611, 0.3389],
        [0.6607, 0.3393],
        [0.6616, 0.3384],
        [0.6623, 0.3377],
        [0.6642, 0.3358],
        [0.6639, 0.3361],
        [0.6623, 0.3377],
        [0.6617, 0.3383],
        [0.6619, 0.3381],
        [0.6606, 0.3394],
        [0.6655, 0.3345],
        [0.6596, 0.3404],
        [0.6653, 0.3347],
        [0.6624, 0.3376],
        [0.6634, 0.3366],
        [0.6617, 0.3383],
        [0.6635, 0.3365],
        [0.6614, 0.3386],
        [0.6636, 0.3364],
        [0.6628, 0.3372],
        [0.6619, 0.3381],
        [0.6643, 0.3357],
        [0.6638, 0.3362],
        [0.6605, 0.3395],
        [0.6618, 0.3382],
        [0.6629, 0.3371],
        [0.6624, 0.3376],
        [0.6613, 0.3387],
        [0.6627, 0.3373],
        [0.6653, 0.3347],
        [0.6638, 0.3362]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0046 loss: 0.6698 acc_train: 0.6103 time: 0.1256s
tensor([[0.6609, 0.3391],
        [0.6617, 0.3383],
        [0.6652, 0.3348],
        [0.6609, 0.3391],
        [0.6640, 0.3360],
        [0.6595, 0.3405],
        [0.6582, 0.3418],
        [0.6597, 0.3403],
        [0.6612, 0.3388],
        [0.6582, 0.3418],
        [0.6636, 0.3364],
        [0.6601, 0.3399],
        [0.6613, 0.3387],
        [0.6614, 0.3386],
        [0.6625, 0.3375],
        [0.6615, 0.3385],
        [0.6621, 0.3379],
        [0.6584, 0.3416],
        [0.6627, 0.3373],
        [0.6589, 0.3411],
        [0.6627, 0.3373],
        [0.6611, 0.3389],
        [0.6622, 0.3378],
        [0.6652, 0.3348],
        [0.6643, 0.3357],
        [0.6607, 0.3393],
        [0.6594, 0.3406],
        [0.6619, 0.3381],
        [0.6602, 0.3398],
        [0.6606, 0.3394],
        [0.6623, 0.3377],
        [0.6607, 0.3393],
        [0.6630, 0.3370],
        [0.6613, 0.3387],
        [0.6620, 0.3380],
        [0.6561, 0.3439],
        [0.6614, 0.3386],
        [0.6611, 0.3389],
        [0.6617, 0.3383],
        [0.6586, 0.3414],
        [0.6634, 0.3366],
        [0.6627, 0.3373],
        [0.6569, 0.3431],
        [0.6605, 0.3395],
        [0.6607, 0.3393],
        [0.6604, 0.3396],
        [0.6643, 0.3357],
        [0.6656, 0.3344],
        [0.6599, 0.3401],
        [0.6612, 0.3388],
        [0.6617, 0.3383],
        [0.6630, 0.3370],
        [0.6625, 0.3375],
        [0.6635, 0.3365],
        [0.6622, 0.3378],
        [0.6628, 0.3372],
        [0.6619, 0.3381],
        [0.6623, 0.3377],
        [0.6596, 0.3404],
        [0.6619, 0.3381],
        [0.6605, 0.3395],
        [0.6618, 0.3382],
        [0.6626, 0.3374],
        [0.6638, 0.3362],
        [0.6599, 0.3401],
        [0.6611, 0.3389],
        [0.6618, 0.3382],
        [0.6620, 0.3380],
        [0.6629, 0.3371],
        [0.6616, 0.3384],
        [0.6609, 0.3391],
        [0.6595, 0.3405],
        [0.6612, 0.3388],
        [0.6616, 0.3384],
        [0.6604, 0.3396],
        [0.6613, 0.3387],
        [0.6632, 0.3368],
        [0.6617, 0.3383],
        [0.6621, 0.3379],
        [0.6604, 0.3396],
        [0.6607, 0.3393],
        [0.6607, 0.3393],
        [0.6612, 0.3388],
        [0.6608, 0.3392],
        [0.6627, 0.3373],
        [0.6592, 0.3408],
        [0.6618, 0.3382],
        [0.6610, 0.3390],
        [0.6592, 0.3408],
        [0.6613, 0.3387],
        [0.6611, 0.3389],
        [0.6607, 0.3393],
        [0.6622, 0.3378],
        [0.6595, 0.3405],
        [0.6603, 0.3397],
        [0.6632, 0.3368],
        [0.6638, 0.3362],
        [0.6607, 0.3393],
        [0.6627, 0.3373],
        [0.6601, 0.3399],
        [0.6601, 0.3399],
        [0.6618, 0.3382],
        [0.6612, 0.3388],
        [0.6584, 0.3416],
        [0.6622, 0.3378],
        [0.6603, 0.3397],
        [0.6631, 0.3369],
        [0.6628, 0.3372],
        [0.6589, 0.3411],
        [0.6601, 0.3399],
        [0.6563, 0.3437],
        [0.6624, 0.3376],
        [0.6627, 0.3373],
        [0.6624, 0.3376],
        [0.6602, 0.3398],
        [0.6558, 0.3442],
        [0.6634, 0.3366],
        [0.6638, 0.3362],
        [0.6637, 0.3363],
        [0.6612, 0.3388],
        [0.6626, 0.3374],
        [0.6592, 0.3408],
        [0.6609, 0.3391],
        [0.6612, 0.3388],
        [0.6634, 0.3366],
        [0.6616, 0.3384],
        [0.6598, 0.3402],
        [0.6609, 0.3391],
        [0.6617, 0.3383],
        [0.6611, 0.3389],
        [0.6630, 0.3370],
        [0.6617, 0.3383],
        [0.6608, 0.3392],
        [0.6603, 0.3397],
        [0.6604, 0.3396],
        [0.6597, 0.3403],
        [0.6611, 0.3389],
        [0.6630, 0.3370],
        [0.6618, 0.3382],
        [0.6600, 0.3400],
        [0.6600, 0.3400],
        [0.6607, 0.3393],
        [0.6605, 0.3395],
        [0.6598, 0.3402],
        [0.6586, 0.3414],
        [0.6634, 0.3366],
        [0.6636, 0.3364],
        [0.6615, 0.3385],
        [0.6614, 0.3386],
        [0.6644, 0.3356],
        [0.6619, 0.3381],
        [0.6647, 0.3353],
        [0.6635, 0.3365],
        [0.6629, 0.3371],
        [0.6640, 0.3360],
        [0.6607, 0.3393],
        [0.6643, 0.3357],
        [0.6613, 0.3387],
        [0.6598, 0.3402],
        [0.6606, 0.3394],
        [0.6615, 0.3385],
        [0.6623, 0.3377],
        [0.6611, 0.3389],
        [0.6621, 0.3379],
        [0.6556, 0.3444],
        [0.6618, 0.3382],
        [0.6606, 0.3394],
        [0.6597, 0.3403],
        [0.6619, 0.3381],
        [0.6608, 0.3392],
        [0.6558, 0.3442],
        [0.6622, 0.3378],
        [0.6608, 0.3392],
        [0.6600, 0.3400],
        [0.6609, 0.3391],
        [0.6605, 0.3395],
        [0.6631, 0.3369],
        [0.6617, 0.3383],
        [0.6591, 0.3409],
        [0.6641, 0.3359],
        [0.6639, 0.3361],
        [0.6598, 0.3402],
        [0.6614, 0.3386],
        [0.6607, 0.3393],
        [0.6613, 0.3387],
        [0.6612, 0.3388],
        [0.6577, 0.3423],
        [0.6623, 0.3377],
        [0.6587, 0.3413],
        [0.6626, 0.3374],
        [0.6642, 0.3358],
        [0.6622, 0.3378],
        [0.6599, 0.3401],
        [0.6598, 0.3402],
        [0.6647, 0.3353],
        [0.6639, 0.3361],
        [0.6637, 0.3363],
        [0.6586, 0.3414],
        [0.6626, 0.3374],
        [0.6616, 0.3384],
        [0.6603, 0.3397],
        [0.6632, 0.3368],
        [0.6632, 0.3368],
        [0.6603, 0.3397],
        [0.6632, 0.3368],
        [0.6614, 0.3386],
        [0.6650, 0.3350],
        [0.6634, 0.3366],
        [0.6620, 0.3380],
        [0.6606, 0.3394],
        [0.6629, 0.3371],
        [0.6592, 0.3408],
        [0.6633, 0.3367],
        [0.6610, 0.3390],
        [0.6614, 0.3386],
        [0.6647, 0.3353],
        [0.6591, 0.3409],
        [0.6624, 0.3376],
        [0.6627, 0.3373],
        [0.6620, 0.3380],
        [0.6603, 0.3397],
        [0.6636, 0.3364],
        [0.6596, 0.3404],
        [0.6626, 0.3374],
        [0.6624, 0.3376],
        [0.6634, 0.3366],
        [0.6549, 0.3451],
        [0.6627, 0.3373],
        [0.6609, 0.3391],
        [0.6610, 0.3390],
        [0.6607, 0.3393],
        [0.6634, 0.3366],
        [0.6645, 0.3355],
        [0.6606, 0.3394],
        [0.6629, 0.3371],
        [0.6647, 0.3353],
        [0.6616, 0.3384],
        [0.6626, 0.3374],
        [0.6603, 0.3397],
        [0.6613, 0.3387],
        [0.6614, 0.3386],
        [0.6610, 0.3390],
        [0.6607, 0.3393],
        [0.6616, 0.3384],
        [0.6621, 0.3379],
        [0.6640, 0.3360],
        [0.6637, 0.3363],
        [0.6622, 0.3378],
        [0.6616, 0.3384],
        [0.6617, 0.3383],
        [0.6605, 0.3395],
        [0.6654, 0.3346],
        [0.6596, 0.3404],
        [0.6651, 0.3349],
        [0.6622, 0.3378],
        [0.6633, 0.3367],
        [0.6615, 0.3385],
        [0.6633, 0.3367],
        [0.6612, 0.3388],
        [0.6634, 0.3366],
        [0.6626, 0.3374],
        [0.6616, 0.3384],
        [0.6642, 0.3358],
        [0.6636, 0.3364],
        [0.6604, 0.3396],
        [0.6616, 0.3384],
        [0.6627, 0.3373],
        [0.6622, 0.3378],
        [0.6611, 0.3389],
        [0.6626, 0.3374],
        [0.6651, 0.3349],
        [0.6635, 0.3365]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0047 loss: 0.6698 acc_train: 0.6103 time: 0.1112s
tensor([[0.6608, 0.3392],
        [0.6616, 0.3384],
        [0.6652, 0.3348],
        [0.6608, 0.3392],
        [0.6639, 0.3361],
        [0.6596, 0.3404],
        [0.6583, 0.3417],
        [0.6596, 0.3404],
        [0.6611, 0.3389],
        [0.6582, 0.3418],
        [0.6636, 0.3364],
        [0.6601, 0.3399],
        [0.6613, 0.3387],
        [0.6615, 0.3385],
        [0.6623, 0.3377],
        [0.6616, 0.3384],
        [0.6620, 0.3380],
        [0.6584, 0.3416],
        [0.6626, 0.3374],
        [0.6589, 0.3411],
        [0.6626, 0.3374],
        [0.6611, 0.3389],
        [0.6620, 0.3380],
        [0.6651, 0.3349],
        [0.6642, 0.3358],
        [0.6605, 0.3395],
        [0.6594, 0.3406],
        [0.6617, 0.3383],
        [0.6602, 0.3398],
        [0.6605, 0.3395],
        [0.6622, 0.3378],
        [0.6606, 0.3394],
        [0.6629, 0.3371],
        [0.6613, 0.3387],
        [0.6619, 0.3381],
        [0.6563, 0.3437],
        [0.6614, 0.3386],
        [0.6610, 0.3390],
        [0.6616, 0.3384],
        [0.6585, 0.3415],
        [0.6634, 0.3366],
        [0.6626, 0.3374],
        [0.6573, 0.3427],
        [0.6604, 0.3396],
        [0.6606, 0.3394],
        [0.6603, 0.3397],
        [0.6641, 0.3359],
        [0.6654, 0.3346],
        [0.6599, 0.3401],
        [0.6610, 0.3390],
        [0.6616, 0.3384],
        [0.6630, 0.3370],
        [0.6624, 0.3376],
        [0.6633, 0.3367],
        [0.6621, 0.3379],
        [0.6627, 0.3373],
        [0.6618, 0.3382],
        [0.6623, 0.3377],
        [0.6596, 0.3404],
        [0.6619, 0.3381],
        [0.6605, 0.3395],
        [0.6618, 0.3382],
        [0.6624, 0.3376],
        [0.6637, 0.3363],
        [0.6599, 0.3401],
        [0.6610, 0.3390],
        [0.6618, 0.3382],
        [0.6619, 0.3381],
        [0.6628, 0.3372],
        [0.6615, 0.3385],
        [0.6609, 0.3391],
        [0.6594, 0.3406],
        [0.6611, 0.3389],
        [0.6617, 0.3383],
        [0.6604, 0.3396],
        [0.6613, 0.3387],
        [0.6630, 0.3370],
        [0.6616, 0.3384],
        [0.6620, 0.3380],
        [0.6604, 0.3396],
        [0.6607, 0.3393],
        [0.6606, 0.3394],
        [0.6612, 0.3388],
        [0.6609, 0.3391],
        [0.6627, 0.3373],
        [0.6592, 0.3408],
        [0.6617, 0.3383],
        [0.6609, 0.3391],
        [0.6592, 0.3408],
        [0.6613, 0.3387],
        [0.6611, 0.3389],
        [0.6607, 0.3393],
        [0.6622, 0.3378],
        [0.6594, 0.3406],
        [0.6604, 0.3396],
        [0.6630, 0.3370],
        [0.6638, 0.3362],
        [0.6606, 0.3394],
        [0.6626, 0.3374],
        [0.6600, 0.3400],
        [0.6600, 0.3400],
        [0.6618, 0.3382],
        [0.6611, 0.3389],
        [0.6584, 0.3416],
        [0.6621, 0.3379],
        [0.6603, 0.3397],
        [0.6631, 0.3369],
        [0.6626, 0.3374],
        [0.6588, 0.3412],
        [0.6600, 0.3400],
        [0.6565, 0.3435],
        [0.6622, 0.3378],
        [0.6626, 0.3374],
        [0.6623, 0.3377],
        [0.6603, 0.3397],
        [0.6561, 0.3439],
        [0.6632, 0.3368],
        [0.6637, 0.3363],
        [0.6635, 0.3365],
        [0.6611, 0.3389],
        [0.6624, 0.3376],
        [0.6591, 0.3409],
        [0.6608, 0.3392],
        [0.6612, 0.3388],
        [0.6634, 0.3366],
        [0.6615, 0.3385],
        [0.6598, 0.3402],
        [0.6608, 0.3392],
        [0.6616, 0.3384],
        [0.6611, 0.3389],
        [0.6629, 0.3371],
        [0.6617, 0.3383],
        [0.6608, 0.3392],
        [0.6602, 0.3398],
        [0.6604, 0.3396],
        [0.6597, 0.3403],
        [0.6611, 0.3389],
        [0.6630, 0.3370],
        [0.6617, 0.3383],
        [0.6599, 0.3401],
        [0.6601, 0.3399],
        [0.6606, 0.3394],
        [0.6604, 0.3396],
        [0.6598, 0.3402],
        [0.6586, 0.3414],
        [0.6634, 0.3366],
        [0.6634, 0.3366],
        [0.6614, 0.3386],
        [0.6614, 0.3386],
        [0.6641, 0.3359],
        [0.6618, 0.3382],
        [0.6645, 0.3355],
        [0.6633, 0.3367],
        [0.6628, 0.3372],
        [0.6638, 0.3362],
        [0.6606, 0.3394],
        [0.6642, 0.3358],
        [0.6612, 0.3388],
        [0.6597, 0.3403],
        [0.6605, 0.3395],
        [0.6614, 0.3386],
        [0.6621, 0.3379],
        [0.6611, 0.3389],
        [0.6620, 0.3380],
        [0.6558, 0.3442],
        [0.6617, 0.3383],
        [0.6605, 0.3395],
        [0.6597, 0.3403],
        [0.6618, 0.3382],
        [0.6607, 0.3393],
        [0.6559, 0.3441],
        [0.6621, 0.3379],
        [0.6608, 0.3392],
        [0.6600, 0.3400],
        [0.6608, 0.3392],
        [0.6604, 0.3396],
        [0.6630, 0.3370],
        [0.6618, 0.3382],
        [0.6591, 0.3409],
        [0.6638, 0.3362],
        [0.6638, 0.3362],
        [0.6597, 0.3403],
        [0.6614, 0.3386],
        [0.6607, 0.3393],
        [0.6612, 0.3388],
        [0.6612, 0.3388],
        [0.6577, 0.3423],
        [0.6622, 0.3378],
        [0.6587, 0.3413],
        [0.6625, 0.3375],
        [0.6640, 0.3360],
        [0.6623, 0.3377],
        [0.6600, 0.3400],
        [0.6598, 0.3402],
        [0.6646, 0.3354],
        [0.6639, 0.3361],
        [0.6636, 0.3364],
        [0.6586, 0.3414],
        [0.6625, 0.3375],
        [0.6615, 0.3385],
        [0.6602, 0.3398],
        [0.6631, 0.3369],
        [0.6631, 0.3369],
        [0.6603, 0.3397],
        [0.6629, 0.3371],
        [0.6613, 0.3387],
        [0.6647, 0.3353],
        [0.6632, 0.3368],
        [0.6620, 0.3380],
        [0.6606, 0.3394],
        [0.6628, 0.3372],
        [0.6591, 0.3409],
        [0.6631, 0.3369],
        [0.6609, 0.3391],
        [0.6614, 0.3386],
        [0.6645, 0.3355],
        [0.6592, 0.3408],
        [0.6622, 0.3378],
        [0.6627, 0.3373],
        [0.6618, 0.3382],
        [0.6603, 0.3397],
        [0.6635, 0.3365],
        [0.6596, 0.3404],
        [0.6624, 0.3376],
        [0.6623, 0.3377],
        [0.6633, 0.3367],
        [0.6550, 0.3450],
        [0.6626, 0.3374],
        [0.6608, 0.3392],
        [0.6609, 0.3391],
        [0.6607, 0.3393],
        [0.6633, 0.3367],
        [0.6643, 0.3357],
        [0.6605, 0.3395],
        [0.6628, 0.3372],
        [0.6646, 0.3354],
        [0.6616, 0.3384],
        [0.6625, 0.3375],
        [0.6602, 0.3398],
        [0.6611, 0.3389],
        [0.6612, 0.3388],
        [0.6610, 0.3390],
        [0.6607, 0.3393],
        [0.6616, 0.3384],
        [0.6619, 0.3381],
        [0.6638, 0.3362],
        [0.6636, 0.3364],
        [0.6622, 0.3378],
        [0.6615, 0.3385],
        [0.6616, 0.3384],
        [0.6604, 0.3396],
        [0.6653, 0.3347],
        [0.6597, 0.3403],
        [0.6650, 0.3350],
        [0.6622, 0.3378],
        [0.6632, 0.3368],
        [0.6614, 0.3386],
        [0.6632, 0.3368],
        [0.6611, 0.3389],
        [0.6632, 0.3368],
        [0.6624, 0.3376],
        [0.6614, 0.3386],
        [0.6640, 0.3360],
        [0.6634, 0.3366],
        [0.6604, 0.3396],
        [0.6614, 0.3386],
        [0.6626, 0.3374],
        [0.6621, 0.3379],
        [0.6610, 0.3390],
        [0.6626, 0.3374],
        [0.6649, 0.3351],
        [0.6634, 0.3366]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0048 loss: 0.6699 acc_train: 0.6103 time: 0.1158s
tensor([[0.6607, 0.3393],
        [0.6616, 0.3384],
        [0.6652, 0.3348],
        [0.6608, 0.3392],
        [0.6638, 0.3362],
        [0.6597, 0.3403],
        [0.6585, 0.3415],
        [0.6596, 0.3404],
        [0.6611, 0.3389],
        [0.6583, 0.3417],
        [0.6635, 0.3365],
        [0.6601, 0.3399],
        [0.6613, 0.3387],
        [0.6616, 0.3384],
        [0.6622, 0.3378],
        [0.6617, 0.3383],
        [0.6620, 0.3380],
        [0.6584, 0.3416],
        [0.6625, 0.3375],
        [0.6590, 0.3410],
        [0.6625, 0.3375],
        [0.6611, 0.3389],
        [0.6620, 0.3380],
        [0.6650, 0.3350],
        [0.6641, 0.3359],
        [0.6605, 0.3395],
        [0.6594, 0.3406],
        [0.6617, 0.3383],
        [0.6602, 0.3398],
        [0.6606, 0.3394],
        [0.6621, 0.3379],
        [0.6605, 0.3395],
        [0.6629, 0.3371],
        [0.6614, 0.3386],
        [0.6619, 0.3381],
        [0.6565, 0.3435],
        [0.6614, 0.3386],
        [0.6609, 0.3391],
        [0.6615, 0.3385],
        [0.6586, 0.3414],
        [0.6634, 0.3366],
        [0.6625, 0.3375],
        [0.6578, 0.3422],
        [0.6604, 0.3396],
        [0.6605, 0.3395],
        [0.6601, 0.3399],
        [0.6639, 0.3361],
        [0.6653, 0.3347],
        [0.6599, 0.3401],
        [0.6609, 0.3391],
        [0.6615, 0.3385],
        [0.6630, 0.3370],
        [0.6624, 0.3376],
        [0.6632, 0.3368],
        [0.6621, 0.3379],
        [0.6626, 0.3374],
        [0.6618, 0.3382],
        [0.6622, 0.3378],
        [0.6597, 0.3403],
        [0.6619, 0.3381],
        [0.6606, 0.3394],
        [0.6618, 0.3382],
        [0.6623, 0.3377],
        [0.6636, 0.3364],
        [0.6599, 0.3401],
        [0.6610, 0.3390],
        [0.6618, 0.3382],
        [0.6618, 0.3382],
        [0.6628, 0.3372],
        [0.6615, 0.3385],
        [0.6609, 0.3391],
        [0.6595, 0.3405],
        [0.6610, 0.3390],
        [0.6618, 0.3382],
        [0.6605, 0.3395],
        [0.6614, 0.3386],
        [0.6628, 0.3372],
        [0.6616, 0.3384],
        [0.6619, 0.3381],
        [0.6604, 0.3396],
        [0.6606, 0.3394],
        [0.6605, 0.3395],
        [0.6612, 0.3388],
        [0.6609, 0.3391],
        [0.6627, 0.3373],
        [0.6593, 0.3407],
        [0.6617, 0.3383],
        [0.6609, 0.3391],
        [0.6592, 0.3408],
        [0.6614, 0.3386],
        [0.6611, 0.3389],
        [0.6607, 0.3393],
        [0.6622, 0.3378],
        [0.6594, 0.3406],
        [0.6605, 0.3395],
        [0.6629, 0.3371],
        [0.6637, 0.3363],
        [0.6605, 0.3395],
        [0.6625, 0.3375],
        [0.6600, 0.3400],
        [0.6600, 0.3400],
        [0.6618, 0.3382],
        [0.6610, 0.3390],
        [0.6584, 0.3416],
        [0.6621, 0.3379],
        [0.6604, 0.3396],
        [0.6631, 0.3369],
        [0.6625, 0.3375],
        [0.6588, 0.3412],
        [0.6600, 0.3400],
        [0.6567, 0.3433],
        [0.6621, 0.3379],
        [0.6625, 0.3375],
        [0.6622, 0.3378],
        [0.6605, 0.3395],
        [0.6564, 0.3436],
        [0.6631, 0.3369],
        [0.6636, 0.3364],
        [0.6633, 0.3367],
        [0.6610, 0.3390],
        [0.6624, 0.3376],
        [0.6591, 0.3409],
        [0.6608, 0.3392],
        [0.6612, 0.3388],
        [0.6634, 0.3366],
        [0.6614, 0.3386],
        [0.6597, 0.3403],
        [0.6608, 0.3392],
        [0.6616, 0.3384],
        [0.6610, 0.3390],
        [0.6629, 0.3371],
        [0.6616, 0.3384],
        [0.6609, 0.3391],
        [0.6602, 0.3398],
        [0.6604, 0.3396],
        [0.6597, 0.3403],
        [0.6610, 0.3390],
        [0.6630, 0.3370],
        [0.6616, 0.3384],
        [0.6598, 0.3402],
        [0.6601, 0.3399],
        [0.6605, 0.3395],
        [0.6604, 0.3396],
        [0.6598, 0.3402],
        [0.6586, 0.3414],
        [0.6634, 0.3366],
        [0.6633, 0.3367],
        [0.6614, 0.3386],
        [0.6613, 0.3387],
        [0.6639, 0.3361],
        [0.6618, 0.3382],
        [0.6643, 0.3357],
        [0.6631, 0.3369],
        [0.6627, 0.3373],
        [0.6637, 0.3363],
        [0.6605, 0.3395],
        [0.6641, 0.3359],
        [0.6612, 0.3388],
        [0.6598, 0.3402],
        [0.6605, 0.3395],
        [0.6614, 0.3386],
        [0.6619, 0.3381],
        [0.6611, 0.3389],
        [0.6620, 0.3380],
        [0.6560, 0.3440],
        [0.6616, 0.3384],
        [0.6605, 0.3395],
        [0.6598, 0.3402],
        [0.6618, 0.3382],
        [0.6607, 0.3393],
        [0.6561, 0.3439],
        [0.6621, 0.3379],
        [0.6608, 0.3392],
        [0.6600, 0.3400],
        [0.6608, 0.3392],
        [0.6604, 0.3396],
        [0.6630, 0.3370],
        [0.6618, 0.3382],
        [0.6591, 0.3409],
        [0.6636, 0.3364],
        [0.6637, 0.3363],
        [0.6597, 0.3403],
        [0.6613, 0.3387],
        [0.6608, 0.3392],
        [0.6612, 0.3388],
        [0.6612, 0.3388],
        [0.6577, 0.3423],
        [0.6622, 0.3378],
        [0.6588, 0.3412],
        [0.6625, 0.3375],
        [0.6639, 0.3361],
        [0.6623, 0.3377],
        [0.6602, 0.3398],
        [0.6598, 0.3402],
        [0.6644, 0.3356],
        [0.6638, 0.3362],
        [0.6636, 0.3364],
        [0.6586, 0.3414],
        [0.6624, 0.3376],
        [0.6615, 0.3385],
        [0.6601, 0.3399],
        [0.6631, 0.3369],
        [0.6631, 0.3369],
        [0.6603, 0.3397],
        [0.6628, 0.3372],
        [0.6612, 0.3388],
        [0.6645, 0.3355],
        [0.6631, 0.3369],
        [0.6620, 0.3380],
        [0.6606, 0.3394],
        [0.6627, 0.3373],
        [0.6591, 0.3409],
        [0.6630, 0.3370],
        [0.6609, 0.3391],
        [0.6614, 0.3386],
        [0.6645, 0.3355],
        [0.6593, 0.3407],
        [0.6621, 0.3379],
        [0.6627, 0.3373],
        [0.6617, 0.3383],
        [0.6602, 0.3398],
        [0.6634, 0.3366],
        [0.6596, 0.3404],
        [0.6623, 0.3377],
        [0.6622, 0.3378],
        [0.6632, 0.3368],
        [0.6552, 0.3448],
        [0.6625, 0.3375],
        [0.6607, 0.3393],
        [0.6608, 0.3392],
        [0.6606, 0.3394],
        [0.6632, 0.3368],
        [0.6642, 0.3358],
        [0.6605, 0.3395],
        [0.6627, 0.3373],
        [0.6645, 0.3355],
        [0.6616, 0.3384],
        [0.6624, 0.3376],
        [0.6601, 0.3399],
        [0.6611, 0.3389],
        [0.6611, 0.3389],
        [0.6610, 0.3390],
        [0.6608, 0.3392],
        [0.6616, 0.3384],
        [0.6618, 0.3382],
        [0.6637, 0.3363],
        [0.6634, 0.3366],
        [0.6622, 0.3378],
        [0.6615, 0.3385],
        [0.6616, 0.3384],
        [0.6604, 0.3396],
        [0.6652, 0.3348],
        [0.6597, 0.3403],
        [0.6649, 0.3351],
        [0.6621, 0.3379],
        [0.6631, 0.3369],
        [0.6614, 0.3386],
        [0.6631, 0.3369],
        [0.6610, 0.3390],
        [0.6631, 0.3369],
        [0.6623, 0.3377],
        [0.6613, 0.3387],
        [0.6639, 0.3361],
        [0.6633, 0.3367],
        [0.6604, 0.3396],
        [0.6614, 0.3386],
        [0.6624, 0.3376],
        [0.6620, 0.3380],
        [0.6609, 0.3391],
        [0.6626, 0.3374],
        [0.6648, 0.3352],
        [0.6632, 0.3368]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0049 loss: 0.6699 acc_train: 0.6103 time: 0.1208s
tensor([[0.6607, 0.3393],
        [0.6617, 0.3383],
        [0.6652, 0.3348],
        [0.6609, 0.3391],
        [0.6639, 0.3361],
        [0.6598, 0.3402],
        [0.6587, 0.3413],
        [0.6597, 0.3403],
        [0.6612, 0.3388],
        [0.6584, 0.3416],
        [0.6635, 0.3365],
        [0.6602, 0.3398],
        [0.6614, 0.3386],
        [0.6617, 0.3383],
        [0.6622, 0.3378],
        [0.6618, 0.3382],
        [0.6621, 0.3379],
        [0.6585, 0.3415],
        [0.6625, 0.3375],
        [0.6591, 0.3409],
        [0.6625, 0.3375],
        [0.6612, 0.3388],
        [0.6621, 0.3379],
        [0.6650, 0.3350],
        [0.6640, 0.3360],
        [0.6606, 0.3394],
        [0.6595, 0.3405],
        [0.6617, 0.3383],
        [0.6603, 0.3397],
        [0.6607, 0.3393],
        [0.6621, 0.3379],
        [0.6606, 0.3394],
        [0.6629, 0.3371],
        [0.6615, 0.3385],
        [0.6620, 0.3380],
        [0.6567, 0.3433],
        [0.6615, 0.3385],
        [0.6610, 0.3390],
        [0.6615, 0.3385],
        [0.6587, 0.3413],
        [0.6634, 0.3366],
        [0.6626, 0.3374],
        [0.6582, 0.3418],
        [0.6605, 0.3395],
        [0.6605, 0.3395],
        [0.6601, 0.3399],
        [0.6639, 0.3361],
        [0.6653, 0.3347],
        [0.6599, 0.3401],
        [0.6609, 0.3391],
        [0.6615, 0.3385],
        [0.6630, 0.3370],
        [0.6624, 0.3376],
        [0.6632, 0.3368],
        [0.6622, 0.3378],
        [0.6626, 0.3374],
        [0.6619, 0.3381],
        [0.6623, 0.3377],
        [0.6598, 0.3402],
        [0.6619, 0.3381],
        [0.6607, 0.3393],
        [0.6618, 0.3382],
        [0.6623, 0.3377],
        [0.6636, 0.3364],
        [0.6600, 0.3400],
        [0.6610, 0.3390],
        [0.6619, 0.3381],
        [0.6618, 0.3382],
        [0.6628, 0.3372],
        [0.6615, 0.3385],
        [0.6609, 0.3391],
        [0.6596, 0.3404],
        [0.6610, 0.3390],
        [0.6619, 0.3381],
        [0.6607, 0.3393],
        [0.6615, 0.3385],
        [0.6627, 0.3373],
        [0.6617, 0.3383],
        [0.6620, 0.3380],
        [0.6606, 0.3394],
        [0.6607, 0.3393],
        [0.6606, 0.3394],
        [0.6612, 0.3388],
        [0.6609, 0.3391],
        [0.6627, 0.3373],
        [0.6595, 0.3405],
        [0.6617, 0.3383],
        [0.6610, 0.3390],
        [0.6593, 0.3407],
        [0.6616, 0.3384],
        [0.6611, 0.3389],
        [0.6608, 0.3392],
        [0.6622, 0.3378],
        [0.6595, 0.3405],
        [0.6607, 0.3393],
        [0.6629, 0.3371],
        [0.6638, 0.3362],
        [0.6606, 0.3394],
        [0.6624, 0.3376],
        [0.6601, 0.3399],
        [0.6601, 0.3399],
        [0.6618, 0.3382],
        [0.6611, 0.3389],
        [0.6585, 0.3415],
        [0.6621, 0.3379],
        [0.6605, 0.3395],
        [0.6631, 0.3369],
        [0.6625, 0.3375],
        [0.6590, 0.3410],
        [0.6601, 0.3399],
        [0.6569, 0.3431],
        [0.6620, 0.3380],
        [0.6625, 0.3375],
        [0.6622, 0.3378],
        [0.6607, 0.3393],
        [0.6567, 0.3433],
        [0.6631, 0.3369],
        [0.6636, 0.3364],
        [0.6632, 0.3368],
        [0.6610, 0.3390],
        [0.6624, 0.3376],
        [0.6592, 0.3408],
        [0.6608, 0.3392],
        [0.6613, 0.3387],
        [0.6634, 0.3366],
        [0.6614, 0.3386],
        [0.6598, 0.3402],
        [0.6608, 0.3392],
        [0.6616, 0.3384],
        [0.6610, 0.3390],
        [0.6629, 0.3371],
        [0.6617, 0.3383],
        [0.6609, 0.3391],
        [0.6602, 0.3398],
        [0.6605, 0.3395],
        [0.6598, 0.3402],
        [0.6610, 0.3390],
        [0.6631, 0.3369],
        [0.6616, 0.3384],
        [0.6599, 0.3401],
        [0.6603, 0.3397],
        [0.6605, 0.3395],
        [0.6605, 0.3395],
        [0.6599, 0.3401],
        [0.6587, 0.3413],
        [0.6634, 0.3366],
        [0.6633, 0.3367],
        [0.6616, 0.3384],
        [0.6614, 0.3386],
        [0.6638, 0.3362],
        [0.6617, 0.3383],
        [0.6642, 0.3358],
        [0.6631, 0.3369],
        [0.6628, 0.3372],
        [0.6636, 0.3364],
        [0.6606, 0.3394],
        [0.6640, 0.3360],
        [0.6614, 0.3386],
        [0.6598, 0.3402],
        [0.6606, 0.3394],
        [0.6614, 0.3386],
        [0.6618, 0.3382],
        [0.6611, 0.3389],
        [0.6622, 0.3378],
        [0.6563, 0.3437],
        [0.6615, 0.3385],
        [0.6606, 0.3394],
        [0.6599, 0.3401],
        [0.6619, 0.3381],
        [0.6607, 0.3393],
        [0.6564, 0.3436],
        [0.6621, 0.3379],
        [0.6609, 0.3391],
        [0.6601, 0.3399],
        [0.6609, 0.3391],
        [0.6605, 0.3395],
        [0.6630, 0.3370],
        [0.6619, 0.3381],
        [0.6593, 0.3407],
        [0.6636, 0.3364],
        [0.6638, 0.3362],
        [0.6599, 0.3401],
        [0.6614, 0.3386],
        [0.6609, 0.3391],
        [0.6613, 0.3387],
        [0.6613, 0.3387],
        [0.6579, 0.3421],
        [0.6623, 0.3377],
        [0.6590, 0.3410],
        [0.6626, 0.3374],
        [0.6639, 0.3361],
        [0.6624, 0.3376],
        [0.6603, 0.3397],
        [0.6599, 0.3401],
        [0.6643, 0.3357],
        [0.6639, 0.3361],
        [0.6636, 0.3364],
        [0.6587, 0.3413],
        [0.6624, 0.3376],
        [0.6616, 0.3384],
        [0.6601, 0.3399],
        [0.6631, 0.3369],
        [0.6631, 0.3369],
        [0.6604, 0.3396],
        [0.6627, 0.3373],
        [0.6612, 0.3388],
        [0.6643, 0.3357],
        [0.6631, 0.3369],
        [0.6620, 0.3380],
        [0.6606, 0.3394],
        [0.6628, 0.3372],
        [0.6592, 0.3408],
        [0.6630, 0.3370],
        [0.6609, 0.3391],
        [0.6615, 0.3385],
        [0.6645, 0.3355],
        [0.6594, 0.3406],
        [0.6621, 0.3379],
        [0.6627, 0.3373],
        [0.6617, 0.3383],
        [0.6602, 0.3398],
        [0.6635, 0.3365],
        [0.6596, 0.3404],
        [0.6623, 0.3377],
        [0.6623, 0.3377],
        [0.6633, 0.3367],
        [0.6555, 0.3445],
        [0.6624, 0.3376],
        [0.6607, 0.3393],
        [0.6608, 0.3392],
        [0.6607, 0.3393],
        [0.6632, 0.3368],
        [0.6642, 0.3358],
        [0.6606, 0.3394],
        [0.6628, 0.3372],
        [0.6644, 0.3356],
        [0.6617, 0.3383],
        [0.6625, 0.3375],
        [0.6601, 0.3399],
        [0.6611, 0.3389],
        [0.6611, 0.3389],
        [0.6610, 0.3390],
        [0.6609, 0.3391],
        [0.6617, 0.3383],
        [0.6619, 0.3381],
        [0.6637, 0.3363],
        [0.6634, 0.3366],
        [0.6623, 0.3377],
        [0.6615, 0.3385],
        [0.6616, 0.3384],
        [0.6604, 0.3396],
        [0.6651, 0.3349],
        [0.6598, 0.3402],
        [0.6648, 0.3352],
        [0.6621, 0.3379],
        [0.6631, 0.3369],
        [0.6615, 0.3385],
        [0.6631, 0.3369],
        [0.6609, 0.3391],
        [0.6630, 0.3370],
        [0.6622, 0.3378],
        [0.6613, 0.3387],
        [0.6639, 0.3361],
        [0.6633, 0.3367],
        [0.6606, 0.3394],
        [0.6614, 0.3386],
        [0.6624, 0.3376],
        [0.6621, 0.3379],
        [0.6610, 0.3390],
        [0.6626, 0.3374],
        [0.6647, 0.3353],
        [0.6632, 0.3368]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0050 loss: 0.6699 acc_train: 0.6103 time: 0.1250s
tensor([[0.6608, 0.3392],
        [0.6618, 0.3382],
        [0.6653, 0.3347],
        [0.6610, 0.3390],
        [0.6639, 0.3361],
        [0.6600, 0.3400],
        [0.6590, 0.3410],
        [0.6599, 0.3401],
        [0.6613, 0.3387],
        [0.6585, 0.3415],
        [0.6636, 0.3364],
        [0.6603, 0.3397],
        [0.6615, 0.3385],
        [0.6618, 0.3382],
        [0.6622, 0.3378],
        [0.6619, 0.3381],
        [0.6622, 0.3378],
        [0.6587, 0.3413],
        [0.6626, 0.3374],
        [0.6593, 0.3407],
        [0.6626, 0.3374],
        [0.6613, 0.3387],
        [0.6622, 0.3378],
        [0.6651, 0.3349],
        [0.6640, 0.3360],
        [0.6608, 0.3392],
        [0.6597, 0.3403],
        [0.6617, 0.3383],
        [0.6604, 0.3396],
        [0.6608, 0.3392],
        [0.6621, 0.3379],
        [0.6607, 0.3393],
        [0.6629, 0.3371],
        [0.6616, 0.3384],
        [0.6620, 0.3380],
        [0.6569, 0.3431],
        [0.6617, 0.3383],
        [0.6611, 0.3389],
        [0.6616, 0.3384],
        [0.6588, 0.3412],
        [0.6634, 0.3366],
        [0.6627, 0.3373],
        [0.6586, 0.3414],
        [0.6607, 0.3393],
        [0.6606, 0.3394],
        [0.6601, 0.3399],
        [0.6638, 0.3362],
        [0.6653, 0.3347],
        [0.6600, 0.3400],
        [0.6610, 0.3390],
        [0.6616, 0.3384],
        [0.6630, 0.3370],
        [0.6625, 0.3375],
        [0.6633, 0.3367],
        [0.6623, 0.3377],
        [0.6626, 0.3374],
        [0.6621, 0.3379],
        [0.6624, 0.3376],
        [0.6600, 0.3400],
        [0.6620, 0.3380],
        [0.6609, 0.3391],
        [0.6618, 0.3382],
        [0.6623, 0.3377],
        [0.6636, 0.3364],
        [0.6601, 0.3399],
        [0.6610, 0.3390],
        [0.6620, 0.3380],
        [0.6619, 0.3381],
        [0.6629, 0.3371],
        [0.6616, 0.3384],
        [0.6610, 0.3390],
        [0.6597, 0.3403],
        [0.6611, 0.3389],
        [0.6620, 0.3380],
        [0.6609, 0.3391],
        [0.6617, 0.3383],
        [0.6627, 0.3373],
        [0.6617, 0.3383],
        [0.6620, 0.3380],
        [0.6607, 0.3393],
        [0.6608, 0.3392],
        [0.6606, 0.3394],
        [0.6613, 0.3387],
        [0.6610, 0.3390],
        [0.6628, 0.3372],
        [0.6597, 0.3403],
        [0.6618, 0.3382],
        [0.6612, 0.3388],
        [0.6595, 0.3405],
        [0.6618, 0.3382],
        [0.6612, 0.3388],
        [0.6608, 0.3392],
        [0.6623, 0.3377],
        [0.6597, 0.3403],
        [0.6608, 0.3392],
        [0.6629, 0.3371],
        [0.6638, 0.3362],
        [0.6608, 0.3392],
        [0.6624, 0.3376],
        [0.6602, 0.3398],
        [0.6602, 0.3398],
        [0.6619, 0.3381],
        [0.6612, 0.3388],
        [0.6586, 0.3414],
        [0.6622, 0.3378],
        [0.6606, 0.3394],
        [0.6631, 0.3369],
        [0.6625, 0.3375],
        [0.6591, 0.3409],
        [0.6602, 0.3398],
        [0.6571, 0.3429],
        [0.6620, 0.3380],
        [0.6626, 0.3374],
        [0.6623, 0.3377],
        [0.6609, 0.3391],
        [0.6570, 0.3430],
        [0.6630, 0.3370],
        [0.6636, 0.3364],
        [0.6632, 0.3368],
        [0.6611, 0.3389],
        [0.6624, 0.3376],
        [0.6594, 0.3406],
        [0.6609, 0.3391],
        [0.6615, 0.3385],
        [0.6635, 0.3365],
        [0.6615, 0.3385],
        [0.6599, 0.3401],
        [0.6610, 0.3390],
        [0.6616, 0.3384],
        [0.6611, 0.3389],
        [0.6629, 0.3371],
        [0.6618, 0.3382],
        [0.6610, 0.3390],
        [0.6603, 0.3397],
        [0.6606, 0.3394],
        [0.6599, 0.3401],
        [0.6611, 0.3389],
        [0.6632, 0.3368],
        [0.6617, 0.3383],
        [0.6599, 0.3401],
        [0.6604, 0.3396],
        [0.6605, 0.3395],
        [0.6607, 0.3393],
        [0.6601, 0.3399],
        [0.6589, 0.3411],
        [0.6635, 0.3365],
        [0.6633, 0.3367],
        [0.6617, 0.3383],
        [0.6614, 0.3386],
        [0.6638, 0.3362],
        [0.6617, 0.3383],
        [0.6642, 0.3358],
        [0.6632, 0.3368],
        [0.6628, 0.3372],
        [0.6636, 0.3364],
        [0.6607, 0.3393],
        [0.6640, 0.3360],
        [0.6616, 0.3384],
        [0.6599, 0.3401],
        [0.6607, 0.3393],
        [0.6615, 0.3385],
        [0.6618, 0.3382],
        [0.6612, 0.3388],
        [0.6623, 0.3377],
        [0.6566, 0.3434],
        [0.6616, 0.3384],
        [0.6607, 0.3393],
        [0.6601, 0.3399],
        [0.6620, 0.3380],
        [0.6608, 0.3392],
        [0.6567, 0.3433],
        [0.6621, 0.3379],
        [0.6609, 0.3391],
        [0.6602, 0.3398],
        [0.6611, 0.3389],
        [0.6606, 0.3394],
        [0.6631, 0.3369],
        [0.6620, 0.3380],
        [0.6594, 0.3406],
        [0.6635, 0.3365],
        [0.6638, 0.3362],
        [0.6601, 0.3399],
        [0.6615, 0.3385],
        [0.6610, 0.3390],
        [0.6615, 0.3385],
        [0.6614, 0.3386],
        [0.6581, 0.3419],
        [0.6624, 0.3376],
        [0.6592, 0.3408],
        [0.6627, 0.3373],
        [0.6640, 0.3360],
        [0.6625, 0.3375],
        [0.6604, 0.3396],
        [0.6600, 0.3400],
        [0.6643, 0.3357],
        [0.6639, 0.3361],
        [0.6637, 0.3363],
        [0.6588, 0.3412],
        [0.6624, 0.3376],
        [0.6618, 0.3382],
        [0.6602, 0.3398],
        [0.6632, 0.3368],
        [0.6632, 0.3368],
        [0.6606, 0.3394],
        [0.6627, 0.3373],
        [0.6613, 0.3387],
        [0.6642, 0.3358],
        [0.6632, 0.3368],
        [0.6621, 0.3379],
        [0.6607, 0.3393],
        [0.6628, 0.3372],
        [0.6593, 0.3407],
        [0.6630, 0.3370],
        [0.6609, 0.3391],
        [0.6616, 0.3384],
        [0.6646, 0.3354],
        [0.6595, 0.3405],
        [0.6621, 0.3379],
        [0.6627, 0.3373],
        [0.6617, 0.3383],
        [0.6602, 0.3398],
        [0.6635, 0.3365],
        [0.6598, 0.3402],
        [0.6623, 0.3377],
        [0.6623, 0.3377],
        [0.6633, 0.3367],
        [0.6558, 0.3442],
        [0.6624, 0.3376],
        [0.6607, 0.3393],
        [0.6610, 0.3390],
        [0.6607, 0.3393],
        [0.6633, 0.3367],
        [0.6642, 0.3358],
        [0.6608, 0.3392],
        [0.6629, 0.3371],
        [0.6644, 0.3356],
        [0.6618, 0.3382],
        [0.6626, 0.3374],
        [0.6601, 0.3399],
        [0.6611, 0.3389],
        [0.6611, 0.3389],
        [0.6610, 0.3390],
        [0.6610, 0.3390],
        [0.6618, 0.3382],
        [0.6619, 0.3381],
        [0.6637, 0.3363],
        [0.6633, 0.3367],
        [0.6624, 0.3376],
        [0.6616, 0.3384],
        [0.6617, 0.3383],
        [0.6605, 0.3395],
        [0.6650, 0.3350],
        [0.6600, 0.3400],
        [0.6648, 0.3352],
        [0.6622, 0.3378],
        [0.6632, 0.3368],
        [0.6615, 0.3385],
        [0.6631, 0.3369],
        [0.6610, 0.3390],
        [0.6630, 0.3370],
        [0.6622, 0.3378],
        [0.6613, 0.3387],
        [0.6638, 0.3362],
        [0.6633, 0.3367],
        [0.6607, 0.3393],
        [0.6614, 0.3386],
        [0.6623, 0.3377],
        [0.6622, 0.3378],
        [0.6611, 0.3389],
        [0.6626, 0.3374],
        [0.6646, 0.3354],
        [0.6632, 0.3368]], device='cuda:7', grad_fn=<IndexBackward0>)
Epoch: 0051 loss: 0.6699 acc_train: 0.6103 time: 0.1271s
[Epoch 50] Loss: 0.66990 Forward: 0.076s Backward: 0.051s Train Accuracy: 61.03 Test Accuracy: 66.18
Training is complete!
(0, tensor(12917, device='cuda:7'))
12917
tensor(indices=tensor([[12917],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  301,   301,   301,  ..., 22447, 22447, 22447],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.4170e-05,  1.2084e-05,  1.6331e-04,  ...,
                       3.1970e-04, -3.2258e-06, -6.3789e-05]),
       size=(22540, 50), nnz=2897, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.3829e-05, -2.0091e-05, -9.7493e-06,  ...,
                       1.7130e-05, -1.2267e-05, -1.1157e-05]),
       size=(22540, 50), nnz=21650, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(1, tensor(21950, device='cuda:7'))
21950
tensor(indices=tensor([[21950],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1004,  1004,  1004,  ..., 22400, 22400, 22400],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.6860e-05, -1.0886e-04,  1.7114e-04,  ...,
                       3.1368e-04, -3.3463e-06, -4.4026e-05]),
       size=(22540, 50), nnz=3019, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4349e-05, -2.0846e-05, -1.0116e-05,  ...,
                       1.7773e-05, -1.2728e-05, -1.1576e-05]),
       size=(22540, 50), nnz=21800, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(2, tensor(3144, device='cuda:7'))
3144
tensor(indices=tensor([[3144],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  888,   888,   888,  ..., 22146, 22146, 22146],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.0950e-05,  1.1505e-05,  4.3568e-04,  ...,
                      -1.4686e-04,  2.3177e-04,  9.6424e-05]),
       size=(22540, 50), nnz=2114, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4647e-05, -2.1279e-05, -1.0326e-05,  ...,
                       1.8143e-05, -1.2993e-05, -1.1817e-05]),
       size=(22540, 50), nnz=20850, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(3, tensor(20225, device='cuda:7'))
20225
tensor(indices=tensor([[20225],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  169,   169,   169,  ..., 22530, 22530, 22530],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 6.5471e-06,  3.2049e-06,  4.5255e-05,  ...,
                       1.3071e-04, -9.7039e-07, -2.5956e-05]),
       size=(22540, 50), nnz=10687, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4271e-05, -2.0732e-05, -1.0060e-05,  ...,
                       1.7677e-05, -1.2659e-05, -1.1513e-05]),
       size=(22540, 50), nnz=30700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(4, tensor(7271, device='cuda:7'))
7271
tensor(indices=tensor([[7271],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  406,   406,   406,  ..., 22441, 22441, 22441],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.5587e-05, -9.2922e-05,  6.9470e-05,  ...,
                       2.5722e-04,  1.5213e-04, -1.3511e-04]),
       size=(22540, 50), nnz=4461, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4984e-05, -2.1768e-05, -1.0563e-05,  ...,
                       1.8560e-05, -1.3291e-05, -1.2088e-05]),
       size=(22540, 50), nnz=23650, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(5, tensor(10768, device='cuda:7'))
10768
tensor(indices=tensor([[10768],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  604,   604,   604,  ..., 21768, 21768, 21768],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.2423e-05,  1.7833e-05,  6.0675e-04,  ...,
                      -2.4259e-04,  1.0297e-04,  3.8735e-05]),
       size=(22540, 50), nnz=1420, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.3731e-05, -1.9948e-05, -9.6802e-06,  ...,
                       1.7009e-05, -1.2181e-05, -1.1078e-05]),
       size=(22540, 50), nnz=19900, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(6, tensor(11934, device='cuda:7'))
11934
tensor(indices=tensor([[11934],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1570,  1570,  1570,  ..., 22510, 22510, 22510],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 3.3247e-05, -1.7734e-04,  2.9361e-04,  ...,
                       2.7125e-04,  1.6271e-04, -9.1779e-05]),
       size=(22540, 50), nnz=1948, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.5030e-05, -2.1835e-05, -1.0596e-05,  ...,
                       1.8617e-05, -1.3332e-05, -1.2125e-05]),
       size=(22540, 50), nnz=20550, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(7, tensor(4336, device='cuda:7'))
4336
tensor(indices=tensor([[4336],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   93,    93,    93,  ..., 22478, 22478, 22478],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 3.7031e-05, -1.0063e-04,  2.6419e-04,  ...,
                       5.3511e-04, -4.8073e-06, -5.3374e-05]),
       size=(22540, 50), nnz=2465, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4164e-05, -2.0577e-05, -9.9850e-06,  ...,
                       1.7544e-05, -1.2564e-05, -1.1426e-05]),
       size=(22540, 50), nnz=21700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(8, tensor(10172, device='cuda:7'))
10172
tensor(indices=tensor([[10172],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  154,   154,   154,  ..., 22502, 22502, 22502],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.8002e-06, -9.0312e-05,  1.4937e-04,  ...,
                       2.9018e-04, -3.3747e-06, -2.4756e-05]),
       size=(22540, 50), nnz=3263, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4951e-05, -2.1720e-05, -1.0540e-05,  ...,
                       1.8519e-05, -1.3262e-05, -1.2061e-05]),
       size=(22540, 50), nnz=21950, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
1
1
(9, tensor(13510, device='cuda:7'))
13510
tensor(indices=tensor([[13510],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   42,    42,    42,  ..., 22429, 22429, 22429],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.6896e-05,  1.2756e-05,  1.8810e-04,  ...,
                       2.6668e-04, -2.2431e-06, -4.2476e-05]),
       size=(22540, 50), nnz=3139, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   42,    42,    42,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-7.2364e-05,  1.9151e-04,  4.2696e-04,  ...,
                       1.7059e-05, -1.2217e-05, -1.1111e-05]),
       size=(22540, 50), nnz=21950, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(10, tensor(19233, device='cuda:7'))
19233
tensor(indices=tensor([[19233],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1667,  1667,  1667,  ..., 21474, 21474, 21474],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 5.4798e-06,  1.5765e-04,  6.3307e-05,  ...,
                      -1.0739e-04,  6.3844e-05,  4.6755e-05]),
       size=(22540, 50), nnz=2944, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.3636e-05, -1.9811e-05, -9.6133e-06,  ...,
                       1.6891e-05, -1.2096e-05, -1.1001e-05]),
       size=(22540, 50), nnz=21650, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(11, tensor(19260, device='cuda:7'))
19260
tensor(indices=tensor([[19260],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  112,   112,   112,  ..., 22455, 22455, 22455],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.3219e-05,  7.8539e-06,  1.2952e-04,  ...,
                       1.8370e-04, -1.6173e-06, -1.1054e-05]),
       size=(22540, 50), nnz=4175, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4521e-05, -2.1096e-05, -1.0237e-05,  ...,
                       1.7987e-05, -1.2881e-05, -1.1715e-05]),
       size=(22540, 50), nnz=23450, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(12, tensor(7860, device='cuda:7'))
7860
tensor(indices=tensor([[7860],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  206,   206,   206,  ..., 22444, 22444, 22444],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.3795e-05,  1.0115e-05,  1.5626e-04,  ...,
                       3.8521e-04, -2.9647e-06, -6.2994e-05]),
       size=(22540, 50), nnz=4696, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4912e-05, -2.1663e-05, -1.0512e-05,  ...,
                       1.8471e-05, -1.3228e-05, -1.2030e-05]),
       size=(22540, 50), nnz=23750, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(13, tensor(9637, device='cuda:7'))
9637
tensor(indices=tensor([[9637],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   16,    16,    16,  ..., 22208, 22208, 22208],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.9922e-05, -1.0744e-04,  1.9660e-04,  ...,
                      -1.4314e-04,  5.1300e-05,  3.6824e-05]),
       size=(22540, 50), nnz=3131, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   16,    16,    16,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 9.9020e-04,  6.0462e-04,  2.4522e-04,  ...,
                       1.8285e-05, -1.3095e-05, -1.1909e-05]),
       size=(22540, 50), nnz=21950, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
2
(14, tensor(7315, device='cuda:7'))
7315
tensor(indices=tensor([[7315],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  135,   135,   135,  ..., 21920, 21920, 21920],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.0368e-05,  4.4813e-04,  1.1797e-04,  ...,
                      -1.5617e-04,  2.8543e-04,  7.4944e-05]),
       size=(22540, 50), nnz=2144, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4136e-05, -2.0536e-05, -9.9654e-06,  ...,
                       1.7510e-05, -1.2539e-05, -1.1404e-05]),
       size=(22540, 50), nnz=21000, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
2
(15, tensor(21185, device='cuda:7'))
21185
tensor(indices=tensor([[21185],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 2547,  2547,  2547,  ..., 22453, 22453, 22453],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.2949e-05,  2.5604e-05,  3.3891e-04,  ...,
                       5.3304e-04, -5.8190e-06, -5.6303e-05]),
       size=(22540, 50), nnz=1623, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4953e-05, -2.1723e-05, -1.0542e-05,  ...,
                       1.8522e-05, -1.3264e-05, -1.2063e-05]),
       size=(22540, 50), nnz=20050, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(16, tensor(9704, device='cuda:7'))
9704
tensor(indices=tensor([[9704],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   44,    44,    44,  ..., 21806, 21806, 21806],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.6870e-05, -1.2364e-04,  1.7256e-04,  ...,
                       6.1560e-04, -4.6733e-06, -9.8797e-05]),
       size=(22540, 50), nnz=2221, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   44,    44,    44,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-5.1599e-03, -2.8795e-02, -4.6961e-03,  ...,
                       1.7700e-05, -1.2676e-05, -1.1528e-05]),
       size=(22540, 50), nnz=21000, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
3
(17, tensor(15542, device='cuda:7'))
15542
tensor(indices=tensor([[15542],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1508,  1508,  1508,  ..., 22413, 22413, 22413],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1790e-05,  3.3859e-04,  9.8409e-05,  ...,
                      -3.9438e-04,  1.9689e-04,  6.8454e-05]),
       size=(22540, 50), nnz=1218, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4575e-05, -2.1174e-05, -1.0275e-05,  ...,
                       1.8054e-05, -1.2929e-05, -1.1758e-05]),
       size=(22540, 50), nnz=19650, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(18, tensor(1543, device='cuda:7'))
1543
tensor(indices=tensor([[1543],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  170,   170,   170,  ..., 22535, 22535, 22535],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1311e-05, -1.1198e-04,  1.0580e-04,  ...,
                       3.8890e-04, -2.7545e-06, -5.3856e-05]),
       size=(22540, 50), nnz=3420, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22535, 22535, 22535],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4266e-05, -2.0726e-05, -1.0057e-05,  ...,
                      -2.0909e-04,  1.9936e-04,  5.0467e-04]),
       size=(22540, 50), nnz=22300, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
3
4
(19, tensor(9956, device='cuda:7'))
9956
tensor(indices=tensor([[9956],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   77,    77,    77,  ..., 22356, 22356, 22356],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.6382e-05,  1.1958e-05,  5.0520e-04,  ...,
                       5.2581e-04, -2.7789e-06, -5.9234e-05]),
       size=(22540, 50), nnz=1944, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.3862e-05, -2.0138e-05, -9.7722e-06,  ...,
                       1.7170e-05, -1.2296e-05, -1.1183e-05]),
       size=(22540, 50), nnz=20800, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(20, tensor(19946, device='cuda:7'))
19946
tensor(indices=tensor([[19946],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  104,   104,   104,  ..., 21864, 21864, 21864],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.6626e-05, -6.8806e-05,  1.2729e-04,  ...,
                      -8.3224e-05,  1.4216e-04,  4.6718e-05]),
       size=(22540, 50), nnz=3655, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.3850e-05, -2.0121e-05, -9.7639e-06,  ...,
                       1.7156e-05, -1.2286e-05, -1.1173e-05]),
       size=(22540, 50), nnz=22700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(21, tensor(2144, device='cuda:7'))
2144
tensor(indices=tensor([[2144],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   29,    29,    29,  ..., 22515, 22515, 22515],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.6926e-05,  1.5553e-05,  1.8925e-04,  ...,
                      -1.2307e-04,  8.1375e-05,  1.8049e-05]),
       size=(22540, 50), nnz=3004, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   29,    29,    29,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 3.4585e-03,  3.8152e-04, -5.7394e-04,  ...,
                       1.8323e-05, -1.3122e-05, -1.1933e-05]),
       size=(22540, 50), nnz=22050, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(22, tensor(17777, device='cuda:7'))
17777
tensor(indices=tensor([[17777],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  977,   977,   977,  ..., 21095, 21095, 21095],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.0871e-05, -1.2108e-04,  2.1751e-04,  ...,
                       7.9824e-04, -8.0433e-06, -1.8581e-04]),
       size=(22540, 50), nnz=1617, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.5027e-05, -2.1831e-05, -1.0594e-05,  ...,
                       1.8613e-05, -1.3330e-05, -1.2123e-05]),
       size=(22540, 50), nnz=20250, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(23, tensor(13745, device='cuda:7'))
13745
tensor(indices=tensor([[13745],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  839,   839,   839,  ..., 22233, 22233, 22233],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.6872e-05,  6.9032e-04,  2.4255e-04,  ...,
                       7.4611e-04, -5.9512e-06, -1.1088e-04]),
       size=(22540, 50), nnz=1616, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4287e-05, -2.0756e-05, -1.0072e-05,  ...,
                       1.7697e-05, -1.2674e-05, -1.1526e-05]),
       size=(22540, 50), nnz=20250, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(24, tensor(5234, device='cuda:7'))
5234
tensor(indices=tensor([[5234],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  397,   397,   397,  ..., 22290, 22290, 22290],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.3837e-05, -1.9793e-04,  3.0869e-04,  ...,
                      -1.4402e-04,  2.5892e-04,  6.8684e-05]),
       size=(22540, 50), nnz=2032, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4146e-05, -2.0551e-05, -9.9728e-06,  ...,
                       1.7523e-05, -1.2549e-05, -1.1412e-05]),
       size=(22540, 50), nnz=20950, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(25, tensor(20943, device='cuda:7'))
20943
tensor(indices=tensor([[20943],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   10,    10,    10,  ..., 22483, 22483, 22483],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.5059e-06,  1.8770e-06,  3.5344e-05,  ...,
                      -2.3442e-05,  1.4465e-05,  6.0725e-06]),
       size=(22540, 50), nnz=15869, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   10,    10,    10,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.5662e-03, -3.6296e-04, -7.3818e-04,  ...,
                       1.8036e-05, -1.2916e-05, -1.1747e-05]),
       size=(22540, 50), nnz=35150, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(26, tensor(3410, device='cuda:7'))
3410
tensor(indices=tensor([[3410],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  160,   160,   160,  ..., 22330, 22330, 22330],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 7.7122e-05,  2.1433e-05,  3.0038e-04,  ...,
                       8.1057e-04, -5.2831e-06, -1.1208e-04]),
       size=(22540, 50), nnz=1847, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.3824e-05, -2.0083e-05, -9.7454e-06,  ...,
                       1.7123e-05, -1.2262e-05, -1.1152e-05]),
       size=(22540, 50), nnz=20500, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(27, tensor(5643, device='cuda:7'))
5643
tensor(indices=tensor([[5643],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  577,   577,   577,  ..., 22279, 22279, 22279],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.9311e-06,  1.4573e-04,  4.9552e-05,  ...,
                       1.5961e-04, -1.7441e-06, -1.7394e-05]),
       size=(22540, 50), nnz=5338, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4499e-05, -2.1063e-05, -1.0221e-05,  ...,
                       1.7959e-05, -1.2861e-05, -1.1697e-05]),
       size=(22540, 50), nnz=24600, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(28, tensor(211, device='cuda:7'))
211
tensor(indices=tensor([[211],
                       [  0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  211,   211,   211,  ..., 22270, 22270, 22270],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 0.0001,  0.0051, -0.0029,  ...,  0.0013,  0.0010,
                      -0.0005]),
       size=(22540, 50), nnz=1327, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4340e-05, -2.0833e-05, -1.0110e-05,  ...,
                       1.7763e-05, -1.2721e-05, -1.1569e-05]),
       size=(22540, 50), nnz=19700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(29, tensor(3969, device='cuda:7'))
3969
tensor(indices=tensor([[3969],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1274,  1274,  1274,  ..., 21527, 21527, 21527],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.9915e-05,  9.4971e-06,  3.0054e-04,  ...,
                      -1.1202e-04,  1.6480e-04,  4.7456e-05]),
       size=(22540, 50), nnz=2743, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.3997e-05, -2.0335e-05, -9.8678e-06,  ...,
                       1.7338e-05, -1.2417e-05, -1.1292e-05]),
       size=(22540, 50), nnz=21500, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(30, tensor(11213, device='cuda:7'))
11213
tensor(indices=tensor([[11213],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[    1,     1,     1,  ..., 22191, 22191, 22191],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.3663e-05, -7.3032e-05,  9.3787e-05,  ...,
                       2.1367e-04, -1.8122e-06, -2.9709e-05]),
       size=(22540, 50), nnz=4493, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[    1,     1,     1,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 3.4976e-04, -7.5796e-04,  1.8964e-05,  ...,
                       1.7019e-05, -1.2188e-05, -1.1084e-05]),
       size=(22540, 50), nnz=23550, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0.0000, 0.0008, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
       grad_fn=<SumBackward1>)
(31, tensor(10620, device='cuda:7'))
10620
tensor(indices=tensor([[10620],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   20,    20,    20,  ..., 22527, 22527, 22527],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.2340e-05, -1.0445e-04,  1.3046e-04,  ...,
                      -1.2180e-04,  1.3757e-04,  6.3025e-05]),
       size=(22540, 50), nnz=2941, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   20,    20,    20,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.1906e-04, -8.8039e-04, -1.0471e-03,  ...,
                       1.8672e-05, -1.3372e-05, -1.2161e-05]),
       size=(22540, 50), nnz=22000, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(32, tensor(11150, device='cuda:7'))
11150
tensor(indices=tensor([[11150],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  410,   410,   410,  ..., 22484, 22484, 22484],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 3.3669e-05, -1.7597e-04,  2.4000e-04,  ...,
                       4.3307e-04,  3.8888e-04, -3.4084e-04]),
       size=(22540, 50), nnz=2091, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4227e-05, -2.0668e-05, -1.0029e-05,  ...,
                       1.7622e-05, -1.2620e-05, -1.1477e-05]),
       size=(22540, 50), nnz=20950, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(33, tensor(10248, device='cuda:7'))
10248
tensor(indices=tensor([[10248],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1484,  1484,  1484,  ..., 22397, 22397, 22397],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 7.6835e-05,  3.4515e-05,  5.0400e-04,  ...,
                       9.2649e-04, -5.7299e-06, -1.5790e-05]),
       size=(22540, 50), nnz=1148, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4008e-05, -2.0350e-05, -9.8750e-06,  ...,
                       1.7351e-05, -1.2426e-05, -1.1301e-05]),
       size=(22540, 50), nnz=19650, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(34, tensor(19890, device='cuda:7'))
19890
tensor(indices=tensor([[19890],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   23,    23,    23,  ..., 22079, 22079, 22079],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 6.5915e-05,  2.4366e-05,  3.7450e-04,  ...,
                      -2.3116e-04,  3.2477e-04,  1.0738e-04]),
       size=(22540, 50), nnz=1466, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   23,    23,    23,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.0817e-03,  1.4540e-03, -1.8794e-03,  ...,
                       1.7458e-05, -1.2503e-05, -1.1371e-05]),
       size=(22540, 50), nnz=20000, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
4
5
(35, tensor(18276, device='cuda:7'))
18276
tensor(indices=tensor([[18276],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1296,  1296,  1296,  ..., 22095, 22095, 22095],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 5.2271e-05, -2.2012e-04,  4.5043e-04,  ...,
                       8.1580e-04, -1.1519e-05, -1.7069e-04]),
       size=(22540, 50), nnz=1502, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4724e-05, -2.1391e-05, -1.0380e-05,  ...,
                       1.8238e-05, -1.3061e-05, -1.1879e-05]),
       size=(22540, 50), nnz=20200, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(36, tensor(1166, device='cuda:7'))
1166
tensor(indices=tensor([[1166],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  593,   593,   593,  ..., 20686, 20686, 20686],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.7967e-05, -1.5204e-04,  2.6563e-04,  ...,
                       4.1444e-04, -4.7246e-06, -2.3667e-05]),
       size=(22540, 50), nnz=2224, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4492e-05, -2.1053e-05, -1.0216e-05,  ...,
                       1.7950e-05, -1.2855e-05, -1.1691e-05]),
       size=(22540, 50), nnz=21000, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(37, tensor(10336, device='cuda:7'))
10336
tensor(indices=tensor([[10336],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  201,   201,   201,  ..., 22311, 22311, 22311],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.1302e-05, -7.4996e-05,  1.7923e-04,  ...,
                       3.1399e-04, -1.4747e-06, -4.7741e-05]),
       size=(22540, 50), nnz=3291, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4086e-05, -2.0464e-05, -9.9302e-06,  ...,
                       1.7448e-05, -1.2495e-05, -1.1364e-05]),
       size=(22540, 50), nnz=22050, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(38, tensor(4256, device='cuda:7'))
4256
tensor(indices=tensor([[4256],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  486,   486,   486,  ..., 20095, 20095, 20095],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 3.7622e-05,  1.2460e-05,  4.0081e-04,  ...,
                       7.2259e-04, -5.2946e-06, -1.3536e-04]),
       size=(22540, 50), nnz=2084, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4111e-05, -2.0500e-05, -9.9479e-06,  ...,
                       1.7479e-05, -1.2517e-05, -1.1384e-05]),
       size=(22540, 50), nnz=21100, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(39, tensor(963, device='cuda:7'))
963
tensor(indices=tensor([[963],
                       [  0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  347,   347,   347,  ..., 21723, 21723, 21723],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 5.0517e-05, -2.4970e-04,  3.3979e-04,  ...,
                       6.8729e-04,  3.9982e-04, -4.0498e-04]),
       size=(22540, 50), nnz=1378, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4890e-05, -2.1632e-05, -1.0497e-05,  ...,
                       1.8444e-05, -1.3209e-05, -1.2013e-05]),
       size=(22540, 50), nnz=19850, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(40, tensor(4369, device='cuda:7'))
4369
tensor(indices=tensor([[4369],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  517,   517,   517,  ..., 22472, 22472, 22472],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.0022e-05,  1.2269e-05,  1.4558e-04,  ...,
                       2.7719e-04, -3.1709e-06, -5.4715e-05]),
       size=(22540, 50), nnz=3415, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4353e-05, -2.0851e-05, -1.0118e-05,  ...,
                       1.7778e-05, -1.2732e-05, -1.1579e-05]),
       size=(22540, 50), nnz=22650, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(41, tensor(6785, device='cuda:7'))
6785
tensor(indices=tensor([[6785],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1074,  1074,  1074,  ..., 22522, 22522, 22522],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 8.7838e-06, -7.7977e-05,  1.3062e-04,  ...,
                       3.0587e-04, -2.5489e-06, -5.2023e-05]),
       size=(22540, 50), nnz=3958, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4706e-05, -2.1364e-05, -1.0367e-05,  ...,
                       1.8216e-05, -1.3045e-05, -1.1864e-05]),
       size=(22540, 50), nnz=23050, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(42, tensor(2579, device='cuda:7'))
2579
tensor(indices=tensor([[2579],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  278,   278,   278,  ..., 21657, 21657, 21657],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.1473e-05,  1.5912e-05,  1.9390e-04,  ...,
                       4.9056e-04, -3.5229e-06, -3.8555e-05]),
       size=(22540, 50), nnz=2891, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.5072e-05, -2.1895e-05, -1.0625e-05,  ...,
                       1.8669e-05, -1.3369e-05, -1.2159e-05]),
       size=(22540, 50), nnz=21700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(43, tensor(17531, device='cuda:7'))
17531
tensor(indices=tensor([[17531],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   91,    91,    91,  ..., 22300, 22300, 22300],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.4474e-05, -6.9204e-05,  1.0008e-04,  ...,
                       2.8378e-04, -1.5366e-06, -2.6479e-05]),
       size=(22540, 50), nnz=4792, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4563e-05, -2.1156e-05, -1.0266e-05,  ...,
                       1.8038e-05, -1.2918e-05, -1.1748e-05]),
       size=(22540, 50), nnz=24200, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(44, tensor(541, device='cuda:7'))
541
tensor(indices=tensor([[541],
                       [  0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  541,   541,   541,  ..., 21195, 21195, 21195],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 0.0001,  0.0062, -0.0034,  ...,  0.0004,  0.0002,
                      -0.0002]),
       size=(22540, 50), nnz=1469, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4372e-05, -2.0879e-05, -1.0132e-05,  ...,
                       1.7802e-05, -1.2749e-05, -1.1594e-05]),
       size=(22540, 50), nnz=20000, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(45, tensor(13333, device='cuda:7'))
13333
tensor(indices=tensor([[13333],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  222,   222,   222,  ..., 22334, 22334, 22334],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.0842e-05,  1.0702e-05,  1.6535e-04,  ...,
                       4.2245e-04, -2.9262e-06, -2.0390e-05]),
       size=(22540, 50), nnz=3609, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4119e-05, -2.0512e-05, -9.9535e-06,  ...,
                       1.7489e-05, -1.2524e-05, -1.1390e-05]),
       size=(22540, 50), nnz=22550, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(46, tensor(19769, device='cuda:7'))
19769
tensor(indices=tensor([[19769],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  848,   848,   848,   848,   848,   848,   848,   848,
                          848,   848,   848,   848,   848,   848,   848,   848,
                          848,   848,   848,   848,   848,   848,   848,   848,
                          848,   848,   848,   848,   848,   848,   848,   848,
                          848,   848,   848,   848,   848,   848,   848,   848,
                          848,   848,   848,   848,   848,   848,   848,   848,
                         3369,  3369,  3369,  3369,  3369,  3369,  3369,  3369,
                         3369,  3369,  3369,  3369,  3369,  3369,  3369,  3369,
                         3369,  3369,  3369,  3369,  3369,  3369,  3369,  3369,
                         3369,  3369,  3369,  3369,  3369,  3369,  3369,  3369,
                         3369,  3369,  3369,  3369,  3369,  3369,  3369,  3369,
                         3369,  3369,  3369,  3369,  3369,  3369,  3369,  4374,
                         4374,  4374,  4374,  4374,  4374,  4374,  4374,  4374,
                         4374,  4374,  4374,  4374,  4374,  4374,  4374,  4374,
                         4374,  4374,  4374,  4374,  4374,  4374,  4374,  4374,
                         4374,  4374,  4374,  4374,  4374,  4374,  4374,  4374,
                         4374,  4374,  4374,  4374,  4374,  4374,  4374,  4374,
                         4374,  4374,  4374,  4374,  4374,  4374,  4374, 13556,
                        13556, 13556, 13556, 13556, 13556, 13556, 13556, 13556,
                        13556, 13556, 13556, 13556, 13556, 13556, 13556, 13556,
                        13556, 13556, 13556, 13556, 13556, 13556, 13556, 13556,
                        13556, 13556, 13556, 13556, 13556, 13556, 13556, 13556,
                        13556, 13556, 13556, 13556, 13556, 13556, 13556, 13556,
                        13556, 13556, 13556, 13556, 13556, 13556, 13556, 15665,
                        15665, 15665, 15665, 15665, 15665, 15665, 15665, 15665,
                        15665, 15665, 15665, 15665, 15665, 15665, 15665, 15665,
                        15665, 15665, 15665, 15665, 15665, 15665, 15665, 15665,
                        15665, 15665, 15665, 15665, 15665, 15665, 15665, 15665,
                        15665, 15665, 15665, 15665, 15665, 15665, 15665, 15665,
                        15665, 15665, 15665, 15665, 15665, 15665, 15665, 17492,
                        17492, 17492, 17492, 17492, 17492, 17492, 17492, 17492,
                        17492, 17492, 17492, 17492, 17492, 17492, 17492, 17492,
                        17492, 17492, 17492, 17492, 17492, 17492, 17492, 17492,
                        17492, 17492, 17492, 17492, 17492, 17492, 17492, 17492,
                        17492, 17492, 17492, 17492, 17492, 17492, 17492, 17492,
                        17492, 17492, 17492, 17492, 17492, 17492, 17492, 17492,
                        19769, 19769, 19769, 19769, 19769, 19769, 19769, 19769,
                        19769, 19769, 19769, 19769, 19769, 19769, 19769, 19769,
                        19769, 19769, 19769, 19769, 19769, 19769, 19769, 19769,
                        19769, 19769, 19769, 19769, 19769, 19769, 19769, 19769,
                        19769, 19769, 19769, 19769, 19769, 19769, 19769, 19769,
                        19769, 19769, 19769, 19769, 19769, 19769, 19769, 20523,
                        20523, 20523, 20523, 20523, 20523, 20523, 20523, 20523,
                        20523, 20523, 20523, 20523, 20523, 20523, 20523, 20523,
                        20523, 20523, 20523, 20523, 20523, 20523, 20523, 20523,
                        20523, 20523, 20523, 20523, 20523, 20523, 20523, 20523,
                        20523, 20523, 20523, 20523, 20523, 20523, 20523, 20523,
                        20523, 20523, 20523, 20523, 20523, 20523, 21110, 21110,
                        21110, 21110, 21110, 21110, 21110, 21110, 21110, 21110,
                        21110, 21110, 21110, 21110, 21110, 21110, 21110, 21110,
                        21110, 21110, 21110, 21110, 21110, 21110, 21110, 21110,
                        21110, 21110, 21110, 21110, 21110, 21110, 21110, 21110,
                        21110, 21110, 21110, 21110, 21110, 21110, 21110, 21110,
                        21110, 21110, 21110, 21110, 21110, 21110, 21110],
                       [    0,     1,     2,     3,     4,     5,     6,     7,
                            8,     9,    10,    11,    12,    13,    14,    15,
                           16,    17,    18,    19,    20,    21,    22,    23,
                           24,    25,    26,    27,    28,    29,    30,    31,
                           32,    33,    34,    36,    37,    38,    39,    41,
                           42,    43,    44,    45,    46,    47,    48,    49,
                            0,     1,     2,     3,     4,     5,     6,     7,
                            8,     9,    10,    11,    12,    13,    14,    15,
                           16,    17,    18,    19,    20,    21,    22,    23,
                           24,    25,    26,    27,    28,    29,    30,    31,
                           32,    33,    34,    35,    37,    38,    39,    41,
                           42,    44,    45,    46,    47,    48,    49,     0,
                            1,     2,     3,     4,     5,     6,     7,     8,
                            9,    10,    11,    12,    13,    14,    15,    16,
                           17,    18,    19,    20,    21,    22,    23,    24,
                           25,    26,    27,    28,    29,    30,    31,    32,
                           33,    34,    35,    36,    37,    38,    39,    41,
                           42,    44,    45,    46,    47,    48,    49,     0,
                            1,     2,     3,     4,     5,     6,     7,     8,
                            9,    10,    11,    12,    13,    14,    15,    16,
                           17,    18,    19,    20,    21,    22,    23,    24,
                           25,    26,    27,    28,    29,    30,    31,    32,
                           33,    34,    35,    36,    37,    38,    39,    41,
                           42,    44,    45,    46,    47,    48,    49,     0,
                            1,     2,     3,     4,     5,     6,     7,     8,
                            9,    10,    12,    13,    14,    15,    16,    17,
                           18,    19,    20,    21,    22,    23,    24,    25,
                           26,    27,    28,    29,    30,    31,    32,    33,
                           34,    35,    36,    37,    38,    39,    41,    42,
                           43,    44,    45,    46,    47,    48,    49,     0,
                            1,     2,     3,     4,     5,     6,     7,     8,
                            9,    10,    11,    12,    13,    14,    15,    16,
                           17,    18,    19,    20,    21,    22,    23,    24,
                           25,    26,    27,    28,    29,    30,    31,    32,
                           33,    34,    35,    36,    37,    38,    39,    41,
                           42,    43,    44,    45,    46,    47,    48,    49,
                            0,     1,     2,     3,     4,     5,     6,     7,
                            8,     9,    10,    11,    12,    13,    14,    15,
                           16,    17,    18,    19,    20,    21,    22,    23,
                           24,    25,    26,    27,    28,    29,    30,    31,
                           32,    33,    34,    36,    37,    38,    39,    41,
                           42,    44,    45,    46,    47,    48,    49,     0,
                            1,     2,     3,     4,     5,     7,     8,     9,
                           10,    11,    12,    13,    14,    15,    16,    17,
                           18,    19,    20,    21,    22,    23,    24,    25,
                           26,    27,    28,    29,    30,    31,    32,    33,
                           34,    35,    36,    37,    38,    39,    41,    42,
                           44,    45,    46,    47,    48,    49,     0,     1,
                            2,     3,     4,     5,     6,     7,     8,     9,
                           10,    11,    12,    13,    14,    15,    16,    17,
                           18,    19,    20,    21,    22,    23,    24,    25,
                           26,    27,    28,    29,    30,    31,    32,    33,
                           34,    35,    36,    37,    38,    39,    41,    42,
                           43,    44,    45,    46,    47,    48,    49]]),
       values=tensor([ 5.0917e-05, -7.4117e-04,  1.1607e-03,  1.1116e-03,
                       4.6696e-04,  1.1857e-03, -2.2309e-06,  6.6148e-03,
                       7.5792e-03,  3.6818e-04,  4.5901e-05, -6.0445e-05,
                       1.5675e-04,  4.2086e-04, -4.2107e-04,  5.4325e-04,
                       2.4760e-04,  1.4520e-03,  1.1051e-03,  1.5595e-03,
                       2.5558e-04,  1.1278e-04,  1.4093e-05, -1.1167e-04,
                       6.1740e-04,  5.4898e-04, -9.6892e-05, -1.2604e-03,
                       3.5824e-03,  2.2626e-03,  1.1811e-03,  3.4176e-04,
                      -1.1134e-03,  1.6783e-03,  2.9870e-03,  3.4323e-05,
                       1.5467e-03, -3.1333e-05,  2.5795e-03,  2.5289e-03,
                       1.3944e-03,  3.7757e-05,  2.0787e-03,  1.9340e-03,
                       4.7678e-04,  3.1690e-03, -2.1418e-05, -7.5355e-04,
                       7.8700e-05, -7.9686e-04,  1.1586e-03,  9.0064e-04,
                       3.8796e-04,  1.0775e-03, -5.1075e-05,  6.1330e-03,
                       7.1896e-03,  6.0581e-04,  8.7041e-05, -1.0568e-04,
                       1.1057e-04,  5.5857e-04, -2.9658e-04,  4.6375e-04,
                       1.4763e-04,  8.3110e-04,  6.5100e-04,  1.2775e-03,
                       2.2668e-04,  1.0489e-04,  1.1824e-05, -8.0763e-05,
                       2.7107e-04,  5.3538e-04, -1.0499e-04, -1.0988e-03,
                       3.0646e-03,  2.0942e-03,  8.5782e-04,  9.8978e-05,
                      -4.4964e-04,  1.4665e-03,  2.3466e-03,  4.0040e-06,
                       1.2751e-03, -3.9020e-05,  1.8480e-03,  2.1892e-03,
                       8.8119e-04,  1.5514e-03,  1.5552e-03,  4.1101e-04,
                       2.6035e-03, -1.6140e-05, -3.3348e-04,  3.4896e-04,
                       1.0637e-04,  2.3577e-03, -4.7110e-06, -4.4859e-04,
                       2.9109e-04, -2.8791e-05,  9.5988e-03,  4.5689e-03,
                       9.2377e-04,  1.0992e-04, -3.1955e-05,  3.1193e-04,
                       9.8693e-04,  1.3681e-03,  1.2403e-03,  1.5862e-03,
                       2.3675e-03,  1.5689e-03, -2.5835e-04,  2.7112e-04,
                       3.2526e-04,  3.0528e-04,  6.2363e-04,  1.8272e-04,
                      -3.4006e-04,  2.2092e-04,  2.0481e-03,  4.5234e-03,
                       2.9791e-03, -3.7914e-04,  2.0447e-04,  9.7196e-04,
                       2.9077e-04,  1.5115e-03, -7.7396e-06,  1.7743e-05,
                       3.1654e-03,  4.9439e-04,  3.1277e-03,  3.7057e-03,
                       1.6982e-03,  8.8264e-04,  9.5826e-04, -1.5918e-04,
                      -1.0684e-03,  9.6905e-04,  3.5678e-04,  2.2914e-04,
                       1.2569e-04,  1.5889e-03, -4.3469e-06, -4.5876e-04,
                       2.4441e-04, -3.4682e-05,  9.0485e-03,  4.7224e-03,
                       9.3831e-04,  6.1350e-05, -1.4632e-05,  2.4928e-04,
                       4.3393e-04,  1.3365e-03,  1.0072e-03,  1.2929e-03,
                       2.4292e-03,  1.6076e-03, -2.6812e-04,  2.2654e-04,
                       3.3849e-04,  3.0821e-04,  4.7156e-04,  1.6151e-04,
                      -2.6679e-04,  3.2279e-04,  1.9327e-03,  3.7391e-03,
                       2.7262e-03, -3.1402e-04,  2.8609e-04,  8.9999e-04,
                       2.1194e-04,  1.4743e-03, -4.2170e-06,  1.4754e-05,
                       2.8045e-03,  4.0812e-04,  2.9627e-03,  3.7494e-03,
                       1.7826e-03,  9.2082e-04,  1.1258e-03, -1.4940e-04,
                      -1.1597e-03,  1.0613e-03,  3.3207e-04,  2.6581e-04,
                       1.0823e-02,  2.2665e-03,  1.5914e-02, -1.5628e-03,
                       9.6351e-03, -1.3981e-04,  3.6896e-02,  4.2869e-02,
                      -5.7899e-04, -2.5622e-04,  6.5558e-03,  2.8476e-03,
                       2.2260e-03,  8.9819e-03, -3.7181e-04,  1.2743e-02,
                       1.6684e-03,  1.1742e-02,  2.8179e-03,  1.9953e-03,
                       5.2285e-04,  7.4566e-04,  6.0519e-03,  4.0109e-03,
                       3.5296e-03,  1.2831e-02,  4.7379e-02,  6.5073e-03,
                       2.7697e-04,  1.0247e-02,  9.2067e-03,  3.6485e-03,
                       5.1921e-03, -1.2455e-04,  6.9839e-05,  1.9981e-02,
                       6.8917e-04,  1.9587e-03,  2.3954e-02,  2.8581e-02,
                       5.0802e-03,  1.4591e-02,  5.4422e-03,  1.4093e-03,
                       2.1127e-02,  1.7495e-03,  5.0351e-03,  3.4516e-04,
                       1.4345e-04,  1.6859e-03, -4.7373e-06, -4.0920e-04,
                       2.7973e-04, -3.4940e-05,  9.5223e-03,  4.9263e-03,
                       9.4849e-04,  1.3310e-04, -4.1465e-05,  3.1769e-04,
                       4.9035e-04,  1.0549e-03,  1.2837e-03,  1.5317e-03,
                       1.6296e-03,  2.0822e-03, -3.1997e-04,  2.4011e-04,
                       3.2150e-04,  2.3256e-04,  3.2520e-04,  1.0971e-04,
                      -3.5730e-04,  2.2087e-04,  1.7975e-03,  4.1946e-03,
                       2.5154e-03, -3.3584e-04,  2.3730e-04,  9.7205e-04,
                       2.5652e-04,  1.6392e-03, -2.5939e-05,  3.9082e-06,
                       2.9170e-03,  5.1911e-04,  2.4683e-03,  3.9562e-03,
                       1.9490e-03,  3.6387e-05,  1.1667e-03,  1.1443e-03,
                      -1.5863e-04, -9.2351e-04,  4.6856e-04,  3.2872e-04,
                       2.0229e-04,  7.4985e-03, -3.7324e-03, -7.3036e-04,
                       1.3008e-03,  7.6601e-03,  1.1739e-05,  4.3890e-02,
                       1.6651e-02,  9.6280e-04,  4.5754e-03,  2.2130e-03,
                      -6.5216e-04, -7.4436e-05, -2.5823e-04,  1.8082e-03,
                       2.5632e-03, -2.6906e-03,  2.4518e-03,  1.2903e-03,
                       1.2461e-03, -7.6290e-04,  3.1381e-03, -2.2582e-04,
                      -1.9790e-04,  1.3180e-02,  5.6805e-03,  2.6847e-03,
                       2.0760e-02,  1.7599e-02, -9.1264e-06,  5.4065e-03,
                       2.0739e-03,  1.4876e-04,  1.9190e-02,  7.5361e-06,
                       4.8545e-03,  1.3658e-03,  5.3855e-03,  1.7900e-02,
                       8.5473e-03,  5.6119e-03,  1.3569e-02,  9.4135e-03,
                       1.3053e-02,  1.3749e-03,  3.1702e-03,  1.0742e-04,
                      -7.7583e-04,  1.1286e-03,  1.4011e-03,  2.4716e-04,
                       1.1516e-03,  6.5341e-03,  6.7603e-03,  2.6127e-04,
                       1.3499e-05, -1.1060e-04,  1.7474e-04,  4.7765e-04,
                      -4.9179e-04,  5.1551e-04,  1.5616e-04,  1.7100e-03,
                       8.7865e-04,  1.1988e-03,  2.6079e-04,  1.6569e-04,
                       1.2692e-05, -1.4556e-04,  3.2822e-04,  6.1041e-04,
                      -1.2496e-04, -1.3235e-03,  3.3970e-03,  1.8813e-03,
                       4.8392e-04,  7.3198e-05, -1.0068e-03,  1.3798e-03,
                       2.7172e-03,  2.5878e-06,  2.4809e-05,  1.3203e-03,
                      -3.1729e-05,  2.1413e-03,  2.2961e-03,  1.2360e-03,
                       1.8828e-03,  1.9869e-03,  3.2071e-04,  2.4223e-03,
                      -2.5463e-05, -3.0878e-04,  9.9653e-05, -7.7191e-04,
                       1.1264e-03,  1.4704e-03,  3.3786e-04,  1.1003e-03,
                      -4.5162e-05,  6.4596e-03,  6.8576e-03,  3.3801e-04,
                       1.8710e-05, -1.1048e-04,  1.5846e-04,  5.5250e-04,
                      -5.3167e-04,  4.5481e-04,  1.6371e-04,  1.6963e-03,
                       8.3076e-04,  1.2274e-03,  2.2549e-04,  2.2505e-04,
                       1.6009e-05, -1.9488e-04,  4.1687e-04,  5.3270e-04,
                      -1.3053e-04, -1.4111e-03,  3.3352e-03,  1.7658e-03,
                       4.4632e-04,  1.0132e-04, -8.4980e-04,  1.4160e-03,
                       2.2561e-03,  7.3072e-06,  1.8375e-05,  1.3887e-03,
                      -3.0498e-05,  2.1191e-03,  2.1747e-03,  1.1940e-03,
                       1.3157e-04,  2.0675e-03,  1.6560e-03,  2.8447e-04,
                       2.3192e-03, -1.8585e-05, -3.7644e-04]),
       size=(22540, 50), nnz=431, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.5839e-05, -2.3010e-05, -1.1166e-05,  ...,
                       1.9619e-05, -1.4050e-05, -1.2778e-05]),
       size=(22540, 50), nnz=18750, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(47, tensor(16980, device='cuda:7'))
16980
tensor(indices=tensor([[16980],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   73,    73,    73,  ..., 22209, 22209, 22209],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 6.5000e-06,  2.3839e-04,  7.4569e-05,  ...,
                       2.9299e-04, -3.0966e-06, -7.1763e-05]),
       size=(22540, 50), nnz=3219, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4388e-05, -2.0903e-05, -1.0143e-05,  ...,
                       1.7822e-05, -1.2763e-05, -1.1608e-05]),
       size=(22540, 50), nnz=22550, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(48, tensor(14021, device='cuda:7'))
14021
tensor(indices=tensor([[14021],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  370,   370,   370,  ..., 22418, 22418, 22418],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 6.0272e-06,  3.3752e-06,  5.2875e-05,  ...,
                      -3.5315e-05,  2.1767e-05,  1.3474e-05]),
       size=(22540, 50), nnz=10547, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4429e-05, -2.0962e-05, -1.0172e-05,  ...,
                       1.7873e-05, -1.2800e-05, -1.1641e-05]),
       size=(22540, 50), nnz=30250, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(49, tensor(9082, device='cuda:7'))
9082
tensor(indices=tensor([[9082],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   94,    94,    94,  ..., 22128, 22128, 22128],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.9993e-05, -9.6296e-05,  1.8698e-04,  ...,
                       3.0028e-04, -3.0753e-06, -8.1735e-05]),
       size=(22540, 50), nnz=3382, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4018e-05, -2.0365e-05, -9.8825e-06,  ...,
                       1.7364e-05, -1.2435e-05, -1.1309e-05]),
       size=(22540, 50), nnz=22700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
5
6
(50, tensor(15956, device='cuda:7'))
15956
tensor(indices=tensor([[15956],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  121,   121,   121,  ..., 21697, 21697, 21697],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.1218e-05,  1.2650e-05,  1.8646e-04,  ...,
                      -1.2499e-04,  9.1947e-05,  2.2442e-05]),
       size=(22540, 50), nnz=2603, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.3927e-05, -2.0233e-05, -9.8182e-06,  ...,
                       1.7251e-05, -1.2354e-05, -1.1236e-05]),
       size=(22540, 50), nnz=21350, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(51, tensor(19216, device='cuda:7'))
19216
tensor(indices=tensor([[19216],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  242,   242,   242,  ..., 22516, 22516, 22516],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 7.8753e-06,  2.4623e-06,  6.7266e-05,  ...,
                      -3.2802e-05,  2.1298e-05,  2.2896e-06]),
       size=(22540, 50), nnz=9596, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4191e-05, -2.0616e-05, -1.0004e-05,  ...,
                       1.7578e-05, -1.2588e-05, -1.1448e-05]),
       size=(22540, 50), nnz=29350, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(52, tensor(18218, device='cuda:7'))
18218
tensor(indices=tensor([[18218],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   38,    38,    38,  ..., 22531, 22531, 22531],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 6.9967e-06, -4.5512e-05,  5.0276e-05,  ...,
                       9.6359e-05, -1.4049e-06, -1.7790e-05]),
       size=(22540, 50), nnz=7525, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   38,    38,    38,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.0935e-04,  1.3506e-03,  3.3861e-03,  ...,
                       1.8880e-05, -1.3520e-05, -1.2296e-05]),
       size=(22540, 50), nnz=26800, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(53, tensor(101, device='cuda:7'))
101
tensor(indices=tensor([[101],
                       [  0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  101,   101,   101,  ..., 22479, 22479, 22479],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.6027e-04,  6.0103e-03, -3.0581e-03,  ...,
                       3.6104e-04, -3.5758e-06, -8.7288e-05]),
       size=(22540, 50), nnz=2437, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4013e-05, -2.0357e-05, -9.8785e-06,  ...,
                       1.7357e-05, -1.2430e-05, -1.1305e-05]),
       size=(22540, 50), nnz=21350, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(54, tensor(5170, device='cuda:7'))
5170
tensor(indices=tensor([[5170],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 1324,  1324,  1324,  ..., 22331, 22331, 22331],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.3929e-05, -2.0127e-04,  4.1489e-04,  ...,
                       8.0666e-04, -6.2500e-06, -4.8425e-05]),
       size=(22540, 50), nnz=1708, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.3803e-05, -2.0053e-05, -9.7307e-06,  ...,
                       1.7097e-05, -1.2244e-05, -1.1135e-05]),
       size=(22540, 50), nnz=20450, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(55, tensor(6744, device='cuda:7'))
6744
tensor(indices=tensor([[6744],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  539,   539,   539,  ..., 22480, 22480, 22480],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 3.7681e-05,  1.7163e-05,  3.9917e-04,  ...,
                       3.4310e-04,  3.5134e-04, -1.6821e-04]),
       size=(22540, 50), nnz=1993, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4203e-05, -2.0633e-05, -1.0012e-05,  ...,
                       1.7592e-05, -1.2599e-05, -1.1458e-05]),
       size=(22540, 50), nnz=20750, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(56, tensor(10582, device='cuda:7'))
10582
tensor(indices=tensor([[10582],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  337,   337,   337,  ..., 22391, 22391, 22391],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.4036e-05, -4.6096e-05,  1.1440e-04,  ...,
                       2.3155e-04, -2.0445e-06, -5.9717e-05]),
       size=(22540, 50), nnz=4870, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4580e-05, -2.1182e-05, -1.0279e-05,  ...,
                       1.8060e-05, -1.2934e-05, -1.1763e-05]),
       size=(22540, 50), nnz=24200, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
7
(57, tensor(7417, device='cuda:7'))
7417
tensor(indices=tensor([[7417],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  349,   349,   349,  ..., 21585, 21585, 21585],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.2340e-05, -1.7635e-04,  2.3983e-04,  ...,
                      -1.7814e-04,  2.2400e-04,  7.7350e-05]),
       size=(22540, 50), nnz=2331, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4623e-05, -2.1243e-05, -1.0309e-05,  ...,
                       1.8113e-05, -1.2971e-05, -1.1797e-05]),
       size=(22540, 50), nnz=21300, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(58, tensor(15108, device='cuda:7'))
15108
tensor(indices=tensor([[15108],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  905,   905,   905,  ..., 21522, 21522, 21522],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.1716e-05,  1.6064e-05,  2.0738e-04,  ...,
                       4.3732e-04,  5.1781e-04, -1.0715e-04]),
       size=(22540, 50), nnz=2180, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4189e-05, -2.0614e-05, -1.0003e-05,  ...,
                       1.7576e-05, -1.2587e-05, -1.1447e-05]),
       size=(22540, 50), nnz=20900, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(59, tensor(22241, device='cuda:7'))
22241
tensor(indices=tensor([[22241],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  340,   340,   340,  ..., 22488, 22488, 22488],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.9125e-05, -6.6399e-05,  1.2191e-04,  ...,
                       1.9626e-04, -2.0093e-06, -2.3186e-05]),
       size=(22540, 50), nnz=4413, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4780e-05, -2.1472e-05, -1.0419e-05,  ...,
                       1.8307e-05, -1.3111e-05, -1.1924e-05]),
       size=(22540, 50), nnz=23350, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
8
(60, tensor(21863, device='cuda:7'))
21863
tensor(indices=tensor([[21863],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   49,    49,    49,  ..., 22495, 22495, 22495],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 6.4569e-05, -3.6967e-04,  6.6676e-04,  ...,
                       9.9627e-04, -9.5797e-06, -2.7648e-04]),
       size=(22540, 50), nnz=1104, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   49,    49,    49,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-4.2710e-05, -1.5806e-03,  1.7451e-04,  ...,
                       1.7480e-05, -1.2518e-05, -1.1385e-05]),
       size=(22540, 50), nnz=19550, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(61, tensor(2846, device='cuda:7'))
2846
tensor(indices=tensor([[2846],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  645,   645,   645,  ..., 22102, 22102, 22102],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.6467e-05, -1.2738e-04,  2.7835e-04,  ...,
                      -1.9794e-04,  2.7785e-04,  2.4243e-05]),
       size=(22540, 50), nnz=1822, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4275e-05, -2.0739e-05, -1.0064e-05,  ...,
                       1.7682e-05, -1.2663e-05, -1.1517e-05]),
       size=(22540, 50), nnz=20550, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
6
(62, tensor(6607, device='cuda:7'))
6607
tensor(indices=tensor([[6607],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  285,   285,   285,  ..., 22448, 22448, 22448],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.3938e-05,  6.2575e-06,  1.9917e-04,  ...,
                       1.8867e-04, -1.8809e-06, -5.1273e-05]),
       size=(22540, 50), nnz=4193, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4077e-05, -2.0451e-05, -9.9240e-06,  ...,
                       1.7437e-05, -1.2487e-05, -1.1357e-05]),
       size=(22540, 50), nnz=23350, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(63, tensor(22189, device='cuda:7'))
22189
tensor(indices=tensor([[22189],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  840,   840,   840,  ..., 22189, 22189, 22189],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([1.3918e-05, 6.9807e-06, 1.9062e-04,  ...,
                      1.2898e-02, 1.3784e-03, 2.4327e-03]),
       size=(22540, 50), nnz=4150, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   25,    25,    25,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1359e-03,  5.1047e-04, -1.1514e-04,  ...,
                       1.7982e-05, -1.2878e-05, -1.1712e-05]),
       size=(22540, 50), nnz=23200, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(64, tensor(8783, device='cuda:7'))
8783
tensor(indices=tensor([[8783],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   26,    26,    26,  ..., 22463, 22463, 22463],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.9120e-05,  8.6039e-06,  2.0367e-04,  ...,
                      -9.7454e-05,  5.0474e-05,  1.7633e-05]),
       size=(22540, 50), nnz=3349, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   26,    26,    26,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.9211e-03, -1.1370e-04, -6.3943e-05,  ...,
                       1.7114e-05, -1.2256e-05, -1.1146e-05]),
       size=(22540, 50), nnz=22350, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(65, tensor(9376, device='cuda:7'))
9376
tensor(indices=tensor([[9376],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  745,   745,   745,  ..., 22492, 22492, 22492],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.0155e-05,  8.1170e-06,  2.0097e-04,  ...,
                       2.7330e-04,  1.6423e-04, -1.9973e-04]),
       size=(22540, 50), nnz=3629, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4851e-05, -2.1574e-05, -1.0469e-05,  ...,
                       1.8395e-05, -1.3173e-05, -1.1981e-05]),
       size=(22540, 50), nnz=22650, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(66, tensor(12544, device='cuda:7'))
12544
tensor(indices=tensor([[12544],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  799,   799,   799,  ..., 22462, 22462, 22462],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.5067e-05, -9.8253e-05,  2.0324e-04,  ...,
                       3.7583e-04, -4.6833e-06, -5.6845e-05]),
       size=(22540, 50), nnz=2464, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.3788e-05, -2.0031e-05, -9.7204e-06,  ...,
                       1.7079e-05, -1.2231e-05, -1.1124e-05]),
       size=(22540, 50), nnz=21600, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
(67, tensor(20261, device='cuda:7'))
20261
tensor(indices=tensor([[20261],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   41,    41,    41,  ..., 21504, 21504, 21504],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.4240e-05,  1.1148e-05,  1.4761e-04,  ...,
                      -9.3649e-05,  4.7723e-05,  3.3116e-05]),
       size=(22540, 50), nnz=3546, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   41,    41,    41,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 6.6208e-03,  3.6048e-03,  8.1946e-03,  ...,
                       1.7751e-05, -1.2712e-05, -1.1561e-05]),
       size=(22540, 50), nnz=22700, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
torch.Size([22540, 50]) tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SumBackward1>)
6607
torch.Size([2, 149304])
tensor(indices=tensor([[6607],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  285,   285,   285,  ..., 22448, 22448, 22448],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.3938e-05,  6.2575e-06,  1.9917e-04,  ...,
                       1.8867e-04, -1.8809e-06, -5.1273e-05]),
       size=(22540, 50), nnz=4193, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4077e-05, -2.0451e-05, -9.9240e-06,  ...,
                       1.7437e-05, -1.2487e-05, -1.1357e-05]),
       size=(22540, 50), nnz=23350, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
21185
torch.Size([2, 149304])
tensor(indices=tensor([[21185],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[    1,     1,     1,  ..., 22453, 22453, 22453],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 3.9320e-05, -2.3590e-04,  2.9081e-04,  ...,
                       5.3254e-04, -5.8135e-06, -5.6249e-05]),
       size=(22540, 50), nnz=1622, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[    1,     1,     1,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.1950e-03, -1.5644e-04, -1.1187e-03,  ...,
                       1.8504e-05, -1.3252e-05, -1.2052e-05]),
       size=(22540, 50), nnz=20300, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
18218
torch.Size([2, 149304])
tensor(indices=tensor([[18218],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[    6,     6,     6,  ..., 22531, 22531, 22531],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 3.1817e-04,  6.0219e-03,  2.3679e-03,  ...,
                       1.2700e-04, -1.8516e-06, -2.3446e-05]),
       size=(22540, 50), nnz=7526, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[    6,     6,     6,  ..., 22531, 22531, 22531],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 7.5202e-02, -3.4934e-02,  7.7422e-03,  ...,
                      -1.5543e-05, -2.3103e-04, -3.8948e-05]),
       size=(22540, 50), nnz=9100, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
6607
tensor(indices=tensor([[6607],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  285,   285,   285,  ..., 22448, 22448, 22448],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.3938e-05,  6.2575e-06,  1.9917e-04,  ...,
                       1.8867e-04, -1.8809e-06, -5.1273e-05]),
       size=(22540, 50), nnz=4193, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4077e-05, -2.0451e-05, -9.9240e-06,  ...,
                       1.7437e-05, -1.2487e-05, -1.1357e-05]),
       size=(22540, 50), nnz=23350, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
21185
tensor(indices=tensor([[21185],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 2547,  2547,  2547,  ..., 22453, 22453, 22453],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.2968e-05,  2.5615e-05,  3.3906e-04,  ...,
                       5.3328e-04, -5.8216e-06, -5.6328e-05]),
       size=(22540, 50), nnz=1623, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4960e-05, -2.1733e-05, -1.0546e-05,  ...,
                       1.8530e-05, -1.3270e-05, -1.2069e-05]),
       size=(22540, 50), nnz=20050, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
18218
tensor(indices=tensor([[18218],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   38,    38,    38,  ..., 22531, 22531, 22531],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 7.5500e-06, -4.9111e-05,  5.4253e-05,  ...,
                       1.0398e-04, -1.5160e-06, -1.9197e-05]),
       size=(22540, 50), nnz=7526, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   38,    38,    38,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.2590e-04,  1.4574e-03,  3.6539e-03,  ...,
                       2.2190e-05, -1.5401e-05, -1.4779e-05]),
       size=(22540, 50), nnz=26800, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
6607
tensor(indices=tensor([[6607],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[  285,   285,   285,  ..., 22448, 22448, 22448],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.3961e-05,  6.2676e-06,  1.9949e-04,  ...,
                       1.8897e-04, -1.8840e-06, -5.1356e-05]),
       size=(22540, 50), nnz=4192, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4100e-05, -2.0484e-05, -9.9400e-06,  ...,
                       1.7465e-05, -1.2507e-05, -1.1375e-05]),
       size=(22540, 50), nnz=23350, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
21185
tensor(indices=tensor([[21185],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 2547,  2547,  2547,  ..., 22453, 22453, 22453],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.2949e-05,  2.5604e-05,  3.3891e-04,  ...,
                       5.3304e-04, -5.8190e-06, -5.6303e-05]),
       size=(22540, 50), nnz=1623, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4953e-05, -2.1723e-05, -1.0542e-05,  ...,
                       1.8522e-05, -1.3264e-05, -1.2063e-05]),
       size=(22540, 50), nnz=20050, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
18218
tensor(indices=tensor([[18218],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   38,    38,    38,  ..., 22531, 22531, 22531],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 6.9027e-06, -4.4900e-05,  4.9601e-05,  ...,
                       9.5065e-05, -1.3860e-06, -1.7551e-05]),
       size=(22540, 50), nnz=7524, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   38,    38,    38,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-2.2835e-04,  1.4390e-03,  3.5867e-03,  ...,
                       1.8626e-05, -1.3339e-05, -1.2131e-05]),
       size=(22540, 50), nnz=26800, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
6607
torch.Size([2, 149304])
tensor(indices=tensor([[6607],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[    5,     5,     5,  ..., 22448, 22448, 22448],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 6.4633e-06,  1.0540e-04,  5.6006e-05,  ...,
                       1.8879e-04, -1.8821e-06, -5.1305e-05]),
       size=(22540, 50), nnz=4194, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[    5,     5,     5,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 2.2084e-01,  1.9594e-01, -8.3788e-02,  ...,
                       1.7448e-05, -1.2495e-05, -1.1364e-05]),
       size=(22540, 50), nnz=23400, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
21185
torch.Size([2, 149304])
tensor(indices=tensor([[21185],
                       [    0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[ 2547,  2547,  2547,  ..., 22453, 22453, 22453],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 4.2949e-05,  2.5604e-05,  3.3891e-04,  ...,
                       5.3304e-04, -5.8190e-06, -5.6303e-05]),
       size=(22540, 50), nnz=1623, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   58,    58,    58,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.4953e-05, -2.1723e-05, -1.0542e-05,  ...,
                       1.8522e-05, -1.3264e-05, -1.2063e-05]),
       size=(22540, 50), nnz=20050, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
9376
torch.Size([2, 149304])
tensor(indices=tensor([[9376],
                       [   0]]),
       values=tensor([1.]),
       size=(22540, 2), nnz=1, layout=torch.sparse_coo)
tensor(indices=tensor([[   13,    13,    13,  ..., 22492, 22492, 22492],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([ 1.1342e-05, -9.0306e-05,  9.8091e-05,  ...,
                       2.7312e-04,  1.6412e-04, -1.9960e-04]),
       size=(22540, 50), nnz=3627, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor(indices=tensor([[   13,    13,    13,  ..., 22533, 22533, 22533],
                       [    0,     1,     2,  ...,    47,    48,    49]]),
       values=tensor([-1.6289e-03,  1.1426e-03, -5.9433e-04,  ...,
                       1.8383e-05, -1.3165e-05, -1.1973e-05]),
       size=(22540, 50), nnz=22800, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
count_nodes_self:  6
count_edges_self:  8
Starting evaluation...
[Evaluation] Test Accuracy: 66.18

