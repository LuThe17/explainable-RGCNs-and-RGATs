Labels loaded.
RDF loaded.
Graph loaded.
False
shape edges:  torch.Size([10430, 3])
num_classes:  4
num_nodes:  2929
num_relations:  28
Parameter containing:
tensor([[ 0.0955,  0.0139, -0.1671,  ..., -0.0094, -0.1550, -0.2604],
        [ 0.0570, -0.1217,  0.1366,  ...,  0.2613,  0.2447,  0.1521],
        [ 0.0267,  0.1130,  0.0559,  ...,  0.2313,  0.2535,  0.2334],
        ...,
        [-0.1728,  0.2424,  0.4050,  ..., -0.0230, -0.1477, -0.0647],
        [-0.2012,  0.0927, -0.0455,  ...,  0.1648,  0.1712,  0.3142],
        [ 0.1765, -0.2284, -0.0496,  ...,  0.0617,  0.2010, -0.0422]],
       requires_grad=True)
Exponential sum:  tensor(9024.6621, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([31.4549, 31.4549, 31.4549,  ...,  1.0000,  1.0000,
                       1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.2268, 0.2268, 0.2268,  ..., 0.9691, 0.9371, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(6233.2783, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([139.0000, 139.0000, 139.0000,  ...,   0.9649,
                        0.9649,   0.9649]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9649]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2418, 0.2506, 0.2477, 0.2599],
        [0.2500, 0.2500, 0.2500, 0.2500],
        [0.2312, 0.2704, 0.2582, 0.2402],
        ...,
        [0.2220, 0.2758, 0.2428, 0.2594],
        [0.2264, 0.2271, 0.2527, 0.2939],
        [0.2552, 0.2512, 0.2342, 0.2594]], grad_fn=<SoftmaxBackward0>)
Epoch: 0001 loss: 1.3855 acc_train: 0.2659
Parameter containing:
tensor([[ 0.0855,  0.0039, -0.1571,  ...,  0.0005, -0.1450, -0.2504],
        [ 0.0470, -0.1117,  0.1267,  ...,  0.2513,  0.2347,  0.1421],
        [ 0.0167,  0.1030,  0.0459,  ...,  0.2213,  0.2435,  0.2234],
        ...,
        [-0.1628,  0.2324,  0.3950,  ..., -0.0130, -0.1378, -0.0547],
        [-0.1912,  0.0827, -0.0355,  ...,  0.1548,  0.1612,  0.3042],
        [ 0.1665, -0.2184, -0.0396,  ...,  0.0517,  0.1910, -0.0322]],
       requires_grad=True)
Exponential sum:  tensor(9070.7773, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([39.0923, 39.0923, 39.0923,  ...,  1.0000,  1.0000,
                       1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.2818, 0.2818, 0.2818,  ..., 0.9743, 0.9445, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(6360.2192, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([139.0000, 139.0000, 139.0000,  ...,   0.9674,
                        0.9674,   0.9674]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9674]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2306, 0.2464, 0.2494, 0.2736],
        [0.2500, 0.2500, 0.2500, 0.2500],
        [0.2258, 0.2652, 0.2578, 0.2513],
        ...,
        [0.2184, 0.2694, 0.2445, 0.2678],
        [0.2209, 0.2253, 0.2552, 0.2986],
        [0.2220, 0.2228, 0.2602, 0.2949]], grad_fn=<SoftmaxBackward0>)
Epoch: 0002 loss: 1.3735 acc_train: 0.3866
Parameter containing:
tensor([[ 0.0756, -0.0045, -0.1471,  ...,  0.0068, -0.1350, -0.2404],
        [ 0.0371, -0.1018,  0.1167,  ...,  0.2413,  0.2248,  0.1321],
        [ 0.0071,  0.0931,  0.0360,  ...,  0.2113,  0.2335,  0.2134],
        ...,
        [-0.1528,  0.2224,  0.3850,  ..., -0.0035, -0.1278, -0.0447],
        [-0.1812,  0.0727, -0.0257,  ...,  0.1448,  0.1512,  0.2942],
        [ 0.1565, -0.2084, -0.0296,  ...,  0.0417,  0.1811, -0.0222]],
       requires_grad=True)
Exponential sum:  tensor(9195.9463, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([47.9192, 47.9192, 47.9192,  ...,  1.0000,  1.0000,
                       1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.3454, 0.3454, 0.3454,  ..., 0.9769, 0.9518, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(6651.2427, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([139.0000, 139.0000, 139.0000,  ...,   0.9697,
                        0.9697,   0.9697]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9697]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2248, 0.2440, 0.2503, 0.2809],
        [0.2500, 0.2500, 0.2500, 0.2500],
        [0.2228, 0.2611, 0.2574, 0.2587],
        ...,
        [0.2167, 0.2652, 0.2467, 0.2714],
        [0.2184, 0.2249, 0.2562, 0.3005],
        [0.1910, 0.1927, 0.2831, 0.3332]], grad_fn=<SoftmaxBackward0>)
Epoch: 0003 loss: 1.3609 acc_train: 0.3788
Parameter containing:
tensor([[ 0.0657, -0.0087, -0.1371,  ...,  0.0069, -0.1250, -0.2304],
        [ 0.0274, -0.0919,  0.1068,  ...,  0.2314,  0.2148,  0.1221],
        [-0.0016,  0.0832,  0.0263,  ...,  0.2013,  0.2235,  0.2035],
        ...,
        [-0.1429,  0.2124,  0.3750,  ...,  0.0046, -0.1178, -0.0350],
        [-0.1713,  0.0629, -0.0161,  ...,  0.1349,  0.1413,  0.2843],
        [ 0.1467, -0.1984, -0.0196,  ...,  0.0318,  0.1712, -0.0124]],
       requires_grad=True)
Exponential sum:  tensor(9312.8945, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([57.5870, 57.5870, 57.5870,  ...,  1.0000,  1.0000,
                       1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.4150, 0.4150, 0.4150,  ..., 0.9797, 0.9571, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(6769.4229, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([139.0000, 139.0000, 139.0000,  ...,   0.9730,
                        0.9730,   0.9730]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9730]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2224, 0.2420, 0.2513, 0.2843],
        [0.2500, 0.2500, 0.2500, 0.2500],
        [0.2219, 0.2576, 0.2573, 0.2632],
        ...,
        [0.2172, 0.2621, 0.2482, 0.2724],
        [0.2181, 0.2259, 0.2558, 0.3002],
        [0.1481, 0.1528, 0.3030, 0.3961]], grad_fn=<SoftmaxBackward0>)
Epoch: 0004 loss: 1.3448 acc_train: 0.3788
Parameter containing:
tensor([[ 0.0560, -0.0087, -0.1273,  ...,  0.0040, -0.1152, -0.2205],
        [ 0.0180, -0.0820,  0.0969,  ...,  0.2214,  0.2049,  0.1123],
        [-0.0084,  0.0734,  0.0170,  ...,  0.1914,  0.2136,  0.1935],
        ...,
        [-0.1330,  0.2025,  0.3651,  ...,  0.0102, -0.1080, -0.0255],
        [-0.1613,  0.0531, -0.0071,  ...,  0.1250,  0.1314,  0.2743],
        [ 0.1369, -0.1884, -0.0104,  ...,  0.0219,  0.1614, -0.0028]],
       requires_grad=True)
Exponential sum:  tensor(9422.9980, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([67.6717, 67.6717, 67.6717,  ...,  1.0000,  1.0000,
                       1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.4876, 0.4876, 0.4876,  ..., 0.9827, 0.9611, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(6939.7153, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([139.0000, 139.0000, 139.0000,  ...,   0.9764,
                        0.9764,   0.9764]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9764]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2220, 0.2406, 0.2521, 0.2852],
        [0.2500, 0.2500, 0.2500, 0.2500],
        [0.2226, 0.2549, 0.2570, 0.2654],
        ...,
        [0.2191, 0.2601, 0.2486, 0.2722],
        [0.2193, 0.2278, 0.2548, 0.2981],
        [0.0973, 0.1039, 0.3103, 0.4886]], grad_fn=<SoftmaxBackward0>)
Epoch: 0005 loss: 1.3238 acc_train: 0.3978
Parameter containing:
tensor([[ 4.6402e-02, -6.3071e-03, -1.1744e-01,  ...,  1.7847e-04,
         -1.0538e-01, -2.1062e-01],
        [ 9.1607e-03, -7.2342e-02,  8.7154e-02,  ...,  2.1155e-01,
          1.9498e-01,  1.0249e-01],
        [-1.2575e-02,  6.3693e-02,  8.1756e-03,  ...,  1.8152e-01,
          2.0372e-01,  1.8365e-01],
        ...,
        [-1.2315e-01,  1.9262e-01,  3.5511e-01,  ...,  1.2784e-02,
         -9.8201e-02, -1.6344e-02],
        [-1.5149e-01,  4.3599e-02,  1.0345e-03,  ...,  1.1517e-01,
          1.2157e-01,  2.6439e-01],
        [ 1.2730e-01, -1.7844e-01, -4.0763e-03,  ...,  1.2531e-02,
          1.5179e-01,  6.6431e-03]], requires_grad=True)
Exponential sum:  tensor(9519.2266, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([77.6620, 77.6620, 77.6620,  ...,  1.0000,  1.0000,
                       1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.5595, 0.5595, 0.5595,  ..., 0.9851, 0.9642, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(7008.5854, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([139.0000, 139.0000, 139.0000,  ...,   0.9800,
                        0.9800,   0.9800]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9800]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2233, 0.2401, 0.2528, 0.2838],
        [0.2500, 0.2500, 0.2500, 0.2500],
        [0.2244, 0.2529, 0.2566, 0.2661],
        ...,
        [0.2217, 0.2590, 0.2480, 0.2714],
        [0.2215, 0.2304, 0.2533, 0.2949],
        [0.0514, 0.0581, 0.2891, 0.6014]], grad_fn=<SoftmaxBackward0>)
Epoch: 0006 loss: 1.2988 acc_train: 0.4324
Parameter containing:
tensor([[ 3.7083e-02, -2.7082e-03, -1.0772e-01,  ..., -3.2054e-03,
         -9.5691e-02, -2.0077e-01],
        [ 1.0255e-03, -6.2796e-02,  7.7533e-02,  ...,  2.0170e-01,
          1.8514e-01,  9.2811e-02],
        [-1.4119e-02,  5.4205e-02,  1.2208e-04,  ...,  1.7170e-01,
          1.9388e-01,  1.7383e-01],
        ...,
        [-1.1342e-01,  1.8279e-01,  3.4520e-01,  ...,  1.2705e-02,
         -8.8538e-02, -7.7687e-03],
        [-1.4170e-01,  3.4318e-02,  7.9488e-03,  ...,  1.0546e-01,
          1.1184e-01,  2.5451e-01],
        [ 1.1788e-01, -1.6838e-01, -1.9255e-03,  ...,  5.1843e-03,
          1.4224e-01,  1.5787e-02]], requires_grad=True)
Exponential sum:  tensor(9604.4072, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([87.3012, 87.3012, 87.3012,  ...,  1.0000,  1.0000,
                       1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.6288, 0.6288, 0.6288,  ..., 0.9872, 0.9666, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(7029.8198, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([139.0000, 139.0000, 139.0000,  ...,   0.9837,
                        0.9837,   0.9837]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9837]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2257, 0.2404, 0.2532, 0.2807],
        [0.2500, 0.2500, 0.2500, 0.2500],
        [0.2270, 0.2517, 0.2558, 0.2655],
        ...,
        [0.2248, 0.2583, 0.2470, 0.2700],
        [0.2241, 0.2328, 0.2521, 0.2909],
        [0.0230, 0.0268, 0.2463, 0.7039]], grad_fn=<SoftmaxBackward0>)
Epoch: 0007 loss: 1.2733 acc_train: 0.4570
Parameter containing:
tensor([[ 2.8084e-02,  1.0754e-03, -9.8118e-02,  ..., -4.9450e-03,
         -8.6139e-02, -1.9099e-01],
        [-6.1365e-03, -5.3451e-02,  6.8076e-02,  ...,  1.9192e-01,
          1.7538e-01,  8.3271e-02],
        [-1.3510e-02,  4.4947e-02, -6.9153e-03,  ...,  1.6196e-01,
          1.8410e-01,  1.6408e-01],
        ...,
        [-1.0380e-01,  1.7303e-01,  3.3533e-01,  ...,  1.0761e-02,
         -7.9019e-02,  7.0040e-05],
        [-1.3201e-01,  2.5379e-02,  1.3307e-02,  ...,  9.5868e-02,
          1.0222e-01,  2.4468e-01],
        [ 1.0866e-01, -1.5824e-01, -3.3941e-03,  ...,  1.0953e-03,
          1.3282e-01,  2.4370e-02]], requires_grad=True)
Exponential sum:  tensor(9682.6289, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([96.3962, 96.3962, 96.3962,  ...,  1.0000,  1.0000,
                       1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.6942, 0.6942, 0.6942,  ..., 0.9891, 0.9685, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(6927.1255, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([139.0000, 139.0000, 139.0000,  ...,   0.9873,
                        0.9873,   0.9873]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9873]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2286, 0.2419, 0.2529, 0.2766],
        [0.2500, 0.2500, 0.2500, 0.2500],
        [0.2297, 0.2511, 0.2548, 0.2644],
        ...,
        [0.2284, 0.2578, 0.2462, 0.2676],
        [0.2269, 0.2353, 0.2513, 0.2864],
        [0.0112, 0.0124, 0.2181, 0.7582]], grad_fn=<SoftmaxBackward0>)
Epoch: 0008 loss: 1.2512 acc_train: 0.4726
Parameter containing:
tensor([[ 0.0195,  0.0042, -0.0887,  ..., -0.0048, -0.0767, -0.1813],
        [-0.0121, -0.0444,  0.0588,  ...,  0.1822,  0.1657,  0.0739],
        [-0.0114,  0.0360, -0.0127,  ...,  0.1523,  0.1744,  0.1544],
        ...,
        [-0.0943,  0.1633,  0.3255,  ...,  0.0076, -0.0697,  0.0070],
        [-0.1224,  0.0169,  0.0169,  ...,  0.0864,  0.0927,  0.2349],
        [ 0.1000, -0.1480, -0.0074,  ...,  0.0019,  0.1237,  0.0319]],
       requires_grad=True)
Exponential sum:  tensor(9758.7051, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([104.7468, 104.7468, 104.7468,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.7542, 0.7542, 0.7542,  ..., 0.9908, 0.9700, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(6891.4932, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([139.0000, 139.0000, 139.0000,  ...,   0.9903,
                        0.9903,   0.9903]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9903]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2314, 0.2439, 0.2527, 0.2721],
        [0.2500, 0.2500, 0.2500, 0.2500],
        [0.2322, 0.2510, 0.2540, 0.2627],
        ...,
        [0.2316, 0.2573, 0.2458, 0.2653],
        [0.2299, 0.2379, 0.2509, 0.2813],
        [0.0079, 0.0076, 0.2397, 0.7448]], grad_fn=<SoftmaxBackward0>)
Epoch: 0009 loss: 1.2320 acc_train: 0.5453
Parameter containing:
tensor([[ 0.0114,  0.0059, -0.0794,  ..., -0.0032, -0.0675, -0.1716],
        [-0.0167, -0.0356,  0.0498,  ...,  0.1726,  0.1561,  0.0647],
        [-0.0082,  0.0274, -0.0171,  ...,  0.1427,  0.1648,  0.1448],
        ...,
        [-0.0850,  0.1538,  0.3157,  ...,  0.0039, -0.0605,  0.0128],
        [-0.1130,  0.0089,  0.0188,  ...,  0.0772,  0.0834,  0.2252],
        [ 0.0914, -0.1378, -0.0127,  ...,  0.0054,  0.1148,  0.0369]],
       requires_grad=True)
Exponential sum:  tensor(9836.4492, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([112.2129, 112.2129, 112.2129,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.8078, 0.8078, 0.8078,  ..., 0.9920, 0.9716, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(6884.5776, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([139.0000, 139.0000, 139.0000,  ...,   0.9932,
                        0.9932,   0.9932]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9932]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2342, 0.2459, 0.2525, 0.2674],
        [0.2500, 0.2500, 0.2500, 0.2500],
        [0.2349, 0.2510, 0.2535, 0.2606],
        ...,
        [0.2347, 0.2569, 0.2460, 0.2624],
        [0.2326, 0.2404, 0.2507, 0.2763],
        [0.0086, 0.0069, 0.3253, 0.6592]], grad_fn=<SoftmaxBackward0>)
Epoch: 0010 loss: 1.2124 acc_train: 0.5687
Parameter containing:
tensor([[ 3.8625e-03,  6.0565e-03, -7.0275e-02,  ..., -8.5400e-04,
         -5.8573e-02, -1.6212e-01],
        [-1.9824e-02, -2.7121e-02,  4.1077e-02,  ...,  1.6304e-01,
          1.4661e-01,  5.5782e-02],
        [-4.5110e-03,  1.9143e-02, -1.9994e-02,  ...,  1.3329e-01,
          1.5527e-01,  1.3539e-01],
        ...,
        [-7.5846e-02,  1.4428e-01,  3.0597e-01,  ...,  8.3193e-05,
         -5.1655e-02,  1.7339e-02],
        [-1.0364e-01,  1.5292e-03,  1.9147e-02,  ...,  6.8088e-02,
          7.4297e-02,  2.1557e-01],
        [ 8.2906e-02, -1.2745e-01, -1.8788e-02,  ...,  1.0730e-02,
          1.0613e-01,  4.0809e-02]], requires_grad=True)
Exponential sum:  tensor(9915.2012, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([118.6934, 118.6934, 118.6934,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.8543, 0.8543, 0.8543,  ..., 0.9930, 0.9733, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(6905.3521, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([139.0000, 139.0000, 139.0000,  ...,   0.9954,
                        0.9954,   0.9954]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9954]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2372, 0.2475, 0.2524, 0.2629],
        [0.2500, 0.2500, 0.2500, 0.2500],
        [0.2376, 0.2510, 0.2531, 0.2583],
        ...,
        [0.2375, 0.2566, 0.2464, 0.2595],
        [0.2350, 0.2427, 0.2508, 0.2716],
        [0.0124, 0.0082, 0.4692, 0.5102]], grad_fn=<SoftmaxBackward0>)
Epoch: 0011 loss: 1.1929 acc_train: 0.5732
Parameter containing:
tensor([[-0.0030,  0.0049, -0.0614,  ...,  0.0015, -0.0499, -0.1527],
        [-0.0216, -0.0191,  0.0327,  ...,  0.1536,  0.1372,  0.0471],
        [-0.0007,  0.0114, -0.0215,  ...,  0.1240,  0.1459,  0.1261],
        ...,
        [-0.0669,  0.1349,  0.2963,  ..., -0.0034, -0.0431,  0.0206],
        [-0.0945, -0.0051,  0.0182,  ...,  0.0593,  0.0654,  0.2060],
        [ 0.0744, -0.1172, -0.0254,  ...,  0.0173,  0.0976,  0.0432]],
       requires_grad=True)
Exponential sum:  tensor(9990.0566, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([124.1167, 124.1167, 124.1167,  ...,   0.9990,
                        0.9990,   0.9990]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.8933, 0.8933, 0.8933,  ..., 0.9936, 0.9751, 0.9990]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(6965.3779, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([139.0000, 139.0000, 139.0000,  ...,   0.9971,
                        0.9971,   0.9971]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9971]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2399, 0.2489, 0.2520, 0.2592],
        [0.2500, 0.2500, 0.2500, 0.2500],
        [0.2399, 0.2511, 0.2526, 0.2564],
        ...,
        [0.2400, 0.2562, 0.2466, 0.2572],
        [0.2371, 0.2446, 0.2509, 0.2674],
        [0.0171, 0.0089, 0.6086, 0.3655]], grad_fn=<SoftmaxBackward0>)
Epoch: 0012 loss: 1.1766 acc_train: 0.6134
Parameter containing:
tensor([[-0.0090,  0.0029, -0.0528,  ...,  0.0032, -0.0414, -0.1434],
        [-0.0220, -0.0116,  0.0247,  ...,  0.1443,  0.1280,  0.0388],
        [ 0.0028,  0.0042, -0.0217,  ...,  0.1148,  0.1366,  0.1169],
        ...,
        [-0.0582,  0.1257,  0.2867,  ..., -0.0060, -0.0348,  0.0226],
        [-0.0855, -0.0109,  0.0161,  ...,  0.0507,  0.0567,  0.1966],
        [ 0.0663, -0.1072, -0.0312,  ...,  0.0238,  0.0889,  0.0461]],
       requires_grad=True)
Exponential sum:  tensor(10054.2305, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([128.4511, 128.4511, 128.4511,  ...,   0.9978,
                        0.9978,   0.9978]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9244, 0.9244, 0.9244,  ..., 0.9940, 0.9772, 0.9978]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(7072.0518, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([128.6848, 128.6848, 128.6848,  ...,   0.9985,
                        0.9985,   0.9985]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9258, 0.9258, 0.9258,  ..., 1.0000, 1.0000, 0.9985]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2421, 0.2501, 0.2514, 0.2564],
        [0.2500, 0.2500, 0.2500, 0.2500],
        [0.2420, 0.2511, 0.2521, 0.2548],
        ...,
        [0.2421, 0.2555, 0.2469, 0.2554],
        [0.2389, 0.2465, 0.2505, 0.2640],
        [0.0199, 0.0081, 0.7081, 0.2639]], grad_fn=<SoftmaxBackward0>)
Epoch: 0013 loss: 1.1622 acc_train: 0.5944
Parameter containing:
tensor([[-0.0143,  0.0005, -0.0445,  ...,  0.0037, -0.0334, -0.1342],
        [-0.0213, -0.0046,  0.0171,  ...,  0.1351,  0.1189,  0.0307],
        [ 0.0056, -0.0023, -0.0208,  ...,  0.1058,  0.1275,  0.1079],
        ...,
        [-0.0498,  0.1166,  0.2771,  ..., -0.0076, -0.0269,  0.0234],
        [-0.0768, -0.0159,  0.0134,  ...,  0.0424,  0.0483,  0.1872],
        [ 0.0584, -0.0977, -0.0352,  ...,  0.0273,  0.0804,  0.0483]],
       requires_grad=True)
Exponential sum:  tensor(10105.1680, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([131.7855, 131.7855, 131.7855,  ...,   0.9970,
                        0.9970,   0.9970]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9483, 0.9483, 0.9483,  ..., 0.9942, 0.9793, 0.9970]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(7303.8843, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([101.4068, 101.4068, 101.4068,  ...,   0.9996,
                        0.9996,   0.9996]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.7295, 0.7295, 0.7295,  ..., 1.0000, 0.9999, 0.9996]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2438, 0.2511, 0.2506, 0.2545],
        [0.2500, 0.2500, 0.2500, 0.2500],
        [0.2435, 0.2511, 0.2516, 0.2538],
        ...,
        [0.2442, 0.2550, 0.2470, 0.2539],
        [0.2407, 0.2482, 0.2500, 0.2611],
        [0.0201, 0.0064, 0.7682, 0.2053]], grad_fn=<SoftmaxBackward0>)
Epoch: 0014 loss: 1.1458 acc_train: 0.5978
Parameter containing:
tensor([[-0.0186, -0.0017, -0.0365,  ...,  0.0032, -0.0257, -0.1252],
        [-0.0197,  0.0019,  0.0100,  ...,  0.1261,  0.1100,  0.0231],
        [ 0.0075, -0.0082, -0.0190,  ...,  0.0970,  0.1185,  0.0990],
        ...,
        [-0.0417,  0.1077,  0.2677,  ..., -0.0080, -0.0194,  0.0231],
        [-0.0682, -0.0199,  0.0100,  ...,  0.0345,  0.0403,  0.1780],
        [ 0.0509, -0.0884, -0.0376,  ...,  0.0283,  0.0722,  0.0499]],
       requires_grad=True)
Exponential sum:  tensor(10150.4746, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([134.2684, 134.2684, 134.2684,  ...,   0.9967,
                        0.9967,   0.9967]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9660, 0.9660, 0.9660,  ..., 0.9944, 0.9816, 0.9967]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(7469.3862, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([87.6810, 87.6810, 87.6810,  ...,  1.0000,  1.0000,
                       1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.6308, 0.6308, 0.6308,  ..., 0.9999, 0.9997, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2454, 0.2515, 0.2500, 0.2532],
        [0.2500, 0.2500, 0.2500, 0.2500],
        [0.2448, 0.2511, 0.2511, 0.2530],
        ...,
        [0.2459, 0.2546, 0.2469, 0.2526],
        [0.2425, 0.2498, 0.2492, 0.2585],
        [0.0176, 0.0047, 0.8020, 0.1757]], grad_fn=<SoftmaxBackward0>)
Epoch: 0015 loss: 1.1254 acc_train: 0.6168
Parameter containing:
tensor([[-0.0220, -0.0034, -0.0289,  ...,  0.0018, -0.0184, -0.1164],
        [-0.0173,  0.0076,  0.0034,  ...,  0.1173,  0.1013,  0.0159],
        [ 0.0084, -0.0133, -0.0165,  ...,  0.0884,  0.1097,  0.0904],
        ...,
        [-0.0340,  0.0990,  0.2583,  ..., -0.0074, -0.0123,  0.0219],
        [-0.0600, -0.0230,  0.0064,  ...,  0.0269,  0.0326,  0.1688],
        [ 0.0438, -0.0795, -0.0387,  ...,  0.0276,  0.0648,  0.0515]],
       requires_grad=True)
Exponential sum:  tensor(10189.5371, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([136.0556, 136.0556, 136.0556,  ...,   0.9967,
                        0.9967,   0.9967]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9788, 0.9788, 0.9788,  ..., 0.9947, 0.9840, 0.9967]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(7557.0376, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([82.9045, 82.9045, 82.9045,  ...,  1.0000,  1.0000,
                       1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.5964, 0.5964, 0.5964,  ..., 0.9996, 0.9997, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2465, 0.2515, 0.2496, 0.2525],
        [0.2500, 0.2500, 0.2500, 0.2500],
        [0.2461, 0.2510, 0.2506, 0.2523],
        ...,
        [0.2471, 0.2541, 0.2469, 0.2519],
        [0.2439, 0.2509, 0.2486, 0.2566],
        [0.0123, 0.0032, 0.8006, 0.1839]], grad_fn=<SoftmaxBackward0>)
Epoch: 0016 loss: 1.1030 acc_train: 0.6514
Parameter containing:
tensor([[-2.4534e-02, -4.2414e-03, -2.1637e-02,  ...,  4.7466e-05,
         -1.1530e-02, -1.0771e-01],
        [-1.4362e-02,  1.2714e-02, -2.6485e-03,  ...,  1.0860e-01,
          9.2742e-02,  9.1929e-03],
        [ 8.2637e-03, -1.7688e-02, -1.3431e-02,  ...,  7.9975e-02,
          1.0110e-01,  8.1985e-02],
        ...,
        [-2.6565e-02,  9.0502e-02,  2.4901e-01,  ..., -5.8819e-03,
         -5.7853e-03,  1.9923e-02],
        [-5.1976e-02, -2.5099e-02,  2.7653e-03,  ...,  1.9780e-02,
          2.5198e-02,  1.5985e-01],
        [ 3.9096e-02, -7.0360e-02, -3.9054e-02,  ...,  2.6499e-02,
          5.9938e-02,  5.5892e-02]], requires_grad=True)
Exponential sum:  tensor(10223.0273, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([137.2788, 137.2788, 137.2788,  ...,   0.9971,
                        0.9971,   0.9971]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9876, 0.9876, 0.9876,  ..., 0.9950, 0.9863, 0.9971]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(7710.5317, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([82.9899, 82.9899, 82.9899,  ...,  1.0000,  1.0000,
                       1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.5970, 0.5970, 0.5970,  ..., 0.9995, 0.9997, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2472, 0.2512, 0.2494, 0.2522],
        [0.2500, 0.2500, 0.2500, 0.2500],
        [0.2470, 0.2508, 0.2503, 0.2519],
        ...,
        [0.2479, 0.2535, 0.2471, 0.2515],
        [0.2448, 0.2515, 0.2485, 0.2552],
        [0.0074, 0.0019, 0.7707, 0.2200]], grad_fn=<SoftmaxBackward0>)
Epoch: 0017 loss: 1.0844 acc_train: 0.6682
Parameter containing:
tensor([[-0.0261, -0.0041, -0.0148,  ..., -0.0015, -0.0052, -0.0992],
        [-0.0110,  0.0171, -0.0081,  ...,  0.1001,  0.0844,  0.0030],
        [ 0.0073, -0.0213, -0.0100,  ...,  0.0718,  0.0927,  0.0738],
        ...,
        [-0.0196,  0.0822,  0.2398,  ..., -0.0038,  0.0002,  0.0173],
        [-0.0443, -0.0263, -0.0007,  ...,  0.0131,  0.0183,  0.1510],
        [ 0.0383, -0.0609, -0.0394,  ...,  0.0266,  0.0589,  0.0622]],
       requires_grad=True)
Exponential sum:  tensor(10243.8828, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([138.0531, 138.0531, 138.0531,  ...,   0.9977,
                        0.9977,   0.9977]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9931, 0.9931, 0.9931,  ..., 0.9954, 0.9885, 0.9977]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(8079.1963, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([85.6898, 85.6898, 85.6898,  ...,  1.0000,  1.0000,
                       1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.6165, 0.6165, 0.6165,  ..., 0.9995, 0.9998, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2478, 0.2509, 0.2494, 0.2518],
        [0.2500, 0.2500, 0.2500, 0.2500],
        [0.2478, 0.2504, 0.2502, 0.2515],
        ...,
        [0.2486, 0.2530, 0.2474, 0.2510],
        [0.2458, 0.2517, 0.2486, 0.2538],
        [0.0052, 0.0011, 0.8183, 0.1754]], grad_fn=<SoftmaxBackward0>)
Epoch: 0018 loss: 1.0643 acc_train: 0.7039
Parameter containing:
tensor([[-0.0269, -0.0031, -0.0085,  ..., -0.0025,  0.0007, -0.0910],
        [-0.0075,  0.0207, -0.0129,  ...,  0.0918,  0.0763, -0.0027],
        [ 0.0056, -0.0241, -0.0065,  ...,  0.0639,  0.0845,  0.0659],
        ...,
        [-0.0130,  0.0741,  0.2307,  ..., -0.0015,  0.0057,  0.0143],
        [-0.0369, -0.0267, -0.0039,  ...,  0.0068,  0.0117,  0.1423],
        [ 0.0401, -0.0511, -0.0404,  ...,  0.0282,  0.0603,  0.0698]],
       requires_grad=True)
Exponential sum:  tensor(10262.5791, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([138.4702, 138.4702, 138.4702,  ...,   0.9984,
                        0.9984,   0.9984]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9961, 0.9961, 0.9961,  ..., 0.9958, 0.9906, 0.9984]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(8676.1709, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([90.8181, 90.8181, 90.8181,  ...,  1.0000,  1.0000,
                       1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.6534, 0.6534, 0.6534,  ..., 0.9995, 0.9999, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[2.4837e-01, 2.5049e-01, 2.4957e-01, 2.5157e-01],
        [2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],
        [2.4831e-01, 2.5013e-01, 2.5024e-01, 2.5132e-01],
        ...,
        [2.4892e-01, 2.5241e-01, 2.4789e-01, 2.5078e-01],
        [2.4690e-01, 2.5164e-01, 2.4878e-01, 2.5268e-01],
        [4.2226e-03, 5.2560e-04, 9.0953e-01, 8.5717e-02]],
       grad_fn=<SoftmaxBackward0>)
Epoch: 0019 loss: 1.0451 acc_train: 0.7128
Parameter containing:
tensor([[-0.0269, -0.0016, -0.0026,  ..., -0.0027,  0.0060, -0.0829],
        [-0.0040,  0.0236, -0.0170,  ...,  0.0838,  0.0685, -0.0079],
        [ 0.0035, -0.0261, -0.0030,  ...,  0.0563,  0.0765,  0.0582],
        ...,
        [-0.0069,  0.0663,  0.2218,  ...,  0.0008,  0.0106,  0.0110],
        [-0.0299, -0.0264, -0.0065,  ...,  0.0010,  0.0057,  0.1338],
        [ 0.0429, -0.0414, -0.0413,  ...,  0.0300,  0.0628,  0.0777]],
       requires_grad=True)
Exponential sum:  tensor(10277.6709, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([138.6216, 138.6216, 138.6216,  ...,   0.9992,
                        0.9992,   0.9992]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9972, 0.9972, 0.9972,  ..., 0.9963, 0.9925, 0.9992]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(9013.1318, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([97.0149, 97.0149, 97.0149,  ...,  1.0000,  1.0000,
                       1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.6979, 0.6979, 0.6979,  ..., 0.9996, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[2.4874e-01, 2.5008e-01, 2.4973e-01, 2.5145e-01],
        [2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],
        [2.4867e-01, 2.4998e-01, 2.5026e-01, 2.5109e-01],
        ...,
        [2.4907e-01, 2.5195e-01, 2.4831e-01, 2.5067e-01],
        [2.4775e-01, 2.5148e-01, 2.4897e-01, 2.5181e-01],
        [3.3208e-03, 2.2068e-04, 9.6249e-01, 3.3964e-02]],
       grad_fn=<SoftmaxBackward0>)
Epoch: 0020 loss: 1.0287 acc_train: 0.7196
Parameter containing:
tensor([[-2.6199e-02,  5.8343e-05,  2.8027e-03,  ..., -2.1199e-03,
          1.0705e-02, -7.5108e-02],
        [-5.7967e-04,  2.5785e-02, -2.0494e-02,  ...,  7.5963e-02,
          6.0904e-02, -1.2435e-02],
        [ 1.1635e-03, -2.7372e-02,  3.8273e-04,  ...,  4.8917e-02,
          6.8826e-02,  5.0796e-02],
        ...,
        [-1.2258e-03,  5.8790e-02,  2.1290e-01,  ...,  2.7824e-03,
          1.4885e-02,  7.5565e-03],
        [-2.3244e-02, -2.5336e-02, -8.4797e-03,  ..., -4.2453e-03,
          1.0563e-04,  1.2542e-01],
        [ 4.5507e-02, -3.2184e-02, -4.1412e-02,  ...,  3.1213e-02,
          6.5172e-02,  8.4641e-02]], requires_grad=True)
Exponential sum:  tensor(10292.2988, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([138.5909, 138.5909, 138.5909,  ...,   0.9999,
                        0.9999,   0.9999]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9970, 0.9970, 0.9970,  ..., 0.9967, 0.9943, 0.9999]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(9327., grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([103.1593, 103.1593, 103.1593,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.7422, 0.7422, 0.7422,  ..., 0.9997, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[2.4899e-01, 2.4982e-01, 2.4988e-01, 2.5130e-01],
        [2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],
        [2.4892e-01, 2.4983e-01, 2.5029e-01, 2.5095e-01],
        ...,
        [2.4908e-01, 2.5151e-01, 2.4872e-01, 2.5069e-01],
        [2.4841e-01, 2.5125e-01, 2.4919e-01, 2.5115e-01],
        [2.4366e-03, 8.4602e-05, 9.8392e-01, 1.3558e-02]],
       grad_fn=<SoftmaxBackward0>)
Epoch: 0021 loss: 1.0143 acc_train: 0.7274
Parameter containing:
tensor([[-0.0249,  0.0016,  0.0077,  ..., -0.0010,  0.0149, -0.0675],
        [ 0.0026,  0.0273, -0.0233,  ...,  0.0684,  0.0536, -0.0164],
        [-0.0011, -0.0279,  0.0034,  ...,  0.0419,  0.0614,  0.0437],
        ...,
        [ 0.0039,  0.0515,  0.2042,  ...,  0.0042,  0.0186,  0.0041],
        [-0.0170, -0.0237, -0.0097,  ..., -0.0090, -0.0050,  0.1172],
        [ 0.0476, -0.0235, -0.0405,  ...,  0.0314,  0.0670,  0.0901]],
       requires_grad=True)
Exponential sum:  tensor(10303.5234, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([138.4482, 138.4482, 138.4482,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9959, 0.9959, 0.9959,  ..., 0.9972, 0.9958, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(9514.3975, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([108.3762, 108.3762, 108.3762,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.7797, 0.7797, 0.7797,  ..., 0.9998, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[2.4916e-01, 2.4971e-01, 2.5002e-01, 2.5111e-01],
        [2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],
        [2.4911e-01, 2.4974e-01, 2.5027e-01, 2.5088e-01],
        ...,
        [2.4913e-01, 2.5113e-01, 2.4906e-01, 2.5069e-01],
        [2.4890e-01, 2.5091e-01, 2.4945e-01, 2.5073e-01],
        [1.6567e-03, 2.9798e-05, 9.9303e-01, 5.2822e-03]],
       grad_fn=<SoftmaxBackward0>)
Epoch: 0022 loss: 1.0040 acc_train: 0.7352
Parameter containing:
tensor([[-0.0230,  0.0027,  0.0120,  ...,  0.0004,  0.0184, -0.0602],
        [ 0.0053,  0.0281, -0.0255,  ...,  0.0611,  0.0466, -0.0198],
        [-0.0030, -0.0279,  0.0060,  ...,  0.0352,  0.0542,  0.0369],
        ...,
        [ 0.0086,  0.0446,  0.1956,  ...,  0.0050,  0.0216,  0.0008],
        [-0.0111, -0.0216, -0.0102,  ..., -0.0132, -0.0095,  0.1093],
        [ 0.0492, -0.0156, -0.0385,  ...,  0.0308,  0.0681,  0.0939]],
       requires_grad=True)
Exponential sum:  tensor(10312.4980, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([138.2520, 138.2520, 138.2520,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9945, 0.9945, 0.9945,  ..., 0.9976, 0.9972, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(9239.4766, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([112.1702, 112.1702, 112.1702,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.8070, 0.8070, 0.8070,  ..., 0.9999, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[2.4928e-01, 2.4976e-01, 2.5005e-01, 2.5091e-01],
        [2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],
        [2.4924e-01, 2.4979e-01, 2.5017e-01, 2.5079e-01],
        ...,
        [2.4922e-01, 2.5083e-01, 2.4930e-01, 2.5066e-01],
        [2.4913e-01, 2.5063e-01, 2.4966e-01, 2.5057e-01],
        [1.0027e-03, 9.7014e-06, 9.9701e-01, 1.9785e-03]],
       grad_fn=<SoftmaxBackward0>)
Epoch: 0023 loss: 0.9979 acc_train: 0.7419
Parameter containing:
tensor([[-0.0208,  0.0031,  0.0158,  ...,  0.0015,  0.0214, -0.0532],
        [ 0.0075,  0.0282, -0.0270,  ...,  0.0540,  0.0399, -0.0226],
        [-0.0043, -0.0272,  0.0081,  ...,  0.0288,  0.0473,  0.0305],
        ...,
        [ 0.0127,  0.0379,  0.1871,  ...,  0.0051,  0.0241, -0.0023],
        [-0.0057, -0.0191, -0.0101,  ..., -0.0168, -0.0136,  0.1015],
        [ 0.0502, -0.0082, -0.0357,  ...,  0.0294,  0.0685,  0.0962]],
       requires_grad=True)
Exponential sum:  tensor(10321.0674, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([138.0463, 138.0463, 138.0463,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9931, 0.9931, 0.9931,  ..., 0.9979, 0.9982, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(8765.6670, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([114.5486, 114.5486, 114.5486,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.8241, 0.8241, 0.8241,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[2.4933e-01, 2.4988e-01, 2.5007e-01, 2.5073e-01],
        [2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],
        [2.4936e-01, 2.4987e-01, 2.5008e-01, 2.5069e-01],
        ...,
        [2.4936e-01, 2.5059e-01, 2.4942e-01, 2.5062e-01],
        [2.4929e-01, 2.5044e-01, 2.4977e-01, 2.5050e-01],
        [5.7375e-04, 3.3344e-06, 9.9862e-01, 8.0066e-04]],
       grad_fn=<SoftmaxBackward0>)
Epoch: 0024 loss: 0.9953 acc_train: 0.7430
Parameter containing:
tensor([[-0.0181,  0.0028,  0.0190,  ...,  0.0020,  0.0239, -0.0465],
        [ 0.0091,  0.0278, -0.0280,  ...,  0.0473,  0.0335, -0.0248],
        [-0.0051, -0.0260,  0.0095,  ...,  0.0227,  0.0407,  0.0244],
        ...,
        [ 0.0163,  0.0316,  0.1788,  ...,  0.0045,  0.0260, -0.0049],
        [-0.0007, -0.0163, -0.0093,  ..., -0.0199, -0.0171,  0.0939],
        [ 0.0506, -0.0015, -0.0322,  ...,  0.0274,  0.0683,  0.0972]],
       requires_grad=True)
Exponential sum:  tensor(10328.9141, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([137.8646, 137.8646, 137.8646,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9918, 0.9918, 0.9918,  ..., 0.9981, 0.9990, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(8664.9258, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([116.0513, 116.0513, 116.0513,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.8349, 0.8349, 0.8349,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[2.4938e-01, 2.4992e-01, 2.5009e-01, 2.5060e-01],
        [2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],
        [2.4951e-01, 2.4989e-01, 2.5001e-01, 2.5059e-01],
        ...,
        [2.4948e-01, 2.5044e-01, 2.4952e-01, 2.5056e-01],
        [2.4947e-01, 2.5032e-01, 2.4974e-01, 2.5047e-01],
        [3.2636e-04, 1.2563e-06, 9.9931e-01, 3.6004e-04]],
       grad_fn=<SoftmaxBackward0>)
Epoch: 0025 loss: 0.9938 acc_train: 0.7453
Parameter containing:
tensor([[-0.0153,  0.0019,  0.0217,  ...,  0.0020,  0.0257, -0.0401],
        [ 0.0102,  0.0269, -0.0284,  ...,  0.0408,  0.0274, -0.0264],
        [-0.0052, -0.0243,  0.0103,  ...,  0.0170,  0.0344,  0.0187],
        ...,
        [ 0.0194,  0.0256,  0.1706,  ...,  0.0033,  0.0273, -0.0072],
        [ 0.0039, -0.0133, -0.0079,  ..., -0.0225, -0.0200,  0.0866],
        [ 0.0504,  0.0047, -0.0281,  ...,  0.0248,  0.0675,  0.0969]],
       requires_grad=True)
Exponential sum:  tensor(10335.9844)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([137.7295, 137.7295, 137.7295,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9908, 0.9908, 0.9908,  ..., 0.9983, 0.9996, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8685.0068)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([117.3477, 117.3477, 117.3477,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.8442, 0.8442, 0.8442,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[2.4940e-01, 2.4994e-01, 2.5009e-01, 2.5058e-01],
        [2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],
        [2.4963e-01, 2.4989e-01, 2.4997e-01, 2.5052e-01],
        ...,
        [2.4959e-01, 2.5034e-01, 2.4957e-01, 2.5049e-01],
        [2.4957e-01, 2.5027e-01, 2.4969e-01, 2.5046e-01],
        [1.8273e-04, 4.9089e-07, 9.9965e-01, 1.6961e-04]])
Parameter containing:
tensor([[-0.0153,  0.0019,  0.0217,  ...,  0.0020,  0.0257, -0.0401],
        [ 0.0102,  0.0269, -0.0284,  ...,  0.0408,  0.0274, -0.0264],
        [-0.0052, -0.0243,  0.0103,  ...,  0.0170,  0.0344,  0.0187],
        ...,
        [ 0.0194,  0.0256,  0.1706,  ...,  0.0033,  0.0273, -0.0072],
        [ 0.0039, -0.0133, -0.0079,  ..., -0.0225, -0.0200,  0.0866],
        [ 0.0504,  0.0047, -0.0281,  ...,  0.0248,  0.0675,  0.0969]],
       requires_grad=True)
Exponential sum:  tensor(10335.9844)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([137.7295, 137.7295, 137.7295,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9908, 0.9908, 0.9908,  ..., 0.9983, 0.9996, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8685.0068)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([117.3477, 117.3477, 117.3477,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.8442, 0.8442, 0.8442,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[2.4940e-01, 2.4994e-01, 2.5009e-01, 2.5058e-01],
        [2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],
        [2.4963e-01, 2.4989e-01, 2.4997e-01, 2.5052e-01],
        ...,
        [2.4959e-01, 2.5034e-01, 2.4957e-01, 2.5049e-01],
        [2.4957e-01, 2.5027e-01, 2.4969e-01, 2.5046e-01],
        [1.8273e-04, 4.9089e-07, 9.9965e-01, 1.6961e-04]])
Parameter containing:
tensor([[-0.0153,  0.0019,  0.0217,  ...,  0.0020,  0.0257, -0.0401],
        [ 0.0102,  0.0269, -0.0284,  ...,  0.0408,  0.0274, -0.0264],
        [-0.0052, -0.0243,  0.0103,  ...,  0.0170,  0.0344,  0.0187],
        ...,
        [ 0.0194,  0.0256,  0.1706,  ...,  0.0033,  0.0273, -0.0072],
        [ 0.0039, -0.0133, -0.0079,  ..., -0.0225, -0.0200,  0.0866],
        [ 0.0504,  0.0047, -0.0281,  ...,  0.0248,  0.0675,  0.0969]],
       requires_grad=True)
Exponential sum:  tensor(10335.9844)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([137.7295, 137.7295, 137.7295,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9908, 0.9908, 0.9908,  ..., 0.9983, 0.9996, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8685.0068)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([117.3477, 117.3477, 117.3477,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.8442, 0.8442, 0.8442,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[2.4940e-01, 2.4994e-01, 2.5009e-01, 2.5058e-01],
        [2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],
        [2.4963e-01, 2.4989e-01, 2.4997e-01, 2.5052e-01],
        ...,
        [2.4959e-01, 2.5034e-01, 2.4957e-01, 2.5049e-01],
        [2.4957e-01, 2.5027e-01, 2.4969e-01, 2.5046e-01],
        [1.8273e-04, 4.9089e-07, 9.9965e-01, 1.6961e-04]])
tensor(indices=tensor([[341],
                       [  0]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.)
tensor(0.)
Parameter containing:
tensor([[-0.0153,  0.0019,  0.0217,  ...,  0.0020,  0.0257, -0.0401],
        [ 0.0102,  0.0269, -0.0284,  ...,  0.0408,  0.0274, -0.0264],
        [-0.0052, -0.0243,  0.0103,  ...,  0.0170,  0.0344,  0.0187],
        ...,
        [ 0.0194,  0.0256,  0.1706,  ...,  0.0033,  0.0273, -0.0072],
        [ 0.0039, -0.0133, -0.0079,  ..., -0.0225, -0.0200,  0.0866],
        [ 0.0504,  0.0047, -0.0281,  ...,  0.0248,  0.0675,  0.0969]],
       requires_grad=True)
Exponential sum:  tensor(10335.9844)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([137.7295, 137.7295, 137.7295,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9908, 0.9908, 0.9908,  ..., 0.9983, 0.9996, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8685.0068)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([117.3477, 117.3477, 117.3477,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.8442, 0.8442, 0.8442,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[2.4940e-01, 2.4994e-01, 2.5009e-01, 2.5058e-01],
        [2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],
        [2.4963e-01, 2.4989e-01, 2.4997e-01, 2.5052e-01],
        ...,
        [2.4959e-01, 2.5034e-01, 2.4957e-01, 2.5049e-01],
        [2.4957e-01, 2.5027e-01, 2.4969e-01, 2.5046e-01],
        [1.8273e-04, 4.9089e-07, 9.9965e-01, 1.6961e-04]])
tensor(indices=tensor([[2597],
                       [   3]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[-0.0153,  0.0019,  0.0217,  ...,  0.0020,  0.0257, -0.0401],
        [ 0.0102,  0.0269, -0.0284,  ...,  0.0408,  0.0274, -0.0264],
        [-0.0052, -0.0243,  0.0103,  ...,  0.0170,  0.0344,  0.0187],
        ...,
        [ 0.0194,  0.0256,  0.1706,  ...,  0.0033,  0.0273, -0.0072],
        [ 0.0039, -0.0133, -0.0079,  ..., -0.0225, -0.0200,  0.0866],
        [ 0.0504,  0.0047, -0.0281,  ...,  0.0248,  0.0675,  0.0969]],
       requires_grad=True)
Exponential sum:  tensor(10335.9844)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([137.7295, 137.7295, 137.7295,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9908, 0.9908, 0.9908,  ..., 0.9983, 0.9996, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8685.0068)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([117.3477, 117.3477, 117.3477,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.8442, 0.8442, 0.8442,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[2.4940e-01, 2.4994e-01, 2.5009e-01, 2.5058e-01],
        [2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],
        [2.4963e-01, 2.4989e-01, 2.4997e-01, 2.5052e-01],
        ...,
        [2.4959e-01, 2.5034e-01, 2.4957e-01, 2.5049e-01],
        [2.4957e-01, 2.5027e-01, 2.4969e-01, 2.5046e-01],
        [1.8273e-04, 4.9089e-07, 9.9965e-01, 1.6961e-04]])
tensor(indices=tensor([[673],
                       [  2]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[-0.0153,  0.0019,  0.0217,  ...,  0.0020,  0.0257, -0.0401],
        [ 0.0102,  0.0269, -0.0284,  ...,  0.0408,  0.0274, -0.0264],
        [-0.0052, -0.0243,  0.0103,  ...,  0.0170,  0.0344,  0.0187],
        ...,
        [ 0.0194,  0.0256,  0.1706,  ...,  0.0033,  0.0273, -0.0072],
        [ 0.0039, -0.0133, -0.0079,  ..., -0.0225, -0.0200,  0.0866],
        [ 0.0504,  0.0047, -0.0281,  ...,  0.0248,  0.0675,  0.0969]],
       requires_grad=True)
Exponential sum:  tensor(10335.9844)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([137.7295, 137.7295, 137.7295,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9908, 0.9908, 0.9908,  ..., 0.9983, 0.9996, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8685.0068)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([117.3477, 117.3477, 117.3477,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.8442, 0.8442, 0.8442,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[2.4940e-01, 2.4994e-01, 2.5009e-01, 2.5058e-01],
        [2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],
        [2.4963e-01, 2.4989e-01, 2.4997e-01, 2.5052e-01],
        ...,
        [2.4959e-01, 2.5034e-01, 2.4957e-01, 2.5049e-01],
        [2.4957e-01, 2.5027e-01, 2.4969e-01, 2.5046e-01],
        [1.8273e-04, 4.9089e-07, 9.9965e-01, 1.6961e-04]])
tensor(indices=tensor([[2657],
                       [   3]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[-0.0153,  0.0019,  0.0217,  ...,  0.0020,  0.0257, -0.0401],
        [ 0.0102,  0.0269, -0.0284,  ...,  0.0408,  0.0274, -0.0264],
        [-0.0052, -0.0243,  0.0103,  ...,  0.0170,  0.0344,  0.0187],
        ...,
        [ 0.0194,  0.0256,  0.1706,  ...,  0.0033,  0.0273, -0.0072],
        [ 0.0039, -0.0133, -0.0079,  ..., -0.0225, -0.0200,  0.0866],
        [ 0.0504,  0.0047, -0.0281,  ...,  0.0248,  0.0675,  0.0969]],
       requires_grad=True)
Exponential sum:  tensor(10335.9844)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([137.7295, 137.7295, 137.7295,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9908, 0.9908, 0.9908,  ..., 0.9983, 0.9996, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8685.0068)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([117.3477, 117.3477, 117.3477,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.8442, 0.8442, 0.8442,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[2.4940e-01, 2.4994e-01, 2.5009e-01, 2.5058e-01],
        [2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],
        [2.4963e-01, 2.4989e-01, 2.4997e-01, 2.5052e-01],
        ...,
        [2.4959e-01, 2.5034e-01, 2.4957e-01, 2.5049e-01],
        [2.4957e-01, 2.5027e-01, 2.4969e-01, 2.5046e-01],
        [1.8273e-04, 4.9089e-07, 9.9965e-01, 1.6961e-04]])
tensor(indices=tensor([[865],
                       [  1]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[-0.0153,  0.0019,  0.0217,  ...,  0.0020,  0.0257, -0.0401],
        [ 0.0102,  0.0269, -0.0284,  ...,  0.0408,  0.0274, -0.0264],
        [-0.0052, -0.0243,  0.0103,  ...,  0.0170,  0.0344,  0.0187],
        ...,
        [ 0.0194,  0.0256,  0.1706,  ...,  0.0033,  0.0273, -0.0072],
        [ 0.0039, -0.0133, -0.0079,  ..., -0.0225, -0.0200,  0.0866],
        [ 0.0504,  0.0047, -0.0281,  ...,  0.0248,  0.0675,  0.0969]],
       requires_grad=True)
Exponential sum:  tensor(10335.9844)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([137.7295, 137.7295, 137.7295,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9908, 0.9908, 0.9908,  ..., 0.9983, 0.9996, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8685.0068)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([117.3477, 117.3477, 117.3477,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.8442, 0.8442, 0.8442,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[2.4940e-01, 2.4994e-01, 2.5009e-01, 2.5058e-01],
        [2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],
        [2.4963e-01, 2.4989e-01, 2.4997e-01, 2.5052e-01],
        ...,
        [2.4959e-01, 2.5034e-01, 2.4957e-01, 2.5049e-01],
        [2.4957e-01, 2.5027e-01, 2.4969e-01, 2.5046e-01],
        [1.8273e-04, 4.9089e-07, 9.9965e-01, 1.6961e-04]])
tensor(indices=tensor([[673],
                       [  2]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[-0.0153,  0.0019,  0.0217,  ...,  0.0020,  0.0257, -0.0401],
        [ 0.0102,  0.0269, -0.0284,  ...,  0.0408,  0.0274, -0.0264],
        [-0.0052, -0.0243,  0.0103,  ...,  0.0170,  0.0344,  0.0187],
        ...,
        [ 0.0194,  0.0256,  0.1706,  ...,  0.0033,  0.0273, -0.0072],
        [ 0.0039, -0.0133, -0.0079,  ..., -0.0225, -0.0200,  0.0866],
        [ 0.0504,  0.0047, -0.0281,  ...,  0.0248,  0.0675,  0.0969]],
       requires_grad=True)
Exponential sum:  tensor(10335.9844)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([137.7295, 137.7295, 137.7295,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9908, 0.9908, 0.9908,  ..., 0.9983, 0.9996, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8685.0068)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([117.3477, 117.3477, 117.3477,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.8442, 0.8442, 0.8442,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[2.4940e-01, 2.4994e-01, 2.5009e-01, 2.5058e-01],
        [2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],
        [2.4963e-01, 2.4989e-01, 2.4997e-01, 2.5052e-01],
        ...,
        [2.4959e-01, 2.5034e-01, 2.4957e-01, 2.5049e-01],
        [2.4957e-01, 2.5027e-01, 2.4969e-01, 2.5046e-01],
        [1.8273e-04, 4.9089e-07, 9.9965e-01, 1.6961e-04]])
tensor(indices=tensor([[2657],
                       [   3]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[-0.0153,  0.0019,  0.0217,  ...,  0.0020,  0.0257, -0.0401],
        [ 0.0102,  0.0269, -0.0284,  ...,  0.0408,  0.0274, -0.0264],
        [-0.0052, -0.0243,  0.0103,  ...,  0.0170,  0.0344,  0.0187],
        ...,
        [ 0.0194,  0.0256,  0.1706,  ...,  0.0033,  0.0273, -0.0072],
        [ 0.0039, -0.0133, -0.0079,  ..., -0.0225, -0.0200,  0.0866],
        [ 0.0504,  0.0047, -0.0281,  ...,  0.0248,  0.0675,  0.0969]],
       requires_grad=True)
Exponential sum:  tensor(10335.9844)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([137.7295, 137.7295, 137.7295,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9908, 0.9908, 0.9908,  ..., 0.9983, 0.9996, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8685.0068)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([117.3477, 117.3477, 117.3477,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.8442, 0.8442, 0.8442,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[2.4940e-01, 2.4994e-01, 2.5009e-01, 2.5058e-01],
        [2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],
        [2.4963e-01, 2.4989e-01, 2.4997e-01, 2.5052e-01],
        ...,
        [2.4959e-01, 2.5034e-01, 2.4957e-01, 2.5049e-01],
        [2.4957e-01, 2.5027e-01, 2.4969e-01, 2.5046e-01],
        [1.8273e-04, 4.9089e-07, 9.9965e-01, 1.6961e-04]])
tensor(indices=tensor([[2597],
                       [   3]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[-0.0153,  0.0019,  0.0217,  ...,  0.0020,  0.0257, -0.0401],
        [ 0.0102,  0.0269, -0.0284,  ...,  0.0408,  0.0274, -0.0264],
        [-0.0052, -0.0243,  0.0103,  ...,  0.0170,  0.0344,  0.0187],
        ...,
        [ 0.0194,  0.0256,  0.1706,  ...,  0.0033,  0.0273, -0.0072],
        [ 0.0039, -0.0133, -0.0079,  ..., -0.0225, -0.0200,  0.0866],
        [ 0.0504,  0.0047, -0.0281,  ...,  0.0248,  0.0675,  0.0969]],
       requires_grad=True)
Exponential sum:  tensor(10335.9844)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([137.7295, 137.7295, 137.7295,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9908, 0.9908, 0.9908,  ..., 0.9983, 0.9996, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8685.0068)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([117.3477, 117.3477, 117.3477,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.8442, 0.8442, 0.8442,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[2.4940e-01, 2.4994e-01, 2.5009e-01, 2.5058e-01],
        [2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],
        [2.4963e-01, 2.4989e-01, 2.4997e-01, 2.5052e-01],
        ...,
        [2.4959e-01, 2.5034e-01, 2.4957e-01, 2.5049e-01],
        [2.4957e-01, 2.5027e-01, 2.4969e-01, 2.5046e-01],
        [1.8273e-04, 4.9089e-07, 9.9965e-01, 1.6961e-04]])
tensor(indices=tensor([[2657],
                       [   3]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[-0.0153,  0.0019,  0.0217,  ...,  0.0020,  0.0257, -0.0401],
        [ 0.0102,  0.0269, -0.0284,  ...,  0.0408,  0.0274, -0.0264],
        [-0.0052, -0.0243,  0.0103,  ...,  0.0170,  0.0344,  0.0187],
        ...,
        [ 0.0194,  0.0256,  0.1706,  ...,  0.0033,  0.0273, -0.0072],
        [ 0.0039, -0.0133, -0.0079,  ..., -0.0225, -0.0200,  0.0866],
        [ 0.0504,  0.0047, -0.0281,  ...,  0.0248,  0.0675,  0.0969]],
       requires_grad=True)
Exponential sum:  tensor(10335.9844)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([137.7295, 137.7295, 137.7295,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9908, 0.9908, 0.9908,  ..., 0.9983, 0.9996, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8685.0068)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([117.3477, 117.3477, 117.3477,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.8442, 0.8442, 0.8442,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[2.4940e-01, 2.4994e-01, 2.5009e-01, 2.5058e-01],
        [2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],
        [2.4963e-01, 2.4989e-01, 2.4997e-01, 2.5052e-01],
        ...,
        [2.4959e-01, 2.5034e-01, 2.4957e-01, 2.5049e-01],
        [2.4957e-01, 2.5027e-01, 2.4969e-01, 2.5046e-01],
        [1.8273e-04, 4.9089e-07, 9.9965e-01, 1.6961e-04]])
tensor(indices=tensor([[673],
                       [  2]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[-0.0153,  0.0019,  0.0217,  ...,  0.0020,  0.0257, -0.0401],
        [ 0.0102,  0.0269, -0.0284,  ...,  0.0408,  0.0274, -0.0264],
        [-0.0052, -0.0243,  0.0103,  ...,  0.0170,  0.0344,  0.0187],
        ...,
        [ 0.0194,  0.0256,  0.1706,  ...,  0.0033,  0.0273, -0.0072],
        [ 0.0039, -0.0133, -0.0079,  ..., -0.0225, -0.0200,  0.0866],
        [ 0.0504,  0.0047, -0.0281,  ...,  0.0248,  0.0675,  0.0969]],
       requires_grad=True)
Exponential sum:  tensor(10335.9844)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([137.7295, 137.7295, 137.7295,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.9908, 0.9908, 0.9908,  ..., 0.9983, 0.9996, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8685.0068)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [  73,   73,   73,  ..., 2821, 2821, 2821],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([117.3477, 117.3477, 117.3477,  ...,   1.0000,
                        1.0000,   1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.8442, 0.8442, 0.8442,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [  73,   73,   73,  ...,  200,  885, 2821],
                       [  13,   18,   31,  ..., 1772, 1505, 1183]]),
       values=tensor([0.0072, 0.0072, 0.0072,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[2.4940e-01, 2.4994e-01, 2.5009e-01, 2.5058e-01],
        [2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],
        [2.4963e-01, 2.4989e-01, 2.4997e-01, 2.5052e-01],
        ...,
        [2.4959e-01, 2.5034e-01, 2.4957e-01, 2.5049e-01],
        [2.4957e-01, 2.5027e-01, 2.4969e-01, 2.5046e-01],
        [1.8273e-04, 4.9089e-07, 9.9965e-01, 1.6961e-04]])
tensor(indices=tensor([[865],
                       [  1]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
count_nodes_self:  0
count_edges_self:  0
Epoch: 25, Loss: 0.9938, Train: 0.7475 Test: 0.5000
