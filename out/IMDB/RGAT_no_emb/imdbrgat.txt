Labels loaded.
RDF loaded.
Graph loaded.
8
0
NVIDIA RTX A6000
8
cuda:  True
0
shape edges:  torch.Size([10430, 3])
num_classes:  4
num_nodes:  2929
num_relations:  28
Parameter containing:
tensor([[ 0.2146, -0.0485, -0.3186,  ...,  0.2023,  0.5307, -0.0446],
        [ 0.1804,  0.0310,  0.0221,  ..., -0.2495, -0.2175, -0.0780],
        [ 0.2934, -0.2230,  0.4211,  ..., -0.2004, -0.1680,  0.0372],
        ...,
        [ 0.0009,  0.1404,  0.2962,  ...,  0.0024, -0.2517, -0.1168],
        [ 0.0970,  0.1029, -0.1037,  ...,  0.1233,  0.1284, -0.0795],
        [-0.1544, -0.0703, -0.0683,  ...,  0.0292, -0.1934,  0.1590]],
       requires_grad=True)
Exponential sum:  tensor(8998.1377, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5526, 0.5526, 0.5526,  ..., 0.8546, 0.8546, 0.8546]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5526, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8546]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(7150.1992, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1.0000, 1.0000, 1.0000,  ..., 0.9050, 0.9957, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2663, 0.2468, 0.2595, 0.2274],
        [0.2700, 0.2401, 0.2622, 0.2276],
        ...,
        [0.2608, 0.2534, 0.2620, 0.2238],
        [0.2536, 0.2395, 0.2570, 0.2499],
        [0.2412, 0.2568, 0.2703, 0.2317]], grad_fn=<SoftmaxBackward0>)
Epoch: 0001 loss: 1.3872 acc_train: 0.2302
Parameter containing:
tensor([[ 0.2046, -0.0385, -0.3086,  ...,  0.1923,  0.5207, -0.0346],
        [ 0.1704,  0.0210,  0.0121,  ..., -0.2395, -0.2075, -0.0680],
        [ 0.2834, -0.2130,  0.4111,  ..., -0.1904, -0.1580,  0.0272],
        ...,
        [-0.0089,  0.1304,  0.2862,  ..., -0.0075, -0.2417, -0.1068],
        [ 0.0870,  0.0929, -0.0937,  ...,  0.1133,  0.1184, -0.0695],
        [-0.1444, -0.0603, -0.0583,  ...,  0.0192, -0.1834,  0.1490]],
       requires_grad=True)
Exponential sum:  tensor(9132.6465, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5913, 0.5913, 0.5913,  ..., 0.8743, 0.8743, 0.8743]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5913, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8743]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(7430.2358, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1.0000, 1.0000, 1.0000,  ..., 0.9301, 0.9951, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2558, 0.2474, 0.2546, 0.2421],
        [0.2622, 0.2416, 0.2575, 0.2387],
        ...,
        [0.2518, 0.2548, 0.2578, 0.2356],
        [0.2454, 0.2406, 0.2535, 0.2605],
        [0.2351, 0.2595, 0.2619, 0.2435]], grad_fn=<SoftmaxBackward0>)
Epoch: 0002 loss: 1.3784 acc_train: 0.4380
Parameter containing:
tensor([[ 0.1946, -0.0287, -0.2986,  ...,  0.1823,  0.5107, -0.0247],
        [ 0.1604,  0.0113,  0.0027,  ..., -0.2295, -0.1976, -0.0581],
        [ 0.2734, -0.2030,  0.4011,  ..., -0.1804, -0.1480,  0.0174],
        ...,
        [-0.0023,  0.1204,  0.2762,  ..., -0.0027, -0.2317, -0.0969],
        [ 0.0770,  0.0830, -0.0838,  ...,  0.1033,  0.1085, -0.0596],
        [-0.1344, -0.0503, -0.0484,  ...,  0.0095, -0.1734,  0.1390]],
       requires_grad=True)
Exponential sum:  tensor(9237.4365, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.6185, 0.6185, 0.6185,  ..., 0.8903, 0.8903, 0.8903]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.6185, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8903]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(7594.7568, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1.0000, 1.0000, 1.0000,  ..., 0.9481, 0.9958, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2497, 0.2470, 0.2504, 0.2529],
        [0.2566, 0.2420, 0.2538, 0.2476],
        ...,
        [0.2478, 0.2557, 0.2534, 0.2432],
        [0.2394, 0.2417, 0.2504, 0.2685],
        [0.2328, 0.2608, 0.2549, 0.2515]], grad_fn=<SoftmaxBackward0>)
Epoch: 0003 loss: 1.3690 acc_train: 0.4179
Parameter containing:
tensor([[ 0.1846, -0.0191, -0.2886,  ...,  0.1724,  0.5007, -0.0152],
        [ 0.1504,  0.0023, -0.0053,  ..., -0.2195, -0.1876, -0.0482],
        [ 0.2634, -0.1930,  0.3912,  ..., -0.1705, -0.1381,  0.0081],
        ...,
        [ 0.0042,  0.1105,  0.2662,  ...,  0.0028, -0.2218, -0.0870],
        [ 0.0671,  0.0731, -0.0739,  ...,  0.0934,  0.0986, -0.0498],
        [-0.1245, -0.0406, -0.0386,  ...,  0.0006, -0.1634,  0.1291]],
       requires_grad=True)
Exponential sum:  tensor(9314.2295, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.6421, 0.6421, 0.6421,  ..., 0.9038, 0.9038, 0.9038]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.6421, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9038]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(7657.4287, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1.0000, 1.0000, 1.0000,  ..., 0.9618, 0.9976, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2462, 0.2471, 0.2474, 0.2593],
        [0.2527, 0.2425, 0.2511, 0.2537],
        ...,
        [0.2460, 0.2569, 0.2492, 0.2479],
        [0.2353, 0.2435, 0.2477, 0.2735],
        [0.2334, 0.2603, 0.2503, 0.2561]], grad_fn=<SoftmaxBackward0>)
Epoch: 0004 loss: 1.3568 acc_train: 0.4168
Parameter containing:
tensor([[ 1.7471e-01, -9.9301e-03, -2.7869e-01,  ...,  1.6245e-01,
          4.9076e-01, -6.1971e-03],
        [ 1.4055e-01, -5.4573e-03, -1.0442e-02,  ..., -2.0959e-01,
         -1.7767e-01, -3.8595e-02],
        [ 2.5346e-01, -1.8312e-01,  3.8119e-01,  ..., -1.6054e-01,
         -1.2818e-01, -3.9654e-04],
        ...,
        [ 6.5465e-03,  1.0060e-01,  2.5626e-01,  ...,  5.1634e-03,
         -2.1185e-01, -7.7149e-02],
        [ 5.7383e-02,  6.3297e-02, -6.4105e-02,  ...,  8.3602e-02,
          8.8723e-02, -4.0120e-02],
        [-1.1458e-01, -3.0983e-02, -2.9037e-02,  ..., -6.7211e-03,
         -1.5352e-01,  1.1919e-01]], requires_grad=True)
Exponential sum:  tensor(9385.8516, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.6660, 0.6660, 0.6660,  ..., 0.9156, 0.9156, 0.9156]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.6660, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9156]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(7784.3887, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1.0000, 1.0000, 1.0000,  ..., 0.9717, 0.9992, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2444, 0.2475, 0.2454, 0.2627],
        [0.2501, 0.2430, 0.2495, 0.2573],
        ...,
        [0.2456, 0.2584, 0.2459, 0.2501],
        [0.2336, 0.2452, 0.2455, 0.2758],
        [0.2356, 0.2593, 0.2470, 0.2581]], grad_fn=<SoftmaxBackward0>)
Epoch: 0005 loss: 1.3395 acc_train: 0.4302
Parameter containing:
tensor([[ 0.1648, -0.0015, -0.2688,  ...,  0.1526,  0.4808,  0.0019],
        [ 0.1307, -0.0112, -0.0125,  ..., -0.1997, -0.1678, -0.0292],
        [ 0.2435, -0.1732,  0.3713,  ..., -0.1507, -0.1184, -0.0075],
        ...,
        [ 0.0052,  0.0908,  0.2463,  ...,  0.0040, -0.2020, -0.0675],
        [ 0.0478,  0.0537, -0.0545,  ...,  0.0739,  0.0790, -0.0307],
        [-0.1048, -0.0217, -0.0198,  ..., -0.0118, -0.1437,  0.1094]],
       requires_grad=True)
Exponential sum:  tensor(9419.3799, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.6869, 0.6869, 0.6869,  ..., 0.9259, 0.9259, 0.9259]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.6869, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9259]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(7841.9443, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1.0000, 1.0000, 1.0000,  ..., 0.9792, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2438, 0.2479, 0.2442, 0.2641],
        [0.2485, 0.2435, 0.2482, 0.2598],
        ...,
        [0.2454, 0.2595, 0.2435, 0.2516],
        [0.2337, 0.2464, 0.2437, 0.2762],
        [0.2382, 0.2577, 0.2455, 0.2586]], grad_fn=<SoftmaxBackward0>)
Epoch: 0006 loss: 1.3163 acc_train: 0.4402
Parameter containing:
tensor([[ 0.1550,  0.0058, -0.2589,  ...,  0.1428,  0.4709,  0.0087],
        [ 0.1210, -0.0145, -0.0119,  ..., -0.1899, -0.1580, -0.0202],
        [ 0.2337, -0.1634,  0.3613,  ..., -0.1409, -0.1086, -0.0128],
        ...,
        [ 0.0020,  0.0812,  0.2365,  ...,  0.0012, -0.1921, -0.0580],
        [ 0.0385,  0.0443, -0.0451,  ...,  0.0643,  0.0694, -0.0217],
        [-0.0951, -0.0130, -0.0111,  ..., -0.0144, -0.1339,  0.0997]],
       requires_grad=True)
Exponential sum:  tensor(9395.2539, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.7073, 0.7073, 0.7073,  ..., 0.9349, 0.9349, 0.9349]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.7073, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9349]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(7823.0654, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1.0000, 1.0000, 1.0000,  ..., 0.9856, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2438, 0.2481, 0.2434, 0.2647],
        [0.2475, 0.2441, 0.2465, 0.2618],
        ...,
        [0.2456, 0.2601, 0.2421, 0.2522],
        [0.2345, 0.2473, 0.2427, 0.2754],
        [0.2407, 0.2564, 0.2448, 0.2581]], grad_fn=<SoftmaxBackward0>)
Epoch: 0007 loss: 1.2883 acc_train: 0.4648
Parameter containing:
tensor([[ 0.1453,  0.0118, -0.2491,  ...,  0.1331,  0.4610,  0.0139],
        [ 0.1113, -0.0155, -0.0097,  ..., -0.1801, -0.1483, -0.0117],
        [ 0.2239, -0.1537,  0.3515,  ..., -0.1312, -0.0990, -0.0161],
        ...,
        [-0.0015,  0.0717,  0.2267,  ..., -0.0019, -0.1823, -0.0487],
        [ 0.0295,  0.0352, -0.0359,  ...,  0.0550,  0.0600, -0.0131],
        [-0.0856, -0.0048, -0.0031,  ..., -0.0147, -0.1242,  0.0901]],
       requires_grad=True)
Exponential sum:  tensor(9410.1836, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.7283, 0.7283, 0.7283,  ..., 0.9430, 0.9430, 0.9430]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.7283, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9430]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(7831.5874, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1.0000, 1.0000, 1.0000,  ..., 0.9901, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2444, 0.2481, 0.2429, 0.2646],
        [0.2468, 0.2447, 0.2451, 0.2633],
        ...,
        [0.2461, 0.2604, 0.2413, 0.2522],
        [0.2359, 0.2478, 0.2423, 0.2739],
        [0.2426, 0.2557, 0.2447, 0.2570]], grad_fn=<SoftmaxBackward0>)
Epoch: 0008 loss: 1.2611 acc_train: 0.4883
Parameter containing:
tensor([[ 0.1357,  0.0162, -0.2393,  ...,  0.1235,  0.4511,  0.0173],
        [ 0.1018, -0.0147, -0.0063,  ..., -0.1704, -0.1386, -0.0038],
        [ 0.2141, -0.1441,  0.3416,  ..., -0.1216, -0.0896, -0.0173],
        ...,
        [-0.0041,  0.0624,  0.2169,  ..., -0.0038, -0.1726, -0.0396],
        [ 0.0208,  0.0264, -0.0271,  ...,  0.0459,  0.0508, -0.0051],
        [-0.0762,  0.0026,  0.0042,  ..., -0.0132, -0.1147,  0.0807]],
       requires_grad=True)
Exponential sum:  tensor(9454.7793, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.7509, 0.7509, 0.7509,  ..., 0.9503, 0.9503, 0.9503]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.7509, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9503]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(7853.2178, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1.0000, 1.0000, 0.9779,  ..., 0.9930, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2451, 0.2482, 0.2430, 0.2636],
        [0.2464, 0.2456, 0.2444, 0.2635],
        ...,
        [0.2466, 0.2603, 0.2411, 0.2520],
        [0.2376, 0.2483, 0.2424, 0.2717],
        [0.2442, 0.2552, 0.2448, 0.2558]], grad_fn=<SoftmaxBackward0>)
Epoch: 0009 loss: 1.2396 acc_train: 0.5307
Parameter containing:
tensor([[ 0.1262,  0.0190, -0.2296,  ...,  0.1141,  0.4412,  0.0190],
        [ 0.0924, -0.0125, -0.0025,  ..., -0.1608, -0.1291,  0.0034],
        [ 0.2044, -0.1345,  0.3318,  ..., -0.1122, -0.0803, -0.0169],
        ...,
        [-0.0049,  0.0534,  0.2072,  ..., -0.0038, -0.1630, -0.0309],
        [ 0.0127,  0.0180, -0.0187,  ...,  0.0370,  0.0419,  0.0022],
        [-0.0670,  0.0091,  0.0104,  ..., -0.0106, -0.1052,  0.0715]],
       requires_grad=True)
Exponential sum:  tensor(9519.1904, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.7751, 0.7751, 0.7751,  ..., 0.9571, 0.9571, 0.9571]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.7751, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9571]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(7912.5391, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1.0000, 1.0000, 0.9608,  ..., 0.9947, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2455, 0.2483, 0.2437, 0.2624],
        [0.2465, 0.2466, 0.2442, 0.2626],
        ...,
        [0.2470, 0.2601, 0.2414, 0.2515],
        [0.2394, 0.2486, 0.2430, 0.2690],
        [0.2455, 0.2547, 0.2452, 0.2546]], grad_fn=<SoftmaxBackward0>)
Epoch: 0010 loss: 1.2222 acc_train: 0.5609
Parameter containing:
tensor([[ 0.1168,  0.0202, -0.2199,  ...,  0.1047,  0.4314,  0.0192],
        [ 0.0832, -0.0094,  0.0012,  ..., -0.1513, -0.1197,  0.0096],
        [ 0.1948, -0.1251,  0.3221,  ..., -0.1029, -0.0712, -0.0152],
        ...,
        [-0.0040,  0.0446,  0.1976,  ..., -0.0024, -0.1535, -0.0226],
        [ 0.0051,  0.0102, -0.0109,  ...,  0.0286,  0.0333,  0.0086],
        [-0.0580,  0.0144,  0.0155,  ..., -0.0072, -0.0960,  0.0625]],
       requires_grad=True)
Exponential sum:  tensor(9595.6709, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.8004, 0.8004, 0.8004,  ..., 0.9635, 0.9635, 0.9635]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.8004, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9635]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(8063.5352, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1.0000, 1.0000, 0.9501,  ..., 0.9959, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2458, 0.2485, 0.2446, 0.2611],
        [0.2468, 0.2475, 0.2446, 0.2611],
        ...,
        [0.2473, 0.2597, 0.2421, 0.2509],
        [0.2412, 0.2488, 0.2439, 0.2662],
        [0.2465, 0.2542, 0.2458, 0.2535]], grad_fn=<SoftmaxBackward0>)
Epoch: 0011 loss: 1.2047 acc_train: 0.5665
Parameter containing:
tensor([[ 1.0757e-01,  1.9956e-02, -2.1036e-01,  ...,  9.5564e-02,
          4.2165e-01,  1.8049e-02],
        [ 7.4246e-02, -5.8143e-03,  4.4169e-03,  ..., -1.4190e-01,
         -1.1048e-01,  1.4872e-02],
        [ 1.8532e-01, -1.1583e-01,  3.1237e-01,  ..., -9.3702e-02,
         -6.2300e-02, -1.2488e-02],
        ...,
        [-1.9933e-03,  3.6106e-02,  1.8810e-01,  ..., -3.1082e-04,
         -1.4413e-01, -1.4738e-02],
        [-1.8524e-03,  2.8824e-03, -3.5469e-03,  ...,  2.0489e-02,
          2.5122e-02,  1.4011e-02],
        [-4.9309e-02,  1.8632e-02,  1.9383e-02,  ..., -3.4563e-03,
         -8.6854e-02,  5.3693e-02]], requires_grad=True)
Exponential sum:  tensor(9676.5557, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.8284, 0.8284, 0.8284,  ..., 0.9693, 0.9693, 0.9693]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.8284, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9693]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(8372.7432, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1.0000, 1.0000, 0.9449,  ..., 0.9967, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2459, 0.2489, 0.2455, 0.2596],
        [0.2472, 0.2484, 0.2451, 0.2592],
        ...,
        [0.2474, 0.2588, 0.2430, 0.2509],
        [0.2428, 0.2488, 0.2449, 0.2635],
        [0.2473, 0.2538, 0.2463, 0.2526]], grad_fn=<SoftmaxBackward0>)
Epoch: 0012 loss: 1.1857 acc_train: 0.5743
Parameter containing:
tensor([[ 9.8504e-02,  1.8605e-02, -2.0089e-01,  ...,  8.6587e-02,
          4.1193e-01,  1.5903e-02],
        [ 6.5474e-02, -2.0360e-03,  6.6701e-03,  ..., -1.3265e-01,
         -1.0140e-01,  1.9059e-02],
        [ 1.7591e-01, -1.0671e-01,  3.0274e-01,  ..., -8.4740e-02,
         -5.3682e-02, -9.1525e-03],
        ...,
        [ 3.9795e-04,  2.7992e-02,  1.7869e-01,  ...,  1.7123e-03,
         -1.3487e-01, -7.3908e-03],
        [-8.0323e-03, -3.7216e-03,  3.1085e-03,  ...,  1.2888e-02,
          1.7345e-02,  1.8407e-02],
        [-4.0912e-02,  2.1615e-02,  2.2037e-02,  ...,  2.3815e-04,
         -7.7955e-02,  4.5209e-02]], requires_grad=True)
Exponential sum:  tensor(9760.2129, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.8578, 0.8578, 0.8578,  ..., 0.9745, 0.9745, 0.9745]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.8578, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9745]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(8817.3740, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1.0000, 1.0000, 0.9515,  ..., 0.9973, 0.9993, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2459, 0.2495, 0.2462, 0.2584],
        [0.2477, 0.2490, 0.2458, 0.2575],
        ...,
        [0.2472, 0.2574, 0.2441, 0.2513],
        [0.2442, 0.2488, 0.2461, 0.2609],
        [0.2480, 0.2532, 0.2467, 0.2521]], grad_fn=<SoftmaxBackward0>)
Epoch: 0013 loss: 1.1672 acc_train: 0.6268
Parameter containing:
tensor([[ 0.0896,  0.0163, -0.1915,  ...,  0.0778,  0.4023,  0.0130],
        [ 0.0570,  0.0016,  0.0078,  ..., -0.1235, -0.0925,  0.0221],
        [ 0.1666, -0.0978,  0.2932,  ..., -0.0760, -0.0454, -0.0055],
        ...,
        [ 0.0024,  0.0203,  0.1694,  ...,  0.0029, -0.1257, -0.0006],
        [-0.0134, -0.0096,  0.0090,  ...,  0.0058,  0.0101,  0.0217],
        [-0.0329,  0.0234,  0.0235,  ...,  0.0035, -0.0693,  0.0370]],
       requires_grad=True)
Exponential sum:  tensor(9841.9512, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.8841, 0.8841, 0.8841,  ..., 0.9789, 0.9789, 0.9789]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.8841, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9789]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(9059.4941, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1.0000, 1.0000, 0.9613,  ..., 0.9979, 0.9989, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2457, 0.2498, 0.2471, 0.2574],
        [0.2481, 0.2493, 0.2466, 0.2560],
        ...,
        [0.2471, 0.2558, 0.2452, 0.2519],
        [0.2453, 0.2487, 0.2473, 0.2587],
        [0.2485, 0.2526, 0.2472, 0.2517]], grad_fn=<SoftmaxBackward0>)
Epoch: 0014 loss: 1.1496 acc_train: 0.6380
Parameter containing:
tensor([[ 0.0810,  0.0134, -0.1823,  ...,  0.0693,  0.3926,  0.0096],
        [ 0.0487,  0.0047,  0.0077,  ..., -0.1146, -0.0838,  0.0241],
        [ 0.1574, -0.0890,  0.2837,  ..., -0.0675, -0.0373, -0.0018],
        ...,
        [ 0.0035,  0.0130,  0.1602,  ...,  0.0028, -0.1168,  0.0055],
        [-0.0179, -0.0147,  0.0142,  ..., -0.0007,  0.0033,  0.0240],
        [-0.0252,  0.0241,  0.0239,  ...,  0.0061, -0.0609,  0.0292]],
       requires_grad=True)
Exponential sum:  tensor(9919.8789, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9050, 0.9050, 0.9050,  ..., 0.9828, 0.9828, 0.9828]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9050, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9828]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(9054.8604, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1.0000, 1.0000, 0.9700,  ..., 0.9983, 0.9987, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2454, 0.2502, 0.2479, 0.2565],
        [0.2484, 0.2494, 0.2475, 0.2547],
        ...,
        [0.2469, 0.2544, 0.2462, 0.2525],
        [0.2462, 0.2487, 0.2484, 0.2567],
        [0.2487, 0.2521, 0.2478, 0.2515]], grad_fn=<SoftmaxBackward0>)
Epoch: 0015 loss: 1.1314 acc_train: 0.6413
Parameter containing:
tensor([[ 0.0725,  0.0100, -0.1731,  ...,  0.0610,  0.3831,  0.0060],
        [ 0.0408,  0.0070,  0.0067,  ..., -0.1058, -0.0753,  0.0251],
        [ 0.1484, -0.0805,  0.2743,  ..., -0.0592, -0.0297,  0.0017],
        ...,
        [ 0.0034,  0.0063,  0.1512,  ...,  0.0017, -0.1080,  0.0109],
        [-0.0215, -0.0189,  0.0185,  ..., -0.0066, -0.0029,  0.0252],
        [-0.0179,  0.0238,  0.0233,  ...,  0.0078, -0.0527,  0.0218]],
       requires_grad=True)
Exponential sum:  tensor(9986.1973, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9210, 0.9210, 0.9210,  ..., 0.9860, 0.9860, 0.9860]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9210, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9860]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(9075.5771, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1.0000, 1.0000, 0.9752,  ..., 0.9986, 0.9988, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2455, 0.2502, 0.2485, 0.2558],
        [0.2488, 0.2495, 0.2482, 0.2535],
        ...,
        [0.2469, 0.2531, 0.2471, 0.2529],
        [0.2470, 0.2486, 0.2494, 0.2550],
        [0.2487, 0.2515, 0.2484, 0.2514]], grad_fn=<SoftmaxBackward0>)
Epoch: 0016 loss: 1.1146 acc_train: 0.6492
Parameter containing:
tensor([[ 6.4316e-02,  6.4481e-03, -1.6411e-01,  ...,  5.2979e-02,
          3.7359e-01,  2.3402e-03],
        [ 3.3204e-02,  8.4672e-03,  4.9135e-03,  ..., -9.7246e-02,
         -6.7088e-02,  2.5145e-02],
        [ 1.3953e-01, -7.2173e-02,  2.6496e-01,  ..., -5.1228e-02,
         -2.2430e-02,  4.7829e-03],
        ...,
        [ 2.2578e-03,  5.2155e-05,  1.4226e-01,  ...,  1.5808e-04,
         -9.9401e-02,  1.5645e-02],
        [-2.4147e-02, -2.2255e-02,  2.1944e-02,  ..., -1.1746e-02,
         -8.4137e-03,  2.5432e-02],
        [-1.1113e-02,  2.2625e-02,  2.1849e-02,  ...,  8.5464e-03,
         -4.4861e-02,  1.4839e-02]], requires_grad=True)
Exponential sum:  tensor(10046.7881, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9337, 0.9337, 0.9337,  ..., 0.9888, 0.9888, 0.9888]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9337, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9888]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(8961.0781, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([1.0000, 1.0000, 1.0000,  ..., 0.9999, 0.9999, 0.9999]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1.0000, 1.0000, 0.9799,  ..., 0.9990, 0.9991, 0.9999]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2459, 0.2502, 0.2490, 0.2550],
        [0.2489, 0.2497, 0.2488, 0.2527],
        ...,
        [0.2471, 0.2520, 0.2479, 0.2530],
        [0.2476, 0.2488, 0.2500, 0.2536],
        [0.2488, 0.2511, 0.2489, 0.2512]], grad_fn=<SoftmaxBackward0>)
Epoch: 0017 loss: 1.1013 acc_train: 0.6581
Parameter containing:
tensor([[ 0.0564,  0.0028, -0.1552,  ...,  0.0453,  0.3642, -0.0011],
        [ 0.0260,  0.0090,  0.0027,  ..., -0.0889, -0.0591,  0.0243],
        [ 0.1308, -0.0641,  0.2557,  ..., -0.0436, -0.0156,  0.0072],
        ...,
        [ 0.0006, -0.0056,  0.1335,  ..., -0.0013, -0.0910,  0.0196],
        [-0.0259, -0.0248,  0.0246,  ..., -0.0162, -0.0133,  0.0248],
        [-0.0048,  0.0207,  0.0197,  ...,  0.0083, -0.0373,  0.0083]],
       requires_grad=True)
Exponential sum:  tensor(10104.5430, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9444, 0.9444, 0.9444,  ..., 0.9912, 0.9912, 0.9912]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9444, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9912]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(8800.5537, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9369, 0.9369, 0.9369,  ..., 0.9994, 0.9994, 0.9994]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9369, 0.9065, 0.9830,  ..., 0.9993, 0.9992, 0.9994]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2464, 0.2501, 0.2493, 0.2543],
        [0.2490, 0.2498, 0.2492, 0.2520],
        ...,
        [0.2475, 0.2512, 0.2486, 0.2527],
        [0.2481, 0.2491, 0.2505, 0.2523],
        [0.2489, 0.2508, 0.2492, 0.2512]], grad_fn=<SoftmaxBackward0>)
Epoch: 0018 loss: 1.0899 acc_train: 0.6715
Parameter containing:
tensor([[ 4.8755e-02, -6.2327e-04, -1.4652e-01,  ...,  3.7877e-02,
          3.5480e-01, -4.1961e-03],
        [ 1.9156e-02,  8.5768e-03,  3.3628e-04,  ..., -8.0732e-02,
         -5.1430e-02,  2.2813e-02],
        [ 1.2225e-01, -5.6338e-02,  2.4660e-01,  ..., -3.6203e-02,
         -9.1874e-03,  8.7506e-03],
        ...,
        [-1.0719e-03, -1.0632e-02,  1.2494e-01,  ..., -2.1866e-03,
         -8.2833e-02,  2.2782e-02],
        [-2.6890e-02, -2.6447e-02,  2.6326e-02,  ..., -2.0009e-02,
         -1.7486e-02,  2.3499e-02],
        [ 1.0021e-03,  1.8249e-02,  1.7087e-02,  ...,  7.2931e-03,
         -3.0163e-02,  2.2881e-03]], requires_grad=True)
Exponential sum:  tensor(10155.8740, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9532, 0.9532, 0.9532,  ..., 0.9933, 0.9933, 0.9933]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9532, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9933]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(8651.5381, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.7460, 0.7460, 0.7460,  ..., 0.9993, 0.9993, 0.9993]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.7460, 0.6515, 0.9856,  ..., 0.9996, 0.9994, 0.9993]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2470, 0.2500, 0.2495, 0.2535],
        [0.2490, 0.2499, 0.2495, 0.2515],
        ...,
        [0.2480, 0.2507, 0.2491, 0.2522],
        [0.2482, 0.2494, 0.2509, 0.2515],
        [0.2490, 0.2506, 0.2493, 0.2511]], grad_fn=<SoftmaxBackward0>)
Epoch: 0019 loss: 1.0795 acc_train: 0.6737
Parameter containing:
tensor([[ 0.0414, -0.0037, -0.1380,  ...,  0.0308,  0.3455, -0.0067],
        [ 0.0127,  0.0074, -0.0018,  ..., -0.0728, -0.0440,  0.0207],
        [ 0.1139, -0.0488,  0.2376,  ..., -0.0292, -0.0033,  0.0095],
        ...,
        [-0.0023, -0.0150,  0.1165,  ..., -0.0021, -0.0749,  0.0252],
        [-0.0271, -0.0273,  0.0273,  ..., -0.0231, -0.0210,  0.0215],
        [ 0.0063,  0.0153,  0.0140,  ...,  0.0056, -0.0234, -0.0032]],
       requires_grad=True)
Exponential sum:  tensor(10198.1123, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9600, 0.9600, 0.9600,  ..., 0.9950, 0.9950, 0.9950]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9600, 1.0000, 1.0000,  ..., 0.9991, 1.0000, 0.9950]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(8572.9990, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.6164, 0.6164, 0.6164,  ..., 0.9993, 0.9993, 0.9993]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.6164, 0.4959, 0.9876,  ..., 0.9999, 0.9995, 0.9993]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2477, 0.2499, 0.2495, 0.2529],
        [0.2492, 0.2500, 0.2497, 0.2511],
        ...,
        [0.2484, 0.2504, 0.2494, 0.2518],
        [0.2484, 0.2496, 0.2509, 0.2510],
        [0.2491, 0.2505, 0.2494, 0.2510]], grad_fn=<SoftmaxBackward0>)
Epoch: 0020 loss: 1.0722 acc_train: 0.6760
Parameter containing:
tensor([[ 0.0344, -0.0063, -0.1296,  ...,  0.0241,  0.3363, -0.0086],
        [ 0.0068,  0.0057, -0.0035,  ..., -0.0652, -0.0370,  0.0181],
        [ 0.1057, -0.0417,  0.2287,  ..., -0.0226,  0.0022,  0.0094],
        ...,
        [-0.0026, -0.0188,  0.1083,  ..., -0.0013, -0.0672,  0.0269],
        [-0.0265, -0.0275,  0.0275,  ..., -0.0254, -0.0238,  0.0191],
        [ 0.0109,  0.0121,  0.0108,  ...,  0.0035, -0.0170, -0.0082]],
       requires_grad=True)
Exponential sum:  tensor(10232.3271, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9651, 0.9651, 0.9651,  ..., 0.9964, 0.9964, 0.9964]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9651, 1.0000, 1.0000,  ..., 0.9986, 1.0000, 0.9964]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(8501.3711, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5322, 0.5322, 0.5322,  ..., 0.9995, 0.9995, 0.9995]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5322, 0.4065, 0.9899,  ..., 1.0000, 0.9997, 0.9995]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2484, 0.2499, 0.2494, 0.2523],
        [0.2492, 0.2501, 0.2499, 0.2507],
        ...,
        [0.2488, 0.2501, 0.2496, 0.2514],
        [0.2487, 0.2497, 0.2507, 0.2509],
        [0.2492, 0.2504, 0.2495, 0.2510]], grad_fn=<SoftmaxBackward0>)
Epoch: 0021 loss: 1.0668 acc_train: 0.6760
Parameter containing:
tensor([[ 2.7782e-02, -8.3082e-03, -1.2136e-01,  ...,  1.7849e-02,
          3.2720e-01, -9.6947e-03],
        [ 1.2797e-03,  3.5865e-03, -4.6166e-03,  ..., -5.7789e-02,
         -3.0255e-02,  1.5157e-02],
        [ 9.7719e-02, -3.4802e-02,  2.1985e-01,  ..., -1.6333e-02,
          7.0708e-03,  8.6511e-03],
        ...,
        [-2.1870e-03, -2.1944e-02,  1.0033e-01,  ..., -6.3000e-05,
         -5.9779e-02,  2.7868e-02],
        [-2.5339e-02, -2.6955e-02,  2.7115e-02,  ..., -2.7002e-02,
         -2.5888e-02,  1.6234e-02],
        [ 1.5056e-02,  8.7571e-03,  7.3553e-03,  ...,  1.2921e-03,
         -1.0956e-02, -1.2593e-02]], requires_grad=True)
Exponential sum:  tensor(10258.4570, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9686, 0.9686, 0.9686,  ..., 0.9975, 0.9975, 0.9975]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9686, 1.0000, 1.0000,  ..., 0.9985, 1.0000, 0.9975]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(8405.8857, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.4841, 0.4841, 0.4841,  ..., 0.9996, 0.9996, 0.9996]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.4841, 0.3626, 0.9922,  ..., 1.0000, 0.9997, 0.9996]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2489, 0.2499, 0.2493, 0.2518],
        [0.2493, 0.2502, 0.2501, 0.2504],
        ...,
        [0.2491, 0.2500, 0.2498, 0.2511],
        [0.2489, 0.2499, 0.2506, 0.2507],
        [0.2493, 0.2502, 0.2496, 0.2508]], grad_fn=<SoftmaxBackward0>)
Epoch: 0022 loss: 1.0622 acc_train: 0.6771
Parameter containing:
tensor([[ 0.0215, -0.0096, -0.1133,  ...,  0.0120,  0.3182, -0.0101],
        [-0.0037,  0.0013, -0.0050,  ..., -0.0507, -0.0239,  0.0120],
        [ 0.0900, -0.0283,  0.2112,  ..., -0.0105,  0.0115,  0.0073],
        ...,
        [-0.0011, -0.0244,  0.0925,  ...,  0.0011, -0.0526,  0.0282],
        [-0.0236, -0.0258,  0.0261,  ..., -0.0280, -0.0273,  0.0131],
        [ 0.0186,  0.0054,  0.0040,  ..., -0.0009, -0.0054, -0.0164]],
       requires_grad=True)
Exponential sum:  tensor(10279.8994, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9707, 0.9707, 0.9707,  ..., 0.9984, 0.9984, 0.9984]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9707, 1.0000, 1.0000,  ..., 0.9986, 1.0000, 0.9984]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(8360.4229, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.4654, 0.4654, 0.4654,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.4654, 0.3517, 0.9944,  ..., 1.0000, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2493, 0.2500, 0.2493, 0.2514],
        [0.2495, 0.2502, 0.2501, 0.2502],
        ...,
        [0.2493, 0.2499, 0.2500, 0.2508],
        [0.2491, 0.2499, 0.2504, 0.2506],
        [0.2494, 0.2501, 0.2498, 0.2506]], grad_fn=<SoftmaxBackward0>)
Epoch: 0023 loss: 1.0564 acc_train: 0.6771
Parameter containing:
tensor([[ 1.5589e-02, -1.0234e-02, -1.0550e-01,  ...,  6.4673e-03,
          3.0923e-01, -9.7760e-03],
        [-8.2797e-03, -8.5919e-04, -4.5891e-03,  ..., -4.3882e-02,
         -1.7883e-02,  8.7173e-03],
        [ 8.2425e-02, -2.2122e-02,  2.0262e-01,  ..., -5.0888e-03,
          1.5296e-02,  5.4408e-03],
        ...,
        [ 2.0736e-04, -2.6299e-02,  8.4967e-02,  ...,  1.7491e-03,
         -4.5776e-02,  2.7888e-02],
        [-2.1467e-02, -2.4203e-02,  2.4521e-02,  ..., -2.8290e-02,
         -2.8147e-02,  9.8824e-03],
        [ 2.1527e-02,  2.0764e-03,  7.3839e-04,  ..., -2.7940e-03,
         -2.6614e-04, -1.9706e-02]], requires_grad=True)
Exponential sum:  tensor(10298.4336, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9715, 0.9715, 0.9715,  ..., 0.9990, 0.9990, 0.9990]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9715, 1.0000, 1.0000,  ..., 0.9987, 1.0000, 0.9990]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(8319.6836, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.4713, 0.4713, 0.4713,  ..., 0.9999, 0.9999, 0.9999]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.4713, 0.3671, 0.9967,  ..., 1.0000, 0.9999, 0.9999]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2497, 0.2499, 0.2493, 0.2511],
        [0.2497, 0.2501, 0.2501, 0.2501],
        ...,
        [0.2496, 0.2497, 0.2501, 0.2506],
        [0.2492, 0.2500, 0.2504, 0.2505],
        [0.2495, 0.2501, 0.2500, 0.2504]], grad_fn=<SoftmaxBackward0>)
Epoch: 0024 loss: 1.0459 acc_train: 0.6883
Parameter containing:
tensor([[ 1.0073e-02, -1.0180e-02, -9.7884e-02,  ...,  1.4117e-03,
          3.0039e-01, -8.8611e-03],
        [-1.2316e-02, -2.7774e-03, -3.6330e-03,  ..., -3.7384e-02,
         -1.2265e-02,  5.4477e-03],
        [ 7.5127e-02, -1.6329e-02,  1.9420e-01,  ..., -1.1097e-04,
          1.8601e-02,  3.3552e-03],
        ...,
        [ 1.3349e-03, -2.7563e-02,  7.7628e-02,  ...,  1.6793e-03,
         -3.9224e-02,  2.7044e-02],
        [-1.8952e-02, -2.2139e-02,  2.2524e-02,  ..., -2.8044e-02,
         -2.8370e-02,  6.6014e-03],
        [ 2.3895e-02, -1.0003e-03, -2.2384e-03,  ..., -4.2340e-03,
          4.4020e-03, -2.2412e-02]], requires_grad=True)
Exponential sum:  tensor(10314.7178, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9714, 0.9714, 0.9714,  ..., 0.9995, 0.9995, 0.9995]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9714, 1.0000, 1.0000,  ..., 0.9990, 1.0000, 0.9995]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential sum:  tensor(8311.2510, grad_fn=<SumBackward0>)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.4967, 0.4967, 0.4967,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.4967, 0.4048, 0.9988,  ..., 1.0000, 0.9999, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo,
       grad_fn=<ToSparseBackward0>)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2499, 0.2498, 0.2495, 0.2508],
        [0.2499, 0.2500, 0.2500, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2493, 0.2500, 0.2503, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2502]], grad_fn=<SoftmaxBackward0>)
Epoch: 0025 loss: 1.0344 acc_train: 0.7061
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[343],
                       [  0]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.)
tensor(0.)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[465],
                       [  3]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[2177],
                       [   3]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[192],
                       [  3]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[1225],
                       [   1]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[1771],
                       [   1]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[2799],
                       [   3]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[2547],
                       [   1]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[365],
                       [  3]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[240],
                       [  1]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[2400],
                       [   3]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[971],
                       [  0]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[1390],
                       [   1]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
1
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[2524],
                       [   0]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[2253],
                       [   0]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.)
tensor(0.)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[757],
                       [  3]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[278],
                       [  0]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.)
tensor(0.)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[2818],
                       [   0]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.)
tensor(0.)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[352],
                       [  2]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[2892],
                       [   2]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[805],
                       [  0]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.)
tensor(0.)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[2736],
                       [   3]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[2645],
                       [   3]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[2543],
                       [   0]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.)
tensor(0.)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[1465],
                       [   2]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[326],
                       [  0]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.)
tensor(0.)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[2561],
                       [   0]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.)
tensor(0.)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[1613],
                       [   2]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[1570],
                       [   2]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[1543],
                       [   3]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[1372],
                       [   3]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[485],
                       [  1]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[482],
                       [  2]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
1
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[1501],
                       [   0]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[2238],
                       [   0]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.)
tensor(0.)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[1113],
                       [   0]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.)
tensor(0.)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[2567],
                       [   0]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.)
tensor(0.)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[2676],
                       [   2]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
n_smallest:                                                                         tensor_nodes  ...  pos_min_nodes
12 tensor(1390, device='cuda:7')  [tensor(0.), tensor(0.), tensor(0.), tensor(0....  ...            132
31 tensor(485, device='cuda:7')   [tensor(0.), tensor(0.), tensor(0.), tensor(0....  ...            485
29 tensor(1543, device='cuda:7')  [tensor(0.), tensor(0.), tensor(0.), tensor(0....  ...           1543

[3 rows x 5 columns]
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[1390],
                       [   1]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[352],
                       [  2]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[2676],
                       [   2]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[482],
                       [  2]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[485],
                       [  1]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[2547],
                       [   1]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[1390],
                       [   1]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[352],
                       [  2]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[2676],
                       [   2]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[482],
                       [  2]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[485],
                       [  1]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
Parameter containing:
tensor([[ 0.0050, -0.0095, -0.0905,  ..., -0.0032,  0.2916, -0.0075],
        [-0.0159, -0.0043, -0.0023,  ..., -0.0312, -0.0070,  0.0023],
        [ 0.0681, -0.0109,  0.1859,  ...,  0.0044,  0.0214,  0.0012],
        ...,
        [ 0.0019, -0.0283,  0.0705,  ...,  0.0010, -0.0330,  0.0257],
        [-0.0162, -0.0197,  0.0202,  ..., -0.0273, -0.0280,  0.0034],
        [ 0.0257, -0.0038, -0.0049,  ..., -0.0051,  0.0086, -0.0246]],
       requires_grad=True)
Exponential sum:  tensor(10329.6855)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.9713, 0.9713, 0.9713,  ..., 0.9998, 0.9998, 0.9998]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.9713, 1.0000, 1.0000,  ..., 0.9992, 0.9999, 0.9998]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Exponential sum:  tensor(8362.3711)
Softmax_output:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Resmat:  tensor(indices=tensor([[   0,    0,    0,  ...,   27,   27,   27],
                       [   1,    1,    1,  ..., 2652, 2652, 2652],
                       [   0,    1,    2,  ..., 2926, 2927, 2928]]),
       values=tensor([0.5338, 0.5338, 0.5338,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=15951334, layout=torch.sparse_coo)
Exponential:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([0.5338, 0.4595, 1.0000,  ..., 1.0000, 1.0000, 1.0000]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
Alpha3:  tensor(indices=tensor([[   0,    0,    0,  ...,   25,   26,   27],
                       [   1,    2,    4,  ...,  649, 1891, 2652],
                       [1594,  152,  461,  ...,  941, 1833, 2395]]),
       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
       size=(28, 2929, 2929), nnz=10430, layout=torch.sparse_coo)
tensor([[0.2500, 0.2500, 0.2500, 0.2500],
        [0.2501, 0.2497, 0.2496, 0.2506],
        [0.2500, 0.2500, 0.2499, 0.2501],
        ...,
        [0.2498, 0.2497, 0.2501, 0.2504],
        [0.2494, 0.2500, 0.2502, 0.2504],
        [0.2496, 0.2501, 0.2501, 0.2501]])
tensor(indices=tensor([[2547],
                       [   1]]),
       values=tensor([1.]),
       size=(2929, 4), nnz=1, layout=torch.sparse_coo)
tensor(0.2000)
tensor(0.2000)
count_nodes_self:  1
count_edges_self:  1
